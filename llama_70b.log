WARNING:root:Defaulting to PJRT_DEVICE=CPU
Using TT-Metal from the source tree: /root/tt-xla/third_party/tt-mlir/src/tt-mlir/third_party/tt-metal/src/tt-metal
WARNING: TT plugin is setting XLA_STABLEHLO_COMPILE to 1. This is required for TT PJRT plugin to work correctly.
============================= test session starts ==============================
platform linux -- Python 3.11.13, pytest-8.4.2, pluggy-1.6.0 -- /root/tt-xla/venv/bin/python
cachedir: .pytest_cache
rootdir: /root/tt-xla
configfile: pytest.ini
plugins: jaxtyping-0.3.3, anyio-4.11.0, split-0.10.0, forked-1.6.0
collecting ... Workaround to exclude model: suryaocr from discovery. Issue #1166
Cannot import path: /root/tt-xla/third_party/tt_forge_models/bevformer/pytorch/loader.py: No module named 'detectron2'
Cannot import path: /root/tt-xla/third_party/tt_forge_models/centernet/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
Cannot import path: /root/tt-xla/third_party/tt_forge_models/rcnn/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
Cannot import path: /root/tt-xla/third_party/tt_forge_models/ssr/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
Cannot import path: /root/tt-xla/third_party/tt_forge_models/vadv2/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
Cannot import path: /root/tt-xla/third_party/tt_forge_models/yolov10/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
Cannot import path: /root/tt-xla/third_party/tt_forge_models/yolov11/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
Cannot import path: /root/tt-xla/third_party/tt_forge_models/yolov4/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
Cannot import path: /root/tt-xla/third_party/tt_forge_models/yolov5/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
Cannot import path: /root/tt-xla/third_party/tt_forge_models/yolov6/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
Cannot import path: /root/tt-xla/third_party/tt_forge_models/yolov8/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
Cannot import path: /root/tt-xla/third_party/tt_forge_models/yolov9/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
Cannot import path: /root/tt-xla/third_party/tt_forge_models/yoloworld/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
collected 1 item

tests/runner/test_models.py::test_all_models[llama/causal_lm/pytorch-llama_3_1_70b-tensor_parallel-full-inference] Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]Fetching 30 files:   3%|▎         | 1/30 [02:02<59:01, 122.11s/it]Fetching 30 files: 100%|██████████| 30/30 [02:02<00:00,  4.07s/it]
Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 30/30 [00:00<00:00, 3109.73it/s]
Some weights of the model checkpoint at meta-llama/Meta-Llama-3.1-70B were not used when initializing LlamaForCausalLM: ['model.layers.1.input_layernorm.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.1.post_attention_layernorm.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.input_layernorm.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.10.post_attention_layernorm.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.input_layernorm.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.11.mlp.up_proj.weight', 'model.layers.11.post_attention_layernorm.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.input_layernorm.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.12.post_attention_layernorm.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.input_layernorm.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.13.post_attention_layernorm.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.14.input_layernorm.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.14.post_attention_layernorm.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.input_layernorm.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.15.mlp.gate_proj.weight', 'model.layers.15.mlp.up_proj.weight', 'model.layers.15.post_attention_layernorm.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.16.input_layernorm.weight', 'model.layers.16.mlp.down_proj.weight', 'model.layers.16.mlp.gate_proj.weight', 'model.layers.16.mlp.up_proj.weight', 'model.layers.16.post_attention_layernorm.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.17.input_layernorm.weight', 'model.layers.17.mlp.down_proj.weight', 'model.layers.17.mlp.gate_proj.weight', 'model.layers.17.mlp.up_proj.weight', 'model.layers.17.post_attention_layernorm.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.input_layernorm.weight', 'model.layers.18.mlp.down_proj.weight', 'model.layers.18.mlp.gate_proj.weight', 'model.layers.18.mlp.up_proj.weight', 'model.layers.18.post_attention_layernorm.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.19.input_layernorm.weight', 'model.layers.19.mlp.down_proj.weight', 'model.layers.19.mlp.gate_proj.weight', 'model.layers.19.mlp.up_proj.weight', 'model.layers.19.post_attention_layernorm.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.2.input_layernorm.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.2.post_attention_layernorm.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.20.input_layernorm.weight', 'model.layers.20.mlp.down_proj.weight', 'model.layers.20.mlp.gate_proj.weight', 'model.layers.20.mlp.up_proj.weight', 'model.layers.20.post_attention_layernorm.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.21.input_layernorm.weight', 'model.layers.21.mlp.down_proj.weight', 'model.layers.21.mlp.gate_proj.weight', 'model.layers.21.mlp.up_proj.weight', 'model.layers.21.post_attention_layernorm.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.input_layernorm.weight', 'model.layers.22.mlp.down_proj.weight', 'model.layers.22.mlp.gate_proj.weight', 'model.layers.22.mlp.up_proj.weight', 'model.layers.22.post_attention_layernorm.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.input_layernorm.weight', 'model.layers.23.mlp.down_proj.weight', 'model.layers.23.mlp.gate_proj.weight', 'model.layers.23.mlp.up_proj.weight', 'model.layers.23.post_attention_layernorm.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.24.input_layernorm.weight', 'model.layers.24.mlp.down_proj.weight', 'model.layers.24.mlp.gate_proj.weight', 'model.layers.24.mlp.up_proj.weight', 'model.layers.24.post_attention_layernorm.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.input_layernorm.weight', 'model.layers.25.mlp.down_proj.weight', 'model.layers.25.mlp.gate_proj.weight', 'model.layers.25.mlp.up_proj.weight', 'model.layers.25.post_attention_layernorm.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.input_layernorm.weight', 'model.layers.26.mlp.down_proj.weight', 'model.layers.26.mlp.gate_proj.weight', 'model.layers.26.mlp.up_proj.weight', 'model.layers.26.post_attention_layernorm.weight', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.27.input_layernorm.weight', 'model.layers.27.mlp.down_proj.weight', 'model.layers.27.mlp.gate_proj.weight', 'model.layers.27.mlp.up_proj.weight', 'model.layers.27.post_attention_layernorm.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.o_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.28.input_layernorm.weight', 'model.layers.28.mlp.down_proj.weight', 'model.layers.28.mlp.gate_proj.weight', 'model.layers.28.mlp.up_proj.weight', 'model.layers.28.post_attention_layernorm.weight', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.28.self_attn.o_proj.weight', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.29.input_layernorm.weight', 'model.layers.29.mlp.down_proj.weight', 'model.layers.29.mlp.gate_proj.weight', 'model.layers.29.mlp.up_proj.weight', 'model.layers.29.post_attention_layernorm.weight', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.o_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.3.input_layernorm.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.3.post_attention_layernorm.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.30.input_layernorm.weight', 'model.layers.30.mlp.down_proj.weight', 'model.layers.30.mlp.gate_proj.weight', 'model.layers.30.mlp.up_proj.weight', 'model.layers.30.post_attention_layernorm.weight', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.o_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.31.input_layernorm.weight', 'model.layers.31.mlp.down_proj.weight', 'model.layers.31.mlp.gate_proj.weight', 'model.layers.31.mlp.up_proj.weight', 'model.layers.31.post_attention_layernorm.weight', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.o_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.32.input_layernorm.weight', 'model.layers.32.mlp.down_proj.weight', 'model.layers.32.mlp.gate_proj.weight', 'model.layers.32.mlp.up_proj.weight', 'model.layers.32.post_attention_layernorm.weight', 'model.layers.32.self_attn.k_proj.weight', 'model.layers.32.self_attn.o_proj.weight', 'model.layers.32.self_attn.q_proj.weight', 'model.layers.32.self_attn.v_proj.weight', 'model.layers.33.input_layernorm.weight', 'model.layers.33.mlp.down_proj.weight', 'model.layers.33.mlp.gate_proj.weight', 'model.layers.33.mlp.up_proj.weight', 'model.layers.33.post_attention_layernorm.weight', 'model.layers.33.self_attn.k_proj.weight', 'model.layers.33.self_attn.o_proj.weight', 'model.layers.33.self_attn.q_proj.weight', 'model.layers.33.self_attn.v_proj.weight', 'model.layers.34.input_layernorm.weight', 'model.layers.34.mlp.down_proj.weight', 'model.layers.34.mlp.gate_proj.weight', 'model.layers.34.mlp.up_proj.weight', 'model.layers.34.post_attention_layernorm.weight', 'model.layers.34.self_attn.k_proj.weight', 'model.layers.34.self_attn.o_proj.weight', 'model.layers.34.self_attn.q_proj.weight', 'model.layers.34.self_attn.v_proj.weight', 'model.layers.35.input_layernorm.weight', 'model.layers.35.mlp.down_proj.weight', 'model.layers.35.mlp.gate_proj.weight', 'model.layers.35.mlp.up_proj.weight', 'model.layers.35.post_attention_layernorm.weight', 'model.layers.35.self_attn.k_proj.weight', 'model.layers.35.self_attn.o_proj.weight', 'model.layers.35.self_attn.q_proj.weight', 'model.layers.35.self_attn.v_proj.weight', 'model.layers.36.input_layernorm.weight', 'model.layers.36.mlp.down_proj.weight', 'model.layers.36.mlp.gate_proj.weight', 'model.layers.36.mlp.up_proj.weight', 'model.layers.36.post_attention_layernorm.weight', 'model.layers.36.self_attn.k_proj.weight', 'model.layers.36.self_attn.o_proj.weight', 'model.layers.36.self_attn.q_proj.weight', 'model.layers.36.self_attn.v_proj.weight', 'model.layers.37.input_layernorm.weight', 'model.layers.37.mlp.down_proj.weight', 'model.layers.37.mlp.gate_proj.weight', 'model.layers.37.mlp.up_proj.weight', 'model.layers.37.post_attention_layernorm.weight', 'model.layers.37.self_attn.k_proj.weight', 'model.layers.37.self_attn.o_proj.weight', 'model.layers.37.self_attn.q_proj.weight', 'model.layers.37.self_attn.v_proj.weight', 'model.layers.38.input_layernorm.weight', 'model.layers.38.mlp.down_proj.weight', 'model.layers.38.mlp.gate_proj.weight', 'model.layers.38.mlp.up_proj.weight', 'model.layers.38.post_attention_layernorm.weight', 'model.layers.38.self_attn.k_proj.weight', 'model.layers.38.self_attn.o_proj.weight', 'model.layers.38.self_attn.q_proj.weight', 'model.layers.38.self_attn.v_proj.weight', 'model.layers.39.input_layernorm.weight', 'model.layers.39.mlp.down_proj.weight', 'model.layers.39.mlp.gate_proj.weight', 'model.layers.39.mlp.up_proj.weight', 'model.layers.39.post_attention_layernorm.weight', 'model.layers.39.self_attn.k_proj.weight', 'model.layers.39.self_attn.o_proj.weight', 'model.layers.39.self_attn.q_proj.weight', 'model.layers.39.self_attn.v_proj.weight', 'model.layers.4.input_layernorm.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.4.post_attention_layernorm.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.40.input_layernorm.weight', 'model.layers.40.mlp.down_proj.weight', 'model.layers.40.mlp.gate_proj.weight', 'model.layers.40.mlp.up_proj.weight', 'model.layers.40.post_attention_layernorm.weight', 'model.layers.40.self_attn.k_proj.weight', 'model.layers.40.self_attn.o_proj.weight', 'model.layers.40.self_attn.q_proj.weight', 'model.layers.40.self_attn.v_proj.weight', 'model.layers.41.input_layernorm.weight', 'model.layers.41.mlp.down_proj.weight', 'model.layers.41.mlp.gate_proj.weight', 'model.layers.41.mlp.up_proj.weight', 'model.layers.41.post_attention_layernorm.weight', 'model.layers.41.self_attn.k_proj.weight', 'model.layers.41.self_attn.o_proj.weight', 'model.layers.41.self_attn.q_proj.weight', 'model.layers.41.self_attn.v_proj.weight', 'model.layers.42.input_layernorm.weight', 'model.layers.42.mlp.down_proj.weight', 'model.layers.42.mlp.gate_proj.weight', 'model.layers.42.mlp.up_proj.weight', 'model.layers.42.post_attention_layernorm.weight', 'model.layers.42.self_attn.k_proj.weight', 'model.layers.42.self_attn.o_proj.weight', 'model.layers.42.self_attn.q_proj.weight', 'model.layers.42.self_attn.v_proj.weight', 'model.layers.43.input_layernorm.weight', 'model.layers.43.mlp.down_proj.weight', 'model.layers.43.mlp.gate_proj.weight', 'model.layers.43.mlp.up_proj.weight', 'model.layers.43.post_attention_layernorm.weight', 'model.layers.43.self_attn.k_proj.weight', 'model.layers.43.self_attn.o_proj.weight', 'model.layers.43.self_attn.q_proj.weight', 'model.layers.43.self_attn.v_proj.weight', 'model.layers.44.input_layernorm.weight', 'model.layers.44.mlp.down_proj.weight', 'model.layers.44.mlp.gate_proj.weight', 'model.layers.44.mlp.up_proj.weight', 'model.layers.44.post_attention_layernorm.weight', 'model.layers.44.self_attn.k_proj.weight', 'model.layers.44.self_attn.o_proj.weight', 'model.layers.44.self_attn.q_proj.weight', 'model.layers.44.self_attn.v_proj.weight', 'model.layers.45.input_layernorm.weight', 'model.layers.45.mlp.down_proj.weight', 'model.layers.45.mlp.gate_proj.weight', 'model.layers.45.mlp.up_proj.weight', 'model.layers.45.post_attention_layernorm.weight', 'model.layers.45.self_attn.k_proj.weight', 'model.layers.45.self_attn.o_proj.weight', 'model.layers.45.self_attn.q_proj.weight', 'model.layers.45.self_attn.v_proj.weight', 'model.layers.46.input_layernorm.weight', 'model.layers.46.mlp.down_proj.weight', 'model.layers.46.mlp.gate_proj.weight', 'model.layers.46.mlp.up_proj.weight', 'model.layers.46.post_attention_layernorm.weight', 'model.layers.46.self_attn.k_proj.weight', 'model.layers.46.self_attn.o_proj.weight', 'model.layers.46.self_attn.q_proj.weight', 'model.layers.46.self_attn.v_proj.weight', 'model.layers.47.input_layernorm.weight', 'model.layers.47.mlp.down_proj.weight', 'model.layers.47.mlp.gate_proj.weight', 'model.layers.47.mlp.up_proj.weight', 'model.layers.47.post_attention_layernorm.weight', 'model.layers.47.self_attn.k_proj.weight', 'model.layers.47.self_attn.o_proj.weight', 'model.layers.47.self_attn.q_proj.weight', 'model.layers.47.self_attn.v_proj.weight', 'model.layers.48.input_layernorm.weight', 'model.layers.48.mlp.down_proj.weight', 'model.layers.48.mlp.gate_proj.weight', 'model.layers.48.mlp.up_proj.weight', 'model.layers.48.post_attention_layernorm.weight', 'model.layers.48.self_attn.k_proj.weight', 'model.layers.48.self_attn.o_proj.weight', 'model.layers.48.self_attn.q_proj.weight', 'model.layers.48.self_attn.v_proj.weight', 'model.layers.49.input_layernorm.weight', 'model.layers.49.mlp.down_proj.weight', 'model.layers.49.mlp.gate_proj.weight', 'model.layers.49.mlp.up_proj.weight', 'model.layers.49.post_attention_layernorm.weight', 'model.layers.49.self_attn.k_proj.weight', 'model.layers.49.self_attn.o_proj.weight', 'model.layers.49.self_attn.q_proj.weight', 'model.layers.49.self_attn.v_proj.weight', 'model.layers.5.input_layernorm.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.5.post_attention_layernorm.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.50.input_layernorm.weight', 'model.layers.50.mlp.down_proj.weight', 'model.layers.50.mlp.gate_proj.weight', 'model.layers.50.mlp.up_proj.weight', 'model.layers.50.post_attention_layernorm.weight', 'model.layers.50.self_attn.k_proj.weight', 'model.layers.50.self_attn.o_proj.weight', 'model.layers.50.self_attn.q_proj.weight', 'model.layers.50.self_attn.v_proj.weight', 'model.layers.51.input_layernorm.weight', 'model.layers.51.mlp.down_proj.weight', 'model.layers.51.mlp.gate_proj.weight', 'model.layers.51.mlp.up_proj.weight', 'model.layers.51.post_attention_layernorm.weight', 'model.layers.51.self_attn.k_proj.weight', 'model.layers.51.self_attn.o_proj.weight', 'model.layers.51.self_attn.q_proj.weight', 'model.layers.51.self_attn.v_proj.weight', 'model.layers.52.input_layernorm.weight', 'model.layers.52.mlp.down_proj.weight', 'model.layers.52.mlp.gate_proj.weight', 'model.layers.52.mlp.up_proj.weight', 'model.layers.52.post_attention_layernorm.weight', 'model.layers.52.self_attn.k_proj.weight', 'model.layers.52.self_attn.o_proj.weight', 'model.layers.52.self_attn.q_proj.weight', 'model.layers.52.self_attn.v_proj.weight', 'model.layers.53.input_layernorm.weight', 'model.layers.53.mlp.down_proj.weight', 'model.layers.53.mlp.gate_proj.weight', 'model.layers.53.mlp.up_proj.weight', 'model.layers.53.post_attention_layernorm.weight', 'model.layers.53.self_attn.k_proj.weight', 'model.layers.53.self_attn.o_proj.weight', 'model.layers.53.self_attn.q_proj.weight', 'model.layers.53.self_attn.v_proj.weight', 'model.layers.54.input_layernorm.weight', 'model.layers.54.mlp.down_proj.weight', 'model.layers.54.mlp.gate_proj.weight', 'model.layers.54.mlp.up_proj.weight', 'model.layers.54.post_attention_layernorm.weight', 'model.layers.54.self_attn.k_proj.weight', 'model.layers.54.self_attn.o_proj.weight', 'model.layers.54.self_attn.q_proj.weight', 'model.layers.54.self_attn.v_proj.weight', 'model.layers.55.input_layernorm.weight', 'model.layers.55.mlp.down_proj.weight', 'model.layers.55.mlp.gate_proj.weight', 'model.layers.55.mlp.up_proj.weight', 'model.layers.55.post_attention_layernorm.weight', 'model.layers.55.self_attn.k_proj.weight', 'model.layers.55.self_attn.o_proj.weight', 'model.layers.55.self_attn.q_proj.weight', 'model.layers.55.self_attn.v_proj.weight', 'model.layers.56.input_layernorm.weight', 'model.layers.56.mlp.down_proj.weight', 'model.layers.56.mlp.gate_proj.weight', 'model.layers.56.mlp.up_proj.weight', 'model.layers.56.post_attention_layernorm.weight', 'model.layers.56.self_attn.k_proj.weight', 'model.layers.56.self_attn.o_proj.weight', 'model.layers.56.self_attn.q_proj.weight', 'model.layers.56.self_attn.v_proj.weight', 'model.layers.57.input_layernorm.weight', 'model.layers.57.mlp.down_proj.weight', 'model.layers.57.mlp.gate_proj.weight', 'model.layers.57.mlp.up_proj.weight', 'model.layers.57.post_attention_layernorm.weight', 'model.layers.57.self_attn.k_proj.weight', 'model.layers.57.self_attn.o_proj.weight', 'model.layers.57.self_attn.q_proj.weight', 'model.layers.57.self_attn.v_proj.weight', 'model.layers.58.input_layernorm.weight', 'model.layers.58.mlp.down_proj.weight', 'model.layers.58.mlp.gate_proj.weight', 'model.layers.58.mlp.up_proj.weight', 'model.layers.58.post_attention_layernorm.weight', 'model.layers.58.self_attn.k_proj.weight', 'model.layers.58.self_attn.o_proj.weight', 'model.layers.58.self_attn.q_proj.weight', 'model.layers.58.self_attn.v_proj.weight', 'model.layers.59.input_layernorm.weight', 'model.layers.59.mlp.down_proj.weight', 'model.layers.59.mlp.gate_proj.weight', 'model.layers.59.mlp.up_proj.weight', 'model.layers.59.post_attention_layernorm.weight', 'model.layers.59.self_attn.k_proj.weight', 'model.layers.59.self_attn.o_proj.weight', 'model.layers.59.self_attn.q_proj.weight', 'model.layers.59.self_attn.v_proj.weight', 'model.layers.6.input_layernorm.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.6.post_attention_layernorm.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.60.input_layernorm.weight', 'model.layers.60.mlp.down_proj.weight', 'model.layers.60.mlp.gate_proj.weight', 'model.layers.60.mlp.up_proj.weight', 'model.layers.60.post_attention_layernorm.weight', 'model.layers.60.self_attn.k_proj.weight', 'model.layers.60.self_attn.o_proj.weight', 'model.layers.60.self_attn.q_proj.weight', 'model.layers.60.self_attn.v_proj.weight', 'model.layers.61.input_layernorm.weight', 'model.layers.61.mlp.down_proj.weight', 'model.layers.61.mlp.gate_proj.weight', 'model.layers.61.mlp.up_proj.weight', 'model.layers.61.post_attention_layernorm.weight', 'model.layers.61.self_attn.k_proj.weight', 'model.layers.61.self_attn.o_proj.weight', 'model.layers.61.self_attn.q_proj.weight', 'model.layers.61.self_attn.v_proj.weight', 'model.layers.62.input_layernorm.weight', 'model.layers.62.mlp.down_proj.weight', 'model.layers.62.mlp.gate_proj.weight', 'model.layers.62.mlp.up_proj.weight', 'model.layers.62.post_attention_layernorm.weight', 'model.layers.62.self_attn.k_proj.weight', 'model.layers.62.self_attn.o_proj.weight', 'model.layers.62.self_attn.q_proj.weight', 'model.layers.62.self_attn.v_proj.weight', 'model.layers.63.input_layernorm.weight', 'model.layers.63.mlp.down_proj.weight', 'model.layers.63.mlp.gate_proj.weight', 'model.layers.63.mlp.up_proj.weight', 'model.layers.63.post_attention_layernorm.weight', 'model.layers.63.self_attn.k_proj.weight', 'model.layers.63.self_attn.o_proj.weight', 'model.layers.63.self_attn.q_proj.weight', 'model.layers.63.self_attn.v_proj.weight', 'model.layers.64.input_layernorm.weight', 'model.layers.64.mlp.down_proj.weight', 'model.layers.64.mlp.gate_proj.weight', 'model.layers.64.mlp.up_proj.weight', 'model.layers.64.post_attention_layernorm.weight', 'model.layers.64.self_attn.k_proj.weight', 'model.layers.64.self_attn.o_proj.weight', 'model.layers.64.self_attn.q_proj.weight', 'model.layers.64.self_attn.v_proj.weight', 'model.layers.65.input_layernorm.weight', 'model.layers.65.mlp.down_proj.weight', 'model.layers.65.mlp.gate_proj.weight', 'model.layers.65.mlp.up_proj.weight', 'model.layers.65.post_attention_layernorm.weight', 'model.layers.65.self_attn.k_proj.weight', 'model.layers.65.self_attn.o_proj.weight', 'model.layers.65.self_attn.q_proj.weight', 'model.layers.65.self_attn.v_proj.weight', 'model.layers.66.input_layernorm.weight', 'model.layers.66.mlp.down_proj.weight', 'model.layers.66.mlp.gate_proj.weight', 'model.layers.66.mlp.up_proj.weight', 'model.layers.66.post_attention_layernorm.weight', 'model.layers.66.self_attn.k_proj.weight', 'model.layers.66.self_attn.o_proj.weight', 'model.layers.66.self_attn.q_proj.weight', 'model.layers.66.self_attn.v_proj.weight', 'model.layers.67.input_layernorm.weight', 'model.layers.67.mlp.down_proj.weight', 'model.layers.67.mlp.gate_proj.weight', 'model.layers.67.mlp.up_proj.weight', 'model.layers.67.post_attention_layernorm.weight', 'model.layers.67.self_attn.k_proj.weight', 'model.layers.67.self_attn.o_proj.weight', 'model.layers.67.self_attn.q_proj.weight', 'model.layers.67.self_attn.v_proj.weight', 'model.layers.68.input_layernorm.weight', 'model.layers.68.mlp.down_proj.weight', 'model.layers.68.mlp.gate_proj.weight', 'model.layers.68.mlp.up_proj.weight', 'model.layers.68.post_attention_layernorm.weight', 'model.layers.68.self_attn.k_proj.weight', 'model.layers.68.self_attn.o_proj.weight', 'model.layers.68.self_attn.q_proj.weight', 'model.layers.68.self_attn.v_proj.weight', 'model.layers.69.input_layernorm.weight', 'model.layers.69.mlp.down_proj.weight', 'model.layers.69.mlp.gate_proj.weight', 'model.layers.69.mlp.up_proj.weight', 'model.layers.69.post_attention_layernorm.weight', 'model.layers.69.self_attn.k_proj.weight', 'model.layers.69.self_attn.o_proj.weight', 'model.layers.69.self_attn.q_proj.weight', 'model.layers.69.self_attn.v_proj.weight', 'model.layers.7.input_layernorm.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.7.post_attention_layernorm.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.70.input_layernorm.weight', 'model.layers.70.mlp.down_proj.weight', 'model.layers.70.mlp.gate_proj.weight', 'model.layers.70.mlp.up_proj.weight', 'model.layers.70.post_attention_layernorm.weight', 'model.layers.70.self_attn.k_proj.weight', 'model.layers.70.self_attn.o_proj.weight', 'model.layers.70.self_attn.q_proj.weight', 'model.layers.70.self_attn.v_proj.weight', 'model.layers.71.input_layernorm.weight', 'model.layers.71.mlp.down_proj.weight', 'model.layers.71.mlp.gate_proj.weight', 'model.layers.71.mlp.up_proj.weight', 'model.layers.71.post_attention_layernorm.weight', 'model.layers.71.self_attn.k_proj.weight', 'model.layers.71.self_attn.o_proj.weight', 'model.layers.71.self_attn.q_proj.weight', 'model.layers.71.self_attn.v_proj.weight', 'model.layers.72.input_layernorm.weight', 'model.layers.72.mlp.down_proj.weight', 'model.layers.72.mlp.gate_proj.weight', 'model.layers.72.mlp.up_proj.weight', 'model.layers.72.post_attention_layernorm.weight', 'model.layers.72.self_attn.k_proj.weight', 'model.layers.72.self_attn.o_proj.weight', 'model.layers.72.self_attn.q_proj.weight', 'model.layers.72.self_attn.v_proj.weight', 'model.layers.73.input_layernorm.weight', 'model.layers.73.mlp.down_proj.weight', 'model.layers.73.mlp.gate_proj.weight', 'model.layers.73.mlp.up_proj.weight', 'model.layers.73.post_attention_layernorm.weight', 'model.layers.73.self_attn.k_proj.weight', 'model.layers.73.self_attn.o_proj.weight', 'model.layers.73.self_attn.q_proj.weight', 'model.layers.73.self_attn.v_proj.weight', 'model.layers.74.input_layernorm.weight', 'model.layers.74.mlp.down_proj.weight', 'model.layers.74.mlp.gate_proj.weight', 'model.layers.74.mlp.up_proj.weight', 'model.layers.74.post_attention_layernorm.weight', 'model.layers.74.self_attn.k_proj.weight', 'model.layers.74.self_attn.o_proj.weight', 'model.layers.74.self_attn.q_proj.weight', 'model.layers.74.self_attn.v_proj.weight', 'model.layers.75.input_layernorm.weight', 'model.layers.75.mlp.down_proj.weight', 'model.layers.75.mlp.gate_proj.weight', 'model.layers.75.mlp.up_proj.weight', 'model.layers.75.post_attention_layernorm.weight', 'model.layers.75.self_attn.k_proj.weight', 'model.layers.75.self_attn.o_proj.weight', 'model.layers.75.self_attn.q_proj.weight', 'model.layers.75.self_attn.v_proj.weight', 'model.layers.76.input_layernorm.weight', 'model.layers.76.mlp.down_proj.weight', 'model.layers.76.mlp.gate_proj.weight', 'model.layers.76.mlp.up_proj.weight', 'model.layers.76.post_attention_layernorm.weight', 'model.layers.76.self_attn.k_proj.weight', 'model.layers.76.self_attn.o_proj.weight', 'model.layers.76.self_attn.q_proj.weight', 'model.layers.76.self_attn.v_proj.weight', 'model.layers.77.input_layernorm.weight', 'model.layers.77.mlp.down_proj.weight', 'model.layers.77.mlp.gate_proj.weight', 'model.layers.77.mlp.up_proj.weight', 'model.layers.77.post_attention_layernorm.weight', 'model.layers.77.self_attn.k_proj.weight', 'model.layers.77.self_attn.o_proj.weight', 'model.layers.77.self_attn.q_proj.weight', 'model.layers.77.self_attn.v_proj.weight', 'model.layers.78.input_layernorm.weight', 'model.layers.78.mlp.down_proj.weight', 'model.layers.78.mlp.gate_proj.weight', 'model.layers.78.mlp.up_proj.weight', 'model.layers.78.post_attention_layernorm.weight', 'model.layers.78.self_attn.k_proj.weight', 'model.layers.78.self_attn.o_proj.weight', 'model.layers.78.self_attn.q_proj.weight', 'model.layers.78.self_attn.v_proj.weight', 'model.layers.79.input_layernorm.weight', 'model.layers.79.mlp.down_proj.weight', 'model.layers.79.mlp.gate_proj.weight', 'model.layers.79.mlp.up_proj.weight', 'model.layers.79.post_attention_layernorm.weight', 'model.layers.79.self_attn.k_proj.weight', 'model.layers.79.self_attn.o_proj.weight', 'model.layers.79.self_attn.q_proj.weight', 'model.layers.79.self_attn.v_proj.weight', 'model.layers.8.input_layernorm.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.8.post_attention_layernorm.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.9.input_layernorm.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.9.post_attention_layernorm.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.weight']
- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2025-10-27 21:33:55.151 (   0.000s) [        9C771B80]   plugin_attributes.cc:58       1| PluginAttributes::PJRT_Plugin_Initialize
2025-10-27 21:33:55.151 (   0.000s) [        9C771B80]     client_instance.cc:481      1| ClientInstance::PJRT_Client_Create
2025-10-27 21:33:55.158 (   0.006s) [        9C771B80]     client_instance.cc:44       1| ClientInstance::ClientInstance
2025-10-27 21:33:55.158 (   0.006s) [        9C771B80]     client_instance.cc:73       1| ClientInstance::Initialize
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]              stubs.inc:103   WARN| STUB: PJRT_Client_TopologyDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     client_instance.cc:529      1| ClientInstance::PJRT_Client_PlatformVersion
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     client_instance.cc:510      1| ClientInstance::PJRT_Client_PlatformName
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     client_instance.cc:540      1| ClientInstance::PJRT_Client_Devices
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     client_instance.cc:553      1| ClientInstance::PJRT_Client_AddressableDevices
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     client_instance.cc:603      1| ClientInstance::PJRT_Client_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.442 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]   plugin_attributes.cc:64       1| PluginAttributes::PJRT_Plugin_Attributes
2025-10-27 21:34:13.443171: W torch_xla/csrc/runtime/profiler.cpp:88] Profiler API not found for PJRT plugin
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.291s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.443 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:13.444 (  18.292s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.224 (  20.073s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.498 (  20.346s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.498 (  20.347s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.499 (  20.347s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.499 (  20.348s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.500 (  20.348s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.500 (  20.349s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.349s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.501 (  20.350s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.502 (  20.350s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.502 (  20.351s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.503 (  20.351s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.554 (  20.403s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.555 (  20.403s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.555 (  20.404s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.556 (  20.404s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.556 (  20.405s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.557 (  20.405s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.557 (  20.405s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.557 (  20.405s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.557 (  20.405s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.557 (  20.405s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.557 (  20.405s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.557 (  20.405s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.557 (  20.405s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.557 (  20.405s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.557 (  20.405s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.557 (  20.405s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.557 (  20.405s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.557 (  20.405s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.557 (  20.405s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.557 (  20.405s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.557 (  20.405s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.557 (  20.405s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.571 (  20.420s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.611 (  20.460s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.611 (  20.460s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.611 (  20.460s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.612 (  20.460s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.612 (  20.461s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.613 (  20.461s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.613 (  20.462s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.629 (  20.477s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.668 (  20.517s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.668 (  20.517s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.668 (  20.517s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.669 (  20.517s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.669 (  20.518s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.670 (  20.518s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.670 (  20.519s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.685 (  20.533s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.533s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.533s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.533s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.533s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.533s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.533s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.533s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.533s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.533s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.533s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.685 (  20.534s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.693 (  20.542s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.693 (  20.542s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.693 (  20.542s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.693 (  20.542s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.693 (  20.542s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.693 (  20.542s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.693 (  20.542s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.693 (  20.542s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.693 (  20.542s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.693 (  20.542s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.693 (  20.542s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.693 (  20.542s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.693 (  20.542s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.694 (  20.542s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.694 (  20.543s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.695 (  20.543s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.695 (  20.544s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.695 (  20.544s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.695 (  20.544s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.695 (  20.544s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.695 (  20.544s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.700 (  20.548s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.700 (  20.549s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.703 (  20.551s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.703 (  20.552s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.704 (  20.552s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.704 (  20.553s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.553s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.554s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.554s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.554s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.554s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.705 (  20.554s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.707 (  20.556s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.707 (  20.556s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.707 (  20.556s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.708 (  20.556s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.708 (  20.557s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.709 (  20.557s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.709 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.710 (  20.558s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.715 (  20.563s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.715 (  20.563s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.715 (  20.563s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.715 (  20.564s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.716 (  20.564s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.716 (  20.565s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:15.717 (  20.565s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:15.722 (  20.570s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:16.056 (  20.904s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.056 (  20.905s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.056 (  20.905s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.056 (  20.905s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.056 (  20.905s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.056 (  20.905s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.056 (  20.905s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.056 (  20.905s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.056 (  20.905s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.056 (  20.905s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.056 (  20.905s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.056 (  20.905s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.056 (  20.905s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.056 (  20.905s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.057 (  20.905s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.057 (  20.906s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.058 (  20.906s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.058 (  20.907s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:16.058 (  20.907s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:16.058 (  20.907s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:16.058 (  20.907s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:16.058 (  20.907s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:16.058 (  20.907s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.253s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.405 (  22.254s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.254s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.406 (  22.255s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.407 (  22.255s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.407 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.408 (  22.256s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.408 (  22.257s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.257s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.409 (  22.258s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:17.410 (  22.258s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.347 (  25.195s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.347 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.348 (  25.196s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.348 (  25.197s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.348 (  25.197s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.348 (  25.197s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.348 (  25.197s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.348 (  25.197s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.348 (  25.197s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.348 (  25.197s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.348 (  25.197s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.348 (  25.197s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.348 (  25.197s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.348 (  25.197s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.348 (  25.197s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.348 (  25.197s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.348 (  25.197s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.348 (  25.197s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.348 (  25.197s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.348 (  25.197s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.422 (  25.270s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.270s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.270s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.270s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.270s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.270s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.270s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.422 (  25.271s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.271s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.423 (  25.272s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]     client_instance.cc:659      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2025-10-27 21:34:20.424 (  25.272s) [        9C771B80]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.278s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.430 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.279s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.280s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.280s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.280s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.280s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.280s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.280s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.431 (  25.280s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.432 (  25.280s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.432 (  25.280s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.432 (  25.280s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:20.450 (  25.298s) [        9C771B80]     client_instance.cc:616      1| ClientInstance::PJRT_Client_Compile
2025-10-27 21:34:20.450 (  25.298s) [        9C771B80]      module_builder.cc:220      1| ModuleBuilder::buildModule
2025-10-27 21:34:20.451 (  25.300s) [        9C771B80]      module_builder.cc:963      1| MLIR Module vhlo:
#loc1 = loc("p0.1")
#loc2 = loc("p1.9")
#loc3 = loc("p2.14")
#loc4 = loc("p3.50")
#loc5 = loc("p4.70")
#loc6 = loc("p5.87")
#loc7 = loc("p6.116")
#loc8 = loc("p7.125")
#loc9 = loc("p8.130")
#loc10 = loc("p9.139")
#loc11 = loc("p10.212")
#loc12 = loc("p11.254")
#loc13 = loc("p12.348")
#loc14 = loc("p13.357")
#loc15 = loc("p14.403")
#loc31 = loc("reduce.30")
#loc129 = loc("reduce.294")
#loc134 = loc("reduce.303")
#loc159 = loc("reduce.328")
#loc196 = loc("reduce.383")
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1> loc("p0.1"), %arg1: !vhlo.tensor_v1<4x136x!vhlo.i64_v1> loc("p1.9"), %arg2: !vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1> loc("p2.14"), %arg3: !vhlo.tensor_v1<8192x!vhlo.bf16_v1> loc("p3.50"), %arg4: !vhlo.tensor_v1<64x!vhlo.f32_v1> loc("p4.70"), %arg5: !vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1> loc("p5.87"), %arg6: !vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1> loc("p6.116"), %arg7: !vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1> loc("p7.125"), %arg8: !vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1> loc("p8.130"), %arg9: !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1> loc("p9.139"), %arg10: !vhlo.tensor_v1<4x136x!vhlo.i64_v1> loc("p10.212"), %arg11: !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1> loc("p11.254"), %arg12: !vhlo.tensor_v1<8192x!vhlo.bf16_v1> loc("p12.348"), %arg13: !vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1> loc("p13.357"), %arg14: !vhlo.tensor_v1<8192x!vhlo.bf16_v1> loc("p14.403")) -> (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x128256x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<"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tensor<136xi64>>}> : () -> !vhlo.tensor_v1<136x!vhlo.i64_v1> loc(#loc)
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %4 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<1.22070313E-4> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %5 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<9.99999974E-6> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %6 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>>}> : () -> !vhlo.tensor_v1<1x1x136x!vhlo.f32_v1> loc(#loc)
    %7 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<8.837890e-02> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1> loc(#loc)
    %8 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<1> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1> loc(#loc)
    %9 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1> loc(#loc)
    %10 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<-3.389530e+38> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1> loc(#loc)
    %11 = "vhlo.broadcast_in_dim_v1"(%10) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1> loc(#loc)
    %12 = "vhlo.broadcast_in_dim_v1"(%9) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1> loc(#loc)
    %13 = "vhlo.broadcast_in_dim_v1"(%9) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bf16_v1> loc(#loc)
    %14 = "vhlo.broadcast_in_dim_v1"(%10) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bf16_v1> loc(#loc)
    %15 = "vhlo.broadcast_in_dim_v1"(%8) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.i64_v1> loc(#loc)
    %16 = "vhlo.broadcast_in_dim_v1"(%7) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1> loc(#loc)
    %17 = "vhlo.broadcast_in_dim_v1"(%5) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1> loc(#loc)
    %18 = "vhlo.broadcast_in_dim_v1"(%4) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1> loc(#loc)
    %19 = "vhlo.broadcast_in_dim_v1"(%3) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1> loc(#loc)
    %20 = "vhlo.reshape_v1"(%arg3) : (!vhlo.tensor_v1<8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1> loc(#loc16)
    %21 = "vhlo.custom_call_v1"(%20) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___input_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1> loc(#loc17)
    %22 = "vhlo.reshape_v1"(%21) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x!vhlo.bf16_v1> loc(#loc18)
    %23 = "vhlo.broadcast_in_dim_v1"(%22) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1> loc(#loc19)
    %24 = "vhlo.reshape_v1"(%arg2) : (!vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1> loc(#loc20)
    %25 = "vhlo.custom_call_v1"(%24) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_embed_tokens_weight">}>} : (!vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1> loc(#loc21)
    %26 = "vhlo.reshape_v1"(%25) : (!vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1> loc(#loc22)
    %27 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x4x136x!vhlo.i64_v1> loc(#loc23)
    %28 = "vhlo.custom_call_v1"(%27) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x4x136x!vhlo.i64_v1> loc(#loc24)
    %29 = "vhlo.reshape_v1"(%28) : (!vhlo.tensor_v1<1x4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<544x!vhlo.i64_v1> loc(#loc25)
    %30 = "vhlo.convert_v1"(%29) : (!vhlo.tensor_v1<544x!vhlo.i64_v1>) -> !vhlo.tensor_v1<544x!vhlo.ui32_v1> loc(#loc26)
    %31 = "vhlo.gather_v2"(%26, %30) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 8192]> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<544x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1> loc(#loc27)
    %32 = "vhlo.reshape_v1"(%31) : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1> loc(#loc28)
    %33 = "vhlo.convert_v1"(%32) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1> loc(#loc29)
    %34 = "vhlo.power_v1"(%33, %19) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1> loc(#loc30)
    %35 = "vhlo.reduce_v1"(%34, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg15: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.30"), %arg16: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.30")):
      %213 = "vhlo.add_v1"(%arg15, %arg16) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc32)
      "vhlo.return_v1"(%213) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1> loc(#loc31)
    %36 = "vhlo.multiply_v1"(%35, %18) : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1> loc(#loc33)
    %37 = "vhlo.reshape_v1"(%36) : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1> loc(#loc34)
    %38 = "vhlo.add_v1"(%37, %17) : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1> loc(#loc35)
    %39 = "vhlo.rsqrt_v2"(%38) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1> loc(#loc36)
    %40 = "vhlo.reshape_v1"(%39) : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1> loc(#loc37)
    %41 = "vhlo.broadcast_in_dim_v1"(%40) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1> loc(#loc38)
    %42 = "vhlo.multiply_v1"(%33, %41) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1> loc(#loc39)
    %43 = "vhlo.convert_v1"(%42) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1> loc(#loc40)
    %44 = "vhlo.multiply_v1"(%23, %43) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1> loc(#loc41)
    %45 = "vhlo.reshape_v1"(%44) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1> loc(#loc42)
    %46 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1> loc(#loc43)
    %47 = "vhlo.custom_call_v1"(%46) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_v_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1> loc(#loc44)
    %48 = "vhlo.reshape_v1"(%47) : (!vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1> loc(#loc45)
    %49 = "vhlo.transpose_v1"(%48) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,1024]{0,1}">} : (!vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x1024x!vhlo.bf16_v1> loc(#loc46)
    %50 = "vhlo.dot_general_v2"(%45, %49) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x1024x!vhlo.bf16_v1> loc(#loc47)
    %51 = "vhlo.reshape_v1"(%50) : (!vhlo.tensor_v1<544x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8x128x!vhlo.bf16_v1> loc(#loc48)
    %52 = "vhlo.transpose_v1"(%51) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[4,8,136,128]{3,1,2,0}">} : (!vhlo.tensor_v1<4x136x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1> loc(#loc49)
    %53 = "vhlo.reshape_v1"(%arg5) : (!vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1> loc(#loc50)
    %54 = "vhlo.custom_call_v1"(%53) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_k_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1> loc(#loc51)
    %55 = "vhlo.reshape_v1"(%54) : (!vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1> loc(#loc52)
    %56 = "vhlo.transpose_v1"(%55) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,1024]{0,1}">} : (!vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x1024x!vhlo.bf16_v1> loc(#loc53)
    %57 = "vhlo.dot_general_v2"(%45, %56) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x1024x!vhlo.bf16_v1> loc(#loc54)
    %58 = "vhlo.reshape_v1"(%57) : (!vhlo.tensor_v1<544x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8x128x!vhlo.bf16_v1> loc(#loc55)
    %59 = "vhlo.transpose_v1"(%58) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[4,8,136,128]{3,1,2,0}">} : (!vhlo.tensor_v1<4x136x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1> loc(#loc56)
    %60 = "vhlo.reshape_v1"(%arg4) : (!vhlo.tensor_v1<64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1> loc(#loc57)
    %61 = "vhlo.custom_call_v1"(%60) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"constant">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_rotary_emb_inv_freq">}>} : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1> loc(#loc58)
    %62 = "vhlo.reshape_v1"(%61) : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1> loc(#loc59)
    %63 = "vhlo.dot_general_v2"(%62, %6) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x136x!vhlo.f32_v1> loc(#loc60)
    %64 = "vhlo.transpose_v1"(%63) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1]> : tensor<3xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[1, 2, 0]> : tensor<3xindex>>, xla_shape = #vhlo.string_v1<"f32[1,136,64]{1,2,0}">} : (!vhlo.tensor_v1<1x64x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x136x64x!vhlo.f32_v1> loc(#loc61)
    %65 = "vhlo.concatenate_v1"(%64, %64) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<1x136x64x!vhlo.f32_v1>, !vhlo.tensor_v1<1x136x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x136x128x!vhlo.f32_v1> loc(#loc62)
    %66 = "vhlo.cosine_v2"(%65) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x136x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x136x128x!vhlo.f32_v1> loc(#loc63)
    %67 = "vhlo.convert_v1"(%66) : (!vhlo.tensor_v1<1x136x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x136x128x!vhlo.bf16_v1> loc(#loc64)
    %68 = "vhlo.reshape_v1"(%67) : (!vhlo.tensor_v1<1x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<136x128x!vhlo.bf16_v1> loc(#loc65)
    %69 = "vhlo.broadcast_in_dim_v1"(%68) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1> loc(#loc66)
    %70 = "vhlo.multiply_v1"(%59, %69) : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1> loc(#loc67)
    %71 = "vhlo.slice_v1"(%59) <{limit_indices = #vhlo.tensor_v1<dense<[4, 8, 136, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x64x!vhlo.bf16_v1> loc(#loc68)
    %72 = "vhlo.negate_v1"(%71) : (!vhlo.tensor_v1<4x8x136x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x64x!vhlo.bf16_v1> loc(#loc69)
    %73 = "vhlo.slice_v1"(%59) <{limit_indices = #vhlo.tensor_v1<dense<[4, 8, 136, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x64x!vhlo.bf16_v1> loc(#loc70)
    %74 = "vhlo.concatenate_v1"(%72, %73) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<4x8x136x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x8x136x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1> loc(#loc71)
    %75 = "vhlo.sine_v2"(%65) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x136x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x136x128x!vhlo.f32_v1> loc(#loc72)
    %76 = "vhlo.convert_v1"(%75) : (!vhlo.tensor_v1<1x136x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x136x128x!vhlo.bf16_v1> loc(#loc73)
    %77 = "vhlo.reshape_v1"(%76) : (!vhlo.tensor_v1<1x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<136x128x!vhlo.bf16_v1> loc(#loc74)
    %78 = "vhlo.broadcast_in_dim_v1"(%77) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1> loc(#loc75)
    %79 = "vhlo.multiply_v1"(%74, %78) : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1> loc(#loc76)
    %80 = "vhlo.add_v1"(%70, %79) : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1> loc(#loc77)
    %81 = "vhlo.reshape_v1"(%arg14) : (!vhlo.tensor_v1<8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1> loc(#loc78)
    %82 = "vhlo.custom_call_v1"(%81) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_norm_weight">}>} : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1> loc(#loc79)
    %83 = "vhlo.reshape_v1"(%82) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x!vhlo.bf16_v1> loc(#loc80)
    %84 = "vhlo.broadcast_in_dim_v1"(%83) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1> loc(#loc81)
    %85 = "vhlo.reshape_v1"(%arg11) : (!vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1> loc(#loc82)
    %86 = "vhlo.custom_call_v1"(%85) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_q_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1> loc(#loc83)
    %87 = "vhlo.reshape_v1"(%86) : (!vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1> loc(#loc84)
    %88 = "vhlo.transpose_v1"(%87) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,8192]{0,1}">} : (!vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1> loc(#loc85)
    %89 = "vhlo.dot_general_v2"(%45, %88) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1> loc(#loc86)
    %90 = "vhlo.reshape_v1"(%89) : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x64x128x!vhlo.bf16_v1> loc(#loc87)
    %91 = "vhlo.transpose_v1"(%90) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[4,64,136,128]{3,1,2,0}">} : (!vhlo.tensor_v1<4x136x64x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1> loc(#loc88)
    %92 = "vhlo.broadcast_in_dim_v1"(%68) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1> loc(#loc89)
    %93 = "vhlo.multiply_v1"(%91, %92) : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1> loc(#loc90)
    %94 = "vhlo.slice_v1"(%91) <{limit_indices = #vhlo.tensor_v1<dense<[4, 64, 136, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x64x!vhlo.bf16_v1> loc(#loc91)
    %95 = "vhlo.negate_v1"(%94) : (!vhlo.tensor_v1<4x64x136x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x64x!vhlo.bf16_v1> loc(#loc92)
    %96 = "vhlo.slice_v1"(%91) <{limit_indices = #vhlo.tensor_v1<dense<[4, 64, 136, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x64x!vhlo.bf16_v1> loc(#loc93)
    %97 = "vhlo.concatenate_v1"(%95, %96) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<4x64x136x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x64x136x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1> loc(#loc94)
    %98 = "vhlo.broadcast_in_dim_v1"(%77) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1> loc(#loc95)
    %99 = "vhlo.multiply_v1"(%97, %98) : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1> loc(#loc96)
    %100 = "vhlo.add_v1"(%93, %99) : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1> loc(#loc97)
    %101 = "vhlo.reshape_v1"(%100) : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<256x136x128x!vhlo.bf16_v1> loc(#loc98)
    %102 = "vhlo.broadcast_in_dim_v1"(%80) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x8x136x128x!vhlo.bf16_v1> loc(#loc99)
    %103 = "vhlo.reshape_v1"(%102) : (!vhlo.tensor_v1<4x8x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1> loc(#loc100)
    %104 = "vhlo.transpose_v1"(%103) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[4,64,128,136]{2,3,1,0}">} : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x128x136x!vhlo.bf16_v1> loc(#loc101)
    %105 = "vhlo.reshape_v1"(%104) : (!vhlo.tensor_v1<4x64x128x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<256x128x136x!vhlo.bf16_v1> loc(#loc102)
    %106 = "vhlo.dot_general_v2"(%101, %105) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<256x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<256x128x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<256x136x136x!vhlo.bf16_v1> loc(#loc103)
    %107 = "vhlo.reshape_v1"(%106) : (!vhlo.tensor_v1<256x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1> loc(#loc104)
    %108 = "vhlo.multiply_v1"(%107, %16) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1> loc(#loc105)
    %109 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>}> : (!vhlo.tensor_v1<136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.i64_v1> loc(#loc106)
    %110 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.i64_v1> loc(#loc107)
    %111 = "vhlo.subtract_v1"(%109, %110) : (!vhlo.tensor_v1<136x136x!vhlo.i64_v1>, !vhlo.tensor_v1<136x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.i64_v1> loc(#loc108)
    %112 = "vhlo.compare_v1"(%111, %15) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GE>}> : (!vhlo.tensor_v1<136x136x!vhlo.i64_v1>, !vhlo.tensor_v1<136x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bool_v1> loc(#loc109)
    %113 = "vhlo.select_v1"(%112, %14, %13) : (!vhlo.tensor_v1<136x136x!vhlo.bool_v1>, !vhlo.tensor_v1<136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bf16_v1> loc(#loc110)
    %114 = "vhlo.compare_v1"(%109, %110) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GT>}> : (!vhlo.tensor_v1<136x136x!vhlo.i64_v1>, !vhlo.tensor_v1<136x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bool_v1> loc(#loc111)
    %115 = "vhlo.convert_v1"(%114) : (!vhlo.tensor_v1<136x136x!vhlo.bool_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bf16_v1> loc(#loc112)
    %116 = "vhlo.multiply_v1"(%113, %115) : (!vhlo.tensor_v1<136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bf16_v1> loc(#loc113)
    %117 = "vhlo.reshape_v1"(%116) : (!vhlo.tensor_v1<136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x136x136x!vhlo.bf16_v1> loc(#loc114)
    %118 = "vhlo.broadcast_in_dim_v1"(%117) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[1, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1> loc(#loc115)
    %119 = "vhlo.reshape_v1"(%arg10) : (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x4x136x!vhlo.i64_v1> loc(#loc116)
    %120 = "vhlo.custom_call_v1"(%119) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_1">}>} : (!vhlo.tensor_v1<1x4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x4x136x!vhlo.i64_v1> loc(#loc117)
    %121 = "vhlo.reshape_v1"(%120) : (!vhlo.tensor_v1<1x4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x1x1x136x!vhlo.i64_v1> loc(#loc118)
    %122 = "vhlo.convert_v1"(%121) : (!vhlo.tensor_v1<4x1x1x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x1x1x136x!vhlo.bf16_v1> loc(#loc119)
    %123 = "vhlo.reshape_v1"(%122) : (!vhlo.tensor_v1<4x1x1x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x!vhlo.bf16_v1> loc(#loc120)
    %124 = "vhlo.broadcast_in_dim_v1"(%123) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<4x1x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1> loc(#loc121)
    %125 = "vhlo.add_v1"(%118, %124) : (!vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1> loc(#loc122)
    %126 = "vhlo.compare_v1"(%125, %12) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 EQ>}> : (!vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bool_v1> loc(#loc123)
    %127 = "vhlo.select_v1"(%126, %11, %118) : (!vhlo.tensor_v1<4x1x136x136x!vhlo.bool_v1>, !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1> loc(#loc124)
    %128 = "vhlo.reshape_v1"(%127) : (!vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x136x!vhlo.bf16_v1> loc(#loc125)
    %129 = "vhlo.broadcast_in_dim_v1"(%128) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<4x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1> loc(#loc126)
    %130 = "vhlo.add_v1"(%108, %129) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1> loc(#loc127)
    %131 = "vhlo.convert_v1"(%130) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1> loc(#loc128)
    %132 = "vhlo.reduce_v1"(%131, %2) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg15: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.294"), %arg16: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.294")):
      %213 = "vhlo.maximum_v1"(%arg15, %arg16) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc130)
      "vhlo.return_v1"(%213) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x!vhlo.f32_v1> loc(#loc129)
    %133 = "vhlo.broadcast_in_dim_v1"(%132) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<4x64x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1> loc(#loc131)
    %134 = "vhlo.subtract_v1"(%131, %133) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>, !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1> loc(#loc132)
    %135 = "vhlo.exponential_v2"(%134) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1> loc(#loc133)
    %136 = "vhlo.reduce_v1"(%135, %0) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg15: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.303"), %arg16: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.303")):
      %213 = "vhlo.add_v1"(%arg15, %arg16) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc135)
      "vhlo.return_v1"(%213) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x!vhlo.f32_v1> loc(#loc134)
    %137 = "vhlo.broadcast_in_dim_v1"(%136) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<4x64x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1> loc(#loc136)
    %138 = "vhlo.divide_v1"(%135, %137) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>, !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1> loc(#loc137)
    %139 = "vhlo.convert_v1"(%138) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1> loc(#loc138)
    %140 = "vhlo.reshape_v1"(%139) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<256x136x136x!vhlo.bf16_v1> loc(#loc139)
    %141 = "vhlo.broadcast_in_dim_v1"(%52) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x8x136x128x!vhlo.bf16_v1> loc(#loc140)
    %142 = "vhlo.reshape_v1"(%141) : (!vhlo.tensor_v1<4x8x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<256x136x128x!vhlo.bf16_v1> loc(#loc141)
    %143 = "vhlo.dot_general_v2"(%140, %142) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<256x136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<256x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<256x136x128x!vhlo.bf16_v1> loc(#loc142)
    %144 = "vhlo.reshape_v1"(%143) : (!vhlo.tensor_v1<256x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1> loc(#loc143)
    %145 = "vhlo.transpose_v1"(%144) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[4,136,64,128]{3,1,2,0}">} : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x64x128x!vhlo.bf16_v1> loc(#loc144)
    %146 = "vhlo.reshape_v1"(%145) : (!vhlo.tensor_v1<4x136x64x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1> loc(#loc145)
    %147 = "vhlo.reshape_v1"(%arg9) : (!vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1> loc(#loc146)
    %148 = "vhlo.custom_call_v1"(%147) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_o_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1> loc(#loc147)
    %149 = "vhlo.reshape_v1"(%148) : (!vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1> loc(#loc148)
    %150 = "vhlo.transpose_v1"(%149) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,8192]{0,1}">} : (!vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1> loc(#loc149)
    %151 = "vhlo.dot_general_v2"(%146, %150) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1> loc(#loc150)
    %152 = "vhlo.reshape_v1"(%151) : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1> loc(#loc151)
    %153 = "vhlo.add_v1"(%32, %152) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1> loc(#loc152)
    %154 = "vhlo.reshape_v1"(%arg12) : (!vhlo.tensor_v1<8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1> loc(#loc153)
    %155 = "vhlo.custom_call_v1"(%154) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___post_attention_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1> loc(#loc154)
    %156 = "vhlo.reshape_v1"(%155) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x!vhlo.bf16_v1> loc(#loc155)
    %157 = "vhlo.broadcast_in_dim_v1"(%156) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1> loc(#loc156)
    %158 = "vhlo.convert_v1"(%153) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1> loc(#loc157)
    %159 = "vhlo.power_v1"(%158, %19) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1> loc(#loc158)
    %160 = "vhlo.reduce_v1"(%159, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg15: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.328"), %arg16: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.328")):
      %213 = "vhlo.add_v1"(%arg15, %arg16) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc160)
      "vhlo.return_v1"(%213) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1> loc(#loc159)
    %161 = "vhlo.multiply_v1"(%160, %18) : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1> loc(#loc161)
    %162 = "vhlo.reshape_v1"(%161) : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1> loc(#loc162)
    %163 = "vhlo.add_v1"(%162, %17) : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1> loc(#loc163)
    %164 = "vhlo.rsqrt_v2"(%163) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1> loc(#loc164)
    %165 = "vhlo.reshape_v1"(%164) : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1> loc(#loc165)
    %166 = "vhlo.broadcast_in_dim_v1"(%165) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1> loc(#loc166)
    %167 = "vhlo.multiply_v1"(%158, %166) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1> loc(#loc167)
    %168 = "vhlo.convert_v1"(%167) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1> loc(#loc168)
    %169 = "vhlo.multiply_v1"(%157, %168) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1> loc(#loc169)
    %170 = "vhlo.reshape_v1"(%169) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1> loc(#loc170)
    %171 = "vhlo.reshape_v1"(%arg13) : (!vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1> loc(#loc171)
    %172 = "vhlo.custom_call_v1"(%171) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_gate_proj_weight">}>} : (!vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1> loc(#loc172)
    %173 = "vhlo.reshape_v1"(%172) : (!vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1> loc(#loc173)
    %174 = "vhlo.transpose_v1"(%173) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,28672]{0,1}">} : (!vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1> loc(#loc174)
    %175 = "vhlo.dot_general_v2"(%170, %174) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x28672x!vhlo.bf16_v1> loc(#loc175)
    %176 = "vhlo.reshape_v1"(%175) : (!vhlo.tensor_v1<544x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1> loc(#loc176)
    %177 = "vhlo.logistic_v2"(%176) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1> loc(#loc177)
    %178 = "vhlo.multiply_v1"(%176, %177) : (!vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1> loc(#loc178)
    %179 = "vhlo.reshape_v1"(%arg8) : (!vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1> loc(#loc179)
    %180 = "vhlo.custom_call_v1"(%179) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_up_proj_weight">}>} : (!vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1> loc(#loc180)
    %181 = "vhlo.reshape_v1"(%180) : (!vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1> loc(#loc181)
    %182 = "vhlo.transpose_v1"(%181) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,28672]{0,1}">} : (!vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1> loc(#loc182)
    %183 = "vhlo.dot_general_v2"(%170, %182) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x28672x!vhlo.bf16_v1> loc(#loc183)
    %184 = "vhlo.reshape_v1"(%183) : (!vhlo.tensor_v1<544x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1> loc(#loc184)
    %185 = "vhlo.multiply_v1"(%178, %184) : (!vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1> loc(#loc185)
    %186 = "vhlo.reshape_v1"(%185) : (!vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x28672x!vhlo.bf16_v1> loc(#loc186)
    %187 = "vhlo.reshape_v1"(%arg7) : (!vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x28672x!vhlo.bf16_v1> loc(#loc187)
    %188 = "vhlo.custom_call_v1"(%187) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_down_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x28672x!vhlo.bf16_v1> loc(#loc188)
    %189 = "vhlo.reshape_v1"(%188) : (!vhlo.tensor_v1<1x8192x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1> loc(#loc189)
    %190 = "vhlo.transpose_v1"(%189) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[28672,8192]{0,1}">} : (!vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1> loc(#loc190)
    %191 = "vhlo.dot_general_v2"(%186, %190) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x28672x!vhlo.bf16_v1>, !vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1> loc(#loc191)
    %192 = "vhlo.reshape_v1"(%191) : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1> loc(#loc192)
    %193 = "vhlo.add_v1"(%153, %192) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1> loc(#loc193)
    %194 = "vhlo.convert_v1"(%193) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1> loc(#loc194)
    %195 = "vhlo.power_v1"(%194, %19) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1> loc(#loc195)
    %196 = "vhlo.reduce_v1"(%195, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg15: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.383"), %arg16: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.383")):
      %213 = "vhlo.add_v1"(%arg15, %arg16) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc197)
      "vhlo.return_v1"(%213) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1> loc(#loc196)
    %197 = "vhlo.multiply_v1"(%196, %18) : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1> loc(#loc198)
    %198 = "vhlo.reshape_v1"(%197) : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1> loc(#loc199)
    %199 = "vhlo.add_v1"(%198, %17) : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1> loc(#loc200)
    %200 = "vhlo.rsqrt_v2"(%199) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1> loc(#loc201)
    %201 = "vhlo.reshape_v1"(%200) : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1> loc(#loc202)
    %202 = "vhlo.broadcast_in_dim_v1"(%201) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1> loc(#loc203)
    %203 = "vhlo.multiply_v1"(%194, %202) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1> loc(#loc204)
    %204 = "vhlo.convert_v1"(%203) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1> loc(#loc205)
    %205 = "vhlo.multiply_v1"(%84, %204) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1> loc(#loc206)
    %206 = "vhlo.reshape_v1"(%205) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1> loc(#loc207)
    %207 = "vhlo.reshape_v1"(%arg6) : (!vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1> loc(#loc208)
    %208 = "vhlo.custom_call_v1"(%207) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___lm_head_weight">}>} : (!vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1> loc(#loc209)
    %209 = "vhlo.reshape_v1"(%208) : (!vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1> loc(#loc210)
    %210 = "vhlo.transpose_v1"(%209) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,128256]{0,1}">} : (!vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x128256x!vhlo.bf16_v1> loc(#loc211)
    %211 = "vhlo.dot_general_v2"(%206, %210) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x128256x!vhlo.bf16_v1> loc(#loc212)
    %212 = "vhlo.reshape_v1"(%211) : (!vhlo.tensor_v1<544x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x128256x!vhlo.bf16_v1> loc(#loc213)
    "vhlo.return_v1"(%52, %80, %212) : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x128256x!vhlo.bf16_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[8,4]<=[32]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[8,4]<=[32]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[8,4]<=[32]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,8]<=[8,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[8,4]<=[32]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,8]<=[8,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[8,4]<=[32]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[8,4]<=[32]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc16 = loc("reshape.51")
#loc17 = loc("custom-call.52")
#loc18 = loc("reshape.53")
#loc19 = loc("broadcast.54")
#loc20 = loc("reshape.15")
#loc21 = loc("custom-call.16")
#loc22 = loc("reshape.17")
#loc23 = loc("reshape.10")
#loc24 = loc("custom-call.11")
#loc25 = loc("reshape.13")
#loc26 = loc("convert.18")
#loc27 = loc("gather.19")
#loc28 = loc("reshape.20")
#loc29 = loc("convert.21")
#loc30 = loc("power.23")
#loc32 = loc("add.29")
#loc33 = loc("multiply.39")
#loc34 = loc("reshape.40")
#loc35 = loc("add.44")
#loc36 = loc("rsqrt.45")
#loc37 = loc("reshape.46")
#loc38 = loc("broadcast.47")
#loc39 = loc("multiply.48")
#loc40 = loc("convert.49")
#loc41 = loc("multiply.55")
#loc42 = loc("reshape.56")
#loc43 = loc("reshape.2")
#loc44 = loc("custom-call.3")
#loc45 = loc("reshape.4")
#loc46 = loc("transpose.5")
#loc47 = loc("dot.57")
#loc48 = loc("reshape.59")
#loc49 = loc("transpose.60")
#loc50 = loc("reshape.88")
#loc51 = loc("custom-call.89")
#loc52 = loc("reshape.90")
#loc53 = loc("transpose.91")
#loc54 = loc("dot.93")
#loc55 = loc("reshape.95")
#loc56 = loc("transpose.96")
#loc57 = loc("reshape.71")
#loc58 = loc("custom-call.72")
#loc59 = loc("reshape.76")
#loc60 = loc("dot.79")
#loc61 = loc("transpose.80")
#loc62 = loc("concatenate.81")
#loc63 = loc("cosine.105")
#loc64 = loc("convert.108")
#loc65 = loc("reshape.110")
#loc66 = loc("broadcast.111")
#loc67 = loc("multiply.112")
#loc68 = loc("slice.98")
#loc69 = loc("negate.99")
#loc70 = loc("slice.97")
#loc71 = loc("concatenate.100")
#loc72 = loc("sine.82")
#loc73 = loc("convert.85")
#loc74 = loc("reshape.101")
#loc75 = loc("broadcast.102")
#loc76 = loc("multiply.103")
#loc77 = loc("add.115")
#loc78 = loc("reshape.404")
#loc79 = loc("custom-call.405")
#loc80 = loc("reshape.406")
#loc81 = loc("broadcast.407")
#loc82 = loc("reshape.255")
#loc83 = loc("custom-call.256")
#loc84 = loc("reshape.257")
#loc85 = loc("transpose.258")
#loc86 = loc("dot.260")
#loc87 = loc("reshape.262")
#loc88 = loc("transpose.263")
#loc89 = loc("broadcast.272")
#loc90 = loc("multiply.273")
#loc91 = loc("slice.265")
#loc92 = loc("negate.266")
#loc93 = loc("slice.264")
#loc94 = loc("concatenate.267")
#loc95 = loc("broadcast.269")
#loc96 = loc("multiply.270")
#loc97 = loc("add.276")
#loc98 = loc("reshape.278")
#loc99 = loc("broadcast.248")
#loc100 = loc("reshape.249")
#loc101 = loc("transpose.250")
#loc102 = loc("reshape.252")
#loc103 = loc("dot.279")
#loc104 = loc("reshape.280")
#loc105 = loc("multiply.282")
#loc106 = loc("broadcast.184")
#loc107 = loc("broadcast.186")
#loc108 = loc("subtract.187")
#loc109 = loc("compare.189")
#loc110 = loc("select.191")
#loc111 = loc("compare.161")
#loc112 = loc("convert.162")
#loc113 = loc("multiply.192")
#loc114 = loc("reshape.193")
#loc115 = loc("broadcast.199")
#loc116 = loc("reshape.213")
#loc117 = loc("custom-call.214")
#loc118 = loc("reshape.218")
#loc119 = loc("convert.223")
#loc120 = loc("reshape.226")
#loc121 = loc("broadcast.227")
#loc122 = loc("add.228")
#loc123 = loc("compare.231")
#loc124 = loc("select.233")
#loc125 = loc("reshape.285")
#loc126 = loc("broadcast.286")
#loc127 = loc("add.287")
#loc128 = loc("convert.288")
#loc130 = loc("maximum.293")
#loc131 = loc("broadcast.295")
#loc132 = loc("subtract.296")
#loc133 = loc("exponential.297")
#loc135 = loc("add.302")
#loc136 = loc("broadcast.304")
#loc137 = loc("divide.305")
#loc138 = loc("convert.306")
#loc139 = loc("reshape.308")
#loc140 = loc("broadcast.151")
#loc141 = loc("reshape.154")
#loc142 = loc("dot.309")
#loc143 = loc("reshape.310")
#loc144 = loc("transpose.311")
#loc145 = loc("reshape.313")
#loc146 = loc("reshape.140")
#loc147 = loc("custom-call.141")
#loc148 = loc("reshape.142")
#loc149 = loc("transpose.143")
#loc150 = loc("dot.314")
#loc151 = loc("reshape.315")
#loc152 = loc("add.318")
#loc153 = loc("reshape.349")
#loc154 = loc("custom-call.350")
#loc155 = loc("reshape.351")
#loc156 = loc("broadcast.352")
#loc157 = loc("convert.319")
#loc158 = loc("power.321")
#loc160 = loc("add.327")
#loc161 = loc("multiply.337")
#loc162 = loc("reshape.338")
#loc163 = loc("add.342")
#loc164 = loc("rsqrt.343")
#loc165 = loc("reshape.344")
#loc166 = loc("broadcast.345")
#loc167 = loc("multiply.346")
#loc168 = loc("convert.347")
#loc169 = loc("multiply.353")
#loc170 = loc("reshape.362")
#loc171 = loc("reshape.358")
#loc172 = loc("custom-call.359")
#loc173 = loc("reshape.360")
#loc174 = loc("transpose.361")
#loc175 = loc("dot.363")
#loc176 = loc("reshape.364")
#loc177 = loc("logistic.365")
#loc178 = loc("multiply.366")
#loc179 = loc("reshape.131")
#loc180 = loc("custom-call.132")
#loc181 = loc("reshape.133")
#loc182 = loc("transpose.134")
#loc183 = loc("dot.355")
#loc184 = loc("reshape.356")
#loc185 = loc("multiply.367")
#loc186 = loc("reshape.368")
#loc187 = loc("reshape.126")
#loc188 = loc("custom-call.127")
#loc189 = loc("reshape.128")
#loc190 = loc("transpose.129")
#loc191 = loc("dot.369")
#loc192 = loc("reshape.370")
#loc193 = loc("add.373")
#loc194 = loc("convert.374")
#loc195 = loc("power.376")
#loc197 = loc("add.382")
#loc198 = loc("multiply.392")
#loc199 = loc("reshape.393")
#loc200 = loc("add.397")
#loc201 = loc("rsqrt.398")
#loc202 = loc("reshape.399")
#loc203 = loc("broadcast.400")
#loc204 = loc("multiply.401")
#loc205 = loc("convert.402")
#loc206 = loc("multiply.408")
#loc207 = loc("reshape.412")
#loc208 = loc("reshape.117")
#loc209 = loc("custom-call.118")
#loc210 = loc("reshape.119")
#loc211 = loc("transpose.120")
#loc212 = loc("dot.413")
#loc213 = loc("reshape.414")
------------------ END OF MLIR MODULE ------------------
// -----// IR Dump Before VhloToVersionPass (vhlo-to-version) ('builtin.module' operation: @SyncTensorsGraph.416) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1>, %arg1: !vhlo.tensor_v1<4x136x!vhlo.i64_v1>, %arg2: !vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1>, %arg3: !vhlo.tensor_v1<8192x!vhlo.bf16_v1>, %arg4: !vhlo.tensor_v1<64x!vhlo.f32_v1>, %arg5: !vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1>, %arg6: !vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1>, %arg7: !vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1>, %arg8: !vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>, %arg9: !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>, %arg10: !vhlo.tensor_v1<4x136x!vhlo.i64_v1>, %arg11: !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>, %arg12: !vhlo.tensor_v1<8192x!vhlo.bf16_v1>, %arg13: !vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>, %arg14: !vhlo.tensor_v1<8192x!vhlo.bf16_v1>) -> (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x128256x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<"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tensor<136xi64>>}> : () -> !vhlo.tensor_v1<136x!vhlo.i64_v1>
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %4 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<1.22070313E-4> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %5 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<9.99999974E-6> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %6 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>>}> : () -> !vhlo.tensor_v1<1x1x136x!vhlo.f32_v1>
    %7 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<8.837890e-02> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1>
    %8 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<1> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1>
    %9 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1>
    %10 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<-3.389530e+38> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1>
    %11 = "vhlo.broadcast_in_dim_v1"(%10) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>
    %12 = "vhlo.broadcast_in_dim_v1"(%9) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>
    %13 = "vhlo.broadcast_in_dim_v1"(%9) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bf16_v1>
    %14 = "vhlo.broadcast_in_dim_v1"(%10) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bf16_v1>
    %15 = "vhlo.broadcast_in_dim_v1"(%8) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.i64_v1>
    %16 = "vhlo.broadcast_in_dim_v1"(%7) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>
    %17 = "vhlo.broadcast_in_dim_v1"(%5) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>
    %18 = "vhlo.broadcast_in_dim_v1"(%4) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1>
    %19 = "vhlo.broadcast_in_dim_v1"(%3) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %20 = "vhlo.reshape_v1"(%arg3) : (!vhlo.tensor_v1<8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %21 = "vhlo.custom_call_v1"(%20) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___input_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %22 = "vhlo.reshape_v1"(%21) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x!vhlo.bf16_v1>
    %23 = "vhlo.broadcast_in_dim_v1"(%22) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %24 = "vhlo.reshape_v1"(%arg2) : (!vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1>
    %25 = "vhlo.custom_call_v1"(%24) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_embed_tokens_weight">}>} : (!vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1>
    %26 = "vhlo.reshape_v1"(%25) : (!vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1>
    %27 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x4x136x!vhlo.i64_v1>
    %28 = "vhlo.custom_call_v1"(%27) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x4x136x!vhlo.i64_v1>
    %29 = "vhlo.reshape_v1"(%28) : (!vhlo.tensor_v1<1x4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<544x!vhlo.i64_v1>
    %30 = "vhlo.convert_v1"(%29) : (!vhlo.tensor_v1<544x!vhlo.i64_v1>) -> !vhlo.tensor_v1<544x!vhlo.ui32_v1>
    %31 = "vhlo.gather_v2"(%26, %30) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 8192]> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<544x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>
    %32 = "vhlo.reshape_v1"(%31) : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %33 = "vhlo.convert_v1"(%32) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %34 = "vhlo.power_v1"(%33, %19) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %35 = "vhlo.reduce_v1"(%34, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg15: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg16: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %213 = "vhlo.add_v1"(%arg15, %arg16) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%213) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1>
    %36 = "vhlo.multiply_v1"(%35, %18) : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1>
    %37 = "vhlo.reshape_v1"(%36) : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>
    %38 = "vhlo.add_v1"(%37, %17) : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>
    %39 = "vhlo.rsqrt_v2"(%38) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>
    %40 = "vhlo.reshape_v1"(%39) : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1>
    %41 = "vhlo.broadcast_in_dim_v1"(%40) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %42 = "vhlo.multiply_v1"(%33, %41) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %43 = "vhlo.convert_v1"(%42) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %44 = "vhlo.multiply_v1"(%23, %43) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %45 = "vhlo.reshape_v1"(%44) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>
    %46 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1>
    %47 = "vhlo.custom_call_v1"(%46) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_v_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1>
    %48 = "vhlo.reshape_v1"(%47) : (!vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1>
    %49 = "vhlo.transpose_v1"(%48) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,1024]{0,1}">} : (!vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x1024x!vhlo.bf16_v1>
    %50 = "vhlo.dot_general_v2"(%45, %49) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x1024x!vhlo.bf16_v1>
    %51 = "vhlo.reshape_v1"(%50) : (!vhlo.tensor_v1<544x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8x128x!vhlo.bf16_v1>
    %52 = "vhlo.transpose_v1"(%51) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[4,8,136,128]{3,1,2,0}">} : (!vhlo.tensor_v1<4x136x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>
    %53 = "vhlo.reshape_v1"(%arg5) : (!vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1>
    %54 = "vhlo.custom_call_v1"(%53) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_k_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1>
    %55 = "vhlo.reshape_v1"(%54) : (!vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1>
    %56 = "vhlo.transpose_v1"(%55) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,1024]{0,1}">} : (!vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x1024x!vhlo.bf16_v1>
    %57 = "vhlo.dot_general_v2"(%45, %56) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x1024x!vhlo.bf16_v1>
    %58 = "vhlo.reshape_v1"(%57) : (!vhlo.tensor_v1<544x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8x128x!vhlo.bf16_v1>
    %59 = "vhlo.transpose_v1"(%58) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[4,8,136,128]{3,1,2,0}">} : (!vhlo.tensor_v1<4x136x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>
    %60 = "vhlo.reshape_v1"(%arg4) : (!vhlo.tensor_v1<64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>
    %61 = "vhlo.custom_call_v1"(%60) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"constant">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_rotary_emb_inv_freq">}>} : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>
    %62 = "vhlo.reshape_v1"(%61) : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>
    %63 = "vhlo.dot_general_v2"(%62, %6) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x136x!vhlo.f32_v1>
    %64 = "vhlo.transpose_v1"(%63) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1]> : tensor<3xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[1, 2, 0]> : tensor<3xindex>>, xla_shape = #vhlo.string_v1<"f32[1,136,64]{1,2,0}">} : (!vhlo.tensor_v1<1x64x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x136x64x!vhlo.f32_v1>
    %65 = "vhlo.concatenate_v1"(%64, %64) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<1x136x64x!vhlo.f32_v1>, !vhlo.tensor_v1<1x136x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x136x128x!vhlo.f32_v1>
    %66 = "vhlo.cosine_v2"(%65) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x136x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x136x128x!vhlo.f32_v1>
    %67 = "vhlo.convert_v1"(%66) : (!vhlo.tensor_v1<1x136x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x136x128x!vhlo.bf16_v1>
    %68 = "vhlo.reshape_v1"(%67) : (!vhlo.tensor_v1<1x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<136x128x!vhlo.bf16_v1>
    %69 = "vhlo.broadcast_in_dim_v1"(%68) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>
    %70 = "vhlo.multiply_v1"(%59, %69) : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>
    %71 = "vhlo.slice_v1"(%59) <{limit_indices = #vhlo.tensor_v1<dense<[4, 8, 136, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x64x!vhlo.bf16_v1>
    %72 = "vhlo.negate_v1"(%71) : (!vhlo.tensor_v1<4x8x136x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x64x!vhlo.bf16_v1>
    %73 = "vhlo.slice_v1"(%59) <{limit_indices = #vhlo.tensor_v1<dense<[4, 8, 136, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x64x!vhlo.bf16_v1>
    %74 = "vhlo.concatenate_v1"(%72, %73) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<4x8x136x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x8x136x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>
    %75 = "vhlo.sine_v2"(%65) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x136x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x136x128x!vhlo.f32_v1>
    %76 = "vhlo.convert_v1"(%75) : (!vhlo.tensor_v1<1x136x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x136x128x!vhlo.bf16_v1>
    %77 = "vhlo.reshape_v1"(%76) : (!vhlo.tensor_v1<1x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<136x128x!vhlo.bf16_v1>
    %78 = "vhlo.broadcast_in_dim_v1"(%77) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>
    %79 = "vhlo.multiply_v1"(%74, %78) : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>
    %80 = "vhlo.add_v1"(%70, %79) : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>
    %81 = "vhlo.reshape_v1"(%arg14) : (!vhlo.tensor_v1<8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %82 = "vhlo.custom_call_v1"(%81) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_norm_weight">}>} : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %83 = "vhlo.reshape_v1"(%82) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x!vhlo.bf16_v1>
    %84 = "vhlo.broadcast_in_dim_v1"(%83) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %85 = "vhlo.reshape_v1"(%arg11) : (!vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1>
    %86 = "vhlo.custom_call_v1"(%85) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_q_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1>
    %87 = "vhlo.reshape_v1"(%86) : (!vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>
    %88 = "vhlo.transpose_v1"(%87) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,8192]{0,1}">} : (!vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>
    %89 = "vhlo.dot_general_v2"(%45, %88) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>
    %90 = "vhlo.reshape_v1"(%89) : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x64x128x!vhlo.bf16_v1>
    %91 = "vhlo.transpose_v1"(%90) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[4,64,136,128]{3,1,2,0}">} : (!vhlo.tensor_v1<4x136x64x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>
    %92 = "vhlo.broadcast_in_dim_v1"(%68) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>
    %93 = "vhlo.multiply_v1"(%91, %92) : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>
    %94 = "vhlo.slice_v1"(%91) <{limit_indices = #vhlo.tensor_v1<dense<[4, 64, 136, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x64x!vhlo.bf16_v1>
    %95 = "vhlo.negate_v1"(%94) : (!vhlo.tensor_v1<4x64x136x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x64x!vhlo.bf16_v1>
    %96 = "vhlo.slice_v1"(%91) <{limit_indices = #vhlo.tensor_v1<dense<[4, 64, 136, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x64x!vhlo.bf16_v1>
    %97 = "vhlo.concatenate_v1"(%95, %96) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<4x64x136x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x64x136x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>
    %98 = "vhlo.broadcast_in_dim_v1"(%77) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>
    %99 = "vhlo.multiply_v1"(%97, %98) : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>
    %100 = "vhlo.add_v1"(%93, %99) : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>
    %101 = "vhlo.reshape_v1"(%100) : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<256x136x128x!vhlo.bf16_v1>
    %102 = "vhlo.broadcast_in_dim_v1"(%80) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x8x136x128x!vhlo.bf16_v1>
    %103 = "vhlo.reshape_v1"(%102) : (!vhlo.tensor_v1<4x8x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>
    %104 = "vhlo.transpose_v1"(%103) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[4,64,128,136]{2,3,1,0}">} : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x128x136x!vhlo.bf16_v1>
    %105 = "vhlo.reshape_v1"(%104) : (!vhlo.tensor_v1<4x64x128x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<256x128x136x!vhlo.bf16_v1>
    %106 = "vhlo.dot_general_v2"(%101, %105) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<256x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<256x128x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<256x136x136x!vhlo.bf16_v1>
    %107 = "vhlo.reshape_v1"(%106) : (!vhlo.tensor_v1<256x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>
    %108 = "vhlo.multiply_v1"(%107, %16) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>
    %109 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>}> : (!vhlo.tensor_v1<136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.i64_v1>
    %110 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.i64_v1>
    %111 = "vhlo.subtract_v1"(%109, %110) : (!vhlo.tensor_v1<136x136x!vhlo.i64_v1>, !vhlo.tensor_v1<136x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.i64_v1>
    %112 = "vhlo.compare_v1"(%111, %15) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GE>}> : (!vhlo.tensor_v1<136x136x!vhlo.i64_v1>, !vhlo.tensor_v1<136x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bool_v1>
    %113 = "vhlo.select_v1"(%112, %14, %13) : (!vhlo.tensor_v1<136x136x!vhlo.bool_v1>, !vhlo.tensor_v1<136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bf16_v1>
    %114 = "vhlo.compare_v1"(%109, %110) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GT>}> : (!vhlo.tensor_v1<136x136x!vhlo.i64_v1>, !vhlo.tensor_v1<136x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bool_v1>
    %115 = "vhlo.convert_v1"(%114) : (!vhlo.tensor_v1<136x136x!vhlo.bool_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bf16_v1>
    %116 = "vhlo.multiply_v1"(%113, %115) : (!vhlo.tensor_v1<136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bf16_v1>
    %117 = "vhlo.reshape_v1"(%116) : (!vhlo.tensor_v1<136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x136x136x!vhlo.bf16_v1>
    %118 = "vhlo.broadcast_in_dim_v1"(%117) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[1, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>
    %119 = "vhlo.reshape_v1"(%arg10) : (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x4x136x!vhlo.i64_v1>
    %120 = "vhlo.custom_call_v1"(%119) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_1">}>} : (!vhlo.tensor_v1<1x4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x4x136x!vhlo.i64_v1>
    %121 = "vhlo.reshape_v1"(%120) : (!vhlo.tensor_v1<1x4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x1x1x136x!vhlo.i64_v1>
    %122 = "vhlo.convert_v1"(%121) : (!vhlo.tensor_v1<4x1x1x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x1x1x136x!vhlo.bf16_v1>
    %123 = "vhlo.reshape_v1"(%122) : (!vhlo.tensor_v1<4x1x1x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x!vhlo.bf16_v1>
    %124 = "vhlo.broadcast_in_dim_v1"(%123) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<4x1x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>
    %125 = "vhlo.add_v1"(%118, %124) : (!vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>
    %126 = "vhlo.compare_v1"(%125, %12) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 EQ>}> : (!vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bool_v1>
    %127 = "vhlo.select_v1"(%126, %11, %118) : (!vhlo.tensor_v1<4x1x136x136x!vhlo.bool_v1>, !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>
    %128 = "vhlo.reshape_v1"(%127) : (!vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x136x!vhlo.bf16_v1>
    %129 = "vhlo.broadcast_in_dim_v1"(%128) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<4x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>
    %130 = "vhlo.add_v1"(%108, %129) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>
    %131 = "vhlo.convert_v1"(%130) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>
    %132 = "vhlo.reduce_v1"(%131, %2) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg15: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg16: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %213 = "vhlo.maximum_v1"(%arg15, %arg16) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%213) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x!vhlo.f32_v1>
    %133 = "vhlo.broadcast_in_dim_v1"(%132) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<4x64x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>
    %134 = "vhlo.subtract_v1"(%131, %133) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>, !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>
    %135 = "vhlo.exponential_v2"(%134) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>
    %136 = "vhlo.reduce_v1"(%135, %0) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg15: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg16: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %213 = "vhlo.add_v1"(%arg15, %arg16) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%213) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x!vhlo.f32_v1>
    %137 = "vhlo.broadcast_in_dim_v1"(%136) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<4x64x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>
    %138 = "vhlo.divide_v1"(%135, %137) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>, !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>
    %139 = "vhlo.convert_v1"(%138) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>
    %140 = "vhlo.reshape_v1"(%139) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<256x136x136x!vhlo.bf16_v1>
    %141 = "vhlo.broadcast_in_dim_v1"(%52) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x8x136x128x!vhlo.bf16_v1>
    %142 = "vhlo.reshape_v1"(%141) : (!vhlo.tensor_v1<4x8x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<256x136x128x!vhlo.bf16_v1>
    %143 = "vhlo.dot_general_v2"(%140, %142) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<256x136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<256x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<256x136x128x!vhlo.bf16_v1>
    %144 = "vhlo.reshape_v1"(%143) : (!vhlo.tensor_v1<256x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>
    %145 = "vhlo.transpose_v1"(%144) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[4,136,64,128]{3,1,2,0}">} : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x64x128x!vhlo.bf16_v1>
    %146 = "vhlo.reshape_v1"(%145) : (!vhlo.tensor_v1<4x136x64x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>
    %147 = "vhlo.reshape_v1"(%arg9) : (!vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1>
    %148 = "vhlo.custom_call_v1"(%147) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_o_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1>
    %149 = "vhlo.reshape_v1"(%148) : (!vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>
    %150 = "vhlo.transpose_v1"(%149) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,8192]{0,1}">} : (!vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>
    %151 = "vhlo.dot_general_v2"(%146, %150) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>
    %152 = "vhlo.reshape_v1"(%151) : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %153 = "vhlo.add_v1"(%32, %152) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %154 = "vhlo.reshape_v1"(%arg12) : (!vhlo.tensor_v1<8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %155 = "vhlo.custom_call_v1"(%154) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___post_attention_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %156 = "vhlo.reshape_v1"(%155) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x!vhlo.bf16_v1>
    %157 = "vhlo.broadcast_in_dim_v1"(%156) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %158 = "vhlo.convert_v1"(%153) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %159 = "vhlo.power_v1"(%158, %19) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %160 = "vhlo.reduce_v1"(%159, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg15: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg16: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %213 = "vhlo.add_v1"(%arg15, %arg16) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%213) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1>
    %161 = "vhlo.multiply_v1"(%160, %18) : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1>
    %162 = "vhlo.reshape_v1"(%161) : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>
    %163 = "vhlo.add_v1"(%162, %17) : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>
    %164 = "vhlo.rsqrt_v2"(%163) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>
    %165 = "vhlo.reshape_v1"(%164) : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1>
    %166 = "vhlo.broadcast_in_dim_v1"(%165) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %167 = "vhlo.multiply_v1"(%158, %166) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %168 = "vhlo.convert_v1"(%167) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %169 = "vhlo.multiply_v1"(%157, %168) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %170 = "vhlo.reshape_v1"(%169) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>
    %171 = "vhlo.reshape_v1"(%arg13) : (!vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1>
    %172 = "vhlo.custom_call_v1"(%171) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_gate_proj_weight">}>} : (!vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1>
    %173 = "vhlo.reshape_v1"(%172) : (!vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>
    %174 = "vhlo.transpose_v1"(%173) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,28672]{0,1}">} : (!vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1>
    %175 = "vhlo.dot_general_v2"(%170, %174) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x28672x!vhlo.bf16_v1>
    %176 = "vhlo.reshape_v1"(%175) : (!vhlo.tensor_v1<544x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>
    %177 = "vhlo.logistic_v2"(%176) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>
    %178 = "vhlo.multiply_v1"(%176, %177) : (!vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>
    %179 = "vhlo.reshape_v1"(%arg8) : (!vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1>
    %180 = "vhlo.custom_call_v1"(%179) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_up_proj_weight">}>} : (!vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1>
    %181 = "vhlo.reshape_v1"(%180) : (!vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>
    %182 = "vhlo.transpose_v1"(%181) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,28672]{0,1}">} : (!vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1>
    %183 = "vhlo.dot_general_v2"(%170, %182) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x28672x!vhlo.bf16_v1>
    %184 = "vhlo.reshape_v1"(%183) : (!vhlo.tensor_v1<544x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>
    %185 = "vhlo.multiply_v1"(%178, %184) : (!vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>
    %186 = "vhlo.reshape_v1"(%185) : (!vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x28672x!vhlo.bf16_v1>
    %187 = "vhlo.reshape_v1"(%arg7) : (!vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x28672x!vhlo.bf16_v1>
    %188 = "vhlo.custom_call_v1"(%187) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_down_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x28672x!vhlo.bf16_v1>
    %189 = "vhlo.reshape_v1"(%188) : (!vhlo.tensor_v1<1x8192x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1>
    %190 = "vhlo.transpose_v1"(%189) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[28672,8192]{0,1}">} : (!vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>
    %191 = "vhlo.dot_general_v2"(%186, %190) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x28672x!vhlo.bf16_v1>, !vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>
    %192 = "vhlo.reshape_v1"(%191) : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %193 = "vhlo.add_v1"(%153, %192) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %194 = "vhlo.convert_v1"(%193) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %195 = "vhlo.power_v1"(%194, %19) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %196 = "vhlo.reduce_v1"(%195, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg15: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg16: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %213 = "vhlo.add_v1"(%arg15, %arg16) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%213) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1>
    %197 = "vhlo.multiply_v1"(%196, %18) : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1>
    %198 = "vhlo.reshape_v1"(%197) : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>
    %199 = "vhlo.add_v1"(%198, %17) : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>
    %200 = "vhlo.rsqrt_v2"(%199) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>
    %201 = "vhlo.reshape_v1"(%200) : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1>
    %202 = "vhlo.broadcast_in_dim_v1"(%201) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %203 = "vhlo.multiply_v1"(%194, %202) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %204 = "vhlo.convert_v1"(%203) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %205 = "vhlo.multiply_v1"(%84, %204) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %206 = "vhlo.reshape_v1"(%205) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>
    %207 = "vhlo.reshape_v1"(%arg6) : (!vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1>
    %208 = "vhlo.custom_call_v1"(%207) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___lm_head_weight">}>} : (!vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1>
    %209 = "vhlo.reshape_v1"(%208) : (!vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1>
    %210 = "vhlo.transpose_v1"(%209) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,128256]{0,1}">} : (!vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x128256x!vhlo.bf16_v1>
    %211 = "vhlo.dot_general_v2"(%206, %210) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x128256x!vhlo.bf16_v1>
    %212 = "vhlo.reshape_v1"(%211) : (!vhlo.tensor_v1<544x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x128256x!vhlo.bf16_v1>
    "vhlo.return_v1"(%52, %80, %212) : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x128256x!vhlo.bf16_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[8,4]<=[32]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[8,4]<=[32]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[8,4]<=[32]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,8]<=[8,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[8,4]<=[32]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,8]<=[8,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[8,4]<=[32]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[8,4]<=[32]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}


// -----// IR Dump Before VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.416) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1>, %arg1: !vhlo.tensor_v1<4x136x!vhlo.i64_v1>, %arg2: !vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1>, %arg3: !vhlo.tensor_v1<8192x!vhlo.bf16_v1>, %arg4: !vhlo.tensor_v1<64x!vhlo.f32_v1>, %arg5: !vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1>, %arg6: !vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1>, %arg7: !vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1>, %arg8: !vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>, %arg9: !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>, %arg10: !vhlo.tensor_v1<4x136x!vhlo.i64_v1>, %arg11: !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>, %arg12: !vhlo.tensor_v1<8192x!vhlo.bf16_v1>, %arg13: !vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>, %arg14: !vhlo.tensor_v1<8192x!vhlo.bf16_v1>) -> (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x128256x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<"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tensor<136xi64>>}> : () -> !vhlo.tensor_v1<136x!vhlo.i64_v1>
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %4 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<1.22070313E-4> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %5 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<9.99999974E-6> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %6 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>>}> : () -> !vhlo.tensor_v1<1x1x136x!vhlo.f32_v1>
    %7 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<8.837890e-02> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1>
    %8 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<1> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1>
    %9 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1>
    %10 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<-3.389530e+38> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1>
    %11 = "vhlo.broadcast_in_dim_v1"(%10) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>
    %12 = "vhlo.broadcast_in_dim_v1"(%9) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>
    %13 = "vhlo.broadcast_in_dim_v1"(%9) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bf16_v1>
    %14 = "vhlo.broadcast_in_dim_v1"(%10) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bf16_v1>
    %15 = "vhlo.broadcast_in_dim_v1"(%8) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.i64_v1>
    %16 = "vhlo.broadcast_in_dim_v1"(%7) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>
    %17 = "vhlo.broadcast_in_dim_v1"(%5) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>
    %18 = "vhlo.broadcast_in_dim_v1"(%4) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1>
    %19 = "vhlo.broadcast_in_dim_v1"(%3) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %20 = "vhlo.reshape_v1"(%arg3) : (!vhlo.tensor_v1<8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %21 = "vhlo.custom_call_v1"(%20) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___input_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %22 = "vhlo.reshape_v1"(%21) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x!vhlo.bf16_v1>
    %23 = "vhlo.broadcast_in_dim_v1"(%22) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %24 = "vhlo.reshape_v1"(%arg2) : (!vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1>
    %25 = "vhlo.custom_call_v1"(%24) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_embed_tokens_weight">}>} : (!vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1>
    %26 = "vhlo.reshape_v1"(%25) : (!vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1>
    %27 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x4x136x!vhlo.i64_v1>
    %28 = "vhlo.custom_call_v1"(%27) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x4x136x!vhlo.i64_v1>
    %29 = "vhlo.reshape_v1"(%28) : (!vhlo.tensor_v1<1x4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<544x!vhlo.i64_v1>
    %30 = "vhlo.convert_v1"(%29) : (!vhlo.tensor_v1<544x!vhlo.i64_v1>) -> !vhlo.tensor_v1<544x!vhlo.ui32_v1>
    %31 = "vhlo.gather_v2"(%26, %30) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 8192]> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<544x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>
    %32 = "vhlo.reshape_v1"(%31) : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %33 = "vhlo.convert_v1"(%32) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %34 = "vhlo.power_v1"(%33, %19) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %35 = "vhlo.reduce_v1"(%34, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg15: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg16: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %213 = "vhlo.add_v1"(%arg15, %arg16) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%213) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1>
    %36 = "vhlo.multiply_v1"(%35, %18) : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1>
    %37 = "vhlo.reshape_v1"(%36) : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>
    %38 = "vhlo.add_v1"(%37, %17) : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>
    %39 = "vhlo.rsqrt_v2"(%38) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>
    %40 = "vhlo.reshape_v1"(%39) : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1>
    %41 = "vhlo.broadcast_in_dim_v1"(%40) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %42 = "vhlo.multiply_v1"(%33, %41) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %43 = "vhlo.convert_v1"(%42) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %44 = "vhlo.multiply_v1"(%23, %43) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %45 = "vhlo.reshape_v1"(%44) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>
    %46 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1>
    %47 = "vhlo.custom_call_v1"(%46) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_v_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1>
    %48 = "vhlo.reshape_v1"(%47) : (!vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1>
    %49 = "vhlo.transpose_v1"(%48) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,1024]{0,1}">} : (!vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x1024x!vhlo.bf16_v1>
    %50 = "vhlo.dot_general_v2"(%45, %49) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x1024x!vhlo.bf16_v1>
    %51 = "vhlo.reshape_v1"(%50) : (!vhlo.tensor_v1<544x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8x128x!vhlo.bf16_v1>
    %52 = "vhlo.transpose_v1"(%51) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[4,8,136,128]{3,1,2,0}">} : (!vhlo.tensor_v1<4x136x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>
    %53 = "vhlo.reshape_v1"(%arg5) : (!vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1>
    %54 = "vhlo.custom_call_v1"(%53) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_k_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1>
    %55 = "vhlo.reshape_v1"(%54) : (!vhlo.tensor_v1<1x1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1>
    %56 = "vhlo.transpose_v1"(%55) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,1024]{0,1}">} : (!vhlo.tensor_v1<1024x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x1024x!vhlo.bf16_v1>
    %57 = "vhlo.dot_general_v2"(%45, %56) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x1024x!vhlo.bf16_v1>
    %58 = "vhlo.reshape_v1"(%57) : (!vhlo.tensor_v1<544x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8x128x!vhlo.bf16_v1>
    %59 = "vhlo.transpose_v1"(%58) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[4,8,136,128]{3,1,2,0}">} : (!vhlo.tensor_v1<4x136x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>
    %60 = "vhlo.reshape_v1"(%arg4) : (!vhlo.tensor_v1<64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>
    %61 = "vhlo.custom_call_v1"(%60) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"constant">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_rotary_emb_inv_freq">}>} : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>
    %62 = "vhlo.reshape_v1"(%61) : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>
    %63 = "vhlo.dot_general_v2"(%62, %6) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x136x!vhlo.f32_v1>
    %64 = "vhlo.transpose_v1"(%63) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1]> : tensor<3xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[1, 2, 0]> : tensor<3xindex>>, xla_shape = #vhlo.string_v1<"f32[1,136,64]{1,2,0}">} : (!vhlo.tensor_v1<1x64x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x136x64x!vhlo.f32_v1>
    %65 = "vhlo.concatenate_v1"(%64, %64) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<1x136x64x!vhlo.f32_v1>, !vhlo.tensor_v1<1x136x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x136x128x!vhlo.f32_v1>
    %66 = "vhlo.cosine_v2"(%65) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x136x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x136x128x!vhlo.f32_v1>
    %67 = "vhlo.convert_v1"(%66) : (!vhlo.tensor_v1<1x136x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x136x128x!vhlo.bf16_v1>
    %68 = "vhlo.reshape_v1"(%67) : (!vhlo.tensor_v1<1x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<136x128x!vhlo.bf16_v1>
    %69 = "vhlo.broadcast_in_dim_v1"(%68) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>
    %70 = "vhlo.multiply_v1"(%59, %69) : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>
    %71 = "vhlo.slice_v1"(%59) <{limit_indices = #vhlo.tensor_v1<dense<[4, 8, 136, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x64x!vhlo.bf16_v1>
    %72 = "vhlo.negate_v1"(%71) : (!vhlo.tensor_v1<4x8x136x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x64x!vhlo.bf16_v1>
    %73 = "vhlo.slice_v1"(%59) <{limit_indices = #vhlo.tensor_v1<dense<[4, 8, 136, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x64x!vhlo.bf16_v1>
    %74 = "vhlo.concatenate_v1"(%72, %73) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<4x8x136x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x8x136x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>
    %75 = "vhlo.sine_v2"(%65) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x136x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x136x128x!vhlo.f32_v1>
    %76 = "vhlo.convert_v1"(%75) : (!vhlo.tensor_v1<1x136x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x136x128x!vhlo.bf16_v1>
    %77 = "vhlo.reshape_v1"(%76) : (!vhlo.tensor_v1<1x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<136x128x!vhlo.bf16_v1>
    %78 = "vhlo.broadcast_in_dim_v1"(%77) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>
    %79 = "vhlo.multiply_v1"(%74, %78) : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>
    %80 = "vhlo.add_v1"(%70, %79) : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>
    %81 = "vhlo.reshape_v1"(%arg14) : (!vhlo.tensor_v1<8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %82 = "vhlo.custom_call_v1"(%81) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_norm_weight">}>} : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %83 = "vhlo.reshape_v1"(%82) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x!vhlo.bf16_v1>
    %84 = "vhlo.broadcast_in_dim_v1"(%83) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %85 = "vhlo.reshape_v1"(%arg11) : (!vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1>
    %86 = "vhlo.custom_call_v1"(%85) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_q_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1>
    %87 = "vhlo.reshape_v1"(%86) : (!vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>
    %88 = "vhlo.transpose_v1"(%87) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,8192]{0,1}">} : (!vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>
    %89 = "vhlo.dot_general_v2"(%45, %88) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>
    %90 = "vhlo.reshape_v1"(%89) : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x64x128x!vhlo.bf16_v1>
    %91 = "vhlo.transpose_v1"(%90) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[4,64,136,128]{3,1,2,0}">} : (!vhlo.tensor_v1<4x136x64x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>
    %92 = "vhlo.broadcast_in_dim_v1"(%68) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>
    %93 = "vhlo.multiply_v1"(%91, %92) : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>
    %94 = "vhlo.slice_v1"(%91) <{limit_indices = #vhlo.tensor_v1<dense<[4, 64, 136, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x64x!vhlo.bf16_v1>
    %95 = "vhlo.negate_v1"(%94) : (!vhlo.tensor_v1<4x64x136x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x64x!vhlo.bf16_v1>
    %96 = "vhlo.slice_v1"(%91) <{limit_indices = #vhlo.tensor_v1<dense<[4, 64, 136, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x64x!vhlo.bf16_v1>
    %97 = "vhlo.concatenate_v1"(%95, %96) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<4x64x136x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x64x136x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>
    %98 = "vhlo.broadcast_in_dim_v1"(%77) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>
    %99 = "vhlo.multiply_v1"(%97, %98) : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>
    %100 = "vhlo.add_v1"(%93, %99) : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>
    %101 = "vhlo.reshape_v1"(%100) : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<256x136x128x!vhlo.bf16_v1>
    %102 = "vhlo.broadcast_in_dim_v1"(%80) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x8x136x128x!vhlo.bf16_v1>
    %103 = "vhlo.reshape_v1"(%102) : (!vhlo.tensor_v1<4x8x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>
    %104 = "vhlo.transpose_v1"(%103) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[4,64,128,136]{2,3,1,0}">} : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x128x136x!vhlo.bf16_v1>
    %105 = "vhlo.reshape_v1"(%104) : (!vhlo.tensor_v1<4x64x128x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<256x128x136x!vhlo.bf16_v1>
    %106 = "vhlo.dot_general_v2"(%101, %105) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<256x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<256x128x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<256x136x136x!vhlo.bf16_v1>
    %107 = "vhlo.reshape_v1"(%106) : (!vhlo.tensor_v1<256x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>
    %108 = "vhlo.multiply_v1"(%107, %16) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>
    %109 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>}> : (!vhlo.tensor_v1<136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.i64_v1>
    %110 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.i64_v1>
    %111 = "vhlo.subtract_v1"(%109, %110) : (!vhlo.tensor_v1<136x136x!vhlo.i64_v1>, !vhlo.tensor_v1<136x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.i64_v1>
    %112 = "vhlo.compare_v1"(%111, %15) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GE>}> : (!vhlo.tensor_v1<136x136x!vhlo.i64_v1>, !vhlo.tensor_v1<136x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bool_v1>
    %113 = "vhlo.select_v1"(%112, %14, %13) : (!vhlo.tensor_v1<136x136x!vhlo.bool_v1>, !vhlo.tensor_v1<136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bf16_v1>
    %114 = "vhlo.compare_v1"(%109, %110) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GT>}> : (!vhlo.tensor_v1<136x136x!vhlo.i64_v1>, !vhlo.tensor_v1<136x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bool_v1>
    %115 = "vhlo.convert_v1"(%114) : (!vhlo.tensor_v1<136x136x!vhlo.bool_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bf16_v1>
    %116 = "vhlo.multiply_v1"(%113, %115) : (!vhlo.tensor_v1<136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<136x136x!vhlo.bf16_v1>
    %117 = "vhlo.reshape_v1"(%116) : (!vhlo.tensor_v1<136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x136x136x!vhlo.bf16_v1>
    %118 = "vhlo.broadcast_in_dim_v1"(%117) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[1, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>
    %119 = "vhlo.reshape_v1"(%arg10) : (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x4x136x!vhlo.i64_v1>
    %120 = "vhlo.custom_call_v1"(%119) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_1">}>} : (!vhlo.tensor_v1<1x4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x4x136x!vhlo.i64_v1>
    %121 = "vhlo.reshape_v1"(%120) : (!vhlo.tensor_v1<1x4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x1x1x136x!vhlo.i64_v1>
    %122 = "vhlo.convert_v1"(%121) : (!vhlo.tensor_v1<4x1x1x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x1x1x136x!vhlo.bf16_v1>
    %123 = "vhlo.reshape_v1"(%122) : (!vhlo.tensor_v1<4x1x1x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x!vhlo.bf16_v1>
    %124 = "vhlo.broadcast_in_dim_v1"(%123) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<4x1x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>
    %125 = "vhlo.add_v1"(%118, %124) : (!vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>
    %126 = "vhlo.compare_v1"(%125, %12) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 EQ>}> : (!vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bool_v1>
    %127 = "vhlo.select_v1"(%126, %11, %118) : (!vhlo.tensor_v1<4x1x136x136x!vhlo.bool_v1>, !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>
    %128 = "vhlo.reshape_v1"(%127) : (!vhlo.tensor_v1<4x1x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x136x!vhlo.bf16_v1>
    %129 = "vhlo.broadcast_in_dim_v1"(%128) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<4x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>
    %130 = "vhlo.add_v1"(%108, %129) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>
    %131 = "vhlo.convert_v1"(%130) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>
    %132 = "vhlo.reduce_v1"(%131, %2) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg15: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg16: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %213 = "vhlo.maximum_v1"(%arg15, %arg16) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%213) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x!vhlo.f32_v1>
    %133 = "vhlo.broadcast_in_dim_v1"(%132) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<4x64x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>
    %134 = "vhlo.subtract_v1"(%131, %133) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>, !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>
    %135 = "vhlo.exponential_v2"(%134) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>
    %136 = "vhlo.reduce_v1"(%135, %0) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg15: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg16: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %213 = "vhlo.add_v1"(%arg15, %arg16) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%213) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x!vhlo.f32_v1>
    %137 = "vhlo.broadcast_in_dim_v1"(%136) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<4x64x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>
    %138 = "vhlo.divide_v1"(%135, %137) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>, !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>
    %139 = "vhlo.convert_v1"(%138) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>
    %140 = "vhlo.reshape_v1"(%139) : (!vhlo.tensor_v1<4x64x136x136x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<256x136x136x!vhlo.bf16_v1>
    %141 = "vhlo.broadcast_in_dim_v1"(%52) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x8x8x136x128x!vhlo.bf16_v1>
    %142 = "vhlo.reshape_v1"(%141) : (!vhlo.tensor_v1<4x8x8x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<256x136x128x!vhlo.bf16_v1>
    %143 = "vhlo.dot_general_v2"(%140, %142) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<256x136x136x!vhlo.bf16_v1>, !vhlo.tensor_v1<256x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<256x136x128x!vhlo.bf16_v1>
    %144 = "vhlo.reshape_v1"(%143) : (!vhlo.tensor_v1<256x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>
    %145 = "vhlo.transpose_v1"(%144) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[4,136,64,128]{3,1,2,0}">} : (!vhlo.tensor_v1<4x64x136x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x64x128x!vhlo.bf16_v1>
    %146 = "vhlo.reshape_v1"(%145) : (!vhlo.tensor_v1<4x136x64x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>
    %147 = "vhlo.reshape_v1"(%arg9) : (!vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1>
    %148 = "vhlo.custom_call_v1"(%147) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_o_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1>
    %149 = "vhlo.reshape_v1"(%148) : (!vhlo.tensor_v1<1x8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>
    %150 = "vhlo.transpose_v1"(%149) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,8192]{0,1}">} : (!vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>
    %151 = "vhlo.dot_general_v2"(%146, %150) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>
    %152 = "vhlo.reshape_v1"(%151) : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %153 = "vhlo.add_v1"(%32, %152) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %154 = "vhlo.reshape_v1"(%arg12) : (!vhlo.tensor_v1<8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %155 = "vhlo.custom_call_v1"(%154) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___post_attention_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %156 = "vhlo.reshape_v1"(%155) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x!vhlo.bf16_v1>
    %157 = "vhlo.broadcast_in_dim_v1"(%156) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %158 = "vhlo.convert_v1"(%153) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %159 = "vhlo.power_v1"(%158, %19) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %160 = "vhlo.reduce_v1"(%159, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg15: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg16: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %213 = "vhlo.add_v1"(%arg15, %arg16) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%213) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1>
    %161 = "vhlo.multiply_v1"(%160, %18) : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1>
    %162 = "vhlo.reshape_v1"(%161) : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>
    %163 = "vhlo.add_v1"(%162, %17) : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>
    %164 = "vhlo.rsqrt_v2"(%163) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>
    %165 = "vhlo.reshape_v1"(%164) : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1>
    %166 = "vhlo.broadcast_in_dim_v1"(%165) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %167 = "vhlo.multiply_v1"(%158, %166) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %168 = "vhlo.convert_v1"(%167) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %169 = "vhlo.multiply_v1"(%157, %168) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %170 = "vhlo.reshape_v1"(%169) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>
    %171 = "vhlo.reshape_v1"(%arg13) : (!vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1>
    %172 = "vhlo.custom_call_v1"(%171) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_gate_proj_weight">}>} : (!vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1>
    %173 = "vhlo.reshape_v1"(%172) : (!vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>
    %174 = "vhlo.transpose_v1"(%173) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,28672]{0,1}">} : (!vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1>
    %175 = "vhlo.dot_general_v2"(%170, %174) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x28672x!vhlo.bf16_v1>
    %176 = "vhlo.reshape_v1"(%175) : (!vhlo.tensor_v1<544x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>
    %177 = "vhlo.logistic_v2"(%176) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>
    %178 = "vhlo.multiply_v1"(%176, %177) : (!vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>
    %179 = "vhlo.reshape_v1"(%arg8) : (!vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1>
    %180 = "vhlo.custom_call_v1"(%179) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_up_proj_weight">}>} : (!vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1>
    %181 = "vhlo.reshape_v1"(%180) : (!vhlo.tensor_v1<1x28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>
    %182 = "vhlo.transpose_v1"(%181) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,28672]{0,1}">} : (!vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1>
    %183 = "vhlo.dot_general_v2"(%170, %182) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x28672x!vhlo.bf16_v1>
    %184 = "vhlo.reshape_v1"(%183) : (!vhlo.tensor_v1<544x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>
    %185 = "vhlo.multiply_v1"(%178, %184) : (!vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>
    %186 = "vhlo.reshape_v1"(%185) : (!vhlo.tensor_v1<4x136x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x28672x!vhlo.bf16_v1>
    %187 = "vhlo.reshape_v1"(%arg7) : (!vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x28672x!vhlo.bf16_v1>
    %188 = "vhlo.custom_call_v1"(%187) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_down_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x28672x!vhlo.bf16_v1>
    %189 = "vhlo.reshape_v1"(%188) : (!vhlo.tensor_v1<1x8192x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1>
    %190 = "vhlo.transpose_v1"(%189) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[28672,8192]{0,1}">} : (!vhlo.tensor_v1<8192x28672x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>
    %191 = "vhlo.dot_general_v2"(%186, %190) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x28672x!vhlo.bf16_v1>, !vhlo.tensor_v1<28672x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>
    %192 = "vhlo.reshape_v1"(%191) : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %193 = "vhlo.add_v1"(%153, %192) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %194 = "vhlo.convert_v1"(%193) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %195 = "vhlo.power_v1"(%194, %19) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %196 = "vhlo.reduce_v1"(%195, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg15: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg16: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %213 = "vhlo.add_v1"(%arg15, %arg16) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%213) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1>
    %197 = "vhlo.multiply_v1"(%196, %18) : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1>
    %198 = "vhlo.reshape_v1"(%197) : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>
    %199 = "vhlo.add_v1"(%198, %17) : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>
    %200 = "vhlo.rsqrt_v2"(%199) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>
    %201 = "vhlo.reshape_v1"(%200) : (!vhlo.tensor_v1<4x136x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.f32_v1>
    %202 = "vhlo.broadcast_in_dim_v1"(%201) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<4x136x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %203 = "vhlo.multiply_v1"(%194, %202) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>
    %204 = "vhlo.convert_v1"(%203) : (!vhlo.tensor_v1<4x136x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %205 = "vhlo.multiply_v1"(%84, %204) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>
    %206 = "vhlo.reshape_v1"(%205) : (!vhlo.tensor_v1<4x136x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>
    %207 = "vhlo.reshape_v1"(%arg6) : (!vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1>
    %208 = "vhlo.custom_call_v1"(%207) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___lm_head_weight">}>} : (!vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1>
    %209 = "vhlo.reshape_v1"(%208) : (!vhlo.tensor_v1<1x128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1>
    %210 = "vhlo.transpose_v1"(%209) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,128256]{0,1}">} : (!vhlo.tensor_v1<128256x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x128256x!vhlo.bf16_v1>
    %211 = "vhlo.dot_general_v2"(%206, %210) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<544x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<544x128256x!vhlo.bf16_v1>
    %212 = "vhlo.reshape_v1"(%211) : (!vhlo.tensor_v1<544x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<4x136x128256x!vhlo.bf16_v1>
    "vhlo.return_v1"(%52, %80, %212) : (!vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x8x136x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<4x136x128256x!vhlo.bf16_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[8,4]<=[32]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[8,4]<=[32]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[8,4]<=[32]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,8]<=[8,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[8,4]<=[32]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,8]<=[8,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[8,4]<=[32]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[8,4]<=[32]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}


// -----// IR Dump After VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.416) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1024x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}"}, %arg1: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}"}, %arg2: tensor<128256x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"}, %arg3: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"}, %arg4: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"}, %arg5: tensor<1024x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}"}, %arg6: tensor<128256x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}"}, %arg7: tensor<8192x28672xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,8]<=[8,4]T(1,0)}"}, %arg8: tensor<28672x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}"}, %arg9: tensor<8192x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,8]<=[8,4]T(1,0)}"}, %arg10: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}"}, %arg11: tensor<8192x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}"}, %arg12: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"}, %arg13: tensor<28672x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}"}, %arg14: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"}) -> (tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<136xi64>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
    %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>
    %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16>
    %c_6 = stablehlo.constant dense<1> : tensor<i64>
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %3 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %4 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64>
    %5 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<4x64x136x136xbf16>
    %6 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<4x136x1xf32>
    %7 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x136xf32>
    %8 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x136x8192xf32>
    %9 = stablehlo.reshape %arg3 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %10 = stablehlo.custom_call @tt.mark_argument(%9) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}} : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xbf16>
    %11 = stablehlo.reshape %10 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %13 = stablehlo.reshape %arg2 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %14 = stablehlo.custom_call @tt.mark_argument(%13) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_embed_tokens_weight"}} : (tensor<1x128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %15 = stablehlo.reshape %14 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %16 = stablehlo.reshape %arg1 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %17 = stablehlo.custom_call @tt.mark_argument(%16) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<1x4x136xi64>) -> tensor<1x4x136xi64>
    %18 = stablehlo.reshape %17 : (tensor<1x4x136xi64>) -> tensor<544xi64>
    %19 = stablehlo.convert %18 : (tensor<544xi64>) -> tensor<544xui32>
    %20 = "stablehlo.gather"(%15, %19) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16>
    %21 = stablehlo.reshape %20 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %22 = stablehlo.convert %21 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %23 = stablehlo.power %22, %8 : tensor<4x136x8192xf32>
    %24 = stablehlo.reduce(%23 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %25 = stablehlo.multiply %24, %7 : tensor<4x136xf32>
    %26 = stablehlo.reshape %25 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %27 = stablehlo.add %26, %6 : tensor<4x136x1xf32>
    %28 = stablehlo.rsqrt %27 : tensor<4x136x1xf32>
    %29 = stablehlo.reshape %28 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %30 = stablehlo.broadcast_in_dim %29, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %31 = stablehlo.multiply %22, %30 : tensor<4x136x8192xf32>
    %32 = stablehlo.convert %31 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %33 = stablehlo.multiply %12, %32 : tensor<4x136x8192xbf16>
    %34 = stablehlo.reshape %33 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %35 = stablehlo.reshape %arg0 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %36 = stablehlo.custom_call @tt.mark_argument(%35) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}} : (tensor<1x1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %37 = stablehlo.reshape %36 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %38 = stablehlo.transpose %37, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %39 = stablehlo.dot_general %34, %38, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %40 = stablehlo.reshape %39 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %41 = stablehlo.transpose %40, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %42 = stablehlo.reshape %arg5 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %43 = stablehlo.custom_call @tt.mark_argument(%42) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}} : (tensor<1x1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %44 = stablehlo.reshape %43 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %45 = stablehlo.transpose %44, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %46 = stablehlo.dot_general %34, %45, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %47 = stablehlo.reshape %46 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %48 = stablehlo.transpose %47, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %49 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %50 = stablehlo.custom_call @tt.mark_argument(%49) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "constant", ttir.name = "l__self___model_rotary_emb_inv_freq"}} : (tensor<1x1x64xf32>) -> tensor<1x1x64xf32>
    %51 = stablehlo.reshape %50 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %52 = stablehlo.dot_general %51, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
    %53 = stablehlo.transpose %52, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
    %54 = stablehlo.concatenate %53, %53, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
    %55 = stablehlo.cosine %54 : tensor<1x136x128xf32>
    %56 = stablehlo.convert %55 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %57 = stablehlo.reshape %56 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %58 = stablehlo.broadcast_in_dim %57, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %59 = stablehlo.multiply %48, %58 : tensor<4x8x136x128xbf16>
    %60 = stablehlo.slice %48 [0:4, 0:8, 0:136, 64:128] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %61 = stablehlo.negate %60 : tensor<4x8x136x64xbf16>
    %62 = stablehlo.slice %48 [0:4, 0:8, 0:136, 0:64] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %63 = stablehlo.concatenate %61, %62, dim = 3 : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16>
    %64 = stablehlo.sine %54 : tensor<1x136x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %66 = stablehlo.reshape %65 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %67 = stablehlo.broadcast_in_dim %66, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %68 = stablehlo.multiply %63, %67 : tensor<4x8x136x128xbf16>
    %69 = stablehlo.add %59, %68 : tensor<4x8x136x128xbf16>
    %70 = stablehlo.reshape %arg14 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %71 = stablehlo.custom_call @tt.mark_argument(%70) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_norm_weight"}} : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xbf16>
    %72 = stablehlo.reshape %71 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %73 = stablehlo.broadcast_in_dim %72, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %74 = stablehlo.reshape %arg11 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %75 = stablehlo.custom_call @tt.mark_argument(%74) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}} : (tensor<1x8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %76 = stablehlo.reshape %75 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %77 = stablehlo.transpose %76, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %78 = stablehlo.dot_general %34, %77, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %79 = stablehlo.reshape %78 : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16>
    %80 = stablehlo.transpose %79, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16>
    %81 = stablehlo.broadcast_in_dim %57, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %82 = stablehlo.multiply %80, %81 : tensor<4x64x136x128xbf16>
    %83 = stablehlo.slice %80 [0:4, 0:64, 0:136, 64:128] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %84 = stablehlo.negate %83 : tensor<4x64x136x64xbf16>
    %85 = stablehlo.slice %80 [0:4, 0:64, 0:136, 0:64] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %86 = stablehlo.concatenate %84, %85, dim = 3 : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16>
    %87 = stablehlo.broadcast_in_dim %66, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %88 = stablehlo.multiply %86, %87 : tensor<4x64x136x128xbf16>
    %89 = stablehlo.add %82, %88 : tensor<4x64x136x128xbf16>
    %90 = stablehlo.reshape %89 : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16>
    %91 = stablehlo.broadcast_in_dim %69, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %92 = stablehlo.reshape %91 : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %93 = stablehlo.transpose %92, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16>
    %94 = stablehlo.reshape %93 : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16>
    %95 = stablehlo.dot_general %90, %94, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16>
    %96 = stablehlo.reshape %95 : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %97 = stablehlo.multiply %96, %5 : tensor<4x64x136x136xbf16>
    %98 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64>
    %99 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64>
    %100 = stablehlo.subtract %98, %99 : tensor<136x136xi64>
    %101 = stablehlo.compare  GE, %100, %4 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %102 = stablehlo.select %101, %3, %2 : tensor<136x136xi1>, tensor<136x136xbf16>
    %103 = stablehlo.compare  GT, %98, %99 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %104 = stablehlo.convert %103 : (tensor<136x136xi1>) -> tensor<136x136xbf16>
    %105 = stablehlo.multiply %102, %104 : tensor<136x136xbf16>
    %106 = stablehlo.reshape %105 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
    %107 = stablehlo.broadcast_in_dim %106, dims = [1, 2, 3] : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16>
    %108 = stablehlo.reshape %arg10 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %109 = stablehlo.custom_call @tt.mark_argument(%108) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_1"}} : (tensor<1x4x136xi64>) -> tensor<1x4x136xi64>
    %110 = stablehlo.reshape %109 : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64>
    %111 = stablehlo.convert %110 : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16>
    %112 = stablehlo.reshape %111 : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16>
    %113 = stablehlo.broadcast_in_dim %112, dims = [0, 1, 3] : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16>
    %114 = stablehlo.add %107, %113 : tensor<4x1x136x136xbf16>
    %115 = stablehlo.compare  EQ, %114, %1 : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1>
    %116 = stablehlo.select %115, %0, %107 : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16>
    %117 = stablehlo.reshape %116 : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16>
    %118 = stablehlo.broadcast_in_dim %117, dims = [0, 2, 3] : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %119 = stablehlo.add %97, %118 : tensor<4x64x136x136xbf16>
    %120 = stablehlo.convert %119 : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32>
    %121 = stablehlo.reduce(%120 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %122 = stablehlo.broadcast_in_dim %121, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %123 = stablehlo.subtract %120, %122 : tensor<4x64x136x136xf32>
    %124 = stablehlo.exponential %123 : tensor<4x64x136x136xf32>
    %125 = stablehlo.reduce(%124 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %126 = stablehlo.broadcast_in_dim %125, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %127 = stablehlo.divide %124, %126 : tensor<4x64x136x136xf32>
    %128 = stablehlo.convert %127 : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16>
    %129 = stablehlo.reshape %128 : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16>
    %130 = stablehlo.broadcast_in_dim %41, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %131 = stablehlo.reshape %130 : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16>
    %132 = stablehlo.dot_general %129, %131, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16>
    %133 = stablehlo.reshape %132 : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %134 = stablehlo.transpose %133, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16>
    %135 = stablehlo.reshape %134 : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16>
    %136 = stablehlo.reshape %arg9 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %137 = stablehlo.custom_call @tt.mark_argument(%136) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}} : (tensor<1x8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %138 = stablehlo.reshape %137 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %139 = stablehlo.transpose %138, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %140 = stablehlo.dot_general %135, %139, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %141 = stablehlo.reshape %140 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %142 = stablehlo.add %21, %141 : tensor<4x136x8192xbf16>
    %143 = stablehlo.reshape %arg12 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %144 = stablehlo.custom_call @tt.mark_argument(%143) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}} : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xbf16>
    %145 = stablehlo.reshape %144 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %146 = stablehlo.broadcast_in_dim %145, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %147 = stablehlo.convert %142 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %148 = stablehlo.power %147, %8 : tensor<4x136x8192xf32>
    %149 = stablehlo.reduce(%148 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %150 = stablehlo.multiply %149, %7 : tensor<4x136xf32>
    %151 = stablehlo.reshape %150 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %152 = stablehlo.add %151, %6 : tensor<4x136x1xf32>
    %153 = stablehlo.rsqrt %152 : tensor<4x136x1xf32>
    %154 = stablehlo.reshape %153 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %155 = stablehlo.broadcast_in_dim %154, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %156 = stablehlo.multiply %147, %155 : tensor<4x136x8192xf32>
    %157 = stablehlo.convert %156 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %158 = stablehlo.multiply %146, %157 : tensor<4x136x8192xbf16>
    %159 = stablehlo.reshape %158 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %160 = stablehlo.reshape %arg13 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %161 = stablehlo.custom_call @tt.mark_argument(%160) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}} : (tensor<1x28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %162 = stablehlo.reshape %161 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %163 = stablehlo.transpose %162, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %164 = stablehlo.dot_general %159, %163, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %165 = stablehlo.reshape %164 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %166 = stablehlo.logistic %165 : tensor<4x136x28672xbf16>
    %167 = stablehlo.multiply %165, %166 : tensor<4x136x28672xbf16>
    %168 = stablehlo.reshape %arg8 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %169 = stablehlo.custom_call @tt.mark_argument(%168) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}} : (tensor<1x28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %170 = stablehlo.reshape %169 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %171 = stablehlo.transpose %170, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %172 = stablehlo.dot_general %159, %171, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %173 = stablehlo.reshape %172 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %174 = stablehlo.multiply %167, %173 : tensor<4x136x28672xbf16>
    %175 = stablehlo.reshape %174 : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16>
    %176 = stablehlo.reshape %arg7 : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
    %177 = stablehlo.custom_call @tt.mark_argument(%176) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}} : (tensor<1x8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
    %178 = stablehlo.reshape %177 : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16>
    %179 = stablehlo.transpose %178, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16>
    %180 = stablehlo.dot_general %175, %179, contracting_dims = [1] x [0] : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16>
    %181 = stablehlo.reshape %180 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %182 = stablehlo.add %142, %181 : tensor<4x136x8192xbf16>
    %183 = stablehlo.convert %182 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %184 = stablehlo.power %183, %8 : tensor<4x136x8192xf32>
    %185 = stablehlo.reduce(%184 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %186 = stablehlo.multiply %185, %7 : tensor<4x136xf32>
    %187 = stablehlo.reshape %186 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %188 = stablehlo.add %187, %6 : tensor<4x136x1xf32>
    %189 = stablehlo.rsqrt %188 : tensor<4x136x1xf32>
    %190 = stablehlo.reshape %189 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %191 = stablehlo.broadcast_in_dim %190, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %192 = stablehlo.multiply %183, %191 : tensor<4x136x8192xf32>
    %193 = stablehlo.convert %192 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %194 = stablehlo.multiply %73, %193 : tensor<4x136x8192xbf16>
    %195 = stablehlo.reshape %194 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %196 = stablehlo.reshape %arg6 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %197 = stablehlo.custom_call @tt.mark_argument(%196) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___lm_head_weight"}} : (tensor<1x128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %198 = stablehlo.reshape %197 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %199 = stablehlo.transpose %198, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16>
    %200 = stablehlo.dot_general %195, %199, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16>
    %201 = stablehlo.reshape %200 : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16>
    return %41, %69, %201 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
  }
}


2025-10-27 21:34:20.663 (  25.511s) [        9C771B80]      module_builder.cc:963      1| MLIR Module shlo:
#loc1 = loc("p0.1")
#loc2 = loc("p1.9")
#loc3 = loc("p2.14")
#loc4 = loc("p3.50")
#loc5 = loc("p4.70")
#loc6 = loc("p5.87")
#loc7 = loc("p6.116")
#loc8 = loc("p7.125")
#loc9 = loc("p8.130")
#loc10 = loc("p9.139")
#loc11 = loc("p10.212")
#loc12 = loc("p11.254")
#loc13 = loc("p12.348")
#loc14 = loc("p13.357")
#loc15 = loc("p14.403")
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1024x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}"} loc("p0.1"), %arg1: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}"} loc("p1.9"), %arg2: tensor<128256x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("p2.14"), %arg3: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p3.50"), %arg4: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p4.70"), %arg5: tensor<1024x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}"} loc("p5.87"), %arg6: tensor<128256x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}"} loc("p6.116"), %arg7: tensor<8192x28672xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,8]<=[8,4]T(1,0)}"} loc("p7.125"), %arg8: tensor<28672x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}"} loc("p8.130"), %arg9: tensor<8192x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,8]<=[8,4]T(1,0)}"} loc("p9.139"), %arg10: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}"} loc("p10.212"), %arg11: tensor<8192x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}"} loc("p11.254"), %arg12: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p12.348"), %arg13: tensor<28672x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}"} loc("p13.357"), %arg14: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p14.403")) -> (tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %c = stablehlo.constant dense<"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tensor<136xi64> loc(#loc)
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32> loc(#loc)
    %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32> loc(#loc)
    %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32> loc(#loc)
    %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16> loc(#loc)
    %c_6 = stablehlo.constant dense<1> : tensor<i64> loc(#loc)
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16> loc(#loc)
    %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16> loc(#loc)
    %3 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16> loc(#loc)
    %4 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64> loc(#loc)
    %5 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<4x64x136x136xbf16> loc(#loc)
    %6 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<4x136x1xf32> loc(#loc)
    %7 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x136xf32> loc(#loc)
    %8 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x136x8192xf32> loc(#loc)
    %9 = stablehlo.reshape %arg3 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16> loc(#loc16)
    %10 = stablehlo.custom_call @tt.mark_argument(%9) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}} : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xbf16> loc(#loc17)
    %11 = stablehlo.reshape %10 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16> loc(#loc18)
    %12 = stablehlo.broadcast_in_dim %11, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16> loc(#loc19)
    %13 = stablehlo.reshape %arg2 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16> loc(#loc20)
    %14 = stablehlo.custom_call @tt.mark_argument(%13) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_embed_tokens_weight"}} : (tensor<1x128256x8192xbf16>) -> tensor<1x128256x8192xbf16> loc(#loc21)
    %15 = stablehlo.reshape %14 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16> loc(#loc22)
    %16 = stablehlo.reshape %arg1 : (tensor<4x136xi64>) -> tensor<1x4x136xi64> loc(#loc23)
    %17 = stablehlo.custom_call @tt.mark_argument(%16) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<1x4x136xi64>) -> tensor<1x4x136xi64> loc(#loc24)
    %18 = stablehlo.reshape %17 : (tensor<1x4x136xi64>) -> tensor<544xi64> loc(#loc25)
    %19 = stablehlo.convert %18 : (tensor<544xi64>) -> tensor<544xui32> loc(#loc26)
    %20 = "stablehlo.gather"(%15, %19) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16> loc(#loc27)
    %21 = stablehlo.reshape %20 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16> loc(#loc28)
    %22 = stablehlo.convert %21 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32> loc(#loc29)
    %23 = stablehlo.power %22, %8 : tensor<4x136x8192xf32> loc(#loc30)
    %24 = stablehlo.reduce(%23 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32> loc(#loc31)
    %25 = stablehlo.multiply %24, %7 : tensor<4x136xf32> loc(#loc32)
    %26 = stablehlo.reshape %25 : (tensor<4x136xf32>) -> tensor<4x136x1xf32> loc(#loc33)
    %27 = stablehlo.add %26, %6 : tensor<4x136x1xf32> loc(#loc34)
    %28 = stablehlo.rsqrt %27 : tensor<4x136x1xf32> loc(#loc35)
    %29 = stablehlo.reshape %28 : (tensor<4x136x1xf32>) -> tensor<4x136xf32> loc(#loc36)
    %30 = stablehlo.broadcast_in_dim %29, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32> loc(#loc37)
    %31 = stablehlo.multiply %22, %30 : tensor<4x136x8192xf32> loc(#loc38)
    %32 = stablehlo.convert %31 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16> loc(#loc39)
    %33 = stablehlo.multiply %12, %32 : tensor<4x136x8192xbf16> loc(#loc40)
    %34 = stablehlo.reshape %33 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16> loc(#loc41)
    %35 = stablehlo.reshape %arg0 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16> loc(#loc42)
    %36 = stablehlo.custom_call @tt.mark_argument(%35) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}} : (tensor<1x1024x8192xbf16>) -> tensor<1x1024x8192xbf16> loc(#loc43)
    %37 = stablehlo.reshape %36 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16> loc(#loc44)
    %38 = stablehlo.transpose %37, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16> loc(#loc45)
    %39 = stablehlo.dot_general %34, %38, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16> loc(#loc46)
    %40 = stablehlo.reshape %39 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16> loc(#loc47)
    %41 = stablehlo.transpose %40, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16> loc(#loc48)
    %42 = stablehlo.reshape %arg5 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16> loc(#loc49)
    %43 = stablehlo.custom_call @tt.mark_argument(%42) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}} : (tensor<1x1024x8192xbf16>) -> tensor<1x1024x8192xbf16> loc(#loc50)
    %44 = stablehlo.reshape %43 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16> loc(#loc51)
    %45 = stablehlo.transpose %44, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16> loc(#loc52)
    %46 = stablehlo.dot_general %34, %45, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16> loc(#loc53)
    %47 = stablehlo.reshape %46 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16> loc(#loc54)
    %48 = stablehlo.transpose %47, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16> loc(#loc55)
    %49 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc56)
    %50 = stablehlo.custom_call @tt.mark_argument(%49) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "constant", ttir.name = "l__self___model_rotary_emb_inv_freq"}} : (tensor<1x1x64xf32>) -> tensor<1x1x64xf32> loc(#loc57)
    %51 = stablehlo.reshape %50 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc58)
    %52 = stablehlo.dot_general %51, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32> loc(#loc59)
    %53 = stablehlo.transpose %52, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32> loc(#loc60)
    %54 = stablehlo.concatenate %53, %53, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32> loc(#loc61)
    %55 = stablehlo.cosine %54 : tensor<1x136x128xf32> loc(#loc62)
    %56 = stablehlo.convert %55 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16> loc(#loc63)
    %57 = stablehlo.reshape %56 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16> loc(#loc64)
    %58 = stablehlo.broadcast_in_dim %57, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16> loc(#loc65)
    %59 = stablehlo.multiply %48, %58 : tensor<4x8x136x128xbf16> loc(#loc66)
    %60 = stablehlo.slice %48 [0:4, 0:8, 0:136, 64:128] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16> loc(#loc67)
    %61 = stablehlo.negate %60 : tensor<4x8x136x64xbf16> loc(#loc68)
    %62 = stablehlo.slice %48 [0:4, 0:8, 0:136, 0:64] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16> loc(#loc69)
    %63 = stablehlo.concatenate %61, %62, dim = 3 : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16> loc(#loc70)
    %64 = stablehlo.sine %54 : tensor<1x136x128xf32> loc(#loc71)
    %65 = stablehlo.convert %64 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16> loc(#loc72)
    %66 = stablehlo.reshape %65 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16> loc(#loc73)
    %67 = stablehlo.broadcast_in_dim %66, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16> loc(#loc74)
    %68 = stablehlo.multiply %63, %67 : tensor<4x8x136x128xbf16> loc(#loc75)
    %69 = stablehlo.add %59, %68 : tensor<4x8x136x128xbf16> loc(#loc76)
    %70 = stablehlo.reshape %arg14 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16> loc(#loc77)
    %71 = stablehlo.custom_call @tt.mark_argument(%70) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_norm_weight"}} : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xbf16> loc(#loc78)
    %72 = stablehlo.reshape %71 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16> loc(#loc79)
    %73 = stablehlo.broadcast_in_dim %72, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16> loc(#loc80)
    %74 = stablehlo.reshape %arg11 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16> loc(#loc81)
    %75 = stablehlo.custom_call @tt.mark_argument(%74) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}} : (tensor<1x8192x8192xbf16>) -> tensor<1x8192x8192xbf16> loc(#loc82)
    %76 = stablehlo.reshape %75 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16> loc(#loc83)
    %77 = stablehlo.transpose %76, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16> loc(#loc84)
    %78 = stablehlo.dot_general %34, %77, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16> loc(#loc85)
    %79 = stablehlo.reshape %78 : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16> loc(#loc86)
    %80 = stablehlo.transpose %79, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16> loc(#loc87)
    %81 = stablehlo.broadcast_in_dim %57, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16> loc(#loc88)
    %82 = stablehlo.multiply %80, %81 : tensor<4x64x136x128xbf16> loc(#loc89)
    %83 = stablehlo.slice %80 [0:4, 0:64, 0:136, 64:128] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16> loc(#loc90)
    %84 = stablehlo.negate %83 : tensor<4x64x136x64xbf16> loc(#loc91)
    %85 = stablehlo.slice %80 [0:4, 0:64, 0:136, 0:64] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16> loc(#loc92)
    %86 = stablehlo.concatenate %84, %85, dim = 3 : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16> loc(#loc93)
    %87 = stablehlo.broadcast_in_dim %66, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16> loc(#loc94)
    %88 = stablehlo.multiply %86, %87 : tensor<4x64x136x128xbf16> loc(#loc95)
    %89 = stablehlo.add %82, %88 : tensor<4x64x136x128xbf16> loc(#loc96)
    %90 = stablehlo.reshape %89 : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16> loc(#loc97)
    %91 = stablehlo.broadcast_in_dim %69, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16> loc(#loc98)
    %92 = stablehlo.reshape %91 : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16> loc(#loc99)
    %93 = stablehlo.transpose %92, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16> loc(#loc100)
    %94 = stablehlo.reshape %93 : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16> loc(#loc101)
    %95 = stablehlo.dot_general %90, %94, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16> loc(#loc102)
    %96 = stablehlo.reshape %95 : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16> loc(#loc103)
    %97 = stablehlo.multiply %96, %5 : tensor<4x64x136x136xbf16> loc(#loc104)
    %98 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64> loc(#loc105)
    %99 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64> loc(#loc106)
    %100 = stablehlo.subtract %98, %99 : tensor<136x136xi64> loc(#loc107)
    %101 = stablehlo.compare  GE, %100, %4 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1> loc(#loc108)
    %102 = stablehlo.select %101, %3, %2 : tensor<136x136xi1>, tensor<136x136xbf16> loc(#loc109)
    %103 = stablehlo.compare  GT, %98, %99 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1> loc(#loc110)
    %104 = stablehlo.convert %103 : (tensor<136x136xi1>) -> tensor<136x136xbf16> loc(#loc111)
    %105 = stablehlo.multiply %102, %104 : tensor<136x136xbf16> loc(#loc112)
    %106 = stablehlo.reshape %105 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16> loc(#loc113)
    %107 = stablehlo.broadcast_in_dim %106, dims = [1, 2, 3] : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16> loc(#loc114)
    %108 = stablehlo.reshape %arg10 : (tensor<4x136xi64>) -> tensor<1x4x136xi64> loc(#loc115)
    %109 = stablehlo.custom_call @tt.mark_argument(%108) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_1"}} : (tensor<1x4x136xi64>) -> tensor<1x4x136xi64> loc(#loc116)
    %110 = stablehlo.reshape %109 : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64> loc(#loc117)
    %111 = stablehlo.convert %110 : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16> loc(#loc118)
    %112 = stablehlo.reshape %111 : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16> loc(#loc119)
    %113 = stablehlo.broadcast_in_dim %112, dims = [0, 1, 3] : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16> loc(#loc120)
    %114 = stablehlo.add %107, %113 : tensor<4x1x136x136xbf16> loc(#loc121)
    %115 = stablehlo.compare  EQ, %114, %1 : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1> loc(#loc122)
    %116 = stablehlo.select %115, %0, %107 : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16> loc(#loc123)
    %117 = stablehlo.reshape %116 : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16> loc(#loc124)
    %118 = stablehlo.broadcast_in_dim %117, dims = [0, 2, 3] : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16> loc(#loc125)
    %119 = stablehlo.add %97, %118 : tensor<4x64x136x136xbf16> loc(#loc126)
    %120 = stablehlo.convert %119 : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32> loc(#loc127)
    %121 = stablehlo.reduce(%120 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32> loc(#loc128)
    %122 = stablehlo.broadcast_in_dim %121, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32> loc(#loc129)
    %123 = stablehlo.subtract %120, %122 : tensor<4x64x136x136xf32> loc(#loc130)
    %124 = stablehlo.exponential %123 : tensor<4x64x136x136xf32> loc(#loc131)
    %125 = stablehlo.reduce(%124 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32> loc(#loc132)
    %126 = stablehlo.broadcast_in_dim %125, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32> loc(#loc133)
    %127 = stablehlo.divide %124, %126 : tensor<4x64x136x136xf32> loc(#loc134)
    %128 = stablehlo.convert %127 : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16> loc(#loc135)
    %129 = stablehlo.reshape %128 : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16> loc(#loc136)
    %130 = stablehlo.broadcast_in_dim %41, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16> loc(#loc137)
    %131 = stablehlo.reshape %130 : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16> loc(#loc138)
    %132 = stablehlo.dot_general %129, %131, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16> loc(#loc139)
    %133 = stablehlo.reshape %132 : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16> loc(#loc140)
    %134 = stablehlo.transpose %133, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16> loc(#loc141)
    %135 = stablehlo.reshape %134 : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16> loc(#loc142)
    %136 = stablehlo.reshape %arg9 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16> loc(#loc143)
    %137 = stablehlo.custom_call @tt.mark_argument(%136) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}} : (tensor<1x8192x8192xbf16>) -> tensor<1x8192x8192xbf16> loc(#loc144)
    %138 = stablehlo.reshape %137 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16> loc(#loc145)
    %139 = stablehlo.transpose %138, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16> loc(#loc146)
    %140 = stablehlo.dot_general %135, %139, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16> loc(#loc147)
    %141 = stablehlo.reshape %140 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16> loc(#loc148)
    %142 = stablehlo.add %21, %141 : tensor<4x136x8192xbf16> loc(#loc149)
    %143 = stablehlo.reshape %arg12 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16> loc(#loc150)
    %144 = stablehlo.custom_call @tt.mark_argument(%143) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}} : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xbf16> loc(#loc151)
    %145 = stablehlo.reshape %144 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16> loc(#loc152)
    %146 = stablehlo.broadcast_in_dim %145, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16> loc(#loc153)
    %147 = stablehlo.convert %142 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32> loc(#loc154)
    %148 = stablehlo.power %147, %8 : tensor<4x136x8192xf32> loc(#loc155)
    %149 = stablehlo.reduce(%148 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32> loc(#loc156)
    %150 = stablehlo.multiply %149, %7 : tensor<4x136xf32> loc(#loc157)
    %151 = stablehlo.reshape %150 : (tensor<4x136xf32>) -> tensor<4x136x1xf32> loc(#loc158)
    %152 = stablehlo.add %151, %6 : tensor<4x136x1xf32> loc(#loc159)
    %153 = stablehlo.rsqrt %152 : tensor<4x136x1xf32> loc(#loc160)
    %154 = stablehlo.reshape %153 : (tensor<4x136x1xf32>) -> tensor<4x136xf32> loc(#loc161)
    %155 = stablehlo.broadcast_in_dim %154, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32> loc(#loc162)
    %156 = stablehlo.multiply %147, %155 : tensor<4x136x8192xf32> loc(#loc163)
    %157 = stablehlo.convert %156 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16> loc(#loc164)
    %158 = stablehlo.multiply %146, %157 : tensor<4x136x8192xbf16> loc(#loc165)
    %159 = stablehlo.reshape %158 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16> loc(#loc166)
    %160 = stablehlo.reshape %arg13 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16> loc(#loc167)
    %161 = stablehlo.custom_call @tt.mark_argument(%160) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}} : (tensor<1x28672x8192xbf16>) -> tensor<1x28672x8192xbf16> loc(#loc168)
    %162 = stablehlo.reshape %161 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16> loc(#loc169)
    %163 = stablehlo.transpose %162, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16> loc(#loc170)
    %164 = stablehlo.dot_general %159, %163, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16> loc(#loc171)
    %165 = stablehlo.reshape %164 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16> loc(#loc172)
    %166 = stablehlo.logistic %165 : tensor<4x136x28672xbf16> loc(#loc173)
    %167 = stablehlo.multiply %165, %166 : tensor<4x136x28672xbf16> loc(#loc174)
    %168 = stablehlo.reshape %arg8 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16> loc(#loc175)
    %169 = stablehlo.custom_call @tt.mark_argument(%168) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}} : (tensor<1x28672x8192xbf16>) -> tensor<1x28672x8192xbf16> loc(#loc176)
    %170 = stablehlo.reshape %169 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16> loc(#loc177)
    %171 = stablehlo.transpose %170, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16> loc(#loc178)
    %172 = stablehlo.dot_general %159, %171, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16> loc(#loc179)
    %173 = stablehlo.reshape %172 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16> loc(#loc180)
    %174 = stablehlo.multiply %167, %173 : tensor<4x136x28672xbf16> loc(#loc181)
    %175 = stablehlo.reshape %174 : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16> loc(#loc182)
    %176 = stablehlo.reshape %arg7 : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16> loc(#loc183)
    %177 = stablehlo.custom_call @tt.mark_argument(%176) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}} : (tensor<1x8192x28672xbf16>) -> tensor<1x8192x28672xbf16> loc(#loc184)
    %178 = stablehlo.reshape %177 : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16> loc(#loc185)
    %179 = stablehlo.transpose %178, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16> loc(#loc186)
    %180 = stablehlo.dot_general %175, %179, contracting_dims = [1] x [0] : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16> loc(#loc187)
    %181 = stablehlo.reshape %180 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16> loc(#loc188)
    %182 = stablehlo.add %142, %181 : tensor<4x136x8192xbf16> loc(#loc189)
    %183 = stablehlo.convert %182 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32> loc(#loc190)
    %184 = stablehlo.power %183, %8 : tensor<4x136x8192xf32> loc(#loc191)
    %185 = stablehlo.reduce(%184 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32> loc(#loc192)
    %186 = stablehlo.multiply %185, %7 : tensor<4x136xf32> loc(#loc193)
    %187 = stablehlo.reshape %186 : (tensor<4x136xf32>) -> tensor<4x136x1xf32> loc(#loc194)
    %188 = stablehlo.add %187, %6 : tensor<4x136x1xf32> loc(#loc195)
    %189 = stablehlo.rsqrt %188 : tensor<4x136x1xf32> loc(#loc196)
    %190 = stablehlo.reshape %189 : (tensor<4x136x1xf32>) -> tensor<4x136xf32> loc(#loc197)
    %191 = stablehlo.broadcast_in_dim %190, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32> loc(#loc198)
    %192 = stablehlo.multiply %183, %191 : tensor<4x136x8192xf32> loc(#loc199)
    %193 = stablehlo.convert %192 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16> loc(#loc200)
    %194 = stablehlo.multiply %73, %193 : tensor<4x136x8192xbf16> loc(#loc201)
    %195 = stablehlo.reshape %194 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16> loc(#loc202)
    %196 = stablehlo.reshape %arg6 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16> loc(#loc203)
    %197 = stablehlo.custom_call @tt.mark_argument(%196) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___lm_head_weight"}} : (tensor<1x128256x8192xbf16>) -> tensor<1x128256x8192xbf16> loc(#loc204)
    %198 = stablehlo.reshape %197 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16> loc(#loc205)
    %199 = stablehlo.transpose %198, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16> loc(#loc206)
    %200 = stablehlo.dot_general %195, %199, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16> loc(#loc207)
    %201 = stablehlo.reshape %200 : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16> loc(#loc208)
    return %41, %69, %201 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc16 = loc("reshape.51")
#loc17 = loc("custom-call.52")
#loc18 = loc("reshape.53")
#loc19 = loc("broadcast.54")
#loc20 = loc("reshape.15")
#loc21 = loc("custom-call.16")
#loc22 = loc("reshape.17")
#loc23 = loc("reshape.10")
#loc24 = loc("custom-call.11")
#loc25 = loc("reshape.13")
#loc26 = loc("convert.18")
#loc27 = loc("gather.19")
#loc28 = loc("reshape.20")
#loc29 = loc("convert.21")
#loc30 = loc("power.23")
#loc31 = loc("reduce.30")
#loc32 = loc("multiply.39")
#loc33 = loc("reshape.40")
#loc34 = loc("add.44")
#loc35 = loc("rsqrt.45")
#loc36 = loc("reshape.46")
#loc37 = loc("broadcast.47")
#loc38 = loc("multiply.48")
#loc39 = loc("convert.49")
#loc40 = loc("multiply.55")
#loc41 = loc("reshape.56")
#loc42 = loc("reshape.2")
#loc43 = loc("custom-call.3")
#loc44 = loc("reshape.4")
#loc45 = loc("transpose.5")
#loc46 = loc("dot.57")
#loc47 = loc("reshape.59")
#loc48 = loc("transpose.60")
#loc49 = loc("reshape.88")
#loc50 = loc("custom-call.89")
#loc51 = loc("reshape.90")
#loc52 = loc("transpose.91")
#loc53 = loc("dot.93")
#loc54 = loc("reshape.95")
#loc55 = loc("transpose.96")
#loc56 = loc("reshape.71")
#loc57 = loc("custom-call.72")
#loc58 = loc("reshape.76")
#loc59 = loc("dot.79")
#loc60 = loc("transpose.80")
#loc61 = loc("concatenate.81")
#loc62 = loc("cosine.105")
#loc63 = loc("convert.108")
#loc64 = loc("reshape.110")
#loc65 = loc("broadcast.111")
#loc66 = loc("multiply.112")
#loc67 = loc("slice.98")
#loc68 = loc("negate.99")
#loc69 = loc("slice.97")
#loc70 = loc("concatenate.100")
#loc71 = loc("sine.82")
#loc72 = loc("convert.85")
#loc73 = loc("reshape.101")
#loc74 = loc("broadcast.102")
#loc75 = loc("multiply.103")
#loc76 = loc("add.115")
#loc77 = loc("reshape.404")
#loc78 = loc("custom-call.405")
#loc79 = loc("reshape.406")
#loc80 = loc("broadcast.407")
#loc81 = loc("reshape.255")
#loc82 = loc("custom-call.256")
#loc83 = loc("reshape.257")
#loc84 = loc("transpose.258")
#loc85 = loc("dot.260")
#loc86 = loc("reshape.262")
#loc87 = loc("transpose.263")
#loc88 = loc("broadcast.272")
#loc89 = loc("multiply.273")
#loc90 = loc("slice.265")
#loc91 = loc("negate.266")
#loc92 = loc("slice.264")
#loc93 = loc("concatenate.267")
#loc94 = loc("broadcast.269")
#loc95 = loc("multiply.270")
#loc96 = loc("add.276")
#loc97 = loc("reshape.278")
#loc98 = loc("broadcast.248")
#loc99 = loc("reshape.249")
#loc100 = loc("transpose.250")
#loc101 = loc("reshape.252")
#loc102 = loc("dot.279")
#loc103 = loc("reshape.280")
#loc104 = loc("multiply.282")
#loc105 = loc("broadcast.184")
#loc106 = loc("broadcast.186")
#loc107 = loc("subtract.187")
#loc108 = loc("compare.189")
#loc109 = loc("select.191")
#loc110 = loc("compare.161")
#loc111 = loc("convert.162")
#loc112 = loc("multiply.192")
#loc113 = loc("reshape.193")
#loc114 = loc("broadcast.199")
#loc115 = loc("reshape.213")
#loc116 = loc("custom-call.214")
#loc117 = loc("reshape.218")
#loc118 = loc("convert.223")
#loc119 = loc("reshape.226")
#loc120 = loc("broadcast.227")
#loc121 = loc("add.228")
#loc122 = loc("compare.231")
#loc123 = loc("select.233")
#loc124 = loc("reshape.285")
#loc125 = loc("broadcast.286")
#loc126 = loc("add.287")
#loc127 = loc("convert.288")
#loc128 = loc("reduce.294")
#loc129 = loc("broadcast.295")
#loc130 = loc("subtract.296")
#loc131 = loc("exponential.297")
#loc132 = loc("reduce.303")
#loc133 = loc("broadcast.304")
#loc134 = loc("divide.305")
#loc135 = loc("convert.306")
#loc136 = loc("reshape.308")
#loc137 = loc("broadcast.151")
#loc138 = loc("reshape.154")
#loc139 = loc("dot.309")
#loc140 = loc("reshape.310")
#loc141 = loc("transpose.311")
#loc142 = loc("reshape.313")
#loc143 = loc("reshape.140")
#loc144 = loc("custom-call.141")
#loc145 = loc("reshape.142")
#loc146 = loc("transpose.143")
#loc147 = loc("dot.314")
#loc148 = loc("reshape.315")
#loc149 = loc("add.318")
#loc150 = loc("reshape.349")
#loc151 = loc("custom-call.350")
#loc152 = loc("reshape.351")
#loc153 = loc("broadcast.352")
#loc154 = loc("convert.319")
#loc155 = loc("power.321")
#loc156 = loc("reduce.328")
#loc157 = loc("multiply.337")
#loc158 = loc("reshape.338")
#loc159 = loc("add.342")
#loc160 = loc("rsqrt.343")
#loc161 = loc("reshape.344")
#loc162 = loc("broadcast.345")
#loc163 = loc("multiply.346")
#loc164 = loc("convert.347")
#loc165 = loc("multiply.353")
#loc166 = loc("reshape.362")
#loc167 = loc("reshape.358")
#loc168 = loc("custom-call.359")
#loc169 = loc("reshape.360")
#loc170 = loc("transpose.361")
#loc171 = loc("dot.363")
#loc172 = loc("reshape.364")
#loc173 = loc("logistic.365")
#loc174 = loc("multiply.366")
#loc175 = loc("reshape.131")
#loc176 = loc("custom-call.132")
#loc177 = loc("reshape.133")
#loc178 = loc("transpose.134")
#loc179 = loc("dot.355")
#loc180 = loc("reshape.356")
#loc181 = loc("multiply.367")
#loc182 = loc("reshape.368")
#loc183 = loc("reshape.126")
#loc184 = loc("custom-call.127")
#loc185 = loc("reshape.128")
#loc186 = loc("transpose.129")
#loc187 = loc("dot.369")
#loc188 = loc("reshape.370")
#loc189 = loc("add.373")
#loc190 = loc("convert.374")
#loc191 = loc("power.376")
#loc192 = loc("reduce.383")
#loc193 = loc("multiply.392")
#loc194 = loc("reshape.393")
#loc195 = loc("add.397")
#loc196 = loc("rsqrt.398")
#loc197 = loc("reshape.399")
#loc198 = loc("broadcast.400")
#loc199 = loc("multiply.401")
#loc200 = loc("convert.402")
#loc201 = loc("multiply.408")
#loc202 = loc("reshape.412")
#loc203 = loc("reshape.117")
#loc204 = loc("custom-call.118")
#loc205 = loc("reshape.119")
#loc206 = loc("transpose.120")
#loc207 = loc("dot.413")
#loc208 = loc("reshape.414")
------------------ END OF MLIR MODULE ------------------
2025-10-27 21:34:20.749 (  25.598s) [        9C771B80]      module_builder.cc:963      1| MLIR Module shlo_frontend:
#loc1 = loc("p0.1")
#loc2 = loc("p1.9")
#loc3 = loc("p2.14")
#loc4 = loc("p3.50")
#loc5 = loc("p4.70")
#loc6 = loc("p5.87")
#loc7 = loc("p6.116")
#loc8 = loc("p7.125")
#loc9 = loc("p8.130")
#loc10 = loc("p9.139")
#loc11 = loc("p10.212")
#loc12 = loc("p11.254")
#loc13 = loc("p12.348")
#loc14 = loc("p13.357")
#loc15 = loc("p14.403")
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1024x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p0.1"), %arg1: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"} loc("p1.9"), %arg2: tensor<128256x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p2.14"), %arg3: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p3.50"), %arg4: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p4.70"), %arg5: tensor<1024x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p5.87"), %arg6: tensor<128256x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___lm_head_weight"} loc("p6.116"), %arg7: tensor<8192x28672xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,8]<=[8,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p7.125"), %arg8: tensor<28672x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p8.130"), %arg9: tensor<8192x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,8]<=[8,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p9.139"), %arg10: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"} loc("p10.212"), %arg11: tensor<8192x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p11.254"), %arg12: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p12.348"), %arg13: tensor<28672x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p13.357"), %arg14: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_norm_weight"} loc("p14.403")) -> (tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %c = stablehlo.constant dense<"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tensor<136xi64> loc(#loc)
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32> loc(#loc)
    %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32> loc(#loc)
    %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32> loc(#loc)
    %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16> loc(#loc)
    %c_6 = stablehlo.constant dense<1> : tensor<i64> loc(#loc)
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16> loc(#loc)
    %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16> loc(#loc)
    %3 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16> loc(#loc)
    %4 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64> loc(#loc)
    %5 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<4x64x136x136xbf16> loc(#loc)
    %6 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<4x136x1xf32> loc(#loc)
    %7 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x136xf32> loc(#loc)
    %8 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x136x8192xf32> loc(#loc)
    %9 = stablehlo.reshape %arg3 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16> loc(#loc16)
    %10 = stablehlo.reshape %9 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16> loc(#loc17)
    %11 = stablehlo.broadcast_in_dim %10, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16> loc(#loc18)
    %12 = stablehlo.reshape %arg2 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16> loc(#loc19)
    %13 = stablehlo.reshape %12 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16> loc(#loc20)
    %14 = stablehlo.reshape %arg1 : (tensor<4x136xi64>) -> tensor<1x4x136xi64> loc(#loc21)
    %15 = stablehlo.reshape %14 : (tensor<1x4x136xi64>) -> tensor<544xi64> loc(#loc22)
    %16 = stablehlo.convert %15 : (tensor<544xi64>) -> tensor<544xui32> loc(#loc23)
    %17 = "stablehlo.gather"(%13, %16) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16> loc(#loc24)
    %18 = stablehlo.reshape %17 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16> loc(#loc25)
    %19 = stablehlo.convert %18 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32> loc(#loc26)
    %20 = stablehlo.power %19, %8 : tensor<4x136x8192xf32> loc(#loc27)
    %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32> loc(#loc28)
    %22 = stablehlo.multiply %21, %7 : tensor<4x136xf32> loc(#loc29)
    %23 = stablehlo.reshape %22 : (tensor<4x136xf32>) -> tensor<4x136x1xf32> loc(#loc30)
    %24 = stablehlo.add %23, %6 : tensor<4x136x1xf32> loc(#loc31)
    %25 = stablehlo.rsqrt %24 : tensor<4x136x1xf32> loc(#loc32)
    %26 = stablehlo.reshape %25 : (tensor<4x136x1xf32>) -> tensor<4x136xf32> loc(#loc33)
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32> loc(#loc34)
    %28 = stablehlo.multiply %19, %27 : tensor<4x136x8192xf32> loc(#loc35)
    %29 = stablehlo.convert %28 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16> loc(#loc36)
    %30 = stablehlo.multiply %11, %29 : tensor<4x136x8192xbf16> loc(#loc37)
    %31 = stablehlo.reshape %30 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16> loc(#loc38)
    %32 = stablehlo.reshape %arg0 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16> loc(#loc39)
    %33 = stablehlo.reshape %32 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16> loc(#loc40)
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16> loc(#loc41)
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16> loc(#loc42)
    %36 = stablehlo.reshape %35 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16> loc(#loc43)
    %37 = stablehlo.transpose %36, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16> loc(#loc44)
    %38 = stablehlo.reshape %arg5 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16> loc(#loc45)
    %39 = stablehlo.reshape %38 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16> loc(#loc46)
    %40 = stablehlo.transpose %39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16> loc(#loc47)
    %41 = stablehlo.dot_general %31, %40, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16> loc(#loc48)
    %42 = stablehlo.reshape %41 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16> loc(#loc49)
    %43 = stablehlo.transpose %42, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16> loc(#loc50)
    %44 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc51)
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc52)
    %46 = stablehlo.dot_general %45, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32> loc(#loc53)
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32> loc(#loc54)
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32> loc(#loc55)
    %49 = stablehlo.cosine %48 : tensor<1x136x128xf32> loc(#loc56)
    %50 = stablehlo.convert %49 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16> loc(#loc57)
    %51 = stablehlo.reshape %50 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16> loc(#loc58)
    %52 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16> loc(#loc59)
    %53 = stablehlo.multiply %43, %52 : tensor<4x8x136x128xbf16> loc(#loc60)
    %54 = stablehlo.slice %43 [0:4, 0:8, 0:136, 64:128] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16> loc(#loc61)
    %55 = stablehlo.negate %54 : tensor<4x8x136x64xbf16> loc(#loc62)
    %56 = stablehlo.slice %43 [0:4, 0:8, 0:136, 0:64] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16> loc(#loc63)
    %57 = stablehlo.concatenate %55, %56, dim = 3 : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16> loc(#loc64)
    %58 = stablehlo.sine %48 : tensor<1x136x128xf32> loc(#loc65)
    %59 = stablehlo.convert %58 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16> loc(#loc66)
    %60 = stablehlo.reshape %59 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16> loc(#loc67)
    %61 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16> loc(#loc68)
    %62 = stablehlo.multiply %57, %61 : tensor<4x8x136x128xbf16> loc(#loc69)
    %63 = stablehlo.add %53, %62 : tensor<4x8x136x128xbf16> loc(#loc70)
    %64 = stablehlo.reshape %arg14 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16> loc(#loc71)
    %65 = stablehlo.reshape %64 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16> loc(#loc72)
    %66 = stablehlo.broadcast_in_dim %65, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16> loc(#loc73)
    %67 = stablehlo.reshape %arg11 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16> loc(#loc74)
    %68 = stablehlo.reshape %67 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16> loc(#loc75)
    %69 = stablehlo.transpose %68, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16> loc(#loc76)
    %70 = stablehlo.dot_general %31, %69, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16> loc(#loc77)
    %71 = stablehlo.reshape %70 : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16> loc(#loc78)
    %72 = stablehlo.transpose %71, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16> loc(#loc79)
    %73 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16> loc(#loc80)
    %74 = stablehlo.multiply %72, %73 : tensor<4x64x136x128xbf16> loc(#loc81)
    %75 = stablehlo.slice %72 [0:4, 0:64, 0:136, 64:128] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16> loc(#loc82)
    %76 = stablehlo.negate %75 : tensor<4x64x136x64xbf16> loc(#loc83)
    %77 = stablehlo.slice %72 [0:4, 0:64, 0:136, 0:64] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16> loc(#loc84)
    %78 = stablehlo.concatenate %76, %77, dim = 3 : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16> loc(#loc85)
    %79 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16> loc(#loc86)
    %80 = stablehlo.multiply %78, %79 : tensor<4x64x136x128xbf16> loc(#loc87)
    %81 = stablehlo.add %74, %80 : tensor<4x64x136x128xbf16> loc(#loc88)
    %82 = stablehlo.reshape %81 : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16> loc(#loc89)
    %83 = stablehlo.broadcast_in_dim %63, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16> loc(#loc90)
    %84 = stablehlo.reshape %83 : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16> loc(#loc91)
    %85 = stablehlo.transpose %84, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16> loc(#loc92)
    %86 = stablehlo.reshape %85 : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16> loc(#loc93)
    %87 = stablehlo.dot_general %82, %86, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16> loc(#loc94)
    %88 = stablehlo.reshape %87 : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16> loc(#loc95)
    %89 = stablehlo.multiply %88, %5 : tensor<4x64x136x136xbf16> loc(#loc96)
    %90 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64> loc(#loc97)
    %91 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64> loc(#loc98)
    %92 = stablehlo.subtract %90, %91 : tensor<136x136xi64> loc(#loc99)
    %93 = stablehlo.compare  GE, %92, %4 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1> loc(#loc100)
    %94 = stablehlo.select %93, %3, %2 : tensor<136x136xi1>, tensor<136x136xbf16> loc(#loc101)
    %95 = stablehlo.compare  GT, %90, %91 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1> loc(#loc102)
    %96 = stablehlo.convert %95 : (tensor<136x136xi1>) -> tensor<136x136xbf16> loc(#loc103)
    %97 = stablehlo.multiply %94, %96 : tensor<136x136xbf16> loc(#loc104)
    %98 = stablehlo.reshape %97 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16> loc(#loc105)
    %99 = stablehlo.broadcast_in_dim %98, dims = [1, 2, 3] : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16> loc(#loc106)
    %100 = stablehlo.reshape %arg10 : (tensor<4x136xi64>) -> tensor<1x4x136xi64> loc(#loc107)
    %101 = stablehlo.reshape %100 : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64> loc(#loc108)
    %102 = stablehlo.convert %101 : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16> loc(#loc109)
    %103 = stablehlo.reshape %102 : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16> loc(#loc110)
    %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 3] : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16> loc(#loc111)
    %105 = stablehlo.add %99, %104 : tensor<4x1x136x136xbf16> loc(#loc112)
    %106 = stablehlo.compare  EQ, %105, %1 : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1> loc(#loc113)
    %107 = stablehlo.select %106, %0, %99 : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16> loc(#loc114)
    %108 = stablehlo.reshape %107 : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16> loc(#loc115)
    %109 = stablehlo.broadcast_in_dim %108, dims = [0, 2, 3] : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16> loc(#loc116)
    %110 = stablehlo.add %89, %109 : tensor<4x64x136x136xbf16> loc(#loc117)
    %111 = stablehlo.convert %110 : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32> loc(#loc118)
    %112 = stablehlo.reduce(%111 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32> loc(#loc119)
    %113 = stablehlo.broadcast_in_dim %112, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32> loc(#loc120)
    %114 = stablehlo.subtract %111, %113 : tensor<4x64x136x136xf32> loc(#loc121)
    %115 = stablehlo.exponential %114 : tensor<4x64x136x136xf32> loc(#loc122)
    %116 = stablehlo.reduce(%115 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32> loc(#loc123)
    %117 = stablehlo.broadcast_in_dim %116, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32> loc(#loc124)
    %118 = stablehlo.divide %115, %117 : tensor<4x64x136x136xf32> loc(#loc125)
    %119 = stablehlo.convert %118 : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16> loc(#loc126)
    %120 = stablehlo.reshape %119 : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16> loc(#loc127)
    %121 = stablehlo.broadcast_in_dim %37, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16> loc(#loc128)
    %122 = stablehlo.reshape %121 : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16> loc(#loc129)
    %123 = stablehlo.dot_general %120, %122, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16> loc(#loc130)
    %124 = stablehlo.reshape %123 : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16> loc(#loc131)
    %125 = stablehlo.transpose %124, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16> loc(#loc132)
    %126 = stablehlo.reshape %125 : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16> loc(#loc133)
    %127 = stablehlo.reshape %arg9 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16> loc(#loc134)
    %128 = stablehlo.reshape %127 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16> loc(#loc135)
    %129 = stablehlo.transpose %128, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16> loc(#loc136)
    %130 = stablehlo.dot_general %126, %129, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16> loc(#loc137)
    %131 = stablehlo.reshape %130 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16> loc(#loc138)
    %132 = stablehlo.add %18, %131 : tensor<4x136x8192xbf16> loc(#loc139)
    %133 = stablehlo.reshape %arg12 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16> loc(#loc140)
    %134 = stablehlo.reshape %133 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16> loc(#loc141)
    %135 = stablehlo.broadcast_in_dim %134, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16> loc(#loc142)
    %136 = stablehlo.convert %132 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32> loc(#loc143)
    %137 = stablehlo.power %136, %8 : tensor<4x136x8192xf32> loc(#loc144)
    %138 = stablehlo.reduce(%137 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32> loc(#loc145)
    %139 = stablehlo.multiply %138, %7 : tensor<4x136xf32> loc(#loc146)
    %140 = stablehlo.reshape %139 : (tensor<4x136xf32>) -> tensor<4x136x1xf32> loc(#loc147)
    %141 = stablehlo.add %140, %6 : tensor<4x136x1xf32> loc(#loc148)
    %142 = stablehlo.rsqrt %141 : tensor<4x136x1xf32> loc(#loc149)
    %143 = stablehlo.reshape %142 : (tensor<4x136x1xf32>) -> tensor<4x136xf32> loc(#loc150)
    %144 = stablehlo.broadcast_in_dim %143, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32> loc(#loc151)
    %145 = stablehlo.multiply %136, %144 : tensor<4x136x8192xf32> loc(#loc152)
    %146 = stablehlo.convert %145 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16> loc(#loc153)
    %147 = stablehlo.multiply %135, %146 : tensor<4x136x8192xbf16> loc(#loc154)
    %148 = stablehlo.reshape %147 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16> loc(#loc155)
    %149 = stablehlo.reshape %arg13 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16> loc(#loc156)
    %150 = stablehlo.reshape %149 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16> loc(#loc157)
    %151 = stablehlo.transpose %150, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16> loc(#loc158)
    %152 = stablehlo.dot_general %148, %151, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16> loc(#loc159)
    %153 = stablehlo.reshape %152 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16> loc(#loc160)
    %154 = stablehlo.logistic %153 : tensor<4x136x28672xbf16> loc(#loc161)
    %155 = stablehlo.multiply %153, %154 : tensor<4x136x28672xbf16> loc(#loc162)
    %156 = stablehlo.reshape %arg8 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16> loc(#loc163)
    %157 = stablehlo.reshape %156 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16> loc(#loc164)
    %158 = stablehlo.transpose %157, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16> loc(#loc165)
    %159 = stablehlo.dot_general %148, %158, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16> loc(#loc166)
    %160 = stablehlo.reshape %159 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16> loc(#loc167)
    %161 = stablehlo.multiply %155, %160 : tensor<4x136x28672xbf16> loc(#loc168)
    %162 = stablehlo.reshape %161 : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16> loc(#loc169)
    %163 = stablehlo.reshape %arg7 : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16> loc(#loc170)
    %164 = stablehlo.reshape %163 : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16> loc(#loc171)
    %165 = stablehlo.transpose %164, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16> loc(#loc172)
    %166 = stablehlo.dot_general %162, %165, contracting_dims = [1] x [0] : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16> loc(#loc173)
    %167 = stablehlo.reshape %166 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16> loc(#loc174)
    %168 = stablehlo.add %132, %167 : tensor<4x136x8192xbf16> loc(#loc175)
    %169 = stablehlo.convert %168 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32> loc(#loc176)
    %170 = stablehlo.power %169, %8 : tensor<4x136x8192xf32> loc(#loc177)
    %171 = stablehlo.reduce(%170 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32> loc(#loc178)
    %172 = stablehlo.multiply %171, %7 : tensor<4x136xf32> loc(#loc179)
    %173 = stablehlo.reshape %172 : (tensor<4x136xf32>) -> tensor<4x136x1xf32> loc(#loc180)
    %174 = stablehlo.add %173, %6 : tensor<4x136x1xf32> loc(#loc181)
    %175 = stablehlo.rsqrt %174 : tensor<4x136x1xf32> loc(#loc182)
    %176 = stablehlo.reshape %175 : (tensor<4x136x1xf32>) -> tensor<4x136xf32> loc(#loc183)
    %177 = stablehlo.broadcast_in_dim %176, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32> loc(#loc184)
    %178 = stablehlo.multiply %169, %177 : tensor<4x136x8192xf32> loc(#loc185)
    %179 = stablehlo.convert %178 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16> loc(#loc186)
    %180 = stablehlo.multiply %66, %179 : tensor<4x136x8192xbf16> loc(#loc187)
    %181 = stablehlo.reshape %180 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16> loc(#loc188)
    %182 = stablehlo.reshape %arg6 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16> loc(#loc189)
    %183 = stablehlo.reshape %182 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16> loc(#loc190)
    %184 = stablehlo.transpose %183, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16> loc(#loc191)
    %185 = stablehlo.dot_general %181, %184, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16> loc(#loc192)
    %186 = stablehlo.reshape %185 : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16> loc(#loc193)
    return %37, %63, %186 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc16 = loc("reshape.51")
#loc17 = loc("reshape.53")
#loc18 = loc("broadcast.54")
#loc19 = loc("reshape.15")
#loc20 = loc("reshape.17")
#loc21 = loc("reshape.10")
#loc22 = loc("reshape.13")
#loc23 = loc("convert.18")
#loc24 = loc("gather.19")
#loc25 = loc("reshape.20")
#loc26 = loc("convert.21")
#loc27 = loc("power.23")
#loc28 = loc("reduce.30")
#loc29 = loc("multiply.39")
#loc30 = loc("reshape.40")
#loc31 = loc("add.44")
#loc32 = loc("rsqrt.45")
#loc33 = loc("reshape.46")
#loc34 = loc("broadcast.47")
#loc35 = loc("multiply.48")
#loc36 = loc("convert.49")
#loc37 = loc("multiply.55")
#loc38 = loc("reshape.56")
#loc39 = loc("reshape.2")
#loc40 = loc("reshape.4")
#loc41 = loc("transpose.5")
#loc42 = loc("dot.57")
#loc43 = loc("reshape.59")
#loc44 = loc("transpose.60")
#loc45 = loc("reshape.88")
#loc46 = loc("reshape.90")
#loc47 = loc("transpose.91")
#loc48 = loc("dot.93")
#loc49 = loc("reshape.95")
#loc50 = loc("transpose.96")
#loc51 = loc("reshape.71")
#loc52 = loc("reshape.76")
#loc53 = loc("dot.79")
#loc54 = loc("transpose.80")
#loc55 = loc("concatenate.81")
#loc56 = loc("cosine.105")
#loc57 = loc("convert.108")
#loc58 = loc("reshape.110")
#loc59 = loc("broadcast.111")
#loc60 = loc("multiply.112")
#loc61 = loc("slice.98")
#loc62 = loc("negate.99")
#loc63 = loc("slice.97")
#loc64 = loc("concatenate.100")
#loc65 = loc("sine.82")
#loc66 = loc("convert.85")
#loc67 = loc("reshape.101")
#loc68 = loc("broadcast.102")
#loc69 = loc("multiply.103")
#loc70 = loc("add.115")
#loc71 = loc("reshape.404")
#loc72 = loc("reshape.406")
#loc73 = loc("broadcast.407")
#loc74 = loc("reshape.255")
#loc75 = loc("reshape.257")
#loc76 = loc("transpose.258")
#loc77 = loc("dot.260")
#loc78 = loc("reshape.262")
#loc79 = loc("transpose.263")
#loc80 = loc("broadcast.272")
#loc81 = loc("multiply.273")
#loc82 = loc("slice.265")
#loc83 = loc("negate.266")
#loc84 = loc("slice.264")
#loc85 = loc("concatenate.267")
#loc86 = loc("broadcast.269")
#loc87 = loc("multiply.270")
#loc88 = loc("add.276")
#loc89 = loc("reshape.278")
#loc90 = loc("broadcast.248")
#loc91 = loc("reshape.249")
#loc92 = loc("transpose.250")
#loc93 = loc("reshape.252")
#loc94 = loc("dot.279")
#loc95 = loc("reshape.280")
#loc96 = loc("multiply.282")
#loc97 = loc("broadcast.184")
#loc98 = loc("broadcast.186")
#loc99 = loc("subtract.187")
#loc100 = loc("compare.189")
#loc101 = loc("select.191")
#loc102 = loc("compare.161")
#loc103 = loc("convert.162")
#loc104 = loc("multiply.192")
#loc105 = loc("reshape.193")
#loc106 = loc("broadcast.199")
#loc107 = loc("reshape.213")
#loc108 = loc("reshape.218")
#loc109 = loc("convert.223")
#loc110 = loc("reshape.226")
#loc111 = loc("broadcast.227")
#loc112 = loc("add.228")
#loc113 = loc("compare.231")
#loc114 = loc("select.233")
#loc115 = loc("reshape.285")
#loc116 = loc("broadcast.286")
#loc117 = loc("add.287")
#loc118 = loc("convert.288")
#loc119 = loc("reduce.294")
#loc120 = loc("broadcast.295")
#loc121 = loc("subtract.296")
#loc122 = loc("exponential.297")
#loc123 = loc("reduce.303")
#loc124 = loc("broadcast.304")
#loc125 = loc("divide.305")
#loc126 = loc("convert.306")
#loc127 = loc("reshape.308")
#loc128 = loc("broadcast.151")
#loc129 = loc("reshape.154")
#loc130 = loc("dot.309")
#loc131 = loc("reshape.310")
#loc132 = loc("transpose.311")
#loc133 = loc("reshape.313")
#loc134 = loc("reshape.140")
#loc135 = loc("reshape.142")
#loc136 = loc("transpose.143")
#loc137 = loc("dot.314")
#loc138 = loc("reshape.315")
#loc139 = loc("add.318")
#loc140 = loc("reshape.349")
#loc141 = loc("reshape.351")
#loc142 = loc("broadcast.352")
#loc143 = loc("convert.319")
#loc144 = loc("power.321")
#loc145 = loc("reduce.328")
#loc146 = loc("multiply.337")
#loc147 = loc("reshape.338")
#loc148 = loc("add.342")
#loc149 = loc("rsqrt.343")
#loc150 = loc("reshape.344")
#loc151 = loc("broadcast.345")
#loc152 = loc("multiply.346")
#loc153 = loc("convert.347")
#loc154 = loc("multiply.353")
#loc155 = loc("reshape.362")
#loc156 = loc("reshape.358")
#loc157 = loc("reshape.360")
#loc158 = loc("transpose.361")
#loc159 = loc("dot.363")
#loc160 = loc("reshape.364")
#loc161 = loc("logistic.365")
#loc162 = loc("multiply.366")
#loc163 = loc("reshape.131")
#loc164 = loc("reshape.133")
#loc165 = loc("transpose.134")
#loc166 = loc("dot.355")
#loc167 = loc("reshape.356")
#loc168 = loc("multiply.367")
#loc169 = loc("reshape.368")
#loc170 = loc("reshape.126")
#loc171 = loc("reshape.128")
#loc172 = loc("transpose.129")
#loc173 = loc("dot.369")
#loc174 = loc("reshape.370")
#loc175 = loc("add.373")
#loc176 = loc("convert.374")
#loc177 = loc("power.376")
#loc178 = loc("reduce.383")
#loc179 = loc("multiply.392")
#loc180 = loc("reshape.393")
#loc181 = loc("add.397")
#loc182 = loc("rsqrt.398")
#loc183 = loc("reshape.399")
#loc184 = loc("broadcast.400")
#loc185 = loc("multiply.401")
#loc186 = loc("convert.402")
#loc187 = loc("multiply.408")
#loc188 = loc("reshape.412")
#loc189 = loc("reshape.117")
#loc190 = loc("reshape.119")
#loc191 = loc("transpose.120")
#loc192 = loc("dot.413")
#loc193 = loc("reshape.414")
------------------ END OF MLIR MODULE ------------------
// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @SyncTensorsGraph.416) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1024x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg1: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg2: tensor<128256x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg3: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg4: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg5: tensor<1024x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg6: tensor<128256x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___lm_head_weight"}, %arg7: tensor<8192x28672xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,8]<=[8,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg8: tensor<28672x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg9: tensor<8192x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,8]<=[8,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg10: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"}, %arg11: tensor<8192x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg12: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg13: tensor<28672x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg14: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<136xi64>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
    %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>
    %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16>
    %c_6 = stablehlo.constant dense<1> : tensor<i64>
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %3 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %4 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64>
    %5 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<4x64x136x136xbf16>
    %6 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<4x136x1xf32>
    %7 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x136xf32>
    %8 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x136x8192xf32>
    %9 = stablehlo.reshape %arg3 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %10 = stablehlo.reshape %9 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %11 = stablehlo.broadcast_in_dim %10, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %12 = stablehlo.reshape %arg2 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %13 = stablehlo.reshape %12 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %14 = stablehlo.reshape %arg1 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %15 = stablehlo.reshape %14 : (tensor<1x4x136xi64>) -> tensor<544xi64>
    %16 = stablehlo.convert %15 : (tensor<544xi64>) -> tensor<544xui32>
    %17 = "stablehlo.gather"(%13, %16) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16>
    %18 = stablehlo.reshape %17 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %19 = stablehlo.convert %18 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %20 = stablehlo.power %19, %8 : tensor<4x136x8192xf32>
    %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %22 = stablehlo.multiply %21, %7 : tensor<4x136xf32>
    %23 = stablehlo.reshape %22 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %24 = stablehlo.add %23, %6 : tensor<4x136x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<4x136x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %28 = stablehlo.multiply %19, %27 : tensor<4x136x8192xf32>
    %29 = stablehlo.convert %28 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %30 = stablehlo.multiply %11, %29 : tensor<4x136x8192xbf16>
    %31 = stablehlo.reshape %30 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %32 = stablehlo.reshape %arg0 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %36 = stablehlo.reshape %35 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %37 = stablehlo.transpose %36, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %38 = stablehlo.reshape %arg5 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %39 = stablehlo.reshape %38 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %40 = stablehlo.transpose %39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %41 = stablehlo.dot_general %31, %40, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %42 = stablehlo.reshape %41 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %43 = stablehlo.transpose %42, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %44 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.dot_general %45, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x136x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %51 = stablehlo.reshape %50 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %52 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %53 = stablehlo.multiply %43, %52 : tensor<4x8x136x128xbf16>
    %54 = stablehlo.slice %43 [0:4, 0:8, 0:136, 64:128] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %55 = stablehlo.negate %54 : tensor<4x8x136x64xbf16>
    %56 = stablehlo.slice %43 [0:4, 0:8, 0:136, 0:64] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %57 = stablehlo.concatenate %55, %56, dim = 3 : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16>
    %58 = stablehlo.sine %48 : tensor<1x136x128xf32>
    %59 = stablehlo.convert %58 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %60 = stablehlo.reshape %59 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %62 = stablehlo.multiply %57, %61 : tensor<4x8x136x128xbf16>
    %63 = stablehlo.add %53, %62 : tensor<4x8x136x128xbf16>
    %64 = stablehlo.reshape %arg14 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %65 = stablehlo.reshape %64 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %66 = stablehlo.broadcast_in_dim %65, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %67 = stablehlo.reshape %arg11 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %68 = stablehlo.reshape %67 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %69 = stablehlo.transpose %68, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %70 = stablehlo.dot_general %31, %69, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %71 = stablehlo.reshape %70 : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16>
    %72 = stablehlo.transpose %71, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16>
    %73 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %74 = stablehlo.multiply %72, %73 : tensor<4x64x136x128xbf16>
    %75 = stablehlo.slice %72 [0:4, 0:64, 0:136, 64:128] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %76 = stablehlo.negate %75 : tensor<4x64x136x64xbf16>
    %77 = stablehlo.slice %72 [0:4, 0:64, 0:136, 0:64] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %78 = stablehlo.concatenate %76, %77, dim = 3 : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16>
    %79 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %80 = stablehlo.multiply %78, %79 : tensor<4x64x136x128xbf16>
    %81 = stablehlo.add %74, %80 : tensor<4x64x136x128xbf16>
    %82 = stablehlo.reshape %81 : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16>
    %83 = stablehlo.broadcast_in_dim %63, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %84 = stablehlo.reshape %83 : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %85 = stablehlo.transpose %84, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16>
    %86 = stablehlo.reshape %85 : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16>
    %87 = stablehlo.dot_general %82, %86, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16>
    %88 = stablehlo.reshape %87 : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %89 = stablehlo.multiply %88, %5 : tensor<4x64x136x136xbf16>
    %90 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64>
    %91 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64>
    %92 = stablehlo.subtract %90, %91 : tensor<136x136xi64>
    %93 = stablehlo.compare  GE, %92, %4 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %94 = stablehlo.select %93, %3, %2 : tensor<136x136xi1>, tensor<136x136xbf16>
    %95 = stablehlo.compare  GT, %90, %91 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %96 = stablehlo.convert %95 : (tensor<136x136xi1>) -> tensor<136x136xbf16>
    %97 = stablehlo.multiply %94, %96 : tensor<136x136xbf16>
    %98 = stablehlo.reshape %97 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [1, 2, 3] : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16>
    %100 = stablehlo.reshape %arg10 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %101 = stablehlo.reshape %100 : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64>
    %102 = stablehlo.convert %101 : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16>
    %103 = stablehlo.reshape %102 : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16>
    %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 3] : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16>
    %105 = stablehlo.add %99, %104 : tensor<4x1x136x136xbf16>
    %106 = stablehlo.compare  EQ, %105, %1 : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1>
    %107 = stablehlo.select %106, %0, %99 : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16>
    %108 = stablehlo.reshape %107 : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16>
    %109 = stablehlo.broadcast_in_dim %108, dims = [0, 2, 3] : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %110 = stablehlo.add %89, %109 : tensor<4x64x136x136xbf16>
    %111 = stablehlo.convert %110 : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32>
    %112 = stablehlo.reduce(%111 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %113 = stablehlo.broadcast_in_dim %112, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %114 = stablehlo.subtract %111, %113 : tensor<4x64x136x136xf32>
    %115 = stablehlo.exponential %114 : tensor<4x64x136x136xf32>
    %116 = stablehlo.reduce(%115 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %117 = stablehlo.broadcast_in_dim %116, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %118 = stablehlo.divide %115, %117 : tensor<4x64x136x136xf32>
    %119 = stablehlo.convert %118 : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16>
    %120 = stablehlo.reshape %119 : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16>
    %121 = stablehlo.broadcast_in_dim %37, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %122 = stablehlo.reshape %121 : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16>
    %123 = stablehlo.dot_general %120, %122, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16>
    %124 = stablehlo.reshape %123 : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %125 = stablehlo.transpose %124, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16>
    %126 = stablehlo.reshape %125 : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16>
    %127 = stablehlo.reshape %arg9 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %128 = stablehlo.reshape %127 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %129 = stablehlo.transpose %128, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %130 = stablehlo.dot_general %126, %129, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %131 = stablehlo.reshape %130 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %132 = stablehlo.add %18, %131 : tensor<4x136x8192xbf16>
    %133 = stablehlo.reshape %arg12 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %134 = stablehlo.reshape %133 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %136 = stablehlo.convert %132 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %137 = stablehlo.power %136, %8 : tensor<4x136x8192xf32>
    %138 = stablehlo.reduce(%137 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %139 = stablehlo.multiply %138, %7 : tensor<4x136xf32>
    %140 = stablehlo.reshape %139 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %141 = stablehlo.add %140, %6 : tensor<4x136x1xf32>
    %142 = stablehlo.rsqrt %141 : tensor<4x136x1xf32>
    %143 = stablehlo.reshape %142 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %144 = stablehlo.broadcast_in_dim %143, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %145 = stablehlo.multiply %136, %144 : tensor<4x136x8192xf32>
    %146 = stablehlo.convert %145 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %147 = stablehlo.multiply %135, %146 : tensor<4x136x8192xbf16>
    %148 = stablehlo.reshape %147 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %149 = stablehlo.reshape %arg13 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %150 = stablehlo.reshape %149 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %151 = stablehlo.transpose %150, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %152 = stablehlo.dot_general %148, %151, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %153 = stablehlo.reshape %152 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %154 = stablehlo.logistic %153 : tensor<4x136x28672xbf16>
    %155 = stablehlo.multiply %153, %154 : tensor<4x136x28672xbf16>
    %156 = stablehlo.reshape %arg8 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %157 = stablehlo.reshape %156 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %158 = stablehlo.transpose %157, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %159 = stablehlo.dot_general %148, %158, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %160 = stablehlo.reshape %159 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %161 = stablehlo.multiply %155, %160 : tensor<4x136x28672xbf16>
    %162 = stablehlo.reshape %161 : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16>
    %163 = stablehlo.reshape %arg7 : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
    %164 = stablehlo.reshape %163 : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16>
    %165 = stablehlo.transpose %164, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16>
    %166 = stablehlo.dot_general %162, %165, contracting_dims = [1] x [0] : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16>
    %167 = stablehlo.reshape %166 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %168 = stablehlo.add %132, %167 : tensor<4x136x8192xbf16>
    %169 = stablehlo.convert %168 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %170 = stablehlo.power %169, %8 : tensor<4x136x8192xf32>
    %171 = stablehlo.reduce(%170 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %172 = stablehlo.multiply %171, %7 : tensor<4x136xf32>
    %173 = stablehlo.reshape %172 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %174 = stablehlo.add %173, %6 : tensor<4x136x1xf32>
    %175 = stablehlo.rsqrt %174 : tensor<4x136x1xf32>
    %176 = stablehlo.reshape %175 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %177 = stablehlo.broadcast_in_dim %176, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %178 = stablehlo.multiply %169, %177 : tensor<4x136x8192xf32>
    %179 = stablehlo.convert %178 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %180 = stablehlo.multiply %66, %179 : tensor<4x136x8192xbf16>
    %181 = stablehlo.reshape %180 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %182 = stablehlo.reshape %arg6 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %183 = stablehlo.reshape %182 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %184 = stablehlo.transpose %183, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16>
    %185 = stablehlo.dot_general %181, %184, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16>
    %186 = stablehlo.reshape %185 : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16>
    return %37, %63, %186 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1024x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg1: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg2: tensor<128256x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg3: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg4: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg5: tensor<1024x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg6: tensor<128256x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___lm_head_weight"}, %arg7: tensor<8192x28672xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,8]<=[8,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg8: tensor<28672x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg9: tensor<8192x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,8]<=[8,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg10: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"}, %arg11: tensor<8192x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg12: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg13: tensor<28672x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg14: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<136xi64>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
    %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>
    %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16>
    %c_6 = stablehlo.constant dense<1> : tensor<i64>
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %3 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %4 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64>
    %5 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<4x64x136x136xbf16>
    %6 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<4x136x1xf32>
    %7 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x136xf32>
    %8 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x136x8192xf32>
    %9 = stablehlo.reshape %arg3 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %10 = stablehlo.reshape %9 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %11 = stablehlo.broadcast_in_dim %10, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %12 = stablehlo.reshape %arg2 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %13 = stablehlo.reshape %12 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %14 = stablehlo.reshape %arg1 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %15 = stablehlo.reshape %14 : (tensor<1x4x136xi64>) -> tensor<544xi64>
    %16 = stablehlo.convert %15 : (tensor<544xi64>) -> tensor<544xui32>
    %17 = "stablehlo.gather"(%13, %16) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16>
    %18 = stablehlo.reshape %17 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %19 = stablehlo.convert %18 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %20 = stablehlo.power %19, %8 : tensor<4x136x8192xf32>
    %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %22 = stablehlo.multiply %21, %7 : tensor<4x136xf32>
    %23 = stablehlo.reshape %22 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %24 = stablehlo.add %23, %6 : tensor<4x136x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<4x136x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %28 = stablehlo.multiply %19, %27 : tensor<4x136x8192xf32>
    %29 = stablehlo.convert %28 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %30 = stablehlo.multiply %11, %29 : tensor<4x136x8192xbf16>
    %31 = stablehlo.reshape %30 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %32 = stablehlo.reshape %arg0 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %36 = stablehlo.reshape %35 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %37 = stablehlo.transpose %36, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %38 = stablehlo.reshape %arg5 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %39 = stablehlo.reshape %38 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %40 = stablehlo.transpose %39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %41 = stablehlo.dot_general %31, %40, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %42 = stablehlo.reshape %41 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %43 = stablehlo.transpose %42, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %44 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.dot_general %45, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x136x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %51 = stablehlo.reshape %50 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %52 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %53 = stablehlo.multiply %43, %52 : tensor<4x8x136x128xbf16>
    %54 = stablehlo.slice %43 [0:4, 0:8, 0:136, 64:128] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %55 = stablehlo.negate %54 : tensor<4x8x136x64xbf16>
    %56 = stablehlo.slice %43 [0:4, 0:8, 0:136, 0:64] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %57 = stablehlo.concatenate %55, %56, dim = 3 : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16>
    %58 = stablehlo.sine %48 : tensor<1x136x128xf32>
    %59 = stablehlo.convert %58 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %60 = stablehlo.reshape %59 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %62 = stablehlo.multiply %57, %61 : tensor<4x8x136x128xbf16>
    %63 = stablehlo.add %53, %62 : tensor<4x8x136x128xbf16>
    %64 = stablehlo.reshape %arg14 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %65 = stablehlo.reshape %64 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %66 = stablehlo.broadcast_in_dim %65, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %67 = stablehlo.reshape %arg11 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %68 = stablehlo.reshape %67 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %69 = stablehlo.transpose %68, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %70 = stablehlo.dot_general %31, %69, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %71 = stablehlo.reshape %70 : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16>
    %72 = stablehlo.transpose %71, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16>
    %73 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %74 = stablehlo.multiply %72, %73 : tensor<4x64x136x128xbf16>
    %75 = stablehlo.slice %72 [0:4, 0:64, 0:136, 64:128] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %76 = stablehlo.negate %75 : tensor<4x64x136x64xbf16>
    %77 = stablehlo.slice %72 [0:4, 0:64, 0:136, 0:64] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %78 = stablehlo.concatenate %76, %77, dim = 3 : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16>
    %79 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %80 = stablehlo.multiply %78, %79 : tensor<4x64x136x128xbf16>
    %81 = stablehlo.add %74, %80 : tensor<4x64x136x128xbf16>
    %82 = stablehlo.reshape %81 : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16>
    %83 = stablehlo.broadcast_in_dim %63, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %84 = stablehlo.reshape %83 : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %85 = stablehlo.transpose %84, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16>
    %86 = stablehlo.reshape %85 : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16>
    %87 = stablehlo.dot_general %82, %86, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16>
    %88 = stablehlo.reshape %87 : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %89 = stablehlo.multiply %88, %5 : tensor<4x64x136x136xbf16>
    %90 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64>
    %91 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64>
    %92 = stablehlo.subtract %90, %91 : tensor<136x136xi64>
    %93 = stablehlo.compare  GE, %92, %4 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %94 = stablehlo.select %93, %3, %2 : tensor<136x136xi1>, tensor<136x136xbf16>
    %95 = stablehlo.compare  GT, %90, %91 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %96 = stablehlo.convert %95 : (tensor<136x136xi1>) -> tensor<136x136xbf16>
    %97 = stablehlo.multiply %94, %96 : tensor<136x136xbf16>
    %98 = stablehlo.reshape %97 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [1, 2, 3] : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16>
    %100 = stablehlo.reshape %arg10 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %101 = stablehlo.reshape %100 : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64>
    %102 = stablehlo.convert %101 : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16>
    %103 = stablehlo.reshape %102 : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16>
    %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 3] : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16>
    %105 = stablehlo.add %99, %104 : tensor<4x1x136x136xbf16>
    %106 = stablehlo.compare  EQ, %105, %1 : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1>
    %107 = stablehlo.select %106, %0, %99 : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16>
    %108 = stablehlo.reshape %107 : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16>
    %109 = stablehlo.broadcast_in_dim %108, dims = [0, 2, 3] : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %110 = stablehlo.add %89, %109 : tensor<4x64x136x136xbf16>
    %111 = stablehlo.convert %110 : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32>
    %112 = stablehlo.reduce(%111 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %113 = stablehlo.broadcast_in_dim %112, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %114 = stablehlo.subtract %111, %113 : tensor<4x64x136x136xf32>
    %115 = stablehlo.exponential %114 : tensor<4x64x136x136xf32>
    %116 = stablehlo.reduce(%115 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %117 = stablehlo.broadcast_in_dim %116, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %118 = stablehlo.divide %115, %117 : tensor<4x64x136x136xf32>
    %119 = stablehlo.convert %118 : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16>
    %120 = stablehlo.reshape %119 : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16>
    %121 = stablehlo.broadcast_in_dim %37, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %122 = stablehlo.reshape %121 : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16>
    %123 = stablehlo.dot_general %120, %122, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16>
    %124 = stablehlo.reshape %123 : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %125 = stablehlo.transpose %124, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16>
    %126 = stablehlo.reshape %125 : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16>
    %127 = stablehlo.reshape %arg9 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %128 = stablehlo.reshape %127 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %129 = stablehlo.transpose %128, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %130 = stablehlo.dot_general %126, %129, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %131 = stablehlo.reshape %130 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %132 = stablehlo.add %18, %131 : tensor<4x136x8192xbf16>
    %133 = stablehlo.reshape %arg12 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %134 = stablehlo.reshape %133 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %136 = stablehlo.convert %132 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %137 = stablehlo.power %136, %8 : tensor<4x136x8192xf32>
    %138 = stablehlo.reduce(%137 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %139 = stablehlo.multiply %138, %7 : tensor<4x136xf32>
    %140 = stablehlo.reshape %139 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %141 = stablehlo.add %140, %6 : tensor<4x136x1xf32>
    %142 = stablehlo.rsqrt %141 : tensor<4x136x1xf32>
    %143 = stablehlo.reshape %142 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %144 = stablehlo.broadcast_in_dim %143, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %145 = stablehlo.multiply %136, %144 : tensor<4x136x8192xf32>
    %146 = stablehlo.convert %145 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %147 = stablehlo.multiply %135, %146 : tensor<4x136x8192xbf16>
    %148 = stablehlo.reshape %147 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %149 = stablehlo.reshape %arg13 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %150 = stablehlo.reshape %149 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %151 = stablehlo.transpose %150, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %152 = stablehlo.dot_general %148, %151, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %153 = stablehlo.reshape %152 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %154 = stablehlo.logistic %153 : tensor<4x136x28672xbf16>
    %155 = stablehlo.multiply %153, %154 : tensor<4x136x28672xbf16>
    %156 = stablehlo.reshape %arg8 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %157 = stablehlo.reshape %156 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %158 = stablehlo.transpose %157, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %159 = stablehlo.dot_general %148, %158, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %160 = stablehlo.reshape %159 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %161 = stablehlo.multiply %155, %160 : tensor<4x136x28672xbf16>
    %162 = stablehlo.reshape %161 : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16>
    %163 = stablehlo.reshape %arg7 : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
    %164 = stablehlo.reshape %163 : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16>
    %165 = stablehlo.transpose %164, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16>
    %166 = stablehlo.dot_general %162, %165, contracting_dims = [1] x [0] : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16>
    %167 = stablehlo.reshape %166 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %168 = stablehlo.add %132, %167 : tensor<4x136x8192xbf16>
    %169 = stablehlo.convert %168 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %170 = stablehlo.power %169, %8 : tensor<4x136x8192xf32>
    %171 = stablehlo.reduce(%170 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %172 = stablehlo.multiply %171, %7 : tensor<4x136xf32>
    %173 = stablehlo.reshape %172 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %174 = stablehlo.add %173, %6 : tensor<4x136x1xf32>
    %175 = stablehlo.rsqrt %174 : tensor<4x136x1xf32>
    %176 = stablehlo.reshape %175 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %177 = stablehlo.broadcast_in_dim %176, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %178 = stablehlo.multiply %169, %177 : tensor<4x136x8192xf32>
    %179 = stablehlo.convert %178 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %180 = stablehlo.multiply %66, %179 : tensor<4x136x8192xbf16>
    %181 = stablehlo.reshape %180 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %182 = stablehlo.reshape %arg6 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %183 = stablehlo.reshape %182 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %184 = stablehlo.transpose %183, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16>
    %185 = stablehlo.dot_general %181, %184, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16>
    %186 = stablehlo.reshape %185 : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16>
    return %37, %63, %186 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
  }
}


// -----// IR Dump Before TTPopulateArgumentTypes (tt-populate-argument-types) ('builtin.module' operation: @SyncTensorsGraph.416) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1024x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg1: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg2: tensor<128256x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg3: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg4: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg5: tensor<1024x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg6: tensor<128256x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___lm_head_weight"}, %arg7: tensor<8192x28672xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,8]<=[8,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg8: tensor<28672x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg9: tensor<8192x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,8]<=[8,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg10: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"}, %arg11: tensor<8192x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg12: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg13: tensor<28672x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg14: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<136xi64>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
    %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>
    %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16>
    %c_6 = stablehlo.constant dense<1> : tensor<i64>
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %3 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %4 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64>
    %5 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<4x64x136x136xbf16>
    %6 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<4x136x1xf32>
    %7 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x136xf32>
    %8 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x136x8192xf32>
    %9 = stablehlo.reshape %arg3 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %10 = stablehlo.reshape %9 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %11 = stablehlo.broadcast_in_dim %10, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %12 = stablehlo.reshape %arg2 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %13 = stablehlo.reshape %12 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %14 = stablehlo.reshape %arg1 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %15 = stablehlo.reshape %14 : (tensor<1x4x136xi64>) -> tensor<544xi64>
    %16 = stablehlo.convert %15 : (tensor<544xi64>) -> tensor<544xui32>
    %17 = "stablehlo.gather"(%13, %16) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16>
    %18 = stablehlo.reshape %17 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %19 = stablehlo.convert %18 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %20 = stablehlo.power %19, %8 : tensor<4x136x8192xf32>
    %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %22 = stablehlo.multiply %21, %7 : tensor<4x136xf32>
    %23 = stablehlo.reshape %22 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %24 = stablehlo.add %23, %6 : tensor<4x136x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<4x136x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %28 = stablehlo.multiply %19, %27 : tensor<4x136x8192xf32>
    %29 = stablehlo.convert %28 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %30 = stablehlo.multiply %11, %29 : tensor<4x136x8192xbf16>
    %31 = stablehlo.reshape %30 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %32 = stablehlo.reshape %arg0 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %36 = stablehlo.reshape %35 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %37 = stablehlo.transpose %36, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %38 = stablehlo.reshape %arg5 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %39 = stablehlo.reshape %38 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %40 = stablehlo.transpose %39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %41 = stablehlo.dot_general %31, %40, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %42 = stablehlo.reshape %41 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %43 = stablehlo.transpose %42, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %44 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.dot_general %45, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x136x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %51 = stablehlo.reshape %50 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %52 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %53 = stablehlo.multiply %43, %52 : tensor<4x8x136x128xbf16>
    %54 = stablehlo.slice %43 [0:4, 0:8, 0:136, 64:128] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %55 = stablehlo.negate %54 : tensor<4x8x136x64xbf16>
    %56 = stablehlo.slice %43 [0:4, 0:8, 0:136, 0:64] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %57 = stablehlo.concatenate %55, %56, dim = 3 : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16>
    %58 = stablehlo.sine %48 : tensor<1x136x128xf32>
    %59 = stablehlo.convert %58 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %60 = stablehlo.reshape %59 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %62 = stablehlo.multiply %57, %61 : tensor<4x8x136x128xbf16>
    %63 = stablehlo.add %53, %62 : tensor<4x8x136x128xbf16>
    %64 = stablehlo.reshape %arg14 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %65 = stablehlo.reshape %64 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %66 = stablehlo.broadcast_in_dim %65, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %67 = stablehlo.reshape %arg11 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %68 = stablehlo.reshape %67 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %69 = stablehlo.transpose %68, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %70 = stablehlo.dot_general %31, %69, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %71 = stablehlo.reshape %70 : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16>
    %72 = stablehlo.transpose %71, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16>
    %73 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %74 = stablehlo.multiply %72, %73 : tensor<4x64x136x128xbf16>
    %75 = stablehlo.slice %72 [0:4, 0:64, 0:136, 64:128] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %76 = stablehlo.negate %75 : tensor<4x64x136x64xbf16>
    %77 = stablehlo.slice %72 [0:4, 0:64, 0:136, 0:64] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %78 = stablehlo.concatenate %76, %77, dim = 3 : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16>
    %79 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %80 = stablehlo.multiply %78, %79 : tensor<4x64x136x128xbf16>
    %81 = stablehlo.add %74, %80 : tensor<4x64x136x128xbf16>
    %82 = stablehlo.reshape %81 : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16>
    %83 = stablehlo.broadcast_in_dim %63, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %84 = stablehlo.reshape %83 : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %85 = stablehlo.transpose %84, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16>
    %86 = stablehlo.reshape %85 : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16>
    %87 = stablehlo.dot_general %82, %86, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16>
    %88 = stablehlo.reshape %87 : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %89 = stablehlo.multiply %88, %5 : tensor<4x64x136x136xbf16>
    %90 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64>
    %91 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64>
    %92 = stablehlo.subtract %90, %91 : tensor<136x136xi64>
    %93 = stablehlo.compare  GE, %92, %4 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %94 = stablehlo.select %93, %3, %2 : tensor<136x136xi1>, tensor<136x136xbf16>
    %95 = stablehlo.compare  GT, %90, %91 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %96 = stablehlo.convert %95 : (tensor<136x136xi1>) -> tensor<136x136xbf16>
    %97 = stablehlo.multiply %94, %96 : tensor<136x136xbf16>
    %98 = stablehlo.reshape %97 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [1, 2, 3] : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16>
    %100 = stablehlo.reshape %arg10 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %101 = stablehlo.reshape %100 : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64>
    %102 = stablehlo.convert %101 : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16>
    %103 = stablehlo.reshape %102 : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16>
    %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 3] : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16>
    %105 = stablehlo.add %99, %104 : tensor<4x1x136x136xbf16>
    %106 = stablehlo.compare  EQ, %105, %1 : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1>
    %107 = stablehlo.select %106, %0, %99 : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16>
    %108 = stablehlo.reshape %107 : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16>
    %109 = stablehlo.broadcast_in_dim %108, dims = [0, 2, 3] : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %110 = stablehlo.add %89, %109 : tensor<4x64x136x136xbf16>
    %111 = stablehlo.convert %110 : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32>
    %112 = stablehlo.reduce(%111 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %113 = stablehlo.broadcast_in_dim %112, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %114 = stablehlo.subtract %111, %113 : tensor<4x64x136x136xf32>
    %115 = stablehlo.exponential %114 : tensor<4x64x136x136xf32>
    %116 = stablehlo.reduce(%115 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %117 = stablehlo.broadcast_in_dim %116, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %118 = stablehlo.divide %115, %117 : tensor<4x64x136x136xf32>
    %119 = stablehlo.convert %118 : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16>
    %120 = stablehlo.reshape %119 : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16>
    %121 = stablehlo.broadcast_in_dim %37, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %122 = stablehlo.reshape %121 : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16>
    %123 = stablehlo.dot_general %120, %122, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16>
    %124 = stablehlo.reshape %123 : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %125 = stablehlo.transpose %124, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16>
    %126 = stablehlo.reshape %125 : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16>
    %127 = stablehlo.reshape %arg9 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %128 = stablehlo.reshape %127 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %129 = stablehlo.transpose %128, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %130 = stablehlo.dot_general %126, %129, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %131 = stablehlo.reshape %130 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %132 = stablehlo.add %18, %131 : tensor<4x136x8192xbf16>
    %133 = stablehlo.reshape %arg12 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %134 = stablehlo.reshape %133 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %136 = stablehlo.convert %132 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %137 = stablehlo.power %136, %8 : tensor<4x136x8192xf32>
    %138 = stablehlo.reduce(%137 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %139 = stablehlo.multiply %138, %7 : tensor<4x136xf32>
    %140 = stablehlo.reshape %139 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %141 = stablehlo.add %140, %6 : tensor<4x136x1xf32>
    %142 = stablehlo.rsqrt %141 : tensor<4x136x1xf32>
    %143 = stablehlo.reshape %142 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %144 = stablehlo.broadcast_in_dim %143, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %145 = stablehlo.multiply %136, %144 : tensor<4x136x8192xf32>
    %146 = stablehlo.convert %145 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %147 = stablehlo.multiply %135, %146 : tensor<4x136x8192xbf16>
    %148 = stablehlo.reshape %147 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %149 = stablehlo.reshape %arg13 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %150 = stablehlo.reshape %149 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %151 = stablehlo.transpose %150, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %152 = stablehlo.dot_general %148, %151, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %153 = stablehlo.reshape %152 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %154 = stablehlo.logistic %153 : tensor<4x136x28672xbf16>
    %155 = stablehlo.multiply %153, %154 : tensor<4x136x28672xbf16>
    %156 = stablehlo.reshape %arg8 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %157 = stablehlo.reshape %156 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %158 = stablehlo.transpose %157, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %159 = stablehlo.dot_general %148, %158, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %160 = stablehlo.reshape %159 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %161 = stablehlo.multiply %155, %160 : tensor<4x136x28672xbf16>
    %162 = stablehlo.reshape %161 : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16>
    %163 = stablehlo.reshape %arg7 : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
    %164 = stablehlo.reshape %163 : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16>
    %165 = stablehlo.transpose %164, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16>
    %166 = stablehlo.dot_general %162, %165, contracting_dims = [1] x [0] : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16>
    %167 = stablehlo.reshape %166 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %168 = stablehlo.add %132, %167 : tensor<4x136x8192xbf16>
    %169 = stablehlo.convert %168 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %170 = stablehlo.power %169, %8 : tensor<4x136x8192xf32>
    %171 = stablehlo.reduce(%170 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %172 = stablehlo.multiply %171, %7 : tensor<4x136xf32>
    %173 = stablehlo.reshape %172 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %174 = stablehlo.add %173, %6 : tensor<4x136x1xf32>
    %175 = stablehlo.rsqrt %174 : tensor<4x136x1xf32>
    %176 = stablehlo.reshape %175 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %177 = stablehlo.broadcast_in_dim %176, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %178 = stablehlo.multiply %169, %177 : tensor<4x136x8192xf32>
    %179 = stablehlo.convert %178 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %180 = stablehlo.multiply %66, %179 : tensor<4x136x8192xbf16>
    %181 = stablehlo.reshape %180 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %182 = stablehlo.reshape %arg6 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %183 = stablehlo.reshape %182 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %184 = stablehlo.transpose %183, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16>
    %185 = stablehlo.dot_general %181, %184, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16>
    %186 = stablehlo.reshape %185 : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16>
    return %37, %63, %186 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
  }
}


// -----// IR Dump Before ApplyArgumentShardStatusPass (apply-argument-shard-status) ('builtin.module' operation: @SyncTensorsGraph.416) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1024x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg1: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg2: tensor<128256x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg3: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg4: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg5: tensor<1024x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg6: tensor<128256x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___lm_head_weight"}, %arg7: tensor<8192x28672xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,8]<=[8,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg8: tensor<28672x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg9: tensor<8192x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,8]<=[8,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg10: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"}, %arg11: tensor<8192x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg12: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg13: tensor<28672x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg14: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<136xi64>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
    %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>
    %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16>
    %c_6 = stablehlo.constant dense<1> : tensor<i64>
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %3 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %4 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64>
    %5 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<4x64x136x136xbf16>
    %6 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<4x136x1xf32>
    %7 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x136xf32>
    %8 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x136x8192xf32>
    %9 = stablehlo.reshape %arg3 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %10 = stablehlo.reshape %9 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %11 = stablehlo.broadcast_in_dim %10, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %12 = stablehlo.reshape %arg2 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %13 = stablehlo.reshape %12 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %14 = stablehlo.reshape %arg1 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %15 = stablehlo.reshape %14 : (tensor<1x4x136xi64>) -> tensor<544xi64>
    %16 = stablehlo.convert %15 : (tensor<544xi64>) -> tensor<544xui32>
    %17 = "stablehlo.gather"(%13, %16) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16>
    %18 = stablehlo.reshape %17 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %19 = stablehlo.convert %18 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %20 = stablehlo.power %19, %8 : tensor<4x136x8192xf32>
    %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %22 = stablehlo.multiply %21, %7 : tensor<4x136xf32>
    %23 = stablehlo.reshape %22 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %24 = stablehlo.add %23, %6 : tensor<4x136x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<4x136x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %28 = stablehlo.multiply %19, %27 : tensor<4x136x8192xf32>
    %29 = stablehlo.convert %28 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %30 = stablehlo.multiply %11, %29 : tensor<4x136x8192xbf16>
    %31 = stablehlo.reshape %30 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %32 = stablehlo.reshape %arg0 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %36 = stablehlo.reshape %35 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %37 = stablehlo.transpose %36, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %38 = stablehlo.reshape %arg5 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %39 = stablehlo.reshape %38 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %40 = stablehlo.transpose %39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %41 = stablehlo.dot_general %31, %40, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %42 = stablehlo.reshape %41 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %43 = stablehlo.transpose %42, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %44 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.dot_general %45, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x136x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %51 = stablehlo.reshape %50 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %52 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %53 = stablehlo.multiply %43, %52 : tensor<4x8x136x128xbf16>
    %54 = stablehlo.slice %43 [0:4, 0:8, 0:136, 64:128] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %55 = stablehlo.negate %54 : tensor<4x8x136x64xbf16>
    %56 = stablehlo.slice %43 [0:4, 0:8, 0:136, 0:64] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %57 = stablehlo.concatenate %55, %56, dim = 3 : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16>
    %58 = stablehlo.sine %48 : tensor<1x136x128xf32>
    %59 = stablehlo.convert %58 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %60 = stablehlo.reshape %59 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %62 = stablehlo.multiply %57, %61 : tensor<4x8x136x128xbf16>
    %63 = stablehlo.add %53, %62 : tensor<4x8x136x128xbf16>
    %64 = stablehlo.reshape %arg14 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %65 = stablehlo.reshape %64 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %66 = stablehlo.broadcast_in_dim %65, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %67 = stablehlo.reshape %arg11 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %68 = stablehlo.reshape %67 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %69 = stablehlo.transpose %68, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %70 = stablehlo.dot_general %31, %69, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %71 = stablehlo.reshape %70 : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16>
    %72 = stablehlo.transpose %71, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16>
    %73 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %74 = stablehlo.multiply %72, %73 : tensor<4x64x136x128xbf16>
    %75 = stablehlo.slice %72 [0:4, 0:64, 0:136, 64:128] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %76 = stablehlo.negate %75 : tensor<4x64x136x64xbf16>
    %77 = stablehlo.slice %72 [0:4, 0:64, 0:136, 0:64] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %78 = stablehlo.concatenate %76, %77, dim = 3 : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16>
    %79 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %80 = stablehlo.multiply %78, %79 : tensor<4x64x136x128xbf16>
    %81 = stablehlo.add %74, %80 : tensor<4x64x136x128xbf16>
    %82 = stablehlo.reshape %81 : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16>
    %83 = stablehlo.broadcast_in_dim %63, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %84 = stablehlo.reshape %83 : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %85 = stablehlo.transpose %84, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16>
    %86 = stablehlo.reshape %85 : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16>
    %87 = stablehlo.dot_general %82, %86, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16>
    %88 = stablehlo.reshape %87 : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %89 = stablehlo.multiply %88, %5 : tensor<4x64x136x136xbf16>
    %90 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64>
    %91 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64>
    %92 = stablehlo.subtract %90, %91 : tensor<136x136xi64>
    %93 = stablehlo.compare  GE, %92, %4 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %94 = stablehlo.select %93, %3, %2 : tensor<136x136xi1>, tensor<136x136xbf16>
    %95 = stablehlo.compare  GT, %90, %91 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %96 = stablehlo.convert %95 : (tensor<136x136xi1>) -> tensor<136x136xbf16>
    %97 = stablehlo.multiply %94, %96 : tensor<136x136xbf16>
    %98 = stablehlo.reshape %97 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [1, 2, 3] : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16>
    %100 = stablehlo.reshape %arg10 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %101 = stablehlo.reshape %100 : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64>
    %102 = stablehlo.convert %101 : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16>
    %103 = stablehlo.reshape %102 : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16>
    %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 3] : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16>
    %105 = stablehlo.add %99, %104 : tensor<4x1x136x136xbf16>
    %106 = stablehlo.compare  EQ, %105, %1 : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1>
    %107 = stablehlo.select %106, %0, %99 : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16>
    %108 = stablehlo.reshape %107 : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16>
    %109 = stablehlo.broadcast_in_dim %108, dims = [0, 2, 3] : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %110 = stablehlo.add %89, %109 : tensor<4x64x136x136xbf16>
    %111 = stablehlo.convert %110 : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32>
    %112 = stablehlo.reduce(%111 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %113 = stablehlo.broadcast_in_dim %112, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %114 = stablehlo.subtract %111, %113 : tensor<4x64x136x136xf32>
    %115 = stablehlo.exponential %114 : tensor<4x64x136x136xf32>
    %116 = stablehlo.reduce(%115 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %117 = stablehlo.broadcast_in_dim %116, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %118 = stablehlo.divide %115, %117 : tensor<4x64x136x136xf32>
    %119 = stablehlo.convert %118 : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16>
    %120 = stablehlo.reshape %119 : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16>
    %121 = stablehlo.broadcast_in_dim %37, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %122 = stablehlo.reshape %121 : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16>
    %123 = stablehlo.dot_general %120, %122, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16>
    %124 = stablehlo.reshape %123 : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %125 = stablehlo.transpose %124, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16>
    %126 = stablehlo.reshape %125 : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16>
    %127 = stablehlo.reshape %arg9 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %128 = stablehlo.reshape %127 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %129 = stablehlo.transpose %128, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %130 = stablehlo.dot_general %126, %129, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %131 = stablehlo.reshape %130 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %132 = stablehlo.add %18, %131 : tensor<4x136x8192xbf16>
    %133 = stablehlo.reshape %arg12 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %134 = stablehlo.reshape %133 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %136 = stablehlo.convert %132 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %137 = stablehlo.power %136, %8 : tensor<4x136x8192xf32>
    %138 = stablehlo.reduce(%137 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %139 = stablehlo.multiply %138, %7 : tensor<4x136xf32>
    %140 = stablehlo.reshape %139 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %141 = stablehlo.add %140, %6 : tensor<4x136x1xf32>
    %142 = stablehlo.rsqrt %141 : tensor<4x136x1xf32>
    %143 = stablehlo.reshape %142 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %144 = stablehlo.broadcast_in_dim %143, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %145 = stablehlo.multiply %136, %144 : tensor<4x136x8192xf32>
    %146 = stablehlo.convert %145 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %147 = stablehlo.multiply %135, %146 : tensor<4x136x8192xbf16>
    %148 = stablehlo.reshape %147 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %149 = stablehlo.reshape %arg13 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %150 = stablehlo.reshape %149 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %151 = stablehlo.transpose %150, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %152 = stablehlo.dot_general %148, %151, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %153 = stablehlo.reshape %152 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %154 = stablehlo.logistic %153 : tensor<4x136x28672xbf16>
    %155 = stablehlo.multiply %153, %154 : tensor<4x136x28672xbf16>
    %156 = stablehlo.reshape %arg8 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %157 = stablehlo.reshape %156 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %158 = stablehlo.transpose %157, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %159 = stablehlo.dot_general %148, %158, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %160 = stablehlo.reshape %159 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %161 = stablehlo.multiply %155, %160 : tensor<4x136x28672xbf16>
    %162 = stablehlo.reshape %161 : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16>
    %163 = stablehlo.reshape %arg7 : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
    %164 = stablehlo.reshape %163 : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16>
    %165 = stablehlo.transpose %164, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16>
    %166 = stablehlo.dot_general %162, %165, contracting_dims = [1] x [0] : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16>
    %167 = stablehlo.reshape %166 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %168 = stablehlo.add %132, %167 : tensor<4x136x8192xbf16>
    %169 = stablehlo.convert %168 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %170 = stablehlo.power %169, %8 : tensor<4x136x8192xf32>
    %171 = stablehlo.reduce(%170 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %172 = stablehlo.multiply %171, %7 : tensor<4x136xf32>
    %173 = stablehlo.reshape %172 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %174 = stablehlo.add %173, %6 : tensor<4x136x1xf32>
    %175 = stablehlo.rsqrt %174 : tensor<4x136x1xf32>
    %176 = stablehlo.reshape %175 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %177 = stablehlo.broadcast_in_dim %176, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %178 = stablehlo.multiply %169, %177 : tensor<4x136x8192xf32>
    %179 = stablehlo.convert %178 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %180 = stablehlo.multiply %66, %179 : tensor<4x136x8192xbf16>
    %181 = stablehlo.reshape %180 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %182 = stablehlo.reshape %arg6 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %183 = stablehlo.reshape %182 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %184 = stablehlo.transpose %183, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16>
    %185 = stablehlo.dot_general %181, %184, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16>
    %186 = stablehlo.reshape %185 : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16>
    return %37, %63, %186 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
  }
}


// -----// IR Dump After ApplyArgumentShardStatusPass (apply-argument-shard-status) ('builtin.module' operation: @SyncTensorsGraph.416) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1024x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg1: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg2: tensor<128256x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg3: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg4: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg5: tensor<1024x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg6: tensor<128256x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg7: tensor<8192x28672xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,8]<=[8,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg8: tensor<28672x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg9: tensor<8192x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,8]<=[8,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg10: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg11: tensor<8192x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg12: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg13: tensor<28672x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg14: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<4x8x136x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x8x136x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x136x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<136xi64>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
    %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>
    %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16>
    %c_6 = stablehlo.constant dense<1> : tensor<i64>
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %3 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %4 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64>
    %5 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<4x64x136x136xbf16>
    %6 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<4x136x1xf32>
    %7 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x136xf32>
    %8 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x136x8192xf32>
    %9 = stablehlo.reshape %arg3 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %10 = stablehlo.reshape %9 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %11 = stablehlo.broadcast_in_dim %10, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %12 = stablehlo.reshape %arg2 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %13 = stablehlo.reshape %12 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %14 = stablehlo.reshape %arg1 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %15 = stablehlo.reshape %14 : (tensor<1x4x136xi64>) -> tensor<544xi64>
    %16 = stablehlo.convert %15 : (tensor<544xi64>) -> tensor<544xui32>
    %17 = "stablehlo.gather"(%13, %16) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16>
    %18 = stablehlo.reshape %17 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %19 = stablehlo.convert %18 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %20 = stablehlo.power %19, %8 : tensor<4x136x8192xf32>
    %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %22 = stablehlo.multiply %21, %7 : tensor<4x136xf32>
    %23 = stablehlo.reshape %22 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %24 = stablehlo.add %23, %6 : tensor<4x136x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<4x136x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %28 = stablehlo.multiply %19, %27 : tensor<4x136x8192xf32>
    %29 = stablehlo.convert %28 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %30 = stablehlo.multiply %11, %29 : tensor<4x136x8192xbf16>
    %31 = stablehlo.reshape %30 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %32 = stablehlo.reshape %arg0 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %36 = stablehlo.reshape %35 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %37 = stablehlo.transpose %36, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %38 = stablehlo.reshape %arg5 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %39 = stablehlo.reshape %38 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %40 = stablehlo.transpose %39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %41 = stablehlo.dot_general %31, %40, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %42 = stablehlo.reshape %41 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %43 = stablehlo.transpose %42, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %44 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.dot_general %45, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x136x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %51 = stablehlo.reshape %50 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %52 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %53 = stablehlo.multiply %43, %52 : tensor<4x8x136x128xbf16>
    %54 = stablehlo.slice %43 [0:4, 0:8, 0:136, 64:128] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %55 = stablehlo.negate %54 : tensor<4x8x136x64xbf16>
    %56 = stablehlo.slice %43 [0:4, 0:8, 0:136, 0:64] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %57 = stablehlo.concatenate %55, %56, dim = 3 : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16>
    %58 = stablehlo.sine %48 : tensor<1x136x128xf32>
    %59 = stablehlo.convert %58 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %60 = stablehlo.reshape %59 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %62 = stablehlo.multiply %57, %61 : tensor<4x8x136x128xbf16>
    %63 = stablehlo.add %53, %62 : tensor<4x8x136x128xbf16>
    %64 = stablehlo.reshape %arg14 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %65 = stablehlo.reshape %64 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %66 = stablehlo.broadcast_in_dim %65, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %67 = stablehlo.reshape %arg11 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %68 = stablehlo.reshape %67 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %69 = stablehlo.transpose %68, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %70 = stablehlo.dot_general %31, %69, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %71 = stablehlo.reshape %70 : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16>
    %72 = stablehlo.transpose %71, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16>
    %73 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %74 = stablehlo.multiply %72, %73 : tensor<4x64x136x128xbf16>
    %75 = stablehlo.slice %72 [0:4, 0:64, 0:136, 64:128] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %76 = stablehlo.negate %75 : tensor<4x64x136x64xbf16>
    %77 = stablehlo.slice %72 [0:4, 0:64, 0:136, 0:64] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %78 = stablehlo.concatenate %76, %77, dim = 3 : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16>
    %79 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %80 = stablehlo.multiply %78, %79 : tensor<4x64x136x128xbf16>
    %81 = stablehlo.add %74, %80 : tensor<4x64x136x128xbf16>
    %82 = stablehlo.reshape %81 : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16>
    %83 = stablehlo.broadcast_in_dim %63, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %84 = stablehlo.reshape %83 : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %85 = stablehlo.transpose %84, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16>
    %86 = stablehlo.reshape %85 : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16>
    %87 = stablehlo.dot_general %82, %86, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16>
    %88 = stablehlo.reshape %87 : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %89 = stablehlo.multiply %88, %5 : tensor<4x64x136x136xbf16>
    %90 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64>
    %91 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64>
    %92 = stablehlo.subtract %90, %91 : tensor<136x136xi64>
    %93 = stablehlo.compare  GE, %92, %4 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %94 = stablehlo.select %93, %3, %2 : tensor<136x136xi1>, tensor<136x136xbf16>
    %95 = stablehlo.compare  GT, %90, %91 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %96 = stablehlo.convert %95 : (tensor<136x136xi1>) -> tensor<136x136xbf16>
    %97 = stablehlo.multiply %94, %96 : tensor<136x136xbf16>
    %98 = stablehlo.reshape %97 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [1, 2, 3] : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16>
    %100 = stablehlo.reshape %arg10 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %101 = stablehlo.reshape %100 : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64>
    %102 = stablehlo.convert %101 : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16>
    %103 = stablehlo.reshape %102 : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16>
    %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 3] : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16>
    %105 = stablehlo.add %99, %104 : tensor<4x1x136x136xbf16>
    %106 = stablehlo.compare  EQ, %105, %1 : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1>
    %107 = stablehlo.select %106, %0, %99 : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16>
    %108 = stablehlo.reshape %107 : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16>
    %109 = stablehlo.broadcast_in_dim %108, dims = [0, 2, 3] : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %110 = stablehlo.add %89, %109 : tensor<4x64x136x136xbf16>
    %111 = stablehlo.convert %110 : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32>
    %112 = stablehlo.reduce(%111 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %113 = stablehlo.broadcast_in_dim %112, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %114 = stablehlo.subtract %111, %113 : tensor<4x64x136x136xf32>
    %115 = stablehlo.exponential %114 : tensor<4x64x136x136xf32>
    %116 = stablehlo.reduce(%115 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %117 = stablehlo.broadcast_in_dim %116, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %118 = stablehlo.divide %115, %117 : tensor<4x64x136x136xf32>
    %119 = stablehlo.convert %118 : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16>
    %120 = stablehlo.reshape %119 : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16>
    %121 = stablehlo.broadcast_in_dim %37, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %122 = stablehlo.reshape %121 : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16>
    %123 = stablehlo.dot_general %120, %122, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16>
    %124 = stablehlo.reshape %123 : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %125 = stablehlo.transpose %124, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16>
    %126 = stablehlo.reshape %125 : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16>
    %127 = stablehlo.reshape %arg9 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %128 = stablehlo.reshape %127 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %129 = stablehlo.transpose %128, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %130 = stablehlo.dot_general %126, %129, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %131 = stablehlo.reshape %130 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %132 = stablehlo.add %18, %131 : tensor<4x136x8192xbf16>
    %133 = stablehlo.reshape %arg12 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %134 = stablehlo.reshape %133 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %136 = stablehlo.convert %132 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %137 = stablehlo.power %136, %8 : tensor<4x136x8192xf32>
    %138 = stablehlo.reduce(%137 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %139 = stablehlo.multiply %138, %7 : tensor<4x136xf32>
    %140 = stablehlo.reshape %139 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %141 = stablehlo.add %140, %6 : tensor<4x136x1xf32>
    %142 = stablehlo.rsqrt %141 : tensor<4x136x1xf32>
    %143 = stablehlo.reshape %142 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %144 = stablehlo.broadcast_in_dim %143, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %145 = stablehlo.multiply %136, %144 : tensor<4x136x8192xf32>
    %146 = stablehlo.convert %145 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %147 = stablehlo.multiply %135, %146 : tensor<4x136x8192xbf16>
    %148 = stablehlo.reshape %147 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %149 = stablehlo.reshape %arg13 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %150 = stablehlo.reshape %149 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %151 = stablehlo.transpose %150, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %152 = stablehlo.dot_general %148, %151, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %153 = stablehlo.reshape %152 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %154 = stablehlo.logistic %153 : tensor<4x136x28672xbf16>
    %155 = stablehlo.multiply %153, %154 : tensor<4x136x28672xbf16>
    %156 = stablehlo.reshape %arg8 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %157 = stablehlo.reshape %156 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %158 = stablehlo.transpose %157, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %159 = stablehlo.dot_general %148, %158, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %160 = stablehlo.reshape %159 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %161 = stablehlo.multiply %155, %160 : tensor<4x136x28672xbf16>
    %162 = stablehlo.reshape %161 : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16>
    %163 = stablehlo.reshape %arg7 : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
    %164 = stablehlo.reshape %163 : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16>
    %165 = stablehlo.transpose %164, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16>
    %166 = stablehlo.dot_general %162, %165, contracting_dims = [1] x [0] : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16>
    %167 = stablehlo.reshape %166 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %168 = stablehlo.add %132, %167 : tensor<4x136x8192xbf16>
    %169 = stablehlo.convert %168 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %170 = stablehlo.power %169, %8 : tensor<4x136x8192xf32>
    %171 = stablehlo.reduce(%170 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %172 = stablehlo.multiply %171, %7 : tensor<4x136xf32>
    %173 = stablehlo.reshape %172 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %174 = stablehlo.add %173, %6 : tensor<4x136x1xf32>
    %175 = stablehlo.rsqrt %174 : tensor<4x136x1xf32>
    %176 = stablehlo.reshape %175 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %177 = stablehlo.broadcast_in_dim %176, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %178 = stablehlo.multiply %169, %177 : tensor<4x136x8192xf32>
    %179 = stablehlo.convert %178 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %180 = stablehlo.multiply %66, %179 : tensor<4x136x8192xbf16>
    %181 = stablehlo.reshape %180 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %182 = stablehlo.reshape %arg6 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %183 = stablehlo.reshape %182 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %184 = stablehlo.transpose %183, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16>
    %185 = stablehlo.dot_general %181, %184, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16>
    %186 = stablehlo.reshape %185 : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16>
    return %37, %63, %186 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
  }
}


// -----// IR Dump Before ConvertXlaSdyToSdyPass (convert-xla-sdy-to-sdy) ('builtin.module' operation: @SyncTensorsGraph.416) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1024x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg1: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg2: tensor<128256x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg3: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg4: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg5: tensor<1024x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg6: tensor<128256x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg7: tensor<8192x28672xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,8]<=[8,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg8: tensor<28672x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg9: tensor<8192x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,8]<=[8,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg10: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg11: tensor<8192x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg12: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg13: tensor<28672x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[8,4]<=[32]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg14: tensor<8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<4x8x136x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x8x136x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x136x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<136xi64>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
    %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>
    %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16>
    %c_6 = stablehlo.constant dense<1> : tensor<i64>
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %3 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %4 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64>
    %5 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<4x64x136x136xbf16>
    %6 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<4x136x1xf32>
    %7 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x136xf32>
    %8 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x136x8192xf32>
    %9 = stablehlo.reshape %arg3 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %10 = stablehlo.reshape %9 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %11 = stablehlo.broadcast_in_dim %10, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %12 = stablehlo.reshape %arg2 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %13 = stablehlo.reshape %12 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %14 = stablehlo.reshape %arg1 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %15 = stablehlo.reshape %14 : (tensor<1x4x136xi64>) -> tensor<544xi64>
    %16 = stablehlo.convert %15 : (tensor<544xi64>) -> tensor<544xui32>
    %17 = "stablehlo.gather"(%13, %16) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16>
    %18 = stablehlo.reshape %17 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %19 = stablehlo.convert %18 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %20 = stablehlo.power %19, %8 : tensor<4x136x8192xf32>
    %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %22 = stablehlo.multiply %21, %7 : tensor<4x136xf32>
    %23 = stablehlo.reshape %22 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %24 = stablehlo.add %23, %6 : tensor<4x136x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<4x136x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %28 = stablehlo.multiply %19, %27 : tensor<4x136x8192xf32>
    %29 = stablehlo.convert %28 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %30 = stablehlo.multiply %11, %29 : tensor<4x136x8192xbf16>
    %31 = stablehlo.reshape %30 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %32 = stablehlo.reshape %arg0 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %36 = stablehlo.reshape %35 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %37 = stablehlo.transpose %36, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %38 = stablehlo.reshape %arg5 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %39 = stablehlo.reshape %38 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %40 = stablehlo.transpose %39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %41 = stablehlo.dot_general %31, %40, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %42 = stablehlo.reshape %41 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %43 = stablehlo.transpose %42, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %44 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.dot_general %45, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x136x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %51 = stablehlo.reshape %50 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %52 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %53 = stablehlo.multiply %43, %52 : tensor<4x8x136x128xbf16>
    %54 = stablehlo.slice %43 [0:4, 0:8, 0:136, 64:128] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %55 = stablehlo.negate %54 : tensor<4x8x136x64xbf16>
    %56 = stablehlo.slice %43 [0:4, 0:8, 0:136, 0:64] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %57 = stablehlo.concatenate %55, %56, dim = 3 : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16>
    %58 = stablehlo.sine %48 : tensor<1x136x128xf32>
    %59 = stablehlo.convert %58 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %60 = stablehlo.reshape %59 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %62 = stablehlo.multiply %57, %61 : tensor<4x8x136x128xbf16>
    %63 = stablehlo.add %53, %62 : tensor<4x8x136x128xbf16>
    %64 = stablehlo.reshape %arg14 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %65 = stablehlo.reshape %64 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %66 = stablehlo.broadcast_in_dim %65, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %67 = stablehlo.reshape %arg11 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %68 = stablehlo.reshape %67 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %69 = stablehlo.transpose %68, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %70 = stablehlo.dot_general %31, %69, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %71 = stablehlo.reshape %70 : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16>
    %72 = stablehlo.transpose %71, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16>
    %73 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %74 = stablehlo.multiply %72, %73 : tensor<4x64x136x128xbf16>
    %75 = stablehlo.slice %72 [0:4, 0:64, 0:136, 64:128] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %76 = stablehlo.negate %75 : tensor<4x64x136x64xbf16>
    %77 = stablehlo.slice %72 [0:4, 0:64, 0:136, 0:64] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %78 = stablehlo.concatenate %76, %77, dim = 3 : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16>
    %79 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %80 = stablehlo.multiply %78, %79 : tensor<4x64x136x128xbf16>
    %81 = stablehlo.add %74, %80 : tensor<4x64x136x128xbf16>
    %82 = stablehlo.reshape %81 : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16>
    %83 = stablehlo.broadcast_in_dim %63, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %84 = stablehlo.reshape %83 : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %85 = stablehlo.transpose %84, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16>
    %86 = stablehlo.reshape %85 : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16>
    %87 = stablehlo.dot_general %82, %86, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16>
    %88 = stablehlo.reshape %87 : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %89 = stablehlo.multiply %88, %5 : tensor<4x64x136x136xbf16>
    %90 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64>
    %91 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64>
    %92 = stablehlo.subtract %90, %91 : tensor<136x136xi64>
    %93 = stablehlo.compare  GE, %92, %4 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %94 = stablehlo.select %93, %3, %2 : tensor<136x136xi1>, tensor<136x136xbf16>
    %95 = stablehlo.compare  GT, %90, %91 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %96 = stablehlo.convert %95 : (tensor<136x136xi1>) -> tensor<136x136xbf16>
    %97 = stablehlo.multiply %94, %96 : tensor<136x136xbf16>
    %98 = stablehlo.reshape %97 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [1, 2, 3] : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16>
    %100 = stablehlo.reshape %arg10 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %101 = stablehlo.reshape %100 : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64>
    %102 = stablehlo.convert %101 : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16>
    %103 = stablehlo.reshape %102 : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16>
    %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 3] : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16>
    %105 = stablehlo.add %99, %104 : tensor<4x1x136x136xbf16>
    %106 = stablehlo.compare  EQ, %105, %1 : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1>
    %107 = stablehlo.select %106, %0, %99 : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16>
    %108 = stablehlo.reshape %107 : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16>
    %109 = stablehlo.broadcast_in_dim %108, dims = [0, 2, 3] : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %110 = stablehlo.add %89, %109 : tensor<4x64x136x136xbf16>
    %111 = stablehlo.convert %110 : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32>
    %112 = stablehlo.reduce(%111 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %113 = stablehlo.broadcast_in_dim %112, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %114 = stablehlo.subtract %111, %113 : tensor<4x64x136x136xf32>
    %115 = stablehlo.exponential %114 : tensor<4x64x136x136xf32>
    %116 = stablehlo.reduce(%115 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %117 = stablehlo.broadcast_in_dim %116, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %118 = stablehlo.divide %115, %117 : tensor<4x64x136x136xf32>
    %119 = stablehlo.convert %118 : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16>
    %120 = stablehlo.reshape %119 : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16>
    %121 = stablehlo.broadcast_in_dim %37, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %122 = stablehlo.reshape %121 : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16>
    %123 = stablehlo.dot_general %120, %122, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16>
    %124 = stablehlo.reshape %123 : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %125 = stablehlo.transpose %124, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16>
    %126 = stablehlo.reshape %125 : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16>
    %127 = stablehlo.reshape %arg9 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %128 = stablehlo.reshape %127 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %129 = stablehlo.transpose %128, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %130 = stablehlo.dot_general %126, %129, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %131 = stablehlo.reshape %130 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %132 = stablehlo.add %18, %131 : tensor<4x136x8192xbf16>
    %133 = stablehlo.reshape %arg12 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %134 = stablehlo.reshape %133 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %136 = stablehlo.convert %132 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %137 = stablehlo.power %136, %8 : tensor<4x136x8192xf32>
    %138 = stablehlo.reduce(%137 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %139 = stablehlo.multiply %138, %7 : tensor<4x136xf32>
    %140 = stablehlo.reshape %139 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %141 = stablehlo.add %140, %6 : tensor<4x136x1xf32>
    %142 = stablehlo.rsqrt %141 : tensor<4x136x1xf32>
    %143 = stablehlo.reshape %142 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %144 = stablehlo.broadcast_in_dim %143, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %145 = stablehlo.multiply %136, %144 : tensor<4x136x8192xf32>
    %146 = stablehlo.convert %145 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %147 = stablehlo.multiply %135, %146 : tensor<4x136x8192xbf16>
    %148 = stablehlo.reshape %147 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %149 = stablehlo.reshape %arg13 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %150 = stablehlo.reshape %149 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %151 = stablehlo.transpose %150, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %152 = stablehlo.dot_general %148, %151, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %153 = stablehlo.reshape %152 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %154 = stablehlo.logistic %153 : tensor<4x136x28672xbf16>
    %155 = stablehlo.multiply %153, %154 : tensor<4x136x28672xbf16>
    %156 = stablehlo.reshape %arg8 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %157 = stablehlo.reshape %156 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %158 = stablehlo.transpose %157, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %159 = stablehlo.dot_general %148, %158, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %160 = stablehlo.reshape %159 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %161 = stablehlo.multiply %155, %160 : tensor<4x136x28672xbf16>
    %162 = stablehlo.reshape %161 : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16>
    %163 = stablehlo.reshape %arg7 : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
    %164 = stablehlo.reshape %163 : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16>
    %165 = stablehlo.transpose %164, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16>
    %166 = stablehlo.dot_general %162, %165, contracting_dims = [1] x [0] : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16>
    %167 = stablehlo.reshape %166 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %168 = stablehlo.add %132, %167 : tensor<4x136x8192xbf16>
    %169 = stablehlo.convert %168 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %170 = stablehlo.power %169, %8 : tensor<4x136x8192xf32>
    %171 = stablehlo.reduce(%170 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %172 = stablehlo.multiply %171, %7 : tensor<4x136xf32>
    %173 = stablehlo.reshape %172 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %174 = stablehlo.add %173, %6 : tensor<4x136x1xf32>
    %175 = stablehlo.rsqrt %174 : tensor<4x136x1xf32>
    %176 = stablehlo.reshape %175 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %177 = stablehlo.broadcast_in_dim %176, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %178 = stablehlo.multiply %169, %177 : tensor<4x136x8192xf32>
    %179 = stablehlo.convert %178 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %180 = stablehlo.multiply %66, %179 : tensor<4x136x8192xbf16>
    %181 = stablehlo.reshape %180 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %182 = stablehlo.reshape %arg6 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %183 = stablehlo.reshape %182 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %184 = stablehlo.transpose %183, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16>
    %185 = stablehlo.dot_general %181, %184, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16>
    %186 = stablehlo.reshape %185 : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16>
    return %37, %63, %186 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
  }
}


// -----// IR Dump After ConvertXlaSdyToSdyPass (convert-xla-sdy-to-sdy) ('builtin.module' operation: @SyncTensorsGraph.416) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg1: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg2: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg3: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg4: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg5: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg6: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg7: tensor<8192x28672xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg8: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg9: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg10: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg11: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg12: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg13: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg14: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<4x8x136x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x8x136x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x136x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<136xi64>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
    %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>
    %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16>
    %c_6 = stablehlo.constant dense<1> : tensor<i64>
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %3 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %4 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64>
    %5 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<4x64x136x136xbf16>
    %6 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<4x136x1xf32>
    %7 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x136xf32>
    %8 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x136x8192xf32>
    %9 = stablehlo.reshape %arg3 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %10 = stablehlo.reshape %9 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %11 = stablehlo.broadcast_in_dim %10, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %12 = stablehlo.reshape %arg2 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %13 = stablehlo.reshape %12 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %14 = stablehlo.reshape %arg1 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %15 = stablehlo.reshape %14 : (tensor<1x4x136xi64>) -> tensor<544xi64>
    %16 = stablehlo.convert %15 : (tensor<544xi64>) -> tensor<544xui32>
    %17 = "stablehlo.gather"(%13, %16) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16>
    %18 = stablehlo.reshape %17 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %19 = stablehlo.convert %18 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %20 = stablehlo.power %19, %8 : tensor<4x136x8192xf32>
    %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %22 = stablehlo.multiply %21, %7 : tensor<4x136xf32>
    %23 = stablehlo.reshape %22 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %24 = stablehlo.add %23, %6 : tensor<4x136x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<4x136x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %28 = stablehlo.multiply %19, %27 : tensor<4x136x8192xf32>
    %29 = stablehlo.convert %28 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %30 = stablehlo.multiply %11, %29 : tensor<4x136x8192xbf16>
    %31 = stablehlo.reshape %30 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %32 = stablehlo.reshape %arg0 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %36 = stablehlo.reshape %35 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %37 = stablehlo.transpose %36, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %38 = stablehlo.reshape %arg5 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %39 = stablehlo.reshape %38 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %40 = stablehlo.transpose %39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %41 = stablehlo.dot_general %31, %40, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %42 = stablehlo.reshape %41 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %43 = stablehlo.transpose %42, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %44 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.dot_general %45, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x136x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %51 = stablehlo.reshape %50 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %52 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %53 = stablehlo.multiply %43, %52 : tensor<4x8x136x128xbf16>
    %54 = stablehlo.slice %43 [0:4, 0:8, 0:136, 64:128] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %55 = stablehlo.negate %54 : tensor<4x8x136x64xbf16>
    %56 = stablehlo.slice %43 [0:4, 0:8, 0:136, 0:64] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %57 = stablehlo.concatenate %55, %56, dim = 3 : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16>
    %58 = stablehlo.sine %48 : tensor<1x136x128xf32>
    %59 = stablehlo.convert %58 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %60 = stablehlo.reshape %59 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %62 = stablehlo.multiply %57, %61 : tensor<4x8x136x128xbf16>
    %63 = stablehlo.add %53, %62 : tensor<4x8x136x128xbf16>
    %64 = stablehlo.reshape %arg14 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %65 = stablehlo.reshape %64 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %66 = stablehlo.broadcast_in_dim %65, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %67 = stablehlo.reshape %arg11 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %68 = stablehlo.reshape %67 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %69 = stablehlo.transpose %68, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %70 = stablehlo.dot_general %31, %69, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %71 = stablehlo.reshape %70 : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16>
    %72 = stablehlo.transpose %71, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16>
    %73 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %74 = stablehlo.multiply %72, %73 : tensor<4x64x136x128xbf16>
    %75 = stablehlo.slice %72 [0:4, 0:64, 0:136, 64:128] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %76 = stablehlo.negate %75 : tensor<4x64x136x64xbf16>
    %77 = stablehlo.slice %72 [0:4, 0:64, 0:136, 0:64] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %78 = stablehlo.concatenate %76, %77, dim = 3 : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16>
    %79 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %80 = stablehlo.multiply %78, %79 : tensor<4x64x136x128xbf16>
    %81 = stablehlo.add %74, %80 : tensor<4x64x136x128xbf16>
    %82 = stablehlo.reshape %81 : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16>
    %83 = stablehlo.broadcast_in_dim %63, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %84 = stablehlo.reshape %83 : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %85 = stablehlo.transpose %84, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16>
    %86 = stablehlo.reshape %85 : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16>
    %87 = stablehlo.dot_general %82, %86, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16>
    %88 = stablehlo.reshape %87 : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %89 = stablehlo.multiply %88, %5 : tensor<4x64x136x136xbf16>
    %90 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64>
    %91 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64>
    %92 = stablehlo.subtract %90, %91 : tensor<136x136xi64>
    %93 = stablehlo.compare  GE, %92, %4 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %94 = stablehlo.select %93, %3, %2 : tensor<136x136xi1>, tensor<136x136xbf16>
    %95 = stablehlo.compare  GT, %90, %91 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %96 = stablehlo.convert %95 : (tensor<136x136xi1>) -> tensor<136x136xbf16>
    %97 = stablehlo.multiply %94, %96 : tensor<136x136xbf16>
    %98 = stablehlo.reshape %97 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [1, 2, 3] : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16>
    %100 = stablehlo.reshape %arg10 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %101 = stablehlo.reshape %100 : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64>
    %102 = stablehlo.convert %101 : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16>
    %103 = stablehlo.reshape %102 : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16>
    %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 3] : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16>
    %105 = stablehlo.add %99, %104 : tensor<4x1x136x136xbf16>
    %106 = stablehlo.compare  EQ, %105, %1 : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1>
    %107 = stablehlo.select %106, %0, %99 : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16>
    %108 = stablehlo.reshape %107 : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16>
    %109 = stablehlo.broadcast_in_dim %108, dims = [0, 2, 3] : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %110 = stablehlo.add %89, %109 : tensor<4x64x136x136xbf16>
    %111 = stablehlo.convert %110 : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32>
    %112 = stablehlo.reduce(%111 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %113 = stablehlo.broadcast_in_dim %112, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %114 = stablehlo.subtract %111, %113 : tensor<4x64x136x136xf32>
    %115 = stablehlo.exponential %114 : tensor<4x64x136x136xf32>
    %116 = stablehlo.reduce(%115 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %117 = stablehlo.broadcast_in_dim %116, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %118 = stablehlo.divide %115, %117 : tensor<4x64x136x136xf32>
    %119 = stablehlo.convert %118 : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16>
    %120 = stablehlo.reshape %119 : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16>
    %121 = stablehlo.broadcast_in_dim %37, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %122 = stablehlo.reshape %121 : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16>
    %123 = stablehlo.dot_general %120, %122, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16>
    %124 = stablehlo.reshape %123 : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %125 = stablehlo.transpose %124, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16>
    %126 = stablehlo.reshape %125 : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16>
    %127 = stablehlo.reshape %arg9 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %128 = stablehlo.reshape %127 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %129 = stablehlo.transpose %128, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %130 = stablehlo.dot_general %126, %129, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %131 = stablehlo.reshape %130 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %132 = stablehlo.add %18, %131 : tensor<4x136x8192xbf16>
    %133 = stablehlo.reshape %arg12 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %134 = stablehlo.reshape %133 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %136 = stablehlo.convert %132 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %137 = stablehlo.power %136, %8 : tensor<4x136x8192xf32>
    %138 = stablehlo.reduce(%137 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %139 = stablehlo.multiply %138, %7 : tensor<4x136xf32>
    %140 = stablehlo.reshape %139 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %141 = stablehlo.add %140, %6 : tensor<4x136x1xf32>
    %142 = stablehlo.rsqrt %141 : tensor<4x136x1xf32>
    %143 = stablehlo.reshape %142 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %144 = stablehlo.broadcast_in_dim %143, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %145 = stablehlo.multiply %136, %144 : tensor<4x136x8192xf32>
    %146 = stablehlo.convert %145 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %147 = stablehlo.multiply %135, %146 : tensor<4x136x8192xbf16>
    %148 = stablehlo.reshape %147 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %149 = stablehlo.reshape %arg13 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %150 = stablehlo.reshape %149 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %151 = stablehlo.transpose %150, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %152 = stablehlo.dot_general %148, %151, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %153 = stablehlo.reshape %152 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %154 = stablehlo.logistic %153 : tensor<4x136x28672xbf16>
    %155 = stablehlo.multiply %153, %154 : tensor<4x136x28672xbf16>
    %156 = stablehlo.reshape %arg8 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %157 = stablehlo.reshape %156 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %158 = stablehlo.transpose %157, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %159 = stablehlo.dot_general %148, %158, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %160 = stablehlo.reshape %159 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %161 = stablehlo.multiply %155, %160 : tensor<4x136x28672xbf16>
    %162 = stablehlo.reshape %161 : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16>
    %163 = stablehlo.reshape %arg7 : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
    %164 = stablehlo.reshape %163 : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16>
    %165 = stablehlo.transpose %164, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16>
    %166 = stablehlo.dot_general %162, %165, contracting_dims = [1] x [0] : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16>
    %167 = stablehlo.reshape %166 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %168 = stablehlo.add %132, %167 : tensor<4x136x8192xbf16>
    %169 = stablehlo.convert %168 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %170 = stablehlo.power %169, %8 : tensor<4x136x8192xf32>
    %171 = stablehlo.reduce(%170 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %172 = stablehlo.multiply %171, %7 : tensor<4x136xf32>
    %173 = stablehlo.reshape %172 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %174 = stablehlo.add %173, %6 : tensor<4x136x1xf32>
    %175 = stablehlo.rsqrt %174 : tensor<4x136x1xf32>
    %176 = stablehlo.reshape %175 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %177 = stablehlo.broadcast_in_dim %176, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %178 = stablehlo.multiply %169, %177 : tensor<4x136x8192xf32>
    %179 = stablehlo.convert %178 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %180 = stablehlo.multiply %66, %179 : tensor<4x136x8192xbf16>
    %181 = stablehlo.reshape %180 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %182 = stablehlo.reshape %arg6 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %183 = stablehlo.reshape %182 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %184 = stablehlo.transpose %183, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16>
    %185 = stablehlo.dot_general %181, %184, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16>
    %186 = stablehlo.reshape %185 : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16>
    return %37, %63, %186 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
  }
}


// -----// IR Dump Before AnalyzeMeshPass (analyze-mesh) ('builtin.module' operation: @SyncTensorsGraph.416) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg1: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg2: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg3: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg4: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg5: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg6: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg7: tensor<8192x28672xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg8: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg9: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg10: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg11: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg12: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg13: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg14: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<4x8x136x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x8x136x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x136x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"0x00000000000000000100000000000000020000000000000003000000000000000400000000000000050000000000000006000000000000000700000000000000080000000000000009000000000000000A000000000000000B000000000000000C000000000000000D000000000000000E000000000000000F0000000000000010000000000000001100000000000000120000000000000013000000000000001400000000000000150000000000000016000000000000001700000000000000180000000000000019000000000000001A000000000000001B000000000000001C000000000000001D000000000000001E000000000000001F0000000000000020000000000000002100000000000000220000000000000023000000000000002400000000000000250000000000000026000000000000002700000000000000280000000000000029000000000000002A000000000000002B000000000000002C000000000000002D000000000000002E000000000000002F0000000000000030000000000000003100000000000000320000000000000033000000000000003400000000000000350000000000000036000000000000003700000000000000380000000000000039000000000000003A000000000000003B000000000000003C000000000000003D000000000000003E000000000000003F0000000000000040000000000000004100000000000000420000000000000043000000000000004400000000000000450000000000000046000000000000004700000000000000480000000000000049000000000000004A000000000000004B000000000000004C000000000000004D000000000000004E000000000000004F0000000000000050000000000000005100000000000000520000000000000053000000000000005400000000000000550000000000000056000000000000005700000000000000580000000000000059000000000000005A000000000000005B000000000000005C000000000000005D000000000000005E000000000000005F0000000000000060000000000000006100000000000000620000000000000063000000000000006400000000000000650000000000000066000000000000006700000000000000680000000000000069000000000000006A000000000000006B000000000000006C000000000000006D000000000000006E000000000000006F0000000000000070000000000000007100000000000000720000000000000073000000000000007400000000000000750000000000000076000000000000007700000000000000780000000000000079000000000000007A000000000000007B000000000000007C000000000000007D000000000000007E000000000000007F0000000000000080000000000000008100000000000000820000000000000083000000000000008400000000000000850000000000000086000000000000008700000000000000"> : tensor<136xi64>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
    %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>
    %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16>
    %c_6 = stablehlo.constant dense<1> : tensor<i64>
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %3 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %4 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64>
    %5 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<4x64x136x136xbf16>
    %6 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<4x136x1xf32>
    %7 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x136xf32>
    %8 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x136x8192xf32>
    %9 = stablehlo.reshape %arg3 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %10 = stablehlo.reshape %9 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %11 = stablehlo.broadcast_in_dim %10, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %12 = stablehlo.reshape %arg2 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %13 = stablehlo.reshape %12 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %14 = stablehlo.reshape %arg1 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %15 = stablehlo.reshape %14 : (tensor<1x4x136xi64>) -> tensor<544xi64>
    %16 = stablehlo.convert %15 : (tensor<544xi64>) -> tensor<544xui32>
    %17 = "stablehlo.gather"(%13, %16) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16>
    %18 = stablehlo.reshape %17 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %19 = stablehlo.convert %18 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %20 = stablehlo.power %19, %8 : tensor<4x136x8192xf32>
    %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %22 = stablehlo.multiply %21, %7 : tensor<4x136xf32>
    %23 = stablehlo.reshape %22 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %24 = stablehlo.add %23, %6 : tensor<4x136x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<4x136x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %28 = stablehlo.multiply %19, %27 : tensor<4x136x8192xf32>
    %29 = stablehlo.convert %28 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %30 = stablehlo.multiply %11, %29 : tensor<4x136x8192xbf16>
    %31 = stablehlo.reshape %30 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %32 = stablehlo.reshape %arg0 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %36 = stablehlo.reshape %35 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %37 = stablehlo.transpose %36, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %38 = stablehlo.reshape %arg5 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %39 = stablehlo.reshape %38 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %40 = stablehlo.transpose %39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %41 = stablehlo.dot_general %31, %40, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %42 = stablehlo.reshape %41 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %43 = stablehlo.transpose %42, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %44 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.dot_general %45, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x136x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %51 = stablehlo.reshape %50 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %52 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %53 = stablehlo.multiply %43, %52 : tensor<4x8x136x128xbf16>
    %54 = stablehlo.slice %43 [0:4, 0:8, 0:136, 64:128] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %55 = stablehlo.negate %54 : tensor<4x8x136x64xbf16>
    %56 = stablehlo.slice %43 [0:4, 0:8, 0:136, 0:64] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %57 = stablehlo.concatenate %55, %56, dim = 3 : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16>
    %58 = stablehlo.sine %48 : tensor<1x136x128xf32>
    %59 = stablehlo.convert %58 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %60 = stablehlo.reshape %59 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %62 = stablehlo.multiply %57, %61 : tensor<4x8x136x128xbf16>
    %63 = stablehlo.add %53, %62 : tensor<4x8x136x128xbf16>
    %64 = stablehlo.reshape %arg14 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %65 = stablehlo.reshape %64 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %66 = stablehlo.broadcast_in_dim %65, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %67 = stablehlo.reshape %arg11 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %68 = stablehlo.reshape %67 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %69 = stablehlo.transpose %68, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %70 = stablehlo.dot_general %31, %69, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %71 = stablehlo.reshape %70 : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16>
    %72 = stablehlo.transpose %71, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16>
    %73 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %74 = stablehlo.multiply %72, %73 : tensor<4x64x136x128xbf16>
    %75 = stablehlo.slice %72 [0:4, 0:64, 0:136, 64:128] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %76 = stablehlo.negate %75 : tensor<4x64x136x64xbf16>
    %77 = stablehlo.slice %72 [0:4, 0:64, 0:136, 0:64] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %78 = stablehlo.concatenate %76, %77, dim = 3 : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16>
    %79 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %80 = stablehlo.multiply %78, %79 : tensor<4x64x136x128xbf16>
    %81 = stablehlo.add %74, %80 : tensor<4x64x136x128xbf16>
    %82 = stablehlo.reshape %81 : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16>
    %83 = stablehlo.broadcast_in_dim %63, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %84 = stablehlo.reshape %83 : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %85 = stablehlo.transpose %84, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16>
    %86 = stablehlo.reshape %85 : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16>
    %87 = stablehlo.dot_general %82, %86, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16>
    %88 = stablehlo.reshape %87 : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %89 = stablehlo.multiply %88, %5 : tensor<4x64x136x136xbf16>
    %90 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64>
    %91 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64>
    %92 = stablehlo.subtract %90, %91 : tensor<136x136xi64>
    %93 = stablehlo.compare  GE, %92, %4 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %94 = stablehlo.select %93, %3, %2 : tensor<136x136xi1>, tensor<136x136xbf16>
    %95 = stablehlo.compare  GT, %90, %91 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %96 = stablehlo.convert %95 : (tensor<136x136xi1>) -> tensor<136x136xbf16>
    %97 = stablehlo.multiply %94, %96 : tensor<136x136xbf16>
    %98 = stablehlo.reshape %97 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [1, 2, 3] : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16>
    %100 = stablehlo.reshape %arg10 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %101 = stablehlo.reshape %100 : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64>
    %102 = stablehlo.convert %101 : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16>
    %103 = stablehlo.reshape %102 : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16>
    %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 3] : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16>
    %105 = stablehlo.add %99, %104 : tensor<4x1x136x136xbf16>
    %106 = stablehlo.compare  EQ, %105, %1 : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1>
    %107 = stablehlo.select %106, %0, %99 : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16>
    %108 = stablehlo.reshape %107 : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16>
    %109 = stablehlo.broadcast_in_dim %108, dims = [0, 2, 3] : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %110 = stablehlo.add %89, %109 : tensor<4x64x136x136xbf16>
    %111 = stablehlo.convert %110 : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32>
    %112 = stablehlo.reduce(%111 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %113 = stablehlo.broadcast_in_dim %112, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %114 = stablehlo.subtract %111, %113 : tensor<4x64x136x136xf32>
    %115 = stablehlo.exponential %114 : tensor<4x64x136x136xf32>
    %116 = stablehlo.reduce(%115 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %117 = stablehlo.broadcast_in_dim %116, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %118 = stablehlo.divide %115, %117 : tensor<4x64x136x136xf32>
    %119 = stablehlo.convert %118 : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16>
    %120 = stablehlo.reshape %119 : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16>
    %121 = stablehlo.broadcast_in_dim %37, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %122 = stablehlo.reshape %121 : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16>
    %123 = stablehlo.dot_general %120, %122, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16>
    %124 = stablehlo.reshape %123 : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %125 = stablehlo.transpose %124, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16>
    %126 = stablehlo.reshape %125 : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16>
    %127 = stablehlo.reshape %arg9 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %128 = stablehlo.reshape %127 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %129 = stablehlo.transpose %128, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %130 = stablehlo.dot_general %126, %129, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %131 = stablehlo.reshape %130 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %132 = stablehlo.add %18, %131 : tensor<4x136x8192xbf16>
    %133 = stablehlo.reshape %arg12 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %134 = stablehlo.reshape %133 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %136 = stablehlo.convert %132 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %137 = stablehlo.power %136, %8 : tensor<4x136x8192xf32>
    %138 = stablehlo.reduce(%137 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %139 = stablehlo.multiply %138, %7 : tensor<4x136xf32>
    %140 = stablehlo.reshape %139 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %141 = stablehlo.add %140, %6 : tensor<4x136x1xf32>
    %142 = stablehlo.rsqrt %141 : tensor<4x136x1xf32>
    %143 = stablehlo.reshape %142 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %144 = stablehlo.broadcast_in_dim %143, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %145 = stablehlo.multiply %136, %144 : tensor<4x136x8192xf32>
    %146 = stablehlo.convert %145 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %147 = stablehlo.multiply %135, %146 : tensor<4x136x8192xbf16>
    %148 = stablehlo.reshape %147 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %149 = stablehlo.reshape %arg13 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %150 = stablehlo.reshape %149 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %151 = stablehlo.transpose %150, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %152 = stablehlo.dot_general %148, %151, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %153 = stablehlo.reshape %152 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %154 = stablehlo.logistic %153 : tensor<4x136x28672xbf16>
    %155 = stablehlo.multiply %153, %154 : tensor<4x136x28672xbf16>
    %156 = stablehlo.reshape %arg8 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %157 = stablehlo.reshape %156 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %158 = stablehlo.transpose %157, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %159 = stablehlo.dot_general %148, %158, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %160 = stablehlo.reshape %159 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %161 = stablehlo.multiply %155, %160 : tensor<4x136x28672xbf16>
    %162 = stablehlo.reshape %161 : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16>
    %163 = stablehlo.reshape %arg7 : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
    %164 = stablehlo.reshape %163 : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16>
    %165 = stablehlo.transpose %164, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16>
    %166 = stablehlo.dot_general %162, %165, contracting_dims = [1] x [0] : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16>
    %167 = stablehlo.reshape %166 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %168 = stablehlo.add %132, %167 : tensor<4x136x8192xbf16>
    %169 = stablehlo.convert %168 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %170 = stablehlo.power %169, %8 : tensor<4x136x8192xf32>
    %171 = stablehlo.reduce(%170 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %172 = stablehlo.multiply %171, %7 : tensor<4x136xf32>
    %173 = stablehlo.reshape %172 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %174 = stablehlo.add %173, %6 : tensor<4x136x1xf32>
    %175 = stablehlo.rsqrt %174 : tensor<4x136x1xf32>
    %176 = stablehlo.reshape %175 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %177 = stablehlo.broadcast_in_dim %176, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %178 = stablehlo.multiply %169, %177 : tensor<4x136x8192xf32>
    %179 = stablehlo.convert %178 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %180 = stablehlo.multiply %66, %179 : tensor<4x136x8192xbf16>
    %181 = stablehlo.reshape %180 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %182 = stablehlo.reshape %arg6 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %183 = stablehlo.reshape %182 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %184 = stablehlo.transpose %183, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16>
    %185 = stablehlo.dot_general %181, %184, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16>
    %186 = stablehlo.reshape %185 : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16>
    return %37, %63, %186 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
  }
}


// -----// IR Dump Before ApplyShardingConstraintsPass (sdy-apply-sharding-constraints) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg1: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg2: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg3: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg4: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg5: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg6: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg7: tensor<8192x28672xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg8: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg9: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg10: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg11: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg12: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg13: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg14: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<4x8x136x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x8x136x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x136x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<136xi64>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
    %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>
    %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16>
    %c_6 = stablehlo.constant dense<1> : tensor<i64>
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %3 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %4 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64>
    %5 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<4x64x136x136xbf16>
    %6 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<4x136x1xf32>
    %7 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x136xf32>
    %8 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x136x8192xf32>
    %9 = stablehlo.reshape %arg3 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %10 = stablehlo.reshape %9 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %11 = stablehlo.broadcast_in_dim %10, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %12 = stablehlo.reshape %arg2 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %13 = stablehlo.reshape %12 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %14 = stablehlo.reshape %arg1 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %15 = stablehlo.reshape %14 : (tensor<1x4x136xi64>) -> tensor<544xi64>
    %16 = stablehlo.convert %15 : (tensor<544xi64>) -> tensor<544xui32>
    %17 = "stablehlo.gather"(%13, %16) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16>
    %18 = stablehlo.reshape %17 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %19 = stablehlo.convert %18 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %20 = stablehlo.power %19, %8 : tensor<4x136x8192xf32>
    %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %22 = stablehlo.multiply %21, %7 : tensor<4x136xf32>
    %23 = stablehlo.reshape %22 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %24 = stablehlo.add %23, %6 : tensor<4x136x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<4x136x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %28 = stablehlo.multiply %19, %27 : tensor<4x136x8192xf32>
    %29 = stablehlo.convert %28 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %30 = stablehlo.multiply %11, %29 : tensor<4x136x8192xbf16>
    %31 = stablehlo.reshape %30 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %32 = stablehlo.reshape %arg0 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %36 = stablehlo.reshape %35 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %37 = stablehlo.transpose %36, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %38 = stablehlo.reshape %arg5 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %39 = stablehlo.reshape %38 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %40 = stablehlo.transpose %39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %41 = stablehlo.dot_general %31, %40, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %42 = stablehlo.reshape %41 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %43 = stablehlo.transpose %42, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %44 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.dot_general %45, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x136x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %51 = stablehlo.reshape %50 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %52 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %53 = stablehlo.multiply %43, %52 : tensor<4x8x136x128xbf16>
    %54 = stablehlo.slice %43 [0:4, 0:8, 0:136, 64:128] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %55 = stablehlo.negate %54 : tensor<4x8x136x64xbf16>
    %56 = stablehlo.slice %43 [0:4, 0:8, 0:136, 0:64] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %57 = stablehlo.concatenate %55, %56, dim = 3 : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16>
    %58 = stablehlo.sine %48 : tensor<1x136x128xf32>
    %59 = stablehlo.convert %58 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %60 = stablehlo.reshape %59 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %62 = stablehlo.multiply %57, %61 : tensor<4x8x136x128xbf16>
    %63 = stablehlo.add %53, %62 : tensor<4x8x136x128xbf16>
    %64 = stablehlo.reshape %arg14 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %65 = stablehlo.reshape %64 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %66 = stablehlo.broadcast_in_dim %65, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %67 = stablehlo.reshape %arg11 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %68 = stablehlo.reshape %67 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %69 = stablehlo.transpose %68, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %70 = stablehlo.dot_general %31, %69, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %71 = stablehlo.reshape %70 : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16>
    %72 = stablehlo.transpose %71, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16>
    %73 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %74 = stablehlo.multiply %72, %73 : tensor<4x64x136x128xbf16>
    %75 = stablehlo.slice %72 [0:4, 0:64, 0:136, 64:128] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %76 = stablehlo.negate %75 : tensor<4x64x136x64xbf16>
    %77 = stablehlo.slice %72 [0:4, 0:64, 0:136, 0:64] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %78 = stablehlo.concatenate %76, %77, dim = 3 : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16>
    %79 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %80 = stablehlo.multiply %78, %79 : tensor<4x64x136x128xbf16>
    %81 = stablehlo.add %74, %80 : tensor<4x64x136x128xbf16>
    %82 = stablehlo.reshape %81 : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16>
    %83 = stablehlo.broadcast_in_dim %63, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %84 = stablehlo.reshape %83 : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %85 = stablehlo.transpose %84, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16>
    %86 = stablehlo.reshape %85 : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16>
    %87 = stablehlo.dot_general %82, %86, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16>
    %88 = stablehlo.reshape %87 : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %89 = stablehlo.multiply %88, %5 : tensor<4x64x136x136xbf16>
    %90 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64>
    %91 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64>
    %92 = stablehlo.subtract %90, %91 : tensor<136x136xi64>
    %93 = stablehlo.compare  GE, %92, %4 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %94 = stablehlo.select %93, %3, %2 : tensor<136x136xi1>, tensor<136x136xbf16>
    %95 = stablehlo.compare  GT, %90, %91 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %96 = stablehlo.convert %95 : (tensor<136x136xi1>) -> tensor<136x136xbf16>
    %97 = stablehlo.multiply %94, %96 : tensor<136x136xbf16>
    %98 = stablehlo.reshape %97 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [1, 2, 3] : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16>
    %100 = stablehlo.reshape %arg10 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %101 = stablehlo.reshape %100 : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64>
    %102 = stablehlo.convert %101 : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16>
    %103 = stablehlo.reshape %102 : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16>
    %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 3] : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16>
    %105 = stablehlo.add %99, %104 : tensor<4x1x136x136xbf16>
    %106 = stablehlo.compare  EQ, %105, %1 : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1>
    %107 = stablehlo.select %106, %0, %99 : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16>
    %108 = stablehlo.reshape %107 : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16>
    %109 = stablehlo.broadcast_in_dim %108, dims = [0, 2, 3] : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %110 = stablehlo.add %89, %109 : tensor<4x64x136x136xbf16>
    %111 = stablehlo.convert %110 : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32>
    %112 = stablehlo.reduce(%111 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %113 = stablehlo.broadcast_in_dim %112, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %114 = stablehlo.subtract %111, %113 : tensor<4x64x136x136xf32>
    %115 = stablehlo.exponential %114 : tensor<4x64x136x136xf32>
    %116 = stablehlo.reduce(%115 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %117 = stablehlo.broadcast_in_dim %116, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %118 = stablehlo.divide %115, %117 : tensor<4x64x136x136xf32>
    %119 = stablehlo.convert %118 : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16>
    %120 = stablehlo.reshape %119 : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16>
    %121 = stablehlo.broadcast_in_dim %37, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %122 = stablehlo.reshape %121 : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16>
    %123 = stablehlo.dot_general %120, %122, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16>
    %124 = stablehlo.reshape %123 : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %125 = stablehlo.transpose %124, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16>
    %126 = stablehlo.reshape %125 : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16>
    %127 = stablehlo.reshape %arg9 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %128 = stablehlo.reshape %127 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %129 = stablehlo.transpose %128, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %130 = stablehlo.dot_general %126, %129, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %131 = stablehlo.reshape %130 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %132 = stablehlo.add %18, %131 : tensor<4x136x8192xbf16>
    %133 = stablehlo.reshape %arg12 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %134 = stablehlo.reshape %133 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %136 = stablehlo.convert %132 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %137 = stablehlo.power %136, %8 : tensor<4x136x8192xf32>
    %138 = stablehlo.reduce(%137 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %139 = stablehlo.multiply %138, %7 : tensor<4x136xf32>
    %140 = stablehlo.reshape %139 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %141 = stablehlo.add %140, %6 : tensor<4x136x1xf32>
    %142 = stablehlo.rsqrt %141 : tensor<4x136x1xf32>
    %143 = stablehlo.reshape %142 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %144 = stablehlo.broadcast_in_dim %143, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %145 = stablehlo.multiply %136, %144 : tensor<4x136x8192xf32>
    %146 = stablehlo.convert %145 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %147 = stablehlo.multiply %135, %146 : tensor<4x136x8192xbf16>
    %148 = stablehlo.reshape %147 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %149 = stablehlo.reshape %arg13 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %150 = stablehlo.reshape %149 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %151 = stablehlo.transpose %150, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %152 = stablehlo.dot_general %148, %151, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %153 = stablehlo.reshape %152 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %154 = stablehlo.logistic %153 : tensor<4x136x28672xbf16>
    %155 = stablehlo.multiply %153, %154 : tensor<4x136x28672xbf16>
    %156 = stablehlo.reshape %arg8 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %157 = stablehlo.reshape %156 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %158 = stablehlo.transpose %157, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %159 = stablehlo.dot_general %148, %158, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %160 = stablehlo.reshape %159 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %161 = stablehlo.multiply %155, %160 : tensor<4x136x28672xbf16>
    %162 = stablehlo.reshape %161 : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16>
    %163 = stablehlo.reshape %arg7 : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
    %164 = stablehlo.reshape %163 : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16>
    %165 = stablehlo.transpose %164, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16>
    %166 = stablehlo.dot_general %162, %165, contracting_dims = [1] x [0] : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16>
    %167 = stablehlo.reshape %166 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %168 = stablehlo.add %132, %167 : tensor<4x136x8192xbf16>
    %169 = stablehlo.convert %168 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %170 = stablehlo.power %169, %8 : tensor<4x136x8192xf32>
    %171 = stablehlo.reduce(%170 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %172 = stablehlo.multiply %171, %7 : tensor<4x136xf32>
    %173 = stablehlo.reshape %172 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %174 = stablehlo.add %173, %6 : tensor<4x136x1xf32>
    %175 = stablehlo.rsqrt %174 : tensor<4x136x1xf32>
    %176 = stablehlo.reshape %175 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %177 = stablehlo.broadcast_in_dim %176, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %178 = stablehlo.multiply %169, %177 : tensor<4x136x8192xf32>
    %179 = stablehlo.convert %178 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %180 = stablehlo.multiply %66, %179 : tensor<4x136x8192xbf16>
    %181 = stablehlo.reshape %180 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %182 = stablehlo.reshape %arg6 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %183 = stablehlo.reshape %182 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %184 = stablehlo.transpose %183, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16>
    %185 = stablehlo.dot_general %181, %184, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16>
    %186 = stablehlo.reshape %185 : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16>
    return %37, %63, %186 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
  }
}


// -----// IR Dump Before AggressivePropagationPass (sdy-aggressive-propagate) ('builtin.module' operation: @SyncTensorsGraph.416) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg1: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg2: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg3: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg4: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg5: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg6: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg7: tensor<8192x28672xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg8: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg9: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg10: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg11: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg12: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg13: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg14: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<4x8x136x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x8x136x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x136x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<136xi64>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
    %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>
    %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16>
    %c_6 = stablehlo.constant dense<1> : tensor<i64>
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %3 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %4 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64>
    %5 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<4x64x136x136xbf16>
    %6 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<4x136x1xf32>
    %7 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x136xf32>
    %8 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x136x8192xf32>
    %9 = stablehlo.reshape %arg3 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %10 = stablehlo.reshape %9 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %11 = stablehlo.broadcast_in_dim %10, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %12 = stablehlo.reshape %arg2 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %13 = stablehlo.reshape %12 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %14 = stablehlo.reshape %arg1 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %15 = stablehlo.reshape %14 : (tensor<1x4x136xi64>) -> tensor<544xi64>
    %16 = stablehlo.convert %15 : (tensor<544xi64>) -> tensor<544xui32>
    %17 = "stablehlo.gather"(%13, %16) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16>
    %18 = stablehlo.reshape %17 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %19 = stablehlo.convert %18 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %20 = stablehlo.power %19, %8 : tensor<4x136x8192xf32>
    %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %22 = stablehlo.multiply %21, %7 : tensor<4x136xf32>
    %23 = stablehlo.reshape %22 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %24 = stablehlo.add %23, %6 : tensor<4x136x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<4x136x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %28 = stablehlo.multiply %19, %27 : tensor<4x136x8192xf32>
    %29 = stablehlo.convert %28 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %30 = stablehlo.multiply %11, %29 : tensor<4x136x8192xbf16>
    %31 = stablehlo.reshape %30 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %32 = stablehlo.reshape %arg0 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %36 = stablehlo.reshape %35 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %37 = stablehlo.transpose %36, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %38 = stablehlo.reshape %arg5 : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %39 = stablehlo.reshape %38 : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %40 = stablehlo.transpose %39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %41 = stablehlo.dot_general %31, %40, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %42 = stablehlo.reshape %41 : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %43 = stablehlo.transpose %42, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %44 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.dot_general %45, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x136x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %51 = stablehlo.reshape %50 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %52 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %53 = stablehlo.multiply %43, %52 : tensor<4x8x136x128xbf16>
    %54 = stablehlo.slice %43 [0:4, 0:8, 0:136, 64:128] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %55 = stablehlo.negate %54 : tensor<4x8x136x64xbf16>
    %56 = stablehlo.slice %43 [0:4, 0:8, 0:136, 0:64] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %57 = stablehlo.concatenate %55, %56, dim = 3 : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16>
    %58 = stablehlo.sine %48 : tensor<1x136x128xf32>
    %59 = stablehlo.convert %58 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %60 = stablehlo.reshape %59 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %62 = stablehlo.multiply %57, %61 : tensor<4x8x136x128xbf16>
    %63 = stablehlo.add %53, %62 : tensor<4x8x136x128xbf16>
    %64 = stablehlo.reshape %arg14 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %65 = stablehlo.reshape %64 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %66 = stablehlo.broadcast_in_dim %65, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %67 = stablehlo.reshape %arg11 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %68 = stablehlo.reshape %67 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %69 = stablehlo.transpose %68, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %70 = stablehlo.dot_general %31, %69, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %71 = stablehlo.reshape %70 : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16>
    %72 = stablehlo.transpose %71, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16>
    %73 = stablehlo.broadcast_in_dim %51, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %74 = stablehlo.multiply %72, %73 : tensor<4x64x136x128xbf16>
    %75 = stablehlo.slice %72 [0:4, 0:64, 0:136, 64:128] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %76 = stablehlo.negate %75 : tensor<4x64x136x64xbf16>
    %77 = stablehlo.slice %72 [0:4, 0:64, 0:136, 0:64] : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %78 = stablehlo.concatenate %76, %77, dim = 3 : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16>
    %79 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %80 = stablehlo.multiply %78, %79 : tensor<4x64x136x128xbf16>
    %81 = stablehlo.add %74, %80 : tensor<4x64x136x128xbf16>
    %82 = stablehlo.reshape %81 : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16>
    %83 = stablehlo.broadcast_in_dim %63, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %84 = stablehlo.reshape %83 : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %85 = stablehlo.transpose %84, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16>
    %86 = stablehlo.reshape %85 : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16>
    %87 = stablehlo.dot_general %82, %86, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16>
    %88 = stablehlo.reshape %87 : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %89 = stablehlo.multiply %88, %5 : tensor<4x64x136x136xbf16>
    %90 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64>
    %91 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64>
    %92 = stablehlo.subtract %90, %91 : tensor<136x136xi64>
    %93 = stablehlo.compare  GE, %92, %4 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %94 = stablehlo.select %93, %3, %2 : tensor<136x136xi1>, tensor<136x136xbf16>
    %95 = stablehlo.compare  GT, %90, %91 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %96 = stablehlo.convert %95 : (tensor<136x136xi1>) -> tensor<136x136xbf16>
    %97 = stablehlo.multiply %94, %96 : tensor<136x136xbf16>
    %98 = stablehlo.reshape %97 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [1, 2, 3] : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16>
    %100 = stablehlo.reshape %arg10 : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %101 = stablehlo.reshape %100 : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64>
    %102 = stablehlo.convert %101 : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16>
    %103 = stablehlo.reshape %102 : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16>
    %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 3] : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16>
    %105 = stablehlo.add %99, %104 : tensor<4x1x136x136xbf16>
    %106 = stablehlo.compare  EQ, %105, %1 : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1>
    %107 = stablehlo.select %106, %0, %99 : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16>
    %108 = stablehlo.reshape %107 : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16>
    %109 = stablehlo.broadcast_in_dim %108, dims = [0, 2, 3] : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %110 = stablehlo.add %89, %109 : tensor<4x64x136x136xbf16>
    %111 = stablehlo.convert %110 : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32>
    %112 = stablehlo.reduce(%111 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %113 = stablehlo.broadcast_in_dim %112, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %114 = stablehlo.subtract %111, %113 : tensor<4x64x136x136xf32>
    %115 = stablehlo.exponential %114 : tensor<4x64x136x136xf32>
    %116 = stablehlo.reduce(%115 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %117 = stablehlo.broadcast_in_dim %116, dims = [0, 1, 2] : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %118 = stablehlo.divide %115, %117 : tensor<4x64x136x136xf32>
    %119 = stablehlo.convert %118 : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16>
    %120 = stablehlo.reshape %119 : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16>
    %121 = stablehlo.broadcast_in_dim %37, dims = [0, 1, 3, 4] : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %122 = stablehlo.reshape %121 : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16>
    %123 = stablehlo.dot_general %120, %122, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16>
    %124 = stablehlo.reshape %123 : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %125 = stablehlo.transpose %124, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16>
    %126 = stablehlo.reshape %125 : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16>
    %127 = stablehlo.reshape %arg9 : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %128 = stablehlo.reshape %127 : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %129 = stablehlo.transpose %128, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %130 = stablehlo.dot_general %126, %129, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %131 = stablehlo.reshape %130 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %132 = stablehlo.add %18, %131 : tensor<4x136x8192xbf16>
    %133 = stablehlo.reshape %arg12 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %134 = stablehlo.reshape %133 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [2] : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %136 = stablehlo.convert %132 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %137 = stablehlo.power %136, %8 : tensor<4x136x8192xf32>
    %138 = stablehlo.reduce(%137 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %139 = stablehlo.multiply %138, %7 : tensor<4x136xf32>
    %140 = stablehlo.reshape %139 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %141 = stablehlo.add %140, %6 : tensor<4x136x1xf32>
    %142 = stablehlo.rsqrt %141 : tensor<4x136x1xf32>
    %143 = stablehlo.reshape %142 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %144 = stablehlo.broadcast_in_dim %143, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %145 = stablehlo.multiply %136, %144 : tensor<4x136x8192xf32>
    %146 = stablehlo.convert %145 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %147 = stablehlo.multiply %135, %146 : tensor<4x136x8192xbf16>
    %148 = stablehlo.reshape %147 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %149 = stablehlo.reshape %arg13 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %150 = stablehlo.reshape %149 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %151 = stablehlo.transpose %150, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %152 = stablehlo.dot_general %148, %151, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %153 = stablehlo.reshape %152 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %154 = stablehlo.logistic %153 : tensor<4x136x28672xbf16>
    %155 = stablehlo.multiply %153, %154 : tensor<4x136x28672xbf16>
    %156 = stablehlo.reshape %arg8 : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %157 = stablehlo.reshape %156 : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %158 = stablehlo.transpose %157, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %159 = stablehlo.dot_general %148, %158, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %160 = stablehlo.reshape %159 : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %161 = stablehlo.multiply %155, %160 : tensor<4x136x28672xbf16>
    %162 = stablehlo.reshape %161 : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16>
    %163 = stablehlo.reshape %arg7 : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
    %164 = stablehlo.reshape %163 : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16>
    %165 = stablehlo.transpose %164, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16>
    %166 = stablehlo.dot_general %162, %165, contracting_dims = [1] x [0] : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16>
    %167 = stablehlo.reshape %166 : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %168 = stablehlo.add %132, %167 : tensor<4x136x8192xbf16>
    %169 = stablehlo.convert %168 : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %170 = stablehlo.power %169, %8 : tensor<4x136x8192xf32>
    %171 = stablehlo.reduce(%170 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %172 = stablehlo.multiply %171, %7 : tensor<4x136xf32>
    %173 = stablehlo.reshape %172 : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %174 = stablehlo.add %173, %6 : tensor<4x136x1xf32>
    %175 = stablehlo.rsqrt %174 : tensor<4x136x1xf32>
    %176 = stablehlo.reshape %175 : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %177 = stablehlo.broadcast_in_dim %176, dims = [0, 1] : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %178 = stablehlo.multiply %169, %177 : tensor<4x136x8192xf32>
    %179 = stablehlo.convert %178 : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %180 = stablehlo.multiply %66, %179 : tensor<4x136x8192xbf16>
    %181 = stablehlo.reshape %180 : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %182 = stablehlo.reshape %arg6 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %183 = stablehlo.reshape %182 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %184 = stablehlo.transpose %183, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16>
    %185 = stablehlo.dot_general %181, %184, contracting_dims = [1] x [0] : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16>
    %186 = stablehlo.reshape %185 : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16>
    return %37, %63, %186 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
  }
}


// -----// IR Dump After AggressivePropagationPass (sdy-aggressive-propagate) ('builtin.module' operation: @SyncTensorsGraph.416) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg1: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg2: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg3: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg4: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg5: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg6: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg7: tensor<8192x28672xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg8: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg9: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg10: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg11: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg12: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg13: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg14: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<4x8x136x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x8x136x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x136x128256xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<136xi64>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
    %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>
    %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16>
    %c_6 = stablehlo.constant dense<1> : tensor<i64>
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_8, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_7, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %3 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %4 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64>
    %5 = stablehlo.broadcast_in_dim %cst_5, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x64x136x136xbf16>
    %6 = stablehlo.broadcast_in_dim %cst_3, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136x1xf32>
    %7 = stablehlo.broadcast_in_dim %cst_2, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136xf32>
    %8 = stablehlo.broadcast_in_dim %cst_1, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136x8192xf32>
    %9 = stablehlo.reshape %arg3 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %10 = stablehlo.reshape %9 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %11 = stablehlo.broadcast_in_dim %10, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %12 = stablehlo.reshape %arg2 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %13 = stablehlo.reshape %12 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %14 = stablehlo.reshape %arg1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {?}]>]>} : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %15 = stablehlo.reshape %14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x4x136xi64>) -> tensor<544xi64>
    %16 = stablehlo.convert %15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<544xi64>) -> tensor<544xui32>
    %17 = "stablehlo.gather"(%13, %16) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16>
    %18 = stablehlo.reshape %17 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %19 = stablehlo.convert %18 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %20 = stablehlo.power %19, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %22 = stablehlo.multiply %21, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
    %23 = stablehlo.reshape %22 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %24 = stablehlo.add %23, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %25 = stablehlo.rsqrt %24 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %26 = stablehlo.reshape %25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %28 = stablehlo.multiply %19, %27 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %29 = stablehlo.convert %28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %30 = stablehlo.multiply %11, %29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %31 = stablehlo.reshape %30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %32 = stablehlo.reshape %arg0 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %33 = stablehlo.reshape %32 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %36 = stablehlo.reshape %35 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %37 = stablehlo.transpose %36, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %38 = stablehlo.reshape %arg5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %39 = stablehlo.reshape %38 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %40 = stablehlo.transpose %39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %41 = stablehlo.dot_general %31, %40, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %42 = stablehlo.reshape %41 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %43 = stablehlo.transpose %42, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %44 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.dot_general %45, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x136x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %51 = stablehlo.reshape %50 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %52 = stablehlo.broadcast_in_dim %51, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %53 = stablehlo.multiply %43, %52 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
    %54 = stablehlo.slice %43 [0:4, 0:8, 0:136, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %55 = stablehlo.negate %54 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x64xbf16>
    %56 = stablehlo.slice %43 [0:4, 0:8, 0:136, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %57 = stablehlo.concatenate %55, %56, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16>
    %58 = stablehlo.sine %48 : tensor<1x136x128xf32>
    %59 = stablehlo.convert %58 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %60 = stablehlo.reshape %59 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %62 = stablehlo.multiply %57, %61 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
    %63 = stablehlo.add %53, %62 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
    %64 = stablehlo.reshape %arg14 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %65 = stablehlo.reshape %64 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %66 = stablehlo.broadcast_in_dim %65, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %67 = stablehlo.reshape %arg11 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %68 = stablehlo.reshape %67 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %69 = stablehlo.transpose %68, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %70 = stablehlo.dot_general %31, %69, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %71 = stablehlo.reshape %70 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16>
    %72 = stablehlo.transpose %71, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16>
    %73 = stablehlo.broadcast_in_dim %51, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %74 = stablehlo.multiply %72, %73 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
    %75 = stablehlo.slice %72 [0:4, 0:64, 0:136, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %76 = stablehlo.negate %75 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x64xbf16>
    %77 = stablehlo.slice %72 [0:4, 0:64, 0:136, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %78 = stablehlo.concatenate %76, %77, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16>
    %79 = stablehlo.broadcast_in_dim %60, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %80 = stablehlo.multiply %78, %79 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
    %81 = stablehlo.add %74, %80 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
    %82 = stablehlo.reshape %81 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16>
    %83 = stablehlo.broadcast_in_dim %63, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %84 = stablehlo.reshape %83 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %85 = stablehlo.transpose %84, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16>
    %86 = stablehlo.reshape %85 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16>
    %87 = stablehlo.dot_general %82, %86, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16>
    %88 = stablehlo.reshape %87 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %89 = stablehlo.multiply %88, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xbf16>
    %90 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64>
    %91 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64>
    %92 = stablehlo.subtract %90, %91 : tensor<136x136xi64>
    %93 = stablehlo.compare  GE, %92, %4 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %94 = stablehlo.select %93, %3, %2 : tensor<136x136xi1>, tensor<136x136xbf16>
    %95 = stablehlo.compare  GT, %90, %91 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %96 = stablehlo.convert %95 : (tensor<136x136xi1>) -> tensor<136x136xbf16>
    %97 = stablehlo.multiply %94, %96 : tensor<136x136xbf16>
    %98 = stablehlo.reshape %97 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16>
    %100 = stablehlo.reshape %arg10 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {?}]>]>} : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %101 = stablehlo.reshape %100 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64>
    %102 = stablehlo.convert %101 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16>
    %103 = stablehlo.reshape %102 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16>
    %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16>
    %105 = stablehlo.add %99, %104 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : tensor<4x1x136x136xbf16>
    %106 = stablehlo.compare  EQ, %105, %1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1>
    %107 = stablehlo.select %106, %0, %99 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16>
    %108 = stablehlo.reshape %107 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16>
    %109 = stablehlo.broadcast_in_dim %108, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %110 = stablehlo.add %89, %109 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xbf16>
    %111 = stablehlo.convert %110 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32>
    %112 = stablehlo.reduce(%111 init: %cst_0) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}]>]>} : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %113 = stablehlo.broadcast_in_dim %112, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %114 = stablehlo.subtract %111, %113 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
    %115 = stablehlo.exponential %114 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
    %116 = stablehlo.reduce(%115 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}]>]>} : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %117 = stablehlo.broadcast_in_dim %116, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %118 = stablehlo.divide %115, %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
    %119 = stablehlo.convert %118 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16>
    %120 = stablehlo.reshape %119 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16>
    %121 = stablehlo.broadcast_in_dim %37, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %122 = stablehlo.reshape %121 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16>
    %123 = stablehlo.dot_general %120, %122, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16>
    %124 = stablehlo.reshape %123 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %125 = stablehlo.transpose %124, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16>
    %126 = stablehlo.reshape %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16>
    %127 = stablehlo.reshape %arg9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %128 = stablehlo.reshape %127 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %129 = stablehlo.transpose %128, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %130 = stablehlo.dot_general %126, %129, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %131 = stablehlo.reshape %130 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %132 = stablehlo.add %18, %131 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %133 = stablehlo.reshape %arg12 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %134 = stablehlo.reshape %133 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %136 = stablehlo.convert %132 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %137 = stablehlo.power %136, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %138 = stablehlo.reduce(%137 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %139 = stablehlo.multiply %138, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
    %140 = stablehlo.reshape %139 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %141 = stablehlo.add %140, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %142 = stablehlo.rsqrt %141 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %143 = stablehlo.reshape %142 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %144 = stablehlo.broadcast_in_dim %143, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %145 = stablehlo.multiply %136, %144 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %146 = stablehlo.convert %145 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %147 = stablehlo.multiply %135, %146 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %148 = stablehlo.reshape %147 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %149 = stablehlo.reshape %arg13 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %150 = stablehlo.reshape %149 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %151 = stablehlo.transpose %150, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %152 = stablehlo.dot_general %148, %151, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %153 = stablehlo.reshape %152 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %154 = stablehlo.logistic %153 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
    %155 = stablehlo.multiply %153, %154 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
    %156 = stablehlo.reshape %arg8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %157 = stablehlo.reshape %156 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %158 = stablehlo.transpose %157, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %159 = stablehlo.dot_general %148, %158, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %160 = stablehlo.reshape %159 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %161 = stablehlo.multiply %155, %160 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
    %162 = stablehlo.reshape %161 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16>
    %163 = stablehlo.reshape %arg7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
    %164 = stablehlo.reshape %163 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16>
    %165 = stablehlo.transpose %164, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16>
    %166 = stablehlo.dot_general %162, %165, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16>
    %167 = stablehlo.reshape %166 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %168 = stablehlo.add %132, %167 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %169 = stablehlo.convert %168 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %170 = stablehlo.power %169, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %171 = stablehlo.reduce(%170 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %172 = stablehlo.multiply %171, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
    %173 = stablehlo.reshape %172 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %174 = stablehlo.add %173, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %175 = stablehlo.rsqrt %174 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %176 = stablehlo.reshape %175 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %177 = stablehlo.broadcast_in_dim %176, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %178 = stablehlo.multiply %169, %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %179 = stablehlo.convert %178 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %180 = stablehlo.multiply %66, %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %181 = stablehlo.reshape %180 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %182 = stablehlo.reshape %arg6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %183 = stablehlo.reshape %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %184 = stablehlo.transpose %183, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16>
    %185 = stablehlo.dot_general %181, %184, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16>
    %186 = stablehlo.reshape %185 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16>
    return %37, %63, %186 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
  }
}


// -----// IR Dump Before ShardingConstraintToReshardPass (sdy-sharding-constraint-to-reshard) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg1: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg2: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg3: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg4: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg5: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg6: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg7: tensor<8192x28672xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg8: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg9: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg10: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg11: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg12: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg13: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg14: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<4x8x136x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x8x136x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x136x128256xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"0x00000000000000000100000000000000020000000000000003000000000000000400000000000000050000000000000006000000000000000700000000000000080000000000000009000000000000000A000000000000000B000000000000000C000000000000000D000000000000000E000000000000000F0000000000000010000000000000001100000000000000120000000000000013000000000000001400000000000000150000000000000016000000000000001700000000000000180000000000000019000000000000001A000000000000001B000000000000001C000000000000001D000000000000001E000000000000001F0000000000000020000000000000002100000000000000220000000000000023000000000000002400000000000000250000000000000026000000000000002700000000000000280000000000000029000000000000002A000000000000002B000000000000002C000000000000002D000000000000002E000000000000002F0000000000000030000000000000003100000000000000320000000000000033000000000000003400000000000000350000000000000036000000000000003700000000000000380000000000000039000000000000003A000000000000003B000000000000003C000000000000003D000000000000003E000000000000003F0000000000000040000000000000004100000000000000420000000000000043000000000000004400000000000000450000000000000046000000000000004700000000000000480000000000000049000000000000004A000000000000004B000000000000004C000000000000004D000000000000004E000000000000004F0000000000000050000000000000005100000000000000520000000000000053000000000000005400000000000000550000000000000056000000000000005700000000000000580000000000000059000000000000005A000000000000005B000000000000005C000000000000005D000000000000005E000000000000005F0000000000000060000000000000006100000000000000620000000000000063000000000000006400000000000000650000000000000066000000000000006700000000000000680000000000000069000000000000006A000000000000006B000000000000006C000000000000006D000000000000006E000000000000006F0000000000000070000000000000007100000000000000720000000000000073000000000000007400000000000000750000000000000076000000000000007700000000000000780000000000000079000000000000007A000000000000007B000000000000007C000000000000007D000000000000007E000000000000007F0000000000000080000000000000008100000000000000820000000000000083000000000000008400000000000000850000000000000086000000000000008700000000000000"> : tensor<136xi64>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
    %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>
    %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16>
    %c_6 = stablehlo.constant dense<1> : tensor<i64>
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_8, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_7, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %3 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %4 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64>
    %5 = stablehlo.broadcast_in_dim %cst_5, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x64x136x136xbf16>
    %6 = stablehlo.broadcast_in_dim %cst_3, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136x1xf32>
    %7 = stablehlo.broadcast_in_dim %cst_2, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136xf32>
    %8 = stablehlo.broadcast_in_dim %cst_1, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136x8192xf32>
    %9 = stablehlo.reshape %arg3 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %10 = stablehlo.reshape %9 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %11 = stablehlo.broadcast_in_dim %10, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %12 = stablehlo.reshape %arg2 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %13 = stablehlo.reshape %12 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %14 = stablehlo.reshape %arg1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {?}]>]>} : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %15 = stablehlo.reshape %14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x4x136xi64>) -> tensor<544xi64>
    %16 = stablehlo.convert %15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<544xi64>) -> tensor<544xui32>
    %17 = "stablehlo.gather"(%13, %16) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16>
    %18 = stablehlo.reshape %17 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %19 = stablehlo.convert %18 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %20 = stablehlo.power %19, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %22 = stablehlo.multiply %21, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
    %23 = stablehlo.reshape %22 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %24 = stablehlo.add %23, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %25 = stablehlo.rsqrt %24 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %26 = stablehlo.reshape %25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %28 = stablehlo.multiply %19, %27 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %29 = stablehlo.convert %28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %30 = stablehlo.multiply %11, %29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %31 = stablehlo.reshape %30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %32 = stablehlo.reshape %arg0 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %33 = stablehlo.reshape %32 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %36 = stablehlo.reshape %35 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %37 = stablehlo.transpose %36, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %38 = stablehlo.reshape %arg5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %39 = stablehlo.reshape %38 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %40 = stablehlo.transpose %39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %41 = stablehlo.dot_general %31, %40, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %42 = stablehlo.reshape %41 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %43 = stablehlo.transpose %42, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %44 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.dot_general %45, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x136x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %51 = stablehlo.reshape %50 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %52 = stablehlo.broadcast_in_dim %51, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %53 = stablehlo.multiply %43, %52 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
    %54 = stablehlo.slice %43 [0:4, 0:8, 0:136, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %55 = stablehlo.negate %54 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x64xbf16>
    %56 = stablehlo.slice %43 [0:4, 0:8, 0:136, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %57 = stablehlo.concatenate %55, %56, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16>
    %58 = stablehlo.sine %48 : tensor<1x136x128xf32>
    %59 = stablehlo.convert %58 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %60 = stablehlo.reshape %59 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %62 = stablehlo.multiply %57, %61 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
    %63 = stablehlo.add %53, %62 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
    %64 = stablehlo.reshape %arg14 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %65 = stablehlo.reshape %64 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %66 = stablehlo.broadcast_in_dim %65, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %67 = stablehlo.reshape %arg11 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %68 = stablehlo.reshape %67 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %69 = stablehlo.transpose %68, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %70 = stablehlo.dot_general %31, %69, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %71 = stablehlo.reshape %70 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16>
    %72 = stablehlo.transpose %71, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16>
    %73 = stablehlo.broadcast_in_dim %51, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %74 = stablehlo.multiply %72, %73 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
    %75 = stablehlo.slice %72 [0:4, 0:64, 0:136, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %76 = stablehlo.negate %75 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x64xbf16>
    %77 = stablehlo.slice %72 [0:4, 0:64, 0:136, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %78 = stablehlo.concatenate %76, %77, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16>
    %79 = stablehlo.broadcast_in_dim %60, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %80 = stablehlo.multiply %78, %79 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
    %81 = stablehlo.add %74, %80 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
    %82 = stablehlo.reshape %81 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16>
    %83 = stablehlo.broadcast_in_dim %63, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %84 = stablehlo.reshape %83 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %85 = stablehlo.transpose %84, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16>
    %86 = stablehlo.reshape %85 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16>
    %87 = stablehlo.dot_general %82, %86, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16>
    %88 = stablehlo.reshape %87 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %89 = stablehlo.multiply %88, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xbf16>
    %90 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64>
    %91 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64>
    %92 = stablehlo.subtract %90, %91 : tensor<136x136xi64>
    %93 = stablehlo.compare  GE, %92, %4 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %94 = stablehlo.select %93, %3, %2 : tensor<136x136xi1>, tensor<136x136xbf16>
    %95 = stablehlo.compare  GT, %90, %91 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %96 = stablehlo.convert %95 : (tensor<136x136xi1>) -> tensor<136x136xbf16>
    %97 = stablehlo.multiply %94, %96 : tensor<136x136xbf16>
    %98 = stablehlo.reshape %97 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16>
    %100 = stablehlo.reshape %arg10 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {?}]>]>} : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %101 = stablehlo.reshape %100 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64>
    %102 = stablehlo.convert %101 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16>
    %103 = stablehlo.reshape %102 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16>
    %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16>
    %105 = stablehlo.add %99, %104 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : tensor<4x1x136x136xbf16>
    %106 = stablehlo.compare  EQ, %105, %1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1>
    %107 = stablehlo.select %106, %0, %99 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16>
    %108 = stablehlo.reshape %107 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16>
    %109 = stablehlo.broadcast_in_dim %108, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %110 = stablehlo.add %89, %109 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xbf16>
    %111 = stablehlo.convert %110 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32>
    %112 = stablehlo.reduce(%111 init: %cst_0) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}]>]>} : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %113 = stablehlo.broadcast_in_dim %112, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %114 = stablehlo.subtract %111, %113 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
    %115 = stablehlo.exponential %114 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
    %116 = stablehlo.reduce(%115 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}]>]>} : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %117 = stablehlo.broadcast_in_dim %116, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %118 = stablehlo.divide %115, %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
    %119 = stablehlo.convert %118 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16>
    %120 = stablehlo.reshape %119 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16>
    %121 = stablehlo.broadcast_in_dim %37, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %122 = stablehlo.reshape %121 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16>
    %123 = stablehlo.dot_general %120, %122, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16>
    %124 = stablehlo.reshape %123 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %125 = stablehlo.transpose %124, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16>
    %126 = stablehlo.reshape %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16>
    %127 = stablehlo.reshape %arg9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %128 = stablehlo.reshape %127 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %129 = stablehlo.transpose %128, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %130 = stablehlo.dot_general %126, %129, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %131 = stablehlo.reshape %130 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %132 = stablehlo.add %18, %131 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %133 = stablehlo.reshape %arg12 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %134 = stablehlo.reshape %133 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %136 = stablehlo.convert %132 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %137 = stablehlo.power %136, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %138 = stablehlo.reduce(%137 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %139 = stablehlo.multiply %138, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
    %140 = stablehlo.reshape %139 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %141 = stablehlo.add %140, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %142 = stablehlo.rsqrt %141 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %143 = stablehlo.reshape %142 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %144 = stablehlo.broadcast_in_dim %143, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %145 = stablehlo.multiply %136, %144 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %146 = stablehlo.convert %145 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %147 = stablehlo.multiply %135, %146 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %148 = stablehlo.reshape %147 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %149 = stablehlo.reshape %arg13 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %150 = stablehlo.reshape %149 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %151 = stablehlo.transpose %150, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %152 = stablehlo.dot_general %148, %151, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %153 = stablehlo.reshape %152 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %154 = stablehlo.logistic %153 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
    %155 = stablehlo.multiply %153, %154 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
    %156 = stablehlo.reshape %arg8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %157 = stablehlo.reshape %156 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %158 = stablehlo.transpose %157, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %159 = stablehlo.dot_general %148, %158, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %160 = stablehlo.reshape %159 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %161 = stablehlo.multiply %155, %160 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
    %162 = stablehlo.reshape %161 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16>
    %163 = stablehlo.reshape %arg7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
    %164 = stablehlo.reshape %163 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16>
    %165 = stablehlo.transpose %164, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16>
    %166 = stablehlo.dot_general %162, %165, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16>
    %167 = stablehlo.reshape %166 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %168 = stablehlo.add %132, %167 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %169 = stablehlo.convert %168 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %170 = stablehlo.power %169, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %171 = stablehlo.reduce(%170 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %172 = stablehlo.multiply %171, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
    %173 = stablehlo.reshape %172 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %174 = stablehlo.add %173, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %175 = stablehlo.rsqrt %174 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %176 = stablehlo.reshape %175 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %177 = stablehlo.broadcast_in_dim %176, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %178 = stablehlo.multiply %169, %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %179 = stablehlo.convert %178 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %180 = stablehlo.multiply %66, %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %181 = stablehlo.reshape %180 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %182 = stablehlo.reshape %arg6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %183 = stablehlo.reshape %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %184 = stablehlo.transpose %183, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16>
    %185 = stablehlo.dot_general %181, %184, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16>
    %186 = stablehlo.reshape %185 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16>
    return %37, %63, %186 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
  }
}


// -----// IR Dump Before InsertExplicitReshardsPass (insert-explicit-reshards) ('builtin.module' operation: @SyncTensorsGraph.416) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg1: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg2: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg3: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg4: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg5: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg6: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg7: tensor<8192x28672xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg8: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg9: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg10: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg11: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg12: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg13: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg14: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<4x8x136x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x8x136x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x136x128256xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<136xi64>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
    %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>
    %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16>
    %c_6 = stablehlo.constant dense<1> : tensor<i64>
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_8, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_7, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %3 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %4 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64>
    %5 = stablehlo.broadcast_in_dim %cst_5, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x64x136x136xbf16>
    %6 = stablehlo.broadcast_in_dim %cst_3, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136x1xf32>
    %7 = stablehlo.broadcast_in_dim %cst_2, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136xf32>
    %8 = stablehlo.broadcast_in_dim %cst_1, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136x8192xf32>
    %9 = stablehlo.reshape %arg3 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %10 = stablehlo.reshape %9 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %11 = stablehlo.broadcast_in_dim %10, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %12 = stablehlo.reshape %arg2 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %13 = stablehlo.reshape %12 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %14 = stablehlo.reshape %arg1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {?}]>]>} : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %15 = stablehlo.reshape %14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x4x136xi64>) -> tensor<544xi64>
    %16 = stablehlo.convert %15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<544xi64>) -> tensor<544xui32>
    %17 = "stablehlo.gather"(%13, %16) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16>
    %18 = stablehlo.reshape %17 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %19 = stablehlo.convert %18 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %20 = stablehlo.power %19, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %22 = stablehlo.multiply %21, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
    %23 = stablehlo.reshape %22 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %24 = stablehlo.add %23, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %25 = stablehlo.rsqrt %24 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %26 = stablehlo.reshape %25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %28 = stablehlo.multiply %19, %27 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %29 = stablehlo.convert %28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %30 = stablehlo.multiply %11, %29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %31 = stablehlo.reshape %30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %32 = stablehlo.reshape %arg0 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %33 = stablehlo.reshape %32 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %36 = stablehlo.reshape %35 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %37 = stablehlo.transpose %36, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %38 = stablehlo.reshape %arg5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %39 = stablehlo.reshape %38 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %40 = stablehlo.transpose %39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %41 = stablehlo.dot_general %31, %40, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %42 = stablehlo.reshape %41 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %43 = stablehlo.transpose %42, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %44 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.dot_general %45, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x136x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %51 = stablehlo.reshape %50 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %52 = stablehlo.broadcast_in_dim %51, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %53 = stablehlo.multiply %43, %52 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
    %54 = stablehlo.slice %43 [0:4, 0:8, 0:136, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %55 = stablehlo.negate %54 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x64xbf16>
    %56 = stablehlo.slice %43 [0:4, 0:8, 0:136, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %57 = stablehlo.concatenate %55, %56, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16>
    %58 = stablehlo.sine %48 : tensor<1x136x128xf32>
    %59 = stablehlo.convert %58 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %60 = stablehlo.reshape %59 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %62 = stablehlo.multiply %57, %61 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
    %63 = stablehlo.add %53, %62 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
    %64 = stablehlo.reshape %arg14 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %65 = stablehlo.reshape %64 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %66 = stablehlo.broadcast_in_dim %65, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %67 = stablehlo.reshape %arg11 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %68 = stablehlo.reshape %67 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %69 = stablehlo.transpose %68, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %70 = stablehlo.dot_general %31, %69, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %71 = stablehlo.reshape %70 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16>
    %72 = stablehlo.transpose %71, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16>
    %73 = stablehlo.broadcast_in_dim %51, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %74 = stablehlo.multiply %72, %73 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
    %75 = stablehlo.slice %72 [0:4, 0:64, 0:136, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %76 = stablehlo.negate %75 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x64xbf16>
    %77 = stablehlo.slice %72 [0:4, 0:64, 0:136, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %78 = stablehlo.concatenate %76, %77, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16>
    %79 = stablehlo.broadcast_in_dim %60, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %80 = stablehlo.multiply %78, %79 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
    %81 = stablehlo.add %74, %80 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
    %82 = stablehlo.reshape %81 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16>
    %83 = stablehlo.broadcast_in_dim %63, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %84 = stablehlo.reshape %83 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %85 = stablehlo.transpose %84, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16>
    %86 = stablehlo.reshape %85 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16>
    %87 = stablehlo.dot_general %82, %86, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16>
    %88 = stablehlo.reshape %87 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %89 = stablehlo.multiply %88, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xbf16>
    %90 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64>
    %91 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64>
    %92 = stablehlo.subtract %90, %91 : tensor<136x136xi64>
    %93 = stablehlo.compare  GE, %92, %4 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %94 = stablehlo.select %93, %3, %2 : tensor<136x136xi1>, tensor<136x136xbf16>
    %95 = stablehlo.compare  GT, %90, %91 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %96 = stablehlo.convert %95 : (tensor<136x136xi1>) -> tensor<136x136xbf16>
    %97 = stablehlo.multiply %94, %96 : tensor<136x136xbf16>
    %98 = stablehlo.reshape %97 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16>
    %100 = stablehlo.reshape %arg10 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {?}]>]>} : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %101 = stablehlo.reshape %100 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64>
    %102 = stablehlo.convert %101 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16>
    %103 = stablehlo.reshape %102 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16>
    %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16>
    %105 = stablehlo.add %99, %104 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : tensor<4x1x136x136xbf16>
    %106 = stablehlo.compare  EQ, %105, %1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1>
    %107 = stablehlo.select %106, %0, %99 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16>
    %108 = stablehlo.reshape %107 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16>
    %109 = stablehlo.broadcast_in_dim %108, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %110 = stablehlo.add %89, %109 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xbf16>
    %111 = stablehlo.convert %110 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32>
    %112 = stablehlo.reduce(%111 init: %cst_0) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}]>]>} : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %113 = stablehlo.broadcast_in_dim %112, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %114 = stablehlo.subtract %111, %113 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
    %115 = stablehlo.exponential %114 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
    %116 = stablehlo.reduce(%115 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}]>]>} : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %117 = stablehlo.broadcast_in_dim %116, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %118 = stablehlo.divide %115, %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
    %119 = stablehlo.convert %118 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16>
    %120 = stablehlo.reshape %119 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16>
    %121 = stablehlo.broadcast_in_dim %37, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %122 = stablehlo.reshape %121 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16>
    %123 = stablehlo.dot_general %120, %122, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16>
    %124 = stablehlo.reshape %123 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %125 = stablehlo.transpose %124, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16>
    %126 = stablehlo.reshape %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16>
    %127 = stablehlo.reshape %arg9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %128 = stablehlo.reshape %127 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %129 = stablehlo.transpose %128, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %130 = stablehlo.dot_general %126, %129, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %131 = stablehlo.reshape %130 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %132 = stablehlo.add %18, %131 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %133 = stablehlo.reshape %arg12 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %134 = stablehlo.reshape %133 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %136 = stablehlo.convert %132 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %137 = stablehlo.power %136, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %138 = stablehlo.reduce(%137 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %139 = stablehlo.multiply %138, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
    %140 = stablehlo.reshape %139 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %141 = stablehlo.add %140, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %142 = stablehlo.rsqrt %141 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %143 = stablehlo.reshape %142 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %144 = stablehlo.broadcast_in_dim %143, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %145 = stablehlo.multiply %136, %144 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %146 = stablehlo.convert %145 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %147 = stablehlo.multiply %135, %146 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %148 = stablehlo.reshape %147 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %149 = stablehlo.reshape %arg13 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %150 = stablehlo.reshape %149 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %151 = stablehlo.transpose %150, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %152 = stablehlo.dot_general %148, %151, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %153 = stablehlo.reshape %152 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %154 = stablehlo.logistic %153 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
    %155 = stablehlo.multiply %153, %154 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
    %156 = stablehlo.reshape %arg8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %157 = stablehlo.reshape %156 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %158 = stablehlo.transpose %157, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %159 = stablehlo.dot_general %148, %158, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %160 = stablehlo.reshape %159 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %161 = stablehlo.multiply %155, %160 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
    %162 = stablehlo.reshape %161 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16>
    %163 = stablehlo.reshape %arg7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
    %164 = stablehlo.reshape %163 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16>
    %165 = stablehlo.transpose %164, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16>
    %166 = stablehlo.dot_general %162, %165, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16>
    %167 = stablehlo.reshape %166 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %168 = stablehlo.add %132, %167 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %169 = stablehlo.convert %168 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %170 = stablehlo.power %169, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %171 = stablehlo.reduce(%170 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %172 = stablehlo.multiply %171, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
    %173 = stablehlo.reshape %172 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %174 = stablehlo.add %173, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %175 = stablehlo.rsqrt %174 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %176 = stablehlo.reshape %175 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %177 = stablehlo.broadcast_in_dim %176, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %178 = stablehlo.multiply %169, %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %179 = stablehlo.convert %178 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %180 = stablehlo.multiply %66, %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %181 = stablehlo.reshape %180 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %182 = stablehlo.reshape %arg6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %183 = stablehlo.reshape %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %184 = stablehlo.transpose %183, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16>
    %185 = stablehlo.dot_general %181, %184, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16>
    %186 = stablehlo.reshape %185 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16>
    return %37, %63, %186 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
  }
}


// -----// IR Dump After InsertExplicitReshardsPass (insert-explicit-reshards) ('builtin.module' operation: @SyncTensorsGraph.416) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg1: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg2: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg3: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg4: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg5: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg6: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg7: tensor<8192x28672xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg8: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg9: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg10: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg11: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg12: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg13: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg14: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<4x8x136x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x8x136x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x136x128256xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<136xi64>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
    %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>
    %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16>
    %c_6 = stablehlo.constant dense<1> : tensor<i64>
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_8, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_7, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %3 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %4 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64>
    %5 = stablehlo.broadcast_in_dim %cst_5, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x64x136x136xbf16>
    %6 = stablehlo.broadcast_in_dim %cst_3, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136x1xf32>
    %7 = stablehlo.broadcast_in_dim %cst_2, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136xf32>
    %8 = stablehlo.broadcast_in_dim %cst_1, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136x8192xf32>
    %9 = stablehlo.reshape %arg3 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %10 = stablehlo.reshape %9 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %11 = stablehlo.broadcast_in_dim %10, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %12 = stablehlo.reshape %arg2 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %13 = stablehlo.reshape %12 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %14 = stablehlo.reshape %arg1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {?}]>]>} : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %15 = stablehlo.reshape %14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x4x136xi64>) -> tensor<544xi64>
    %16 = stablehlo.convert %15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<544xi64>) -> tensor<544xui32>
    %17 = "stablehlo.gather"(%13, %16) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16>
    %18 = stablehlo.reshape %17 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %19 = stablehlo.convert %18 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %20 = stablehlo.power %19, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %22 = stablehlo.multiply %21, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
    %23 = stablehlo.reshape %22 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %24 = stablehlo.add %23, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %25 = stablehlo.rsqrt %24 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %26 = stablehlo.reshape %25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %28 = stablehlo.multiply %19, %27 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %29 = stablehlo.convert %28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %30 = stablehlo.multiply %11, %29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %31 = stablehlo.reshape %30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %32 = stablehlo.reshape %arg0 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %33 = stablehlo.reshape %32 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %35 = sdy.reshard %31 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
    %36 = stablehlo.dot_general %35, %34, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %37 = sdy.all_reduce {"_axis_1"} %36 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x1024xbf16>
    %38 = sdy.reshard %37 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x1024xbf16>
    %39 = stablehlo.reshape %38 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %40 = stablehlo.transpose %39, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %41 = stablehlo.reshape %arg5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %42 = stablehlo.reshape %41 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %43 = stablehlo.transpose %42, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %44 = sdy.reshard %31 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
    %45 = stablehlo.dot_general %44, %43, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %46 = sdy.all_reduce {"_axis_1"} %45 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x1024xbf16>
    %47 = sdy.reshard %46 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x1024xbf16>
    %48 = stablehlo.reshape %47 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %49 = stablehlo.transpose %48, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %50 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %51 = stablehlo.reshape %50 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %52 = stablehlo.dot_general %51, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
    %53 = stablehlo.transpose %52, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
    %54 = stablehlo.concatenate %53, %53, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
    %55 = stablehlo.cosine %54 : tensor<1x136x128xf32>
    %56 = stablehlo.convert %55 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %57 = stablehlo.reshape %56 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %58 = stablehlo.broadcast_in_dim %57, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %59 = stablehlo.multiply %49, %58 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
    %60 = stablehlo.slice %49 [0:4, 0:8, 0:136, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %61 = stablehlo.negate %60 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x64xbf16>
    %62 = stablehlo.slice %49 [0:4, 0:8, 0:136, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %63 = stablehlo.concatenate %61, %62, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16>
    %64 = stablehlo.sine %54 : tensor<1x136x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %66 = stablehlo.reshape %65 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %67 = stablehlo.broadcast_in_dim %66, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %68 = stablehlo.multiply %63, %67 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
    %69 = stablehlo.add %59, %68 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
    %70 = stablehlo.reshape %arg14 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %71 = stablehlo.reshape %70 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %72 = stablehlo.broadcast_in_dim %71, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %73 = stablehlo.reshape %arg11 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %74 = stablehlo.reshape %73 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %76 = sdy.reshard %31 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
    %77 = stablehlo.dot_general %76, %75, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %78 = sdy.all_reduce {"_axis_1"} %77 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x8192xbf16>
    %79 = sdy.reshard %78 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x8192xbf16>
    %80 = stablehlo.reshape %79 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16>
    %81 = stablehlo.transpose %80, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16>
    %82 = stablehlo.broadcast_in_dim %57, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %83 = stablehlo.multiply %81, %82 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
    %84 = stablehlo.slice %81 [0:4, 0:64, 0:136, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %85 = stablehlo.negate %84 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x64xbf16>
    %86 = stablehlo.slice %81 [0:4, 0:64, 0:136, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %87 = stablehlo.concatenate %85, %86, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16>
    %88 = stablehlo.broadcast_in_dim %66, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %89 = stablehlo.multiply %87, %88 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
    %90 = stablehlo.add %83, %89 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
    %91 = stablehlo.reshape %90 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16>
    %92 = stablehlo.broadcast_in_dim %69, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %93 = stablehlo.reshape %92 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %94 = stablehlo.transpose %93, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16>
    %95 = stablehlo.reshape %94 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16>
    %96 = stablehlo.dot_general %91, %95, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16>
    %97 = stablehlo.reshape %96 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %98 = stablehlo.multiply %97, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xbf16>
    %99 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64>
    %100 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64>
    %101 = stablehlo.subtract %99, %100 : tensor<136x136xi64>
    %102 = stablehlo.compare  GE, %101, %4 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %103 = stablehlo.select %102, %3, %2 : tensor<136x136xi1>, tensor<136x136xbf16>
    %104 = stablehlo.compare  GT, %99, %100 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %105 = stablehlo.convert %104 : (tensor<136x136xi1>) -> tensor<136x136xbf16>
    %106 = stablehlo.multiply %103, %105 : tensor<136x136xbf16>
    %107 = stablehlo.reshape %106 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
    %108 = stablehlo.broadcast_in_dim %107, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16>
    %109 = stablehlo.reshape %arg10 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {?}]>]>} : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %110 = stablehlo.reshape %109 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64>
    %111 = stablehlo.convert %110 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16>
    %112 = stablehlo.reshape %111 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16>
    %113 = stablehlo.broadcast_in_dim %112, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16>
    %114 = stablehlo.add %108, %113 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : tensor<4x1x136x136xbf16>
    %115 = stablehlo.compare  EQ, %114, %1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1>
    %116 = stablehlo.select %115, %0, %108 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16>
    %117 = stablehlo.reshape %116 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16>
    %118 = stablehlo.broadcast_in_dim %117, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %119 = stablehlo.add %98, %118 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xbf16>
    %120 = stablehlo.convert %119 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32>
    %121 = stablehlo.reduce(%120 init: %cst_0) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}]>]>} : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %122 = stablehlo.broadcast_in_dim %121, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %123 = stablehlo.subtract %120, %122 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
    %124 = stablehlo.exponential %123 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
    %125 = stablehlo.reduce(%124 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}]>]>} : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %126 = stablehlo.broadcast_in_dim %125, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %127 = stablehlo.divide %124, %126 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
    %128 = stablehlo.convert %127 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16>
    %129 = stablehlo.reshape %128 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16>
    %130 = stablehlo.broadcast_in_dim %40, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %131 = stablehlo.reshape %130 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16>
    %132 = stablehlo.dot_general %129, %131, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16>
    %133 = stablehlo.reshape %132 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %134 = stablehlo.transpose %133, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16>
    %135 = stablehlo.reshape %134 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16>
    %136 = stablehlo.reshape %arg9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %137 = stablehlo.reshape %136 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %138 = stablehlo.transpose %137, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %139 = sdy.reshard %135 <@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x8192xbf16>
    %140 = stablehlo.dot_general %139, %138, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %141 = sdy.all_reduce {"_axis_0"} %140 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
    %142 = stablehlo.reshape %141 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %143 = sdy.reshard %142 <@mesh, [{"_axis_1", ?}, {?}, {?}]> : tensor<4x136x8192xbf16>
    %144 = stablehlo.add %18, %143 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %145 = stablehlo.reshape %arg12 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %146 = stablehlo.reshape %145 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %147 = stablehlo.broadcast_in_dim %146, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %148 = stablehlo.convert %144 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %149 = stablehlo.power %148, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %150 = stablehlo.reduce(%149 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %151 = stablehlo.multiply %150, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
    %152 = stablehlo.reshape %151 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %153 = stablehlo.add %152, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %154 = stablehlo.rsqrt %153 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %155 = stablehlo.reshape %154 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %156 = stablehlo.broadcast_in_dim %155, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %157 = stablehlo.multiply %148, %156 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %158 = stablehlo.convert %157 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %159 = stablehlo.multiply %147, %158 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %160 = stablehlo.reshape %159 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %161 = stablehlo.reshape %arg13 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %162 = stablehlo.reshape %161 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %163 = stablehlo.transpose %162, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %164 = sdy.reshard %160 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
    %165 = stablehlo.dot_general %164, %163, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %166 = sdy.all_reduce {"_axis_1"} %165 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
    %167 = sdy.reshard %166 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
    %168 = stablehlo.reshape %167 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %169 = stablehlo.logistic %168 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
    %170 = stablehlo.multiply %168, %169 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
    %171 = stablehlo.reshape %arg8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %172 = stablehlo.reshape %171 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %173 = stablehlo.transpose %172, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %174 = sdy.reshard %160 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
    %175 = stablehlo.dot_general %174, %173, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %176 = sdy.all_reduce {"_axis_1"} %175 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
    %177 = sdy.reshard %176 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
    %178 = stablehlo.reshape %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %179 = stablehlo.multiply %170, %178 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
    %180 = stablehlo.reshape %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16>
    %181 = stablehlo.reshape %arg7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
    %182 = stablehlo.reshape %181 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16>
    %183 = stablehlo.transpose %182, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16>
    %184 = sdy.reshard %180 <@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
    %185 = stablehlo.dot_general %184, %183, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16>
    %186 = sdy.all_reduce {"_axis_0"} %185 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
    %187 = stablehlo.reshape %186 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %188 = sdy.reshard %187 <@mesh, [{"_axis_1", ?}, {?}, {?}]> : tensor<4x136x8192xbf16>
    %189 = stablehlo.add %144, %188 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %190 = stablehlo.convert %189 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %191 = stablehlo.power %190, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %192 = stablehlo.reduce(%191 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %193 = stablehlo.multiply %192, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
    %194 = stablehlo.reshape %193 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %195 = stablehlo.add %194, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %196 = stablehlo.rsqrt %195 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %197 = stablehlo.reshape %196 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %198 = stablehlo.broadcast_in_dim %197, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %199 = stablehlo.multiply %190, %198 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %200 = stablehlo.convert %199 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %201 = stablehlo.multiply %72, %200 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %202 = stablehlo.reshape %201 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %203 = stablehlo.reshape %arg6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %204 = stablehlo.reshape %203 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %205 = stablehlo.transpose %204, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16>
    %206 = sdy.reshard %202 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
    %207 = stablehlo.dot_general %206, %205, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16>
    %208 = sdy.all_reduce {"_axis_1"} %207 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x128256xbf16>
    %209 = sdy.reshard %208 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x128256xbf16>
    %210 = stablehlo.reshape %209 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16>
    return %40, %69, %210 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
  }
}


// -----// IR Dump Before WrapUnderManualComputationPass (wrap-under-manual-computation) ('builtin.module' operation: @SyncTensorsGraph.416) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg1: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg2: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg3: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg4: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg5: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg6: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg7: tensor<8192x28672xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg8: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg9: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg10: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg11: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg12: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg13: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg14: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<4x8x136x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x8x136x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x136x128256xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"0x00000000000000000100000000000000020000000000000003000000000000000400000000000000050000000000000006000000000000000700000000000000080000000000000009000000000000000A000000000000000B000000000000000C000000000000000D000000000000000E000000000000000F0000000000000010000000000000001100000000000000120000000000000013000000000000001400000000000000150000000000000016000000000000001700000000000000180000000000000019000000000000001A000000000000001B000000000000001C000000000000001D000000000000001E000000000000001F0000000000000020000000000000002100000000000000220000000000000023000000000000002400000000000000250000000000000026000000000000002700000000000000280000000000000029000000000000002A000000000000002B000000000000002C000000000000002D000000000000002E000000000000002F0000000000000030000000000000003100000000000000320000000000000033000000000000003400000000000000350000000000000036000000000000003700000000000000380000000000000039000000000000003A000000000000003B000000000000003C000000000000003D000000000000003E000000000000003F0000000000000040000000000000004100000000000000420000000000000043000000000000004400000000000000450000000000000046000000000000004700000000000000480000000000000049000000000000004A000000000000004B000000000000004C000000000000004D000000000000004E000000000000004F0000000000000050000000000000005100000000000000520000000000000053000000000000005400000000000000550000000000000056000000000000005700000000000000580000000000000059000000000000005A000000000000005B000000000000005C000000000000005D000000000000005E000000000000005F0000000000000060000000000000006100000000000000620000000000000063000000000000006400000000000000650000000000000066000000000000006700000000000000680000000000000069000000000000006A000000000000006B000000000000006C000000000000006D000000000000006E000000000000006F0000000000000070000000000000007100000000000000720000000000000073000000000000007400000000000000750000000000000076000000000000007700000000000000780000000000000079000000000000007A000000000000007B000000000000007C000000000000007D000000000000007E000000000000007F0000000000000080000000000000008100000000000000820000000000000083000000000000008400000000000000850000000000000086000000000000008700000000000000"> : tensor<136xi64>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
    %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>
    %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16>
    %c_6 = stablehlo.constant dense<1> : tensor<i64>
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_8, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_7, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %3 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
    %4 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64>
    %5 = stablehlo.broadcast_in_dim %cst_5, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x64x136x136xbf16>
    %6 = stablehlo.broadcast_in_dim %cst_3, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136x1xf32>
    %7 = stablehlo.broadcast_in_dim %cst_2, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136xf32>
    %8 = stablehlo.broadcast_in_dim %cst_1, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136x8192xf32>
    %9 = stablehlo.reshape %arg3 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %10 = stablehlo.reshape %9 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %11 = stablehlo.broadcast_in_dim %10, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %12 = stablehlo.reshape %arg2 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %13 = stablehlo.reshape %12 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %14 = stablehlo.reshape %arg1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {?}]>]>} : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %15 = stablehlo.reshape %14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x4x136xi64>) -> tensor<544xi64>
    %16 = stablehlo.convert %15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<544xi64>) -> tensor<544xui32>
    %17 = "stablehlo.gather"(%13, %16) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16>
    %18 = stablehlo.reshape %17 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %19 = stablehlo.convert %18 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %20 = stablehlo.power %19, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %22 = stablehlo.multiply %21, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
    %23 = stablehlo.reshape %22 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %24 = stablehlo.add %23, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %25 = stablehlo.rsqrt %24 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %26 = stablehlo.reshape %25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %28 = stablehlo.multiply %19, %27 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %29 = stablehlo.convert %28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %30 = stablehlo.multiply %11, %29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %31 = stablehlo.reshape %30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %32 = stablehlo.reshape %arg0 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %33 = stablehlo.reshape %32 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %35 = sdy.reshard %31 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
    %36 = stablehlo.dot_general %35, %34, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %37 = sdy.all_reduce {"_axis_1"} %36 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x1024xbf16>
    %38 = sdy.reshard %37 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x1024xbf16>
    %39 = stablehlo.reshape %38 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %40 = stablehlo.transpose %39, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %41 = stablehlo.reshape %arg5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
    %42 = stablehlo.reshape %41 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
    %43 = stablehlo.transpose %42, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
    %44 = sdy.reshard %31 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
    %45 = stablehlo.dot_general %44, %43, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
    %46 = sdy.all_reduce {"_axis_1"} %45 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x1024xbf16>
    %47 = sdy.reshard %46 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x1024xbf16>
    %48 = stablehlo.reshape %47 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
    %49 = stablehlo.transpose %48, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
    %50 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %51 = stablehlo.reshape %50 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %52 = stablehlo.dot_general %51, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
    %53 = stablehlo.transpose %52, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
    %54 = stablehlo.concatenate %53, %53, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
    %55 = stablehlo.cosine %54 : tensor<1x136x128xf32>
    %56 = stablehlo.convert %55 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %57 = stablehlo.reshape %56 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %58 = stablehlo.broadcast_in_dim %57, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %59 = stablehlo.multiply %49, %58 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
    %60 = stablehlo.slice %49 [0:4, 0:8, 0:136, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %61 = stablehlo.negate %60 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x64xbf16>
    %62 = stablehlo.slice %49 [0:4, 0:8, 0:136, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
    %63 = stablehlo.concatenate %61, %62, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16>
    %64 = stablehlo.sine %54 : tensor<1x136x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
    %66 = stablehlo.reshape %65 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
    %67 = stablehlo.broadcast_in_dim %66, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
    %68 = stablehlo.multiply %63, %67 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
    %69 = stablehlo.add %59, %68 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
    %70 = stablehlo.reshape %arg14 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %71 = stablehlo.reshape %70 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %72 = stablehlo.broadcast_in_dim %71, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %73 = stablehlo.reshape %arg11 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %74 = stablehlo.reshape %73 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %76 = sdy.reshard %31 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
    %77 = stablehlo.dot_general %76, %75, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %78 = sdy.all_reduce {"_axis_1"} %77 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x8192xbf16>
    %79 = sdy.reshard %78 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x8192xbf16>
    %80 = stablehlo.reshape %79 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16>
    %81 = stablehlo.transpose %80, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16>
    %82 = stablehlo.broadcast_in_dim %57, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %83 = stablehlo.multiply %81, %82 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
    %84 = stablehlo.slice %81 [0:4, 0:64, 0:136, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %85 = stablehlo.negate %84 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x64xbf16>
    %86 = stablehlo.slice %81 [0:4, 0:64, 0:136, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
    %87 = stablehlo.concatenate %85, %86, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16>
    %88 = stablehlo.broadcast_in_dim %66, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %89 = stablehlo.multiply %87, %88 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
    %90 = stablehlo.add %83, %89 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
    %91 = stablehlo.reshape %90 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16>
    %92 = stablehlo.broadcast_in_dim %69, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %93 = stablehlo.reshape %92 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %94 = stablehlo.transpose %93, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16>
    %95 = stablehlo.reshape %94 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16>
    %96 = stablehlo.dot_general %91, %95, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16>
    %97 = stablehlo.reshape %96 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %98 = stablehlo.multiply %97, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xbf16>
    %99 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64>
    %100 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64>
    %101 = stablehlo.subtract %99, %100 : tensor<136x136xi64>
    %102 = stablehlo.compare  GE, %101, %4 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %103 = stablehlo.select %102, %3, %2 : tensor<136x136xi1>, tensor<136x136xbf16>
    %104 = stablehlo.compare  GT, %99, %100 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
    %105 = stablehlo.convert %104 : (tensor<136x136xi1>) -> tensor<136x136xbf16>
    %106 = stablehlo.multiply %103, %105 : tensor<136x136xbf16>
    %107 = stablehlo.reshape %106 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
    %108 = stablehlo.broadcast_in_dim %107, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16>
    %109 = stablehlo.reshape %arg10 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {?}]>]>} : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
    %110 = stablehlo.reshape %109 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64>
    %111 = stablehlo.convert %110 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16>
    %112 = stablehlo.reshape %111 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16>
    %113 = stablehlo.broadcast_in_dim %112, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16>
    %114 = stablehlo.add %108, %113 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : tensor<4x1x136x136xbf16>
    %115 = stablehlo.compare  EQ, %114, %1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1>
    %116 = stablehlo.select %115, %0, %108 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16>
    %117 = stablehlo.reshape %116 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16>
    %118 = stablehlo.broadcast_in_dim %117, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16>
    %119 = stablehlo.add %98, %118 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xbf16>
    %120 = stablehlo.convert %119 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32>
    %121 = stablehlo.reduce(%120 init: %cst_0) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}]>]>} : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %122 = stablehlo.broadcast_in_dim %121, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %123 = stablehlo.subtract %120, %122 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
    %124 = stablehlo.exponential %123 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
    %125 = stablehlo.reduce(%124 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}]>]>} : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
    %126 = stablehlo.broadcast_in_dim %125, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
    %127 = stablehlo.divide %124, %126 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
    %128 = stablehlo.convert %127 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16>
    %129 = stablehlo.reshape %128 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16>
    %130 = stablehlo.broadcast_in_dim %40, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
    %131 = stablehlo.reshape %130 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16>
    %132 = stablehlo.dot_general %129, %131, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16>
    %133 = stablehlo.reshape %132 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16>
    %134 = stablehlo.transpose %133, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16>
    %135 = stablehlo.reshape %134 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16>
    %136 = stablehlo.reshape %arg9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
    %137 = stablehlo.reshape %136 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %138 = stablehlo.transpose %137, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
    %139 = sdy.reshard %135 <@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x8192xbf16>
    %140 = stablehlo.dot_general %139, %138, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
    %141 = sdy.all_reduce {"_axis_0"} %140 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
    %142 = stablehlo.reshape %141 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %143 = sdy.reshard %142 <@mesh, [{"_axis_1", ?}, {?}, {?}]> : tensor<4x136x8192xbf16>
    %144 = stablehlo.add %18, %143 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %145 = stablehlo.reshape %arg12 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
    %146 = stablehlo.reshape %145 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
    %147 = stablehlo.broadcast_in_dim %146, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
    %148 = stablehlo.convert %144 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %149 = stablehlo.power %148, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %150 = stablehlo.reduce(%149 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %151 = stablehlo.multiply %150, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
    %152 = stablehlo.reshape %151 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %153 = stablehlo.add %152, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %154 = stablehlo.rsqrt %153 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %155 = stablehlo.reshape %154 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %156 = stablehlo.broadcast_in_dim %155, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %157 = stablehlo.multiply %148, %156 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %158 = stablehlo.convert %157 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %159 = stablehlo.multiply %147, %158 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %160 = stablehlo.reshape %159 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %161 = stablehlo.reshape %arg13 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %162 = stablehlo.reshape %161 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %163 = stablehlo.transpose %162, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %164 = sdy.reshard %160 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
    %165 = stablehlo.dot_general %164, %163, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %166 = sdy.all_reduce {"_axis_1"} %165 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
    %167 = sdy.reshard %166 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
    %168 = stablehlo.reshape %167 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %169 = stablehlo.logistic %168 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
    %170 = stablehlo.multiply %168, %169 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
    %171 = stablehlo.reshape %arg8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
    %172 = stablehlo.reshape %171 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
    %173 = stablehlo.transpose %172, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
    %174 = sdy.reshard %160 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
    %175 = stablehlo.dot_general %174, %173, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
    %176 = sdy.all_reduce {"_axis_1"} %175 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
    %177 = sdy.reshard %176 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
    %178 = stablehlo.reshape %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
    %179 = stablehlo.multiply %170, %178 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
    %180 = stablehlo.reshape %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16>
    %181 = stablehlo.reshape %arg7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
    %182 = stablehlo.reshape %181 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16>
    %183 = stablehlo.transpose %182, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16>
    %184 = sdy.reshard %180 <@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
    %185 = stablehlo.dot_general %184, %183, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16>
    %186 = sdy.all_reduce {"_axis_0"} %185 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
    %187 = stablehlo.reshape %186 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
    %188 = sdy.reshard %187 <@mesh, [{"_axis_1", ?}, {?}, {?}]> : tensor<4x136x8192xbf16>
    %189 = stablehlo.add %144, %188 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %190 = stablehlo.convert %189 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
    %191 = stablehlo.power %190, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %192 = stablehlo.reduce(%191 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
    %193 = stablehlo.multiply %192, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
    %194 = stablehlo.reshape %193 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
    %195 = stablehlo.add %194, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %196 = stablehlo.rsqrt %195 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
    %197 = stablehlo.reshape %196 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
    %198 = stablehlo.broadcast_in_dim %197, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
    %199 = stablehlo.multiply %190, %198 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
    %200 = stablehlo.convert %199 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
    %201 = stablehlo.multiply %72, %200 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
    %202 = stablehlo.reshape %201 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
    %203 = stablehlo.reshape %arg6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
    %204 = stablehlo.reshape %203 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
    %205 = stablehlo.transpose %204, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16>
    %206 = sdy.reshard %202 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
    %207 = stablehlo.dot_general %206, %205, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16>
    %208 = sdy.all_reduce {"_axis_1"} %207 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x128256xbf16>
    %209 = sdy.reshard %208 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x128256xbf16>
    %210 = stablehlo.reshape %209 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16>
    return %40, %69, %210 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
  }
}


// -----// IR Dump After WrapUnderManualComputationPass (wrap-under-manual-computation) ('builtin.module' operation: @SyncTensorsGraph.416) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg1: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg2: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg3: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg4: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg5: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg6: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg7: tensor<8192x28672xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg8: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg9: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg10: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg11: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg12: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg13: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg14: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<4x8x136x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x8x136x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x136x128256xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14) in_shardings=[<@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{"_axis_1"}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{"_axis_1"}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{"_axis_1"}, {"_axis_0"}]>, <@mesh, [{"_axis_1"}, {}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{}]>] out_shardings=[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, <@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>] manual_axes={} (%arg15: tensor<1024x8192xbf16>, %arg16: tensor<4x136xi64>, %arg17: tensor<128256x8192xbf16>, %arg18: tensor<8192xbf16>, %arg19: tensor<64xf32>, %arg20: tensor<1024x8192xbf16>, %arg21: tensor<128256x8192xbf16>, %arg22: tensor<8192x28672xbf16>, %arg23: tensor<28672x8192xbf16>, %arg24: tensor<8192x8192xbf16>, %arg25: tensor<4x136xi64>, %arg26: tensor<8192x8192xbf16>, %arg27: tensor<8192xbf16>, %arg28: tensor<28672x8192xbf16>, %arg29: tensor<8192xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
      %c = stablehlo.constant dense<"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tensor<136xi64>
      %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
      %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
      %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32>
      %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
      %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>
      %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16>
      %c_6 = stablehlo.constant dense<1> : tensor<i64>
      %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_8, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
      %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
      %3 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
      %4 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
      %5 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64>
      %6 = stablehlo.broadcast_in_dim %cst_5, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x64x136x136xbf16>
      %7 = stablehlo.broadcast_in_dim %cst_3, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136x1xf32>
      %8 = stablehlo.broadcast_in_dim %cst_2, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136xf32>
      %9 = stablehlo.broadcast_in_dim %cst_1, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136x8192xf32>
      %10 = stablehlo.reshape %arg18 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
      %11 = stablehlo.reshape %10 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
      %12 = stablehlo.broadcast_in_dim %11, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
      %13 = stablehlo.reshape %arg17 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
      %14 = stablehlo.reshape %13 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
      %15 = stablehlo.reshape %arg16 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {?}]>]>} : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
      %16 = stablehlo.reshape %15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x4x136xi64>) -> tensor<544xi64>
      %17 = stablehlo.convert %16 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<544xi64>) -> tensor<544xui32>
      %18 = "stablehlo.gather"(%14, %17) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16>
      %19 = stablehlo.reshape %18 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
      %20 = stablehlo.convert %19 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
      %21 = stablehlo.power %20, %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %22 = stablehlo.reduce(%21 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
      %23 = stablehlo.multiply %22, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
      %24 = stablehlo.reshape %23 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
      %25 = stablehlo.add %24, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %26 = stablehlo.rsqrt %25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %27 = stablehlo.reshape %26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
      %28 = stablehlo.broadcast_in_dim %27, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
      %29 = stablehlo.multiply %20, %28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %30 = stablehlo.convert %29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
      %31 = stablehlo.multiply %12, %30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
      %32 = stablehlo.reshape %31 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
      %33 = stablehlo.reshape %arg15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
      %34 = stablehlo.reshape %33 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
      %35 = stablehlo.transpose %34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
      %36 = sdy.reshard %32 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
      %37 = stablehlo.dot_general %36, %35, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
      %38 = sdy.all_reduce {"_axis_1"} %37 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x1024xbf16>
      %39 = sdy.reshard %38 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x1024xbf16>
      %40 = stablehlo.reshape %39 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
      %41 = stablehlo.transpose %40, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
      %42 = stablehlo.reshape %arg20 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
      %43 = stablehlo.reshape %42 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
      %44 = stablehlo.transpose %43, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
      %45 = sdy.reshard %32 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
      %46 = stablehlo.dot_general %45, %44, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
      %47 = sdy.all_reduce {"_axis_1"} %46 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x1024xbf16>
      %48 = sdy.reshard %47 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x1024xbf16>
      %49 = stablehlo.reshape %48 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
      %50 = stablehlo.transpose %49, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
      %51 = stablehlo.reshape %arg19 : (tensor<64xf32>) -> tensor<1x1x64xf32>
      %52 = stablehlo.reshape %51 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
      %53 = stablehlo.dot_general %52, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
      %54 = stablehlo.transpose %53, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
      %55 = stablehlo.concatenate %54, %54, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
      %56 = stablehlo.cosine %55 : tensor<1x136x128xf32>
      %57 = stablehlo.convert %56 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
      %58 = stablehlo.reshape %57 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
      %59 = stablehlo.broadcast_in_dim %58, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
      %60 = stablehlo.multiply %50, %59 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
      %61 = stablehlo.slice %50 [0:4, 0:8, 0:136, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
      %62 = stablehlo.negate %61 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x64xbf16>
      %63 = stablehlo.slice %50 [0:4, 0:8, 0:136, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
      %64 = stablehlo.concatenate %62, %63, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16>
      %65 = stablehlo.sine %55 : tensor<1x136x128xf32>
      %66 = stablehlo.convert %65 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
      %67 = stablehlo.reshape %66 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
      %68 = stablehlo.broadcast_in_dim %67, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
      %69 = stablehlo.multiply %64, %68 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
      %70 = stablehlo.add %60, %69 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
      %71 = stablehlo.reshape %arg29 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
      %72 = stablehlo.reshape %71 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
      %73 = stablehlo.broadcast_in_dim %72, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
      %74 = stablehlo.reshape %arg26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
      %75 = stablehlo.reshape %74 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
      %76 = stablehlo.transpose %75, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
      %77 = sdy.reshard %32 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
      %78 = stablehlo.dot_general %77, %76, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
      %79 = sdy.all_reduce {"_axis_1"} %78 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x8192xbf16>
      %80 = sdy.reshard %79 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x8192xbf16>
      %81 = stablehlo.reshape %80 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16>
      %82 = stablehlo.transpose %81, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16>
      %83 = stablehlo.broadcast_in_dim %58, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
      %84 = stablehlo.multiply %82, %83 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
      %85 = stablehlo.slice %82 [0:4, 0:64, 0:136, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
      %86 = stablehlo.negate %85 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x64xbf16>
      %87 = stablehlo.slice %82 [0:4, 0:64, 0:136, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
      %88 = stablehlo.concatenate %86, %87, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16>
      %89 = stablehlo.broadcast_in_dim %67, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
      %90 = stablehlo.multiply %88, %89 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
      %91 = stablehlo.add %84, %90 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
      %92 = stablehlo.reshape %91 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16>
      %93 = stablehlo.broadcast_in_dim %70, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
      %94 = stablehlo.reshape %93 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16>
      %95 = stablehlo.transpose %94, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16>
      %96 = stablehlo.reshape %95 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16>
      %97 = stablehlo.dot_general %92, %96, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16>
      %98 = stablehlo.reshape %97 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16>
      %99 = stablehlo.multiply %98, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xbf16>
      %100 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64>
      %101 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64>
      %102 = stablehlo.subtract %100, %101 : tensor<136x136xi64>
      %103 = stablehlo.compare  GE, %102, %5 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
      %104 = stablehlo.select %103, %4, %3 : tensor<136x136xi1>, tensor<136x136xbf16>
      %105 = stablehlo.compare  GT, %100, %101 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
      %106 = stablehlo.convert %105 : (tensor<136x136xi1>) -> tensor<136x136xbf16>
      %107 = stablehlo.multiply %104, %106 : tensor<136x136xbf16>
      %108 = stablehlo.reshape %107 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
      %109 = stablehlo.broadcast_in_dim %108, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16>
      %110 = stablehlo.reshape %arg25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {?}]>]>} : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
      %111 = stablehlo.reshape %110 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64>
      %112 = stablehlo.convert %111 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16>
      %113 = stablehlo.reshape %112 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16>
      %114 = stablehlo.broadcast_in_dim %113, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16>
      %115 = stablehlo.add %109, %114 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : tensor<4x1x136x136xbf16>
      %116 = stablehlo.compare  EQ, %115, %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1>
      %117 = stablehlo.select %116, %1, %109 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16>
      %118 = stablehlo.reshape %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16>
      %119 = stablehlo.broadcast_in_dim %118, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16>
      %120 = stablehlo.add %99, %119 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xbf16>
      %121 = stablehlo.convert %120 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32>
      %122 = stablehlo.reduce(%121 init: %cst_0) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}]>]>} : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
      %123 = stablehlo.broadcast_in_dim %122, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
      %124 = stablehlo.subtract %121, %123 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
      %125 = stablehlo.exponential %124 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
      %126 = stablehlo.reduce(%125 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}]>]>} : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
      %127 = stablehlo.broadcast_in_dim %126, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
      %128 = stablehlo.divide %125, %127 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
      %129 = stablehlo.convert %128 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16>
      %130 = stablehlo.reshape %129 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16>
      %131 = stablehlo.broadcast_in_dim %41, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
      %132 = stablehlo.reshape %131 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16>
      %133 = stablehlo.dot_general %130, %132, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16>
      %134 = stablehlo.reshape %133 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16>
      %135 = stablehlo.transpose %134, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16>
      %136 = stablehlo.reshape %135 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16>
      %137 = stablehlo.reshape %arg24 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
      %138 = stablehlo.reshape %137 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
      %139 = stablehlo.transpose %138, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
      %140 = sdy.reshard %136 <@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x8192xbf16>
      %141 = stablehlo.dot_general %140, %139, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
      %142 = sdy.all_reduce {"_axis_0"} %141 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
      %143 = stablehlo.reshape %142 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
      %144 = sdy.reshard %143 <@mesh, [{"_axis_1", ?}, {?}, {?}]> : tensor<4x136x8192xbf16>
      %145 = stablehlo.add %19, %144 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
      %146 = stablehlo.reshape %arg27 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
      %147 = stablehlo.reshape %146 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
      %148 = stablehlo.broadcast_in_dim %147, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
      %149 = stablehlo.convert %145 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
      %150 = stablehlo.power %149, %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %151 = stablehlo.reduce(%150 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
      %152 = stablehlo.multiply %151, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
      %153 = stablehlo.reshape %152 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
      %154 = stablehlo.add %153, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %155 = stablehlo.rsqrt %154 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %156 = stablehlo.reshape %155 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
      %157 = stablehlo.broadcast_in_dim %156, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
      %158 = stablehlo.multiply %149, %157 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %159 = stablehlo.convert %158 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
      %160 = stablehlo.multiply %148, %159 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
      %161 = stablehlo.reshape %160 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
      %162 = stablehlo.reshape %arg28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
      %163 = stablehlo.reshape %162 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
      %164 = stablehlo.transpose %163, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
      %165 = sdy.reshard %161 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
      %166 = stablehlo.dot_general %165, %164, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
      %167 = sdy.all_reduce {"_axis_1"} %166 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
      %168 = sdy.reshard %167 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
      %169 = stablehlo.reshape %168 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
      %170 = stablehlo.logistic %169 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
      %171 = stablehlo.multiply %169, %170 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
      %172 = stablehlo.reshape %arg23 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
      %173 = stablehlo.reshape %172 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
      %174 = stablehlo.transpose %173, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
      %175 = sdy.reshard %161 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
      %176 = stablehlo.dot_general %175, %174, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
      %177 = sdy.all_reduce {"_axis_1"} %176 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
      %178 = sdy.reshard %177 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
      %179 = stablehlo.reshape %178 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
      %180 = stablehlo.multiply %171, %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
      %181 = stablehlo.reshape %180 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16>
      %182 = stablehlo.reshape %arg22 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
      %183 = stablehlo.reshape %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16>
      %184 = stablehlo.transpose %183, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16>
      %185 = sdy.reshard %181 <@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
      %186 = stablehlo.dot_general %185, %184, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16>
      %187 = sdy.all_reduce {"_axis_0"} %186 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
      %188 = stablehlo.reshape %187 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
      %189 = sdy.reshard %188 <@mesh, [{"_axis_1", ?}, {?}, {?}]> : tensor<4x136x8192xbf16>
      %190 = stablehlo.add %145, %189 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
      %191 = stablehlo.convert %190 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
      %192 = stablehlo.power %191, %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %193 = stablehlo.reduce(%192 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
      %194 = stablehlo.multiply %193, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
      %195 = stablehlo.reshape %194 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
      %196 = stablehlo.add %195, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %197 = stablehlo.rsqrt %196 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %198 = stablehlo.reshape %197 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
      %199 = stablehlo.broadcast_in_dim %198, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
      %200 = stablehlo.multiply %191, %199 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %201 = stablehlo.convert %200 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
      %202 = stablehlo.multiply %73, %201 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
      %203 = stablehlo.reshape %202 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
      %204 = stablehlo.reshape %arg21 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
      %205 = stablehlo.reshape %204 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
      %206 = stablehlo.transpose %205, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16>
      %207 = sdy.reshard %203 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
      %208 = stablehlo.dot_general %207, %206, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16>
      %209 = sdy.all_reduce {"_axis_1"} %208 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x128256xbf16>
      %210 = sdy.reshard %209 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x128256xbf16>
      %211 = stablehlo.reshape %210 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16>
      sdy.return %41, %70, %211 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
    } : (tensor<1024x8192xbf16>, tensor<4x136xi64>, tensor<128256x8192xbf16>, tensor<8192xbf16>, tensor<64xf32>, tensor<1024x8192xbf16>, tensor<128256x8192xbf16>, tensor<8192x28672xbf16>, tensor<28672x8192xbf16>, tensor<8192x8192xbf16>, tensor<4x136xi64>, tensor<8192x8192xbf16>, tensor<8192xbf16>, tensor<28672x8192xbf16>, tensor<8192xbf16>) -> (tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>)
    return %0#0, %0#1, %0#2 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
  }
}


// -----// IR Dump Before ReshardToCollectivesPass (sdy-reshard-to-collectives) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg1: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg2: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg3: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg4: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg5: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg6: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg7: tensor<8192x28672xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg8: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg9: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg10: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg11: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg12: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg13: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg14: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<4x8x136x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x8x136x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x136x128256xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14) in_shardings=[<@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{"_axis_1"}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{"_axis_1"}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{"_axis_1"}, {"_axis_0"}]>, <@mesh, [{"_axis_1"}, {}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{}]>] out_shardings=[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, <@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>] manual_axes={} (%arg15: tensor<1024x8192xbf16>, %arg16: tensor<4x136xi64>, %arg17: tensor<128256x8192xbf16>, %arg18: tensor<8192xbf16>, %arg19: tensor<64xf32>, %arg20: tensor<1024x8192xbf16>, %arg21: tensor<128256x8192xbf16>, %arg22: tensor<8192x28672xbf16>, %arg23: tensor<28672x8192xbf16>, %arg24: tensor<8192x8192xbf16>, %arg25: tensor<4x136xi64>, %arg26: tensor<8192x8192xbf16>, %arg27: tensor<8192xbf16>, %arg28: tensor<28672x8192xbf16>, %arg29: tensor<8192xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
      %c = stablehlo.constant dense<"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tensor<136xi64>
      %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
      %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
      %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32>
      %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
      %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>
      %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16>
      %c_6 = stablehlo.constant dense<1> : tensor<i64>
      %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_8, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
      %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
      %3 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
      %4 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
      %5 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64>
      %6 = stablehlo.broadcast_in_dim %cst_5, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x64x136x136xbf16>
      %7 = stablehlo.broadcast_in_dim %cst_3, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136x1xf32>
      %8 = stablehlo.broadcast_in_dim %cst_2, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136xf32>
      %9 = stablehlo.broadcast_in_dim %cst_1, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136x8192xf32>
      %10 = stablehlo.reshape %arg18 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
      %11 = stablehlo.reshape %10 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
      %12 = stablehlo.broadcast_in_dim %11, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
      %13 = stablehlo.reshape %arg17 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
      %14 = stablehlo.reshape %13 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
      %15 = stablehlo.reshape %arg16 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {?}]>]>} : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
      %16 = stablehlo.reshape %15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x4x136xi64>) -> tensor<544xi64>
      %17 = stablehlo.convert %16 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<544xi64>) -> tensor<544xui32>
      %18 = "stablehlo.gather"(%14, %17) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16>
      %19 = stablehlo.reshape %18 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
      %20 = stablehlo.convert %19 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
      %21 = stablehlo.power %20, %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %22 = stablehlo.reduce(%21 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
      %23 = stablehlo.multiply %22, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
      %24 = stablehlo.reshape %23 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
      %25 = stablehlo.add %24, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %26 = stablehlo.rsqrt %25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %27 = stablehlo.reshape %26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
      %28 = stablehlo.broadcast_in_dim %27, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
      %29 = stablehlo.multiply %20, %28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %30 = stablehlo.convert %29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
      %31 = stablehlo.multiply %12, %30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
      %32 = stablehlo.reshape %31 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
      %33 = stablehlo.reshape %arg15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
      %34 = stablehlo.reshape %33 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
      %35 = stablehlo.transpose %34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
      %36 = sdy.reshard %32 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
      %37 = stablehlo.dot_general %36, %35, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
      %38 = sdy.all_reduce {"_axis_1"} %37 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x1024xbf16>
      %39 = sdy.reshard %38 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x1024xbf16>
      %40 = stablehlo.reshape %39 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
      %41 = stablehlo.transpose %40, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
      %42 = stablehlo.reshape %arg20 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
      %43 = stablehlo.reshape %42 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
      %44 = stablehlo.transpose %43, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
      %45 = sdy.reshard %32 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
      %46 = stablehlo.dot_general %45, %44, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
      %47 = sdy.all_reduce {"_axis_1"} %46 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x1024xbf16>
      %48 = sdy.reshard %47 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x1024xbf16>
      %49 = stablehlo.reshape %48 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
      %50 = stablehlo.transpose %49, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
      %51 = stablehlo.reshape %arg19 : (tensor<64xf32>) -> tensor<1x1x64xf32>
      %52 = stablehlo.reshape %51 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
      %53 = stablehlo.dot_general %52, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
      %54 = stablehlo.transpose %53, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
      %55 = stablehlo.concatenate %54, %54, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
      %56 = stablehlo.cosine %55 : tensor<1x136x128xf32>
      %57 = stablehlo.convert %56 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
      %58 = stablehlo.reshape %57 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
      %59 = stablehlo.broadcast_in_dim %58, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
      %60 = stablehlo.multiply %50, %59 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
      %61 = stablehlo.slice %50 [0:4, 0:8, 0:136, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
      %62 = stablehlo.negate %61 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x64xbf16>
      %63 = stablehlo.slice %50 [0:4, 0:8, 0:136, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
      %64 = stablehlo.concatenate %62, %63, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16>
      %65 = stablehlo.sine %55 : tensor<1x136x128xf32>
      %66 = stablehlo.convert %65 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
      %67 = stablehlo.reshape %66 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
      %68 = stablehlo.broadcast_in_dim %67, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
      %69 = stablehlo.multiply %64, %68 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
      %70 = stablehlo.add %60, %69 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
      %71 = stablehlo.reshape %arg29 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
      %72 = stablehlo.reshape %71 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
      %73 = stablehlo.broadcast_in_dim %72, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
      %74 = stablehlo.reshape %arg26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
      %75 = stablehlo.reshape %74 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
      %76 = stablehlo.transpose %75, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
      %77 = sdy.reshard %32 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
      %78 = stablehlo.dot_general %77, %76, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
      %79 = sdy.all_reduce {"_axis_1"} %78 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x8192xbf16>
      %80 = sdy.reshard %79 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x8192xbf16>
      %81 = stablehlo.reshape %80 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16>
      %82 = stablehlo.transpose %81, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16>
      %83 = stablehlo.broadcast_in_dim %58, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
      %84 = stablehlo.multiply %82, %83 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
      %85 = stablehlo.slice %82 [0:4, 0:64, 0:136, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
      %86 = stablehlo.negate %85 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x64xbf16>
      %87 = stablehlo.slice %82 [0:4, 0:64, 0:136, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
      %88 = stablehlo.concatenate %86, %87, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16>
      %89 = stablehlo.broadcast_in_dim %67, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
      %90 = stablehlo.multiply %88, %89 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
      %91 = stablehlo.add %84, %90 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
      %92 = stablehlo.reshape %91 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16>
      %93 = stablehlo.broadcast_in_dim %70, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
      %94 = stablehlo.reshape %93 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16>
      %95 = stablehlo.transpose %94, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16>
      %96 = stablehlo.reshape %95 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16>
      %97 = stablehlo.dot_general %92, %96, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16>
      %98 = stablehlo.reshape %97 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16>
      %99 = stablehlo.multiply %98, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xbf16>
      %100 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64>
      %101 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64>
      %102 = stablehlo.subtract %100, %101 : tensor<136x136xi64>
      %103 = stablehlo.compare  GE, %102, %5 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
      %104 = stablehlo.select %103, %4, %3 : tensor<136x136xi1>, tensor<136x136xbf16>
      %105 = stablehlo.compare  GT, %100, %101 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
      %106 = stablehlo.convert %105 : (tensor<136x136xi1>) -> tensor<136x136xbf16>
      %107 = stablehlo.multiply %104, %106 : tensor<136x136xbf16>
      %108 = stablehlo.reshape %107 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
      %109 = stablehlo.broadcast_in_dim %108, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16>
      %110 = stablehlo.reshape %arg25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {?}]>]>} : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
      %111 = stablehlo.reshape %110 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64>
      %112 = stablehlo.convert %111 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16>
      %113 = stablehlo.reshape %112 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16>
      %114 = stablehlo.broadcast_in_dim %113, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16>
      %115 = stablehlo.add %109, %114 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : tensor<4x1x136x136xbf16>
      %116 = stablehlo.compare  EQ, %115, %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1>
      %117 = stablehlo.select %116, %1, %109 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16>
      %118 = stablehlo.reshape %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16>
      %119 = stablehlo.broadcast_in_dim %118, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16>
      %120 = stablehlo.add %99, %119 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xbf16>
      %121 = stablehlo.convert %120 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32>
      %122 = stablehlo.reduce(%121 init: %cst_0) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}]>]>} : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
      %123 = stablehlo.broadcast_in_dim %122, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
      %124 = stablehlo.subtract %121, %123 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
      %125 = stablehlo.exponential %124 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
      %126 = stablehlo.reduce(%125 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}]>]>} : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
      %127 = stablehlo.broadcast_in_dim %126, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
      %128 = stablehlo.divide %125, %127 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
      %129 = stablehlo.convert %128 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16>
      %130 = stablehlo.reshape %129 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16>
      %131 = stablehlo.broadcast_in_dim %41, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
      %132 = stablehlo.reshape %131 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16>
      %133 = stablehlo.dot_general %130, %132, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16>
      %134 = stablehlo.reshape %133 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16>
      %135 = stablehlo.transpose %134, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16>
      %136 = stablehlo.reshape %135 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16>
      %137 = stablehlo.reshape %arg24 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
      %138 = stablehlo.reshape %137 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
      %139 = stablehlo.transpose %138, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
      %140 = sdy.reshard %136 <@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x8192xbf16>
      %141 = stablehlo.dot_general %140, %139, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
      %142 = sdy.all_reduce {"_axis_0"} %141 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
      %143 = stablehlo.reshape %142 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
      %144 = sdy.reshard %143 <@mesh, [{"_axis_1", ?}, {?}, {?}]> : tensor<4x136x8192xbf16>
      %145 = stablehlo.add %19, %144 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
      %146 = stablehlo.reshape %arg27 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
      %147 = stablehlo.reshape %146 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
      %148 = stablehlo.broadcast_in_dim %147, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
      %149 = stablehlo.convert %145 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
      %150 = stablehlo.power %149, %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %151 = stablehlo.reduce(%150 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
      %152 = stablehlo.multiply %151, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
      %153 = stablehlo.reshape %152 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
      %154 = stablehlo.add %153, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %155 = stablehlo.rsqrt %154 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %156 = stablehlo.reshape %155 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
      %157 = stablehlo.broadcast_in_dim %156, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
      %158 = stablehlo.multiply %149, %157 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %159 = stablehlo.convert %158 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
      %160 = stablehlo.multiply %148, %159 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
      %161 = stablehlo.reshape %160 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
      %162 = stablehlo.reshape %arg28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
      %163 = stablehlo.reshape %162 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
      %164 = stablehlo.transpose %163, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
      %165 = sdy.reshard %161 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
      %166 = stablehlo.dot_general %165, %164, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
      %167 = sdy.all_reduce {"_axis_1"} %166 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
      %168 = sdy.reshard %167 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
      %169 = stablehlo.reshape %168 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
      %170 = stablehlo.logistic %169 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
      %171 = stablehlo.multiply %169, %170 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
      %172 = stablehlo.reshape %arg23 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
      %173 = stablehlo.reshape %172 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
      %174 = stablehlo.transpose %173, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
      %175 = sdy.reshard %161 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
      %176 = stablehlo.dot_general %175, %174, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
      %177 = sdy.all_reduce {"_axis_1"} %176 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
      %178 = sdy.reshard %177 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
      %179 = stablehlo.reshape %178 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
      %180 = stablehlo.multiply %171, %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
      %181 = stablehlo.reshape %180 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16>
      %182 = stablehlo.reshape %arg22 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
      %183 = stablehlo.reshape %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16>
      %184 = stablehlo.transpose %183, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16>
      %185 = sdy.reshard %181 <@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
      %186 = stablehlo.dot_general %185, %184, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16>
      %187 = sdy.all_reduce {"_axis_0"} %186 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
      %188 = stablehlo.reshape %187 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
      %189 = sdy.reshard %188 <@mesh, [{"_axis_1", ?}, {?}, {?}]> : tensor<4x136x8192xbf16>
      %190 = stablehlo.add %145, %189 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
      %191 = stablehlo.convert %190 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
      %192 = stablehlo.power %191, %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %193 = stablehlo.reduce(%192 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
      %194 = stablehlo.multiply %193, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
      %195 = stablehlo.reshape %194 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
      %196 = stablehlo.add %195, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %197 = stablehlo.rsqrt %196 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %198 = stablehlo.reshape %197 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
      %199 = stablehlo.broadcast_in_dim %198, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
      %200 = stablehlo.multiply %191, %199 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %201 = stablehlo.convert %200 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
      %202 = stablehlo.multiply %73, %201 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
      %203 = stablehlo.reshape %202 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
      %204 = stablehlo.reshape %arg21 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
      %205 = stablehlo.reshape %204 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
      %206 = stablehlo.transpose %205, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16>
      %207 = sdy.reshard %203 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
      %208 = stablehlo.dot_general %207, %206, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16>
      %209 = sdy.all_reduce {"_axis_1"} %208 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x128256xbf16>
      %210 = sdy.reshard %209 <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]> : tensor<544x128256xbf16>
      %211 = stablehlo.reshape %210 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16>
      sdy.return %41, %70, %211 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
    } : (tensor<1024x8192xbf16>, tensor<4x136xi64>, tensor<128256x8192xbf16>, tensor<8192xbf16>, tensor<64xf32>, tensor<1024x8192xbf16>, tensor<128256x8192xbf16>, tensor<8192x28672xbf16>, tensor<28672x8192xbf16>, tensor<8192x8192xbf16>, tensor<4x136xi64>, tensor<8192x8192xbf16>, tensor<8192xbf16>, tensor<28672x8192xbf16>, tensor<8192xbf16>) -> (tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>)
    return %0#0, %0#1, %0#2 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
  }
}


// -----// IR Dump After ReshardToCollectivesPass (sdy-reshard-to-collectives) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg1: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg2: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg3: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg4: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg5: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg6: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg7: tensor<8192x28672xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg8: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg9: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg10: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg11: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg12: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg13: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg14: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<4x8x136x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x8x136x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x136x128256xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14) in_shardings=[<@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{"_axis_1"}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{"_axis_1"}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{"_axis_1"}, {"_axis_0"}]>, <@mesh, [{"_axis_1"}, {}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{}]>] out_shardings=[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, <@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>] manual_axes={} (%arg15: tensor<1024x8192xbf16>, %arg16: tensor<4x136xi64>, %arg17: tensor<128256x8192xbf16>, %arg18: tensor<8192xbf16>, %arg19: tensor<64xf32>, %arg20: tensor<1024x8192xbf16>, %arg21: tensor<128256x8192xbf16>, %arg22: tensor<8192x28672xbf16>, %arg23: tensor<28672x8192xbf16>, %arg24: tensor<8192x8192xbf16>, %arg25: tensor<4x136xi64>, %arg26: tensor<8192x8192xbf16>, %arg27: tensor<8192xbf16>, %arg28: tensor<28672x8192xbf16>, %arg29: tensor<8192xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
      %c = stablehlo.constant dense<"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tensor<136xi64>
      %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
      %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
      %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32>
      %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
      %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>
      %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16>
      %c_6 = stablehlo.constant dense<1> : tensor<i64>
      %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_8, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
      %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
      %3 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
      %4 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
      %5 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64>
      %6 = stablehlo.broadcast_in_dim %cst_5, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x64x136x136xbf16>
      %7 = stablehlo.broadcast_in_dim %cst_3, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136x1xf32>
      %8 = stablehlo.broadcast_in_dim %cst_2, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136xf32>
      %9 = stablehlo.broadcast_in_dim %cst_1, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136x8192xf32>
      %10 = stablehlo.reshape %arg18 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
      %11 = stablehlo.reshape %10 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
      %12 = stablehlo.broadcast_in_dim %11, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
      %13 = stablehlo.reshape %arg17 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
      %14 = stablehlo.reshape %13 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
      %15 = stablehlo.reshape %arg16 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {?}]>]>} : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
      %16 = stablehlo.reshape %15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x4x136xi64>) -> tensor<544xi64>
      %17 = stablehlo.convert %16 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<544xi64>) -> tensor<544xui32>
      %18 = "stablehlo.gather"(%14, %17) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16>
      %19 = stablehlo.reshape %18 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
      %20 = stablehlo.convert %19 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
      %21 = stablehlo.power %20, %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %22 = stablehlo.reduce(%21 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
      %23 = stablehlo.multiply %22, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
      %24 = stablehlo.reshape %23 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
      %25 = stablehlo.add %24, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %26 = stablehlo.rsqrt %25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %27 = stablehlo.reshape %26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
      %28 = stablehlo.broadcast_in_dim %27, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
      %29 = stablehlo.multiply %20, %28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %30 = stablehlo.convert %29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
      %31 = stablehlo.multiply %12, %30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
      %32 = stablehlo.reshape %31 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
      %33 = stablehlo.reshape %arg15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
      %34 = stablehlo.reshape %33 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
      %35 = stablehlo.transpose %34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
      %36 = sdy.all_to_all [{"_axis_1"}: 0->1] %32 out_sharding=<@mesh, [{}, {"_axis_1"}]> : tensor<544x8192xbf16>
      %37 = stablehlo.dot_general %36, %35, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
      %38 = sdy.all_reduce {"_axis_1"} %37 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x1024xbf16>
      %39 = sdy.all_slice [{"_axis_1"}, {}] %38 out_sharding=<@mesh, [{"_axis_1"}, {"_axis_0"}]> : tensor<544x1024xbf16>
      %40 = stablehlo.reshape %39 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
      %41 = stablehlo.transpose %40, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
      %42 = stablehlo.reshape %arg20 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
      %43 = stablehlo.reshape %42 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
      %44 = stablehlo.transpose %43, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
      %45 = sdy.all_to_all [{"_axis_1"}: 0->1] %32 out_sharding=<@mesh, [{}, {"_axis_1"}]> : tensor<544x8192xbf16>
      %46 = stablehlo.dot_general %45, %44, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
      %47 = sdy.all_reduce {"_axis_1"} %46 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x1024xbf16>
      %48 = sdy.all_slice [{"_axis_1"}, {}] %47 out_sharding=<@mesh, [{"_axis_1"}, {"_axis_0"}]> : tensor<544x1024xbf16>
      %49 = stablehlo.reshape %48 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
      %50 = stablehlo.transpose %49, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
      %51 = stablehlo.reshape %arg19 : (tensor<64xf32>) -> tensor<1x1x64xf32>
      %52 = stablehlo.reshape %51 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
      %53 = stablehlo.dot_general %52, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
      %54 = stablehlo.transpose %53, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
      %55 = stablehlo.concatenate %54, %54, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
      %56 = stablehlo.cosine %55 : tensor<1x136x128xf32>
      %57 = stablehlo.convert %56 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
      %58 = stablehlo.reshape %57 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
      %59 = stablehlo.broadcast_in_dim %58, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
      %60 = stablehlo.multiply %50, %59 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
      %61 = stablehlo.slice %50 [0:4, 0:8, 0:136, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
      %62 = stablehlo.negate %61 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x64xbf16>
      %63 = stablehlo.slice %50 [0:4, 0:8, 0:136, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
      %64 = stablehlo.concatenate %62, %63, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16>
      %65 = stablehlo.sine %55 : tensor<1x136x128xf32>
      %66 = stablehlo.convert %65 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
      %67 = stablehlo.reshape %66 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
      %68 = stablehlo.broadcast_in_dim %67, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
      %69 = stablehlo.multiply %64, %68 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
      %70 = stablehlo.add %60, %69 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
      %71 = stablehlo.reshape %arg29 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
      %72 = stablehlo.reshape %71 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
      %73 = stablehlo.broadcast_in_dim %72, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
      %74 = stablehlo.reshape %arg26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
      %75 = stablehlo.reshape %74 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
      %76 = stablehlo.transpose %75, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
      %77 = sdy.all_to_all [{"_axis_1"}: 0->1] %32 out_sharding=<@mesh, [{}, {"_axis_1"}]> : tensor<544x8192xbf16>
      %78 = stablehlo.dot_general %77, %76, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
      %79 = sdy.all_reduce {"_axis_1"} %78 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x8192xbf16>
      %80 = sdy.all_slice [{"_axis_1"}, {}] %79 out_sharding=<@mesh, [{"_axis_1"}, {"_axis_0"}]> : tensor<544x8192xbf16>
      %81 = stablehlo.reshape %80 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16>
      %82 = stablehlo.transpose %81, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16>
      %83 = stablehlo.broadcast_in_dim %58, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
      %84 = stablehlo.multiply %82, %83 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
      %85 = stablehlo.slice %82 [0:4, 0:64, 0:136, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
      %86 = stablehlo.negate %85 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x64xbf16>
      %87 = stablehlo.slice %82 [0:4, 0:64, 0:136, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
      %88 = stablehlo.concatenate %86, %87, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16>
      %89 = stablehlo.broadcast_in_dim %67, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
      %90 = stablehlo.multiply %88, %89 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
      %91 = stablehlo.add %84, %90 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
      %92 = stablehlo.reshape %91 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16>
      %93 = stablehlo.broadcast_in_dim %70, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
      %94 = stablehlo.reshape %93 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16>
      %95 = stablehlo.transpose %94, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16>
      %96 = stablehlo.reshape %95 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16>
      %97 = stablehlo.dot_general %92, %96, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16>
      %98 = stablehlo.reshape %97 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16>
      %99 = stablehlo.multiply %98, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xbf16>
      %100 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64>
      %101 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64>
      %102 = stablehlo.subtract %100, %101 : tensor<136x136xi64>
      %103 = stablehlo.compare  GE, %102, %5 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
      %104 = stablehlo.select %103, %4, %3 : tensor<136x136xi1>, tensor<136x136xbf16>
      %105 = stablehlo.compare  GT, %100, %101 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
      %106 = stablehlo.convert %105 : (tensor<136x136xi1>) -> tensor<136x136xbf16>
      %107 = stablehlo.multiply %104, %106 : tensor<136x136xbf16>
      %108 = stablehlo.reshape %107 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
      %109 = stablehlo.broadcast_in_dim %108, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16>
      %110 = stablehlo.reshape %arg25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {?}]>]>} : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
      %111 = stablehlo.reshape %110 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64>
      %112 = stablehlo.convert %111 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16>
      %113 = stablehlo.reshape %112 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16>
      %114 = stablehlo.broadcast_in_dim %113, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16>
      %115 = stablehlo.add %109, %114 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : tensor<4x1x136x136xbf16>
      %116 = stablehlo.compare  EQ, %115, %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1>
      %117 = stablehlo.select %116, %1, %109 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16>
      %118 = stablehlo.reshape %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16>
      %119 = stablehlo.broadcast_in_dim %118, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16>
      %120 = stablehlo.add %99, %119 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xbf16>
      %121 = stablehlo.convert %120 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32>
      %122 = stablehlo.reduce(%121 init: %cst_0) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}]>]>} : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
      %123 = stablehlo.broadcast_in_dim %122, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
      %124 = stablehlo.subtract %121, %123 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
      %125 = stablehlo.exponential %124 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
      %126 = stablehlo.reduce(%125 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}]>]>} : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
      %127 = stablehlo.broadcast_in_dim %126, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
      %128 = stablehlo.divide %125, %127 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
      %129 = stablehlo.convert %128 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16>
      %130 = stablehlo.reshape %129 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16>
      %131 = stablehlo.broadcast_in_dim %41, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
      %132 = stablehlo.reshape %131 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16>
      %133 = stablehlo.dot_general %130, %132, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16>
      %134 = stablehlo.reshape %133 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16>
      %135 = stablehlo.transpose %134, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16>
      %136 = stablehlo.reshape %135 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16>
      %137 = stablehlo.reshape %arg24 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
      %138 = stablehlo.reshape %137 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
      %139 = stablehlo.transpose %138, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
      %140 = sdy.all_gather [{"_axis_1"}, {}] %136 out_sharding=<@mesh, [{}, {"_axis_0"}]> : tensor<544x8192xbf16>
      %141 = stablehlo.dot_general %140, %139, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
      %142 = sdy.all_reduce {"_axis_0"} %141 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
      %143 = stablehlo.reshape %142 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
      %144 = sdy.all_to_all [{"_axis_1"}: 2->0] %143 out_sharding=<@mesh, [{"_axis_1"}, {}, {}]> : tensor<4x136x8192xbf16>
      %145 = stablehlo.add %19, %144 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
      %146 = stablehlo.reshape %arg27 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
      %147 = stablehlo.reshape %146 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
      %148 = stablehlo.broadcast_in_dim %147, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
      %149 = stablehlo.convert %145 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
      %150 = stablehlo.power %149, %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %151 = stablehlo.reduce(%150 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
      %152 = stablehlo.multiply %151, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
      %153 = stablehlo.reshape %152 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
      %154 = stablehlo.add %153, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %155 = stablehlo.rsqrt %154 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %156 = stablehlo.reshape %155 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
      %157 = stablehlo.broadcast_in_dim %156, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
      %158 = stablehlo.multiply %149, %157 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %159 = stablehlo.convert %158 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
      %160 = stablehlo.multiply %148, %159 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
      %161 = stablehlo.reshape %160 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
      %162 = stablehlo.reshape %arg28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
      %163 = stablehlo.reshape %162 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
      %164 = stablehlo.transpose %163, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
      %165 = sdy.all_to_all [{"_axis_1"}: 0->1] %161 out_sharding=<@mesh, [{}, {"_axis_1"}]> : tensor<544x8192xbf16>
      %166 = stablehlo.dot_general %165, %164, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
      %167 = sdy.all_reduce {"_axis_1"} %166 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
      %168 = sdy.all_slice [{"_axis_1"}, {}] %167 out_sharding=<@mesh, [{"_axis_1"}, {"_axis_0"}]> : tensor<544x28672xbf16>
      %169 = stablehlo.reshape %168 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
      %170 = stablehlo.logistic %169 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
      %171 = stablehlo.multiply %169, %170 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
      %172 = stablehlo.reshape %arg23 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
      %173 = stablehlo.reshape %172 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
      %174 = stablehlo.transpose %173, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
      %175 = sdy.all_to_all [{"_axis_1"}: 0->1] %161 out_sharding=<@mesh, [{}, {"_axis_1"}]> : tensor<544x8192xbf16>
      %176 = stablehlo.dot_general %175, %174, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
      %177 = sdy.all_reduce {"_axis_1"} %176 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
      %178 = sdy.all_slice [{"_axis_1"}, {}] %177 out_sharding=<@mesh, [{"_axis_1"}, {"_axis_0"}]> : tensor<544x28672xbf16>
      %179 = stablehlo.reshape %178 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
      %180 = stablehlo.multiply %171, %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
      %181 = stablehlo.reshape %180 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16>
      %182 = stablehlo.reshape %arg22 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
      %183 = stablehlo.reshape %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16>
      %184 = stablehlo.transpose %183, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16>
      %185 = sdy.all_gather [{"_axis_1"}, {}] %181 out_sharding=<@mesh, [{}, {"_axis_0"}]> : tensor<544x28672xbf16>
      %186 = stablehlo.dot_general %185, %184, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16>
      %187 = sdy.all_reduce {"_axis_0"} %186 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
      %188 = stablehlo.reshape %187 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
      %189 = sdy.all_to_all [{"_axis_1"}: 2->0] %188 out_sharding=<@mesh, [{"_axis_1"}, {}, {}]> : tensor<4x136x8192xbf16>
      %190 = stablehlo.add %145, %189 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
      %191 = stablehlo.convert %190 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
      %192 = stablehlo.power %191, %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %193 = stablehlo.reduce(%192 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
      %194 = stablehlo.multiply %193, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
      %195 = stablehlo.reshape %194 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
      %196 = stablehlo.add %195, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %197 = stablehlo.rsqrt %196 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %198 = stablehlo.reshape %197 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
      %199 = stablehlo.broadcast_in_dim %198, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
      %200 = stablehlo.multiply %191, %199 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %201 = stablehlo.convert %200 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
      %202 = stablehlo.multiply %73, %201 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
      %203 = stablehlo.reshape %202 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
      %204 = stablehlo.reshape %arg21 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
      %205 = stablehlo.reshape %204 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
      %206 = stablehlo.transpose %205, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16>
      %207 = sdy.all_to_all [{"_axis_1"}: 0->1] %203 out_sharding=<@mesh, [{}, {"_axis_1"}]> : tensor<544x8192xbf16>
      %208 = stablehlo.dot_general %207, %206, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16>
      %209 = sdy.all_reduce {"_axis_1"} %208 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x128256xbf16>
      %210 = sdy.all_slice [{"_axis_1"}, {}] %209 out_sharding=<@mesh, [{"_axis_1"}, {"_axis_0"}]> : tensor<544x128256xbf16>
      %211 = stablehlo.reshape %210 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16>
      sdy.return %41, %70, %211 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
    } : (tensor<1024x8192xbf16>, tensor<4x136xi64>, tensor<128256x8192xbf16>, tensor<8192xbf16>, tensor<64xf32>, tensor<1024x8192xbf16>, tensor<128256x8192xbf16>, tensor<8192x28672xbf16>, tensor<28672x8192xbf16>, tensor<8192x8192xbf16>, tensor<4x136xi64>, tensor<8192x8192xbf16>, tensor<8192xbf16>, tensor<28672x8192xbf16>, tensor<8192xbf16>) -> (tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>)
    return %0#0, %0#1, %0#2 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
  }
}


// -----// IR Dump Before UpdateGlobalToLocalShapesPass (update-global-to-local-shapes) ('builtin.module' operation: @SyncTensorsGraph.416) //----- //
module @SyncTensorsGraph.416 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg1: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg2: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg3: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg4: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg5: tensor<1024x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg6: tensor<128256x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg7: tensor<8192x28672xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg8: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg9: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg10: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg11: tensor<8192x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg12: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg13: tensor<28672x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg14: tensor<8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<4x8x136x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x8x136x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<4x136x128256xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14) in_shardings=[<@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{"_axis_1"}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{"_axis_1"}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{"_axis_1"}, {"_axis_0"}]>, <@mesh, [{"_axis_1"}, {}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{}]>] out_shardings=[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, <@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>] manual_axes={} (%arg15: tensor<1024x8192xbf16>, %arg16: tensor<4x136xi64>, %arg17: tensor<128256x8192xbf16>, %arg18: tensor<8192xbf16>, %arg19: tensor<64xf32>, %arg20: tensor<1024x8192xbf16>, %arg21: tensor<128256x8192xbf16>, %arg22: tensor<8192x28672xbf16>, %arg23: tensor<28672x8192xbf16>, %arg24: tensor<8192x8192xbf16>, %arg25: tensor<4x136xi64>, %arg26: tensor<8192x8192xbf16>, %arg27: tensor<8192xbf16>, %arg28: tensor<28672x8192xbf16>, %arg29: tensor<8192xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
      %c = stablehlo.constant dense<"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tensor<136xi64>
      %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
      %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
      %cst_2 = stablehlo.constant dense<1.22070313E-4> : tensor<f32>
      %cst_3 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
      %cst_4 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>
      %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16>
      %c_6 = stablehlo.constant dense<1> : tensor<i64>
      %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_8, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
      %2 = stablehlo.broadcast_in_dim %cst_7, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x1x136x136xbf16>
      %3 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
      %4 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<136x136xbf16>
      %5 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<136x136xi64>
      %6 = stablehlo.broadcast_in_dim %cst_5, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<4x64x136x136xbf16>
      %7 = stablehlo.broadcast_in_dim %cst_3, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136x1xf32>
      %8 = stablehlo.broadcast_in_dim %cst_2, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136xf32>
      %9 = stablehlo.broadcast_in_dim %cst_1, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<4x136x8192xf32>
      %10 = stablehlo.reshape %arg18 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
      %11 = stablehlo.reshape %10 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
      %12 = stablehlo.broadcast_in_dim %11, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
      %13 = stablehlo.reshape %arg17 : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
      %14 = stablehlo.reshape %13 : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
      %15 = stablehlo.reshape %arg16 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {?}]>]>} : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
      %16 = stablehlo.reshape %15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x4x136xi64>) -> tensor<544xi64>
      %17 = stablehlo.convert %16 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<544xi64>) -> tensor<544xui32>
      %18 = "stablehlo.gather"(%14, %17) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<128256x8192xbf16>, tensor<544xui32>) -> tensor<544x8192xbf16>
      %19 = stablehlo.reshape %18 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
      %20 = stablehlo.convert %19 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
      %21 = stablehlo.power %20, %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %22 = stablehlo.reduce(%21 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
      %23 = stablehlo.multiply %22, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
      %24 = stablehlo.reshape %23 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
      %25 = stablehlo.add %24, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %26 = stablehlo.rsqrt %25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %27 = stablehlo.reshape %26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
      %28 = stablehlo.broadcast_in_dim %27, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
      %29 = stablehlo.multiply %20, %28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %30 = stablehlo.convert %29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
      %31 = stablehlo.multiply %12, %30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
      %32 = stablehlo.reshape %31 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
      %33 = stablehlo.reshape %arg15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
      %34 = stablehlo.reshape %33 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
      %35 = stablehlo.transpose %34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
      %36 = sdy.all_to_all [{"_axis_1"}: 0->1] %32 out_sharding=<@mesh, [{}, {"_axis_1"}]> : tensor<544x8192xbf16>
      %37 = stablehlo.dot_general %36, %35, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
      %38 = sdy.all_reduce {"_axis_1"} %37 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x1024xbf16>
      %39 = sdy.all_slice [{"_axis_1"}, {}] %38 out_sharding=<@mesh, [{"_axis_1"}, {"_axis_0"}]> : tensor<544x1024xbf16>
      %40 = stablehlo.reshape %39 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
      %41 = stablehlo.transpose %40, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
      %42 = stablehlo.reshape %arg20 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1024x8192xbf16>) -> tensor<1x1024x8192xbf16>
      %43 = stablehlo.reshape %42 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x1024x8192xbf16>) -> tensor<1024x8192xbf16>
      %44 = stablehlo.transpose %43, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<1024x8192xbf16>) -> tensor<8192x1024xbf16>
      %45 = sdy.all_to_all [{"_axis_1"}: 0->1] %32 out_sharding=<@mesh, [{}, {"_axis_1"}]> : tensor<544x8192xbf16>
      %46 = stablehlo.dot_general %45, %44, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x1024xbf16>) -> tensor<544x1024xbf16>
      %47 = sdy.all_reduce {"_axis_1"} %46 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x1024xbf16>
      %48 = sdy.all_slice [{"_axis_1"}, {}] %47 out_sharding=<@mesh, [{"_axis_1"}, {"_axis_0"}]> : tensor<544x1024xbf16>
      %49 = stablehlo.reshape %48 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x1024xbf16>) -> tensor<4x136x8x128xbf16>
      %50 = stablehlo.transpose %49, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<4x136x8x128xbf16>) -> tensor<4x8x136x128xbf16>
      %51 = stablehlo.reshape %arg19 : (tensor<64xf32>) -> tensor<1x1x64xf32>
      %52 = stablehlo.reshape %51 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
      %53 = stablehlo.dot_general %52, %cst_4, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
      %54 = stablehlo.transpose %53, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
      %55 = stablehlo.concatenate %54, %54, dim = 2 : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
      %56 = stablehlo.cosine %55 : tensor<1x136x128xf32>
      %57 = stablehlo.convert %56 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
      %58 = stablehlo.reshape %57 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
      %59 = stablehlo.broadcast_in_dim %58, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
      %60 = stablehlo.multiply %50, %59 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
      %61 = stablehlo.slice %50 [0:4, 0:8, 0:136, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
      %62 = stablehlo.negate %61 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x64xbf16>
      %63 = stablehlo.slice %50 [0:4, 0:8, 0:136, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x136x64xbf16>
      %64 = stablehlo.concatenate %62, %63, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x136x64xbf16>, tensor<4x8x136x64xbf16>) -> tensor<4x8x136x128xbf16>
      %65 = stablehlo.sine %55 : tensor<1x136x128xf32>
      %66 = stablehlo.convert %65 : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
      %67 = stablehlo.reshape %66 : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
      %68 = stablehlo.broadcast_in_dim %67, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x8x136x128xbf16>
      %69 = stablehlo.multiply %64, %68 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
      %70 = stablehlo.add %60, %69 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x8x136x128xbf16>
      %71 = stablehlo.reshape %arg29 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
      %72 = stablehlo.reshape %71 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
      %73 = stablehlo.broadcast_in_dim %72, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
      %74 = stablehlo.reshape %arg26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
      %75 = stablehlo.reshape %74 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
      %76 = stablehlo.transpose %75, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
      %77 = sdy.all_to_all [{"_axis_1"}: 0->1] %32 out_sharding=<@mesh, [{}, {"_axis_1"}]> : tensor<544x8192xbf16>
      %78 = stablehlo.dot_general %77, %76, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
      %79 = sdy.all_reduce {"_axis_1"} %78 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x8192xbf16>
      %80 = sdy.all_slice [{"_axis_1"}, {}] %79 out_sharding=<@mesh, [{"_axis_1"}, {"_axis_0"}]> : tensor<544x8192xbf16>
      %81 = stablehlo.reshape %80 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x64x128xbf16>
      %82 = stablehlo.transpose %81, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<4x136x64x128xbf16>) -> tensor<4x64x136x128xbf16>
      %83 = stablehlo.broadcast_in_dim %58, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
      %84 = stablehlo.multiply %82, %83 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
      %85 = stablehlo.slice %82 [0:4, 0:64, 0:136, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
      %86 = stablehlo.negate %85 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x64xbf16>
      %87 = stablehlo.slice %82 [0:4, 0:64, 0:136, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x136x64xbf16>
      %88 = stablehlo.concatenate %86, %87, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x64xbf16>, tensor<4x64x136x64xbf16>) -> tensor<4x64x136x128xbf16>
      %89 = stablehlo.broadcast_in_dim %67, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<136x128xbf16>) -> tensor<4x64x136x128xbf16>
      %90 = stablehlo.multiply %88, %89 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
      %91 = stablehlo.add %84, %90 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x128xbf16>
      %92 = stablehlo.reshape %91 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x128xbf16>) -> tensor<256x136x128xbf16>
      %93 = stablehlo.broadcast_in_dim %70, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
      %94 = stablehlo.reshape %93 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x8x136x128xbf16>) -> tensor<4x64x136x128xbf16>
      %95 = stablehlo.transpose %94, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x64x128x136xbf16>
      %96 = stablehlo.reshape %95 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x128x136xbf16>) -> tensor<256x128x136xbf16>
      %97 = stablehlo.dot_general %92, %96, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x128xbf16>, tensor<256x128x136xbf16>) -> tensor<256x136x136xbf16>
      %98 = stablehlo.reshape %97 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x136xbf16>) -> tensor<4x64x136x136xbf16>
      %99 = stablehlo.multiply %98, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xbf16>
      %100 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<136xi64>) -> tensor<136x136xi64>
      %101 = stablehlo.broadcast_in_dim %c, dims = [0] : (tensor<136xi64>) -> tensor<136x136xi64>
      %102 = stablehlo.subtract %100, %101 : tensor<136x136xi64>
      %103 = stablehlo.compare  GE, %102, %5 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
      %104 = stablehlo.select %103, %4, %3 : tensor<136x136xi1>, tensor<136x136xbf16>
      %105 = stablehlo.compare  GT, %100, %101 : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
      %106 = stablehlo.convert %105 : (tensor<136x136xi1>) -> tensor<136x136xbf16>
      %107 = stablehlo.multiply %104, %106 : tensor<136x136xbf16>
      %108 = stablehlo.reshape %107 : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
      %109 = stablehlo.broadcast_in_dim %108, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<1x136x136xbf16>) -> tensor<4x1x136x136xbf16>
      %110 = stablehlo.reshape %arg25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {?}]>]>} : (tensor<4x136xi64>) -> tensor<1x4x136xi64>
      %111 = stablehlo.reshape %110 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<1x4x136xi64>) -> tensor<4x1x1x136xi64>
      %112 = stablehlo.convert %111 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x1x136xi64>) -> tensor<4x1x1x136xbf16>
      %113 = stablehlo.reshape %112 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x1x1x136xbf16>) -> tensor<4x1x136xbf16>
      %114 = stablehlo.broadcast_in_dim %113, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x136xbf16>) -> tensor<4x1x136x136xbf16>
      %115 = stablehlo.add %109, %114 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : tensor<4x1x136x136xbf16>
      %116 = stablehlo.compare  EQ, %115, %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<4x1x136x136xbf16>, tensor<4x1x136x136xbf16>) -> tensor<4x1x136x136xi1>
      %117 = stablehlo.select %116, %1, %109 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}, {?}]>]>} : tensor<4x1x136x136xi1>, tensor<4x1x136x136xbf16>
      %118 = stablehlo.reshape %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x1x136x136xbf16>) -> tensor<4x136x136xbf16>
      %119 = stablehlo.broadcast_in_dim %118, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x136x136xbf16>) -> tensor<4x64x136x136xbf16>
      %120 = stablehlo.add %99, %119 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xbf16>
      %121 = stablehlo.convert %120 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xbf16>) -> tensor<4x64x136x136xf32>
      %122 = stablehlo.reduce(%121 init: %cst_0) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}]>]>} : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
      %123 = stablehlo.broadcast_in_dim %122, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
      %124 = stablehlo.subtract %121, %123 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
      %125 = stablehlo.exponential %124 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
      %126 = stablehlo.reduce(%125 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}]>]>} : (tensor<4x64x136x136xf32>, tensor<f32>) -> tensor<4x64x136xf32>
      %127 = stablehlo.broadcast_in_dim %126, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136xf32>) -> tensor<4x64x136x136xf32>
      %128 = stablehlo.divide %125, %127 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<4x64x136x136xf32>
      %129 = stablehlo.convert %128 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xf32>) -> tensor<4x64x136x136xbf16>
      %130 = stablehlo.reshape %129 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x64x136x136xbf16>) -> tensor<256x136x136xbf16>
      %131 = stablehlo.broadcast_in_dim %41, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<4x8x136x128xbf16>) -> tensor<4x8x8x136x128xbf16>
      %132 = stablehlo.reshape %131 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<4x8x8x136x128xbf16>) -> tensor<256x136x128xbf16>
      %133 = stablehlo.dot_general %130, %132, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", "_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x136xbf16>, tensor<256x136x128xbf16>) -> tensor<256x136x128xbf16>
      %134 = stablehlo.reshape %133 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<256x136x128xbf16>) -> tensor<4x64x136x128xbf16>
      %135 = stablehlo.transpose %134, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<4x64x136x128xbf16>) -> tensor<4x136x64x128xbf16>
      %136 = stablehlo.reshape %135 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<4x136x64x128xbf16>) -> tensor<544x8192xbf16>
      %137 = stablehlo.reshape %arg24 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<8192x8192xbf16>) -> tensor<1x8192x8192xbf16>
      %138 = stablehlo.reshape %137 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x8192x8192xbf16>) -> tensor<8192x8192xbf16>
      %139 = stablehlo.transpose %138, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<8192x8192xbf16>) -> tensor<8192x8192xbf16>
      %140 = sdy.all_gather [{"_axis_1"}, {}] %136 out_sharding=<@mesh, [{}, {"_axis_0"}]> : tensor<544x8192xbf16>
      %141 = stablehlo.dot_general %140, %139, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x8192xbf16>) -> tensor<544x8192xbf16>
      %142 = sdy.all_reduce {"_axis_0"} %141 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
      %143 = stablehlo.reshape %142 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
      %144 = sdy.all_to_all [{"_axis_1"}: 2->0] %143 out_sharding=<@mesh, [{"_axis_1"}, {}, {}]> : tensor<4x136x8192xbf16>
      %145 = stablehlo.add %19, %144 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
      %146 = stablehlo.reshape %arg27 : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
      %147 = stablehlo.reshape %146 : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
      %148 = stablehlo.broadcast_in_dim %147, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<8192xbf16>) -> tensor<4x136x8192xbf16>
      %149 = stablehlo.convert %145 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
      %150 = stablehlo.power %149, %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %151 = stablehlo.reduce(%150 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
      %152 = stablehlo.multiply %151, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
      %153 = stablehlo.reshape %152 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
      %154 = stablehlo.add %153, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %155 = stablehlo.rsqrt %154 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %156 = stablehlo.reshape %155 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
      %157 = stablehlo.broadcast_in_dim %156, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
      %158 = stablehlo.multiply %149, %157 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %159 = stablehlo.convert %158 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
      %160 = stablehlo.multiply %148, %159 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
      %161 = stablehlo.reshape %160 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
      %162 = stablehlo.reshape %arg28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
      %163 = stablehlo.reshape %162 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
      %164 = stablehlo.transpose %163, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
      %165 = sdy.all_to_all [{"_axis_1"}: 0->1] %161 out_sharding=<@mesh, [{}, {"_axis_1"}]> : tensor<544x8192xbf16>
      %166 = stablehlo.dot_general %165, %164, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
      %167 = sdy.all_reduce {"_axis_1"} %166 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
      %168 = sdy.all_slice [{"_axis_1"}, {}] %167 out_sharding=<@mesh, [{"_axis_1"}, {"_axis_0"}]> : tensor<544x28672xbf16>
      %169 = stablehlo.reshape %168 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
      %170 = stablehlo.logistic %169 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
      %171 = stablehlo.multiply %169, %170 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
      %172 = stablehlo.reshape %arg23 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<28672x8192xbf16>) -> tensor<1x28672x8192xbf16>
      %173 = stablehlo.reshape %172 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x28672x8192xbf16>) -> tensor<28672x8192xbf16>
      %174 = stablehlo.transpose %173, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<28672x8192xbf16>) -> tensor<8192x28672xbf16>
      %175 = sdy.all_to_all [{"_axis_1"}: 0->1] %161 out_sharding=<@mesh, [{}, {"_axis_1"}]> : tensor<544x8192xbf16>
      %176 = stablehlo.dot_general %175, %174, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x28672xbf16>) -> tensor<544x28672xbf16>
      %177 = sdy.all_reduce {"_axis_1"} %176 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x28672xbf16>
      %178 = sdy.all_slice [{"_axis_1"}, {}] %177 out_sharding=<@mesh, [{"_axis_1"}, {"_axis_0"}]> : tensor<544x28672xbf16>
      %179 = stablehlo.reshape %178 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x28672xbf16>) -> tensor<4x136x28672xbf16>
      %180 = stablehlo.multiply %171, %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : tensor<4x136x28672xbf16>
      %181 = stablehlo.reshape %180 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<4x136x28672xbf16>) -> tensor<544x28672xbf16>
      %182 = stablehlo.reshape %arg22 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<8192x28672xbf16>) -> tensor<1x8192x28672xbf16>
      %183 = stablehlo.reshape %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x8192x28672xbf16>) -> tensor<8192x28672xbf16>
      %184 = stablehlo.transpose %183, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<8192x28672xbf16>) -> tensor<28672x8192xbf16>
      %185 = sdy.all_gather [{"_axis_1"}, {}] %181 out_sharding=<@mesh, [{}, {"_axis_0"}]> : tensor<544x28672xbf16>
      %186 = stablehlo.dot_general %185, %184, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<544x28672xbf16>, tensor<28672x8192xbf16>) -> tensor<544x8192xbf16>
      %187 = sdy.all_reduce {"_axis_0"} %186 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<544x8192xbf16>
      %188 = stablehlo.reshape %187 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<544x8192xbf16>) -> tensor<4x136x8192xbf16>
      %189 = sdy.all_to_all [{"_axis_1"}: 2->0] %188 out_sharding=<@mesh, [{"_axis_1"}, {}, {}]> : tensor<4x136x8192xbf16>
      %190 = stablehlo.add %145, %189 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
      %191 = stablehlo.convert %190 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xf32>
      %192 = stablehlo.power %191, %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %193 = stablehlo.reduce(%192 init: %cst) applies stablehlo.add across dimensions = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xf32>, tensor<f32>) -> tensor<4x136xf32>
      %194 = stablehlo.multiply %193, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : tensor<4x136xf32>
      %195 = stablehlo.reshape %194 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x1xf32>
      %196 = stablehlo.add %195, %7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %197 = stablehlo.rsqrt %196 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x1xf32>
      %198 = stablehlo.reshape %197 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x1xf32>) -> tensor<4x136xf32>
      %199 = stablehlo.broadcast_in_dim %198, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136xf32>) -> tensor<4x136x8192xf32>
      %200 = stablehlo.multiply %191, %199 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xf32>
      %201 = stablehlo.convert %200 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : (tensor<4x136x8192xf32>) -> tensor<4x136x8192xbf16>
      %202 = stablehlo.multiply %73, %201 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {?}]>]>} : tensor<4x136x8192xbf16>
      %203 = stablehlo.reshape %202 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}]>]>} : (tensor<4x136x8192xbf16>) -> tensor<544x8192xbf16>
      %204 = stablehlo.reshape %arg21 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
      %205 = stablehlo.reshape %204 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
      %206 = stablehlo.transpose %205, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<128256x8192xbf16>) -> tensor<8192x128256xbf16>
      %207 = sdy.all_to_all [{"_axis_1"}: 0->1] %203 out_sharding=<@mesh, [{}, {"_axis_1"}]> : tensor<544x8192xbf16>
      %208 = stablehlo.dot_general %207, %206, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<544x8192xbf16>, tensor<8192x128256xbf16>) -> tensor<544x128256xbf16>
      %209 = sdy.all_reduce {"_axis_1"} %208 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<544x128256xbf16>
      %210 = sdy.all_slice [{"_axis_1"}, {}] %209 out_sharding=<@mesh, [{"_axis_1"}, {"_axis_0"}]> : tensor<544x128256xbf16>
      %211 = stablehlo.reshape %210 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>} : (tensor<544x128256xbf16>) -> tensor<4x136x128256xbf16>
      sdy.return %41, %70, %211 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
    } : (tensor<1024x8192xbf16>, tensor<4x136xi64>, tensor<128256x8192xbf16>, tensor<8192xbf16>, tensor<64xf32>, tensor<1024x8192xbf16>, tensor<128256x8192xbf16>, tensor<8192x28672xbf16>, tensor<28672x8192xbf16>, tensor<8192x8192xbf16>, tensor<4x136xi64>, tensor<8192x8192xbf16>, tensor<8192xbf16>, tensor<28672x8192xbf16>, tensor<8192xbf16>) -> (tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>)
    return %0#0, %0#1, %0#2 : tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>
  }
}


loc("dot.57"): error: number of output elements (557056) doesn't match expected number of elements (69632)
// -----// IR Dump After UpdateGlobalToLocalShapesPass Failed (update-global-to-local-shapes) ('builtin.module' operation: @SyncTensorsGraph.416) //----- //
"builtin.module"() <{sym_name = "SyncTensorsGraph.416"}> ({
  "sdy.mesh"() <{mesh = #sdy.mesh<["_axis_0"=8, "_axis_1"=4]>, sym_name = "mesh"}> : () -> ()
  "func.func"() <{arg_attrs = [{ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}], function_type = (tensor<1024x8192xbf16>, tensor<4x136xi64>, tensor<128256x8192xbf16>, tensor<8192xbf16>, tensor<64xf32>, tensor<1024x8192xbf16>, tensor<128256x8192xbf16>, tensor<8192x28672xbf16>, tensor<28672x8192xbf16>, tensor<8192x8192xbf16>, tensor<4x136xi64>, tensor<8192x8192xbf16>, tensor<8192xbf16>, tensor<28672x8192xbf16>, tensor<8192xbf16>) -> (tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>), res_attrs = [{ttcore.shard_status = #ttcore.shard_status<unsharded>}, {ttcore.shard_status = #ttcore.shard_status<unsharded>}, {ttcore.shard_status = #ttcore.shard_status<unsharded>}], sym_name = "main"}> ({
  ^bb0(%arg0: tensor<1024x8192xbf16>, %arg1: tensor<4x136xi64>, %arg2: tensor<128256x8192xbf16>, %arg3: tensor<8192xbf16>, %arg4: tensor<64xf32>, %arg5: tensor<1024x8192xbf16>, %arg6: tensor<128256x8192xbf16>, %arg7: tensor<8192x28672xbf16>, %arg8: tensor<28672x8192xbf16>, %arg9: tensor<8192x8192xbf16>, %arg10: tensor<4x136xi64>, %arg11: tensor<8192x8192xbf16>, %arg12: tensor<8192xbf16>, %arg13: tensor<28672x8192xbf16>, %arg14: tensor<8192xbf16>):
    %0:3 = "sdy.manual_computation"(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14) <{in_shardings = #sdy.sharding_per_value<[<@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{"_axis_1"}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{"_axis_1"}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{"_axis_1"}, {"_axis_0"}]>, <@mesh, [{"_axis_1"}, {}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}]>, <@mesh, [{}]>]>, manual_axes = #sdy<manual_axes{"_axis_0", "_axis_1"}>, out_shardings = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}, {?}, {?}]>, <@mesh, [{"_axis_1", ?}, {?}, {"_axis_0", ?}]>]>}> ({
    ^bb0(%arg15: tensor<128x2048xbf16>, %arg16: tensor<1x136xi64>, %arg17: tensor<128256x8192xbf16>, %arg18: tensor<8192xbf16>, %arg19: tensor<64xf32>, %arg20: tensor<128x2048xbf16>, %arg21: tensor<16032x2048xbf16>, %arg22: tensor<2048x3584xbf16>, %arg23: tensor<3584x2048xbf16>, %arg24: tensor<2048x1024xbf16>, %arg25: tensor<1x136xi64>, %arg26: tensor<1024x2048xbf16>, %arg27: tensor<8192xbf16>, %arg28: tensor<3584x2048xbf16>, %arg29: tensor<8192xbf16>):
      %1 = "stablehlo.constant"() <{value = dense<0.000000e+00> : tensor<f32>}> : () -> tensor<f32>
      %2 = "stablehlo.constant"() <{value = dense<"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tensor<136xi64>}> : () -> tensor<136xi64>
      %3 = "stablehlo.constant"() <{value = dense<0xFF800000> : tensor<f32>}> : () -> tensor<f32>
      %4 = "stablehlo.constant"() <{value = dense<2.000000e+00> : tensor<f32>}> : () -> tensor<f32>
      %5 = "stablehlo.constant"() <{value = dense<1.22070313E-4> : tensor<f32>}> : () -> tensor<f32>
      %6 = "stablehlo.constant"() <{value = dense<9.99999974E-6> : tensor<f32>}> : () -> tensor<f32>
      %7 = "stablehlo.constant"() <{value = dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE420000004300000143000002430000034300000443000005430000064300000743"> : tensor<1x1x136xf32>}> : () -> tensor<1x1x136xf32>
      %8 = "stablehlo.constant"() <{value = dense<8.837890e-02> : tensor<bf16>}> : () -> tensor<bf16>
      %9 = "stablehlo.constant"() <{value = dense<1> : tensor<i64>}> : () -> tensor<i64>
      %10 = "stablehlo.constant"() <{value = dense<0.000000e+00> : tensor<bf16>}> : () -> tensor<bf16>
      %11 = "stablehlo.constant"() <{value = dense<-3.389530e+38> : tensor<bf16>}> : () -> tensor<bf16>
      %12 = "stablehlo.broadcast_in_dim"(%11) <{broadcast_dimensions = array<i64>}> : (tensor<bf16>) -> tensor<1x1x136x136xbf16>
      %13 = "stablehlo.broadcast_in_dim"(%10) <{broadcast_dimensions = array<i64>}> : (tensor<bf16>) -> tensor<1x1x136x136xbf16>
      %14 = "stablehlo.broadcast_in_dim"(%10) <{broadcast_dimensions = array<i64>}> : (tensor<bf16>) -> tensor<136x136xbf16>
      %15 = "stablehlo.broadcast_in_dim"(%11) <{broadcast_dimensions = array<i64>}> : (tensor<bf16>) -> tensor<136x136xbf16>
      %16 = "stablehlo.broadcast_in_dim"(%9) <{broadcast_dimensions = array<i64>}> : (tensor<i64>) -> tensor<136x136xi64>
      %17 = "stablehlo.broadcast_in_dim"(%8) <{broadcast_dimensions = array<i64>}> : (tensor<bf16>) -> tensor<1x8x136x136xbf16>
      %18 = "stablehlo.broadcast_in_dim"(%6) <{broadcast_dimensions = array<i64>}> : (tensor<f32>) -> tensor<1x136x1xf32>
      %19 = "stablehlo.broadcast_in_dim"(%5) <{broadcast_dimensions = array<i64>}> : (tensor<f32>) -> tensor<1x136xf32>
      %20 = "stablehlo.broadcast_in_dim"(%4) <{broadcast_dimensions = array<i64>}> : (tensor<f32>) -> tensor<1x136x8192xf32>
      %21 = "stablehlo.reshape"(%arg18) : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
      %22 = "stablehlo.reshape"(%21) : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
      %23 = "stablehlo.broadcast_in_dim"(%22) <{broadcast_dimensions = array<i64: 2>}> : (tensor<8192xbf16>) -> tensor<1x136x8192xbf16>
      %24 = "stablehlo.reshape"(%arg17) : (tensor<128256x8192xbf16>) -> tensor<1x128256x8192xbf16>
      %25 = "stablehlo.reshape"(%24) : (tensor<1x128256x8192xbf16>) -> tensor<128256x8192xbf16>
      %26 = "stablehlo.reshape"(%arg16) : (tensor<1x136xi64>) -> tensor<1x1x136xi64>
      %27 = "stablehlo.reshape"(%26) : (tensor<1x1x136xi64>) -> tensor<136xi64>
      %28 = "stablehlo.convert"(%27) : (tensor<136xi64>) -> tensor<136xui32>
      %29 = "stablehlo.gather"(%25, %28) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 8192>}> : (tensor<128256x8192xbf16>, tensor<136xui32>) -> tensor<136x8192xbf16>
      %30 = "stablehlo.reshape"(%29) : (tensor<136x8192xbf16>) -> tensor<1x136x8192xbf16>
      %31 = "stablehlo.convert"(%30) : (tensor<1x136x8192xbf16>) -> tensor<1x136x8192xf32>
      %32 = "stablehlo.power"(%31, %20) : (tensor<1x136x8192xf32>, tensor<1x136x8192xf32>) -> tensor<1x136x8192xf32>
      %33 = "stablehlo.reduce"(%32, %1) <{dimensions = array<i64: 2>}> ({
      ^bb0(%arg54: tensor<f32>, %arg55: tensor<f32>):
        %253 = "stablehlo.add"(%arg54, %arg55) : (tensor<f32>, tensor<f32>) -> tensor<f32>
        "stablehlo.return"(%253) : (tensor<f32>) -> ()
      }) : (tensor<1x136x8192xf32>, tensor<f32>) -> tensor<1x136xf32>
      %34 = "stablehlo.multiply"(%33, %19) : (tensor<1x136xf32>, tensor<1x136xf32>) -> tensor<1x136xf32>
      %35 = "stablehlo.reshape"(%34) : (tensor<1x136xf32>) -> tensor<1x136x1xf32>
      %36 = "stablehlo.add"(%35, %18) : (tensor<1x136x1xf32>, tensor<1x136x1xf32>) -> tensor<1x136x1xf32>
      %37 = "stablehlo.rsqrt"(%36) : (tensor<1x136x1xf32>) -> tensor<1x136x1xf32>
      %38 = "stablehlo.reshape"(%37) : (tensor<1x136x1xf32>) -> tensor<1x136xf32>
      %39 = "stablehlo.broadcast_in_dim"(%38) <{broadcast_dimensions = array<i64: 0, 1>}> : (tensor<1x136xf32>) -> tensor<1x136x8192xf32>
      %40 = "stablehlo.multiply"(%31, %39) : (tensor<1x136x8192xf32>, tensor<1x136x8192xf32>) -> tensor<1x136x8192xf32>
      %41 = "stablehlo.convert"(%40) : (tensor<1x136x8192xf32>) -> tensor<1x136x8192xbf16>
      %42 = "stablehlo.multiply"(%23, %41) : (tensor<1x136x8192xbf16>, tensor<1x136x8192xbf16>) -> tensor<1x136x8192xbf16>
      %43 = "stablehlo.reshape"(%42) : (tensor<1x136x8192xbf16>) -> tensor<136x8192xbf16>
      %44 = "stablehlo.reshape"(%arg15) : (tensor<128x2048xbf16>) -> tensor<1x128x2048xbf16>
      %45 = "stablehlo.reshape"(%44) : (tensor<1x128x2048xbf16>) -> tensor<128x2048xbf16>
      %46 = "stablehlo.transpose"(%45) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<128x2048xbf16>) -> tensor<2048x128xbf16>
      %47 = "stablehlo.all_to_all"(%43) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, concat_dimension = 0 : i64, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>, split_count = 4 : i64, split_dimension = 1 : i64}> : (tensor<136x8192xbf16>) -> tensor<544x2048xbf16>
      %48 = "stablehlo.dot_general"(%47, %46) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<544x2048xbf16>, tensor<2048x128xbf16>) -> tensor<544x128xbf16>
      %49 = "stablehlo.all_reduce"(%48) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>}> ({
      ^bb0(%arg52: tensor<bf16>, %arg53: tensor<bf16>):
        %252 = "stablehlo.add"(%arg52, %arg53) : (tensor<bf16>, tensor<bf16>) -> tensor<bf16>
        "stablehlo.return"(%252) : (tensor<bf16>) -> ()
      }) : (tensor<544x128xbf16>) -> tensor<544x128xbf16>
      %50 = "stablehlo.reshape"(%49) : (tensor<544x128xbf16>) -> tensor<4x136x1024xbf16>
      %51 = "stablehlo.all_to_all"(%50) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, concat_dimension = 0 : i64, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>, split_count = 4 : i64, split_dimension = 0 : i64}> : (tensor<4x136x1024xbf16>) -> tensor<4x136x1024xbf16>
      %52 = "stablehlo.slice"(%51) <{limit_indices = array<i64: 1, 136, 1024>, start_indices = array<i64: 0, 0, 0>, strides = array<i64: 1, 1, 1>}> : (tensor<4x136x1024xbf16>) -> tensor<1x136x1024xbf16>
      %53 = "stablehlo.reshape"(%52) : (tensor<1x136x1024xbf16>) -> tensor<136x1024xbf16>
      %54 = "stablehlo.reshape"(%53) : (tensor<136x1024xbf16>) -> tensor<1x136x1x128xbf16>
      %55 = "stablehlo.transpose"(%54) <{permutation = array<i64: 0, 2, 1, 3>}> {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<1x136x1x128xbf16>) -> tensor<1x1x136x128xbf16>
      %56 = "stablehlo.reshape"(%arg20) : (tensor<128x2048xbf16>) -> tensor<1x128x2048xbf16>
      %57 = "stablehlo.reshape"(%56) : (tensor<1x128x2048xbf16>) -> tensor<128x2048xbf16>
      %58 = "stablehlo.transpose"(%57) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,1024]{0,1}"} : (tensor<128x2048xbf16>) -> tensor<2048x128xbf16>
      %59 = "stablehlo.all_to_all"(%43) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, concat_dimension = 0 : i64, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>, split_count = 4 : i64, split_dimension = 1 : i64}> : (tensor<136x8192xbf16>) -> tensor<544x2048xbf16>
      %60 = "stablehlo.dot_general"(%59, %58) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<544x2048xbf16>, tensor<2048x128xbf16>) -> tensor<544x128xbf16>
      %61 = "stablehlo.all_reduce"(%60) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>}> ({
      ^bb0(%arg50: tensor<bf16>, %arg51: tensor<bf16>):
        %251 = "stablehlo.add"(%arg50, %arg51) : (tensor<bf16>, tensor<bf16>) -> tensor<bf16>
        "stablehlo.return"(%251) : (tensor<bf16>) -> ()
      }) : (tensor<544x128xbf16>) -> tensor<544x128xbf16>
      %62 = "stablehlo.reshape"(%61) : (tensor<544x128xbf16>) -> tensor<4x136x1024xbf16>
      %63 = "stablehlo.all_to_all"(%62) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, concat_dimension = 0 : i64, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>, split_count = 4 : i64, split_dimension = 0 : i64}> : (tensor<4x136x1024xbf16>) -> tensor<4x136x1024xbf16>
      %64 = "stablehlo.slice"(%63) <{limit_indices = array<i64: 1, 136, 1024>, start_indices = array<i64: 0, 0, 0>, strides = array<i64: 1, 1, 1>}> : (tensor<4x136x1024xbf16>) -> tensor<1x136x1024xbf16>
      %65 = "stablehlo.reshape"(%64) : (tensor<1x136x1024xbf16>) -> tensor<136x1024xbf16>
      %66 = "stablehlo.reshape"(%65) : (tensor<136x1024xbf16>) -> tensor<1x136x1x128xbf16>
      %67 = "stablehlo.transpose"(%66) <{permutation = array<i64: 0, 2, 1, 3>}> {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,8,136,128]{3,1,2,0}"} : (tensor<1x136x1x128xbf16>) -> tensor<1x1x136x128xbf16>
      %68 = "stablehlo.reshape"(%arg19) : (tensor<64xf32>) -> tensor<1x1x64xf32>
      %69 = "stablehlo.reshape"(%68) : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
      %70 = "stablehlo.dot_general"(%69, %7) <{dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>}> : (tensor<1x64x1xf32>, tensor<1x1x136xf32>) -> tensor<1x64x136xf32>
      %71 = "stablehlo.transpose"(%70) <{permutation = array<i64: 0, 2, 1>}> {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,136,64]{1,2,0}"} : (tensor<1x64x136xf32>) -> tensor<1x136x64xf32>
      %72 = "stablehlo.concatenate"(%71, %71) <{dimension = 2 : i64}> : (tensor<1x136x64xf32>, tensor<1x136x64xf32>) -> tensor<1x136x128xf32>
      %73 = "stablehlo.cosine"(%72) : (tensor<1x136x128xf32>) -> tensor<1x136x128xf32>
      %74 = "stablehlo.convert"(%73) : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
      %75 = "stablehlo.reshape"(%74) : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
      %76 = "stablehlo.broadcast_in_dim"(%75) <{broadcast_dimensions = array<i64: 2, 3>}> : (tensor<136x128xbf16>) -> tensor<1x1x136x128xbf16>
      %77 = "stablehlo.multiply"(%67, %76) : (tensor<1x1x136x128xbf16>, tensor<1x1x136x128xbf16>) -> tensor<1x1x136x128xbf16>
      %78 = "stablehlo.slice"(%67) <{limit_indices = array<i64: 1, 1, 136, 128>, start_indices = array<i64: 0, 0, 0, 64>, strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x1x136x128xbf16>) -> tensor<1x1x136x64xbf16>
      %79 = "stablehlo.negate"(%78) : (tensor<1x1x136x64xbf16>) -> tensor<1x1x136x64xbf16>
      %80 = "stablehlo.slice"(%67) <{limit_indices = array<i64: 1, 1, 136, 64>, start_indices = array<i64: 0, 0, 0, 0>, strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x1x136x128xbf16>) -> tensor<1x1x136x64xbf16>
      %81 = "stablehlo.concatenate"(%79, %80) <{dimension = 3 : i64}> : (tensor<1x1x136x64xbf16>, tensor<1x1x136x64xbf16>) -> tensor<1x1x136x128xbf16>
      %82 = "stablehlo.sine"(%72) : (tensor<1x136x128xf32>) -> tensor<1x136x128xf32>
      %83 = "stablehlo.convert"(%82) : (tensor<1x136x128xf32>) -> tensor<1x136x128xbf16>
      %84 = "stablehlo.reshape"(%83) : (tensor<1x136x128xbf16>) -> tensor<136x128xbf16>
      %85 = "stablehlo.broadcast_in_dim"(%84) <{broadcast_dimensions = array<i64: 2, 3>}> : (tensor<136x128xbf16>) -> tensor<1x1x136x128xbf16>
      %86 = "stablehlo.multiply"(%81, %85) : (tensor<1x1x136x128xbf16>, tensor<1x1x136x128xbf16>) -> tensor<1x1x136x128xbf16>
      %87 = "stablehlo.add"(%77, %86) : (tensor<1x1x136x128xbf16>, tensor<1x1x136x128xbf16>) -> tensor<1x1x136x128xbf16>
      %88 = "stablehlo.reshape"(%arg29) : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
      %89 = "stablehlo.reshape"(%88) : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
      %90 = "stablehlo.broadcast_in_dim"(%89) <{broadcast_dimensions = array<i64: 2>}> : (tensor<8192xbf16>) -> tensor<1x136x8192xbf16>
      %91 = "stablehlo.reshape"(%arg26) : (tensor<1024x2048xbf16>) -> tensor<1x1024x2048xbf16>
      %92 = "stablehlo.reshape"(%91) : (tensor<1x1024x2048xbf16>) -> tensor<1024x2048xbf16>
      %93 = "stablehlo.transpose"(%92) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<1024x2048xbf16>) -> tensor<2048x1024xbf16>
      %94 = "stablehlo.all_to_all"(%43) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, concat_dimension = 0 : i64, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>, split_count = 4 : i64, split_dimension = 1 : i64}> : (tensor<136x8192xbf16>) -> tensor<544x2048xbf16>
      %95 = "stablehlo.dot_general"(%94, %93) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<544x2048xbf16>, tensor<2048x1024xbf16>) -> tensor<544x1024xbf16>
      %96 = "stablehlo.all_reduce"(%95) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>}> ({
      ^bb0(%arg48: tensor<bf16>, %arg49: tensor<bf16>):
        %250 = "stablehlo.add"(%arg48, %arg49) : (tensor<bf16>, tensor<bf16>) -> tensor<bf16>
        "stablehlo.return"(%250) : (tensor<bf16>) -> ()
      }) : (tensor<544x1024xbf16>) -> tensor<544x1024xbf16>
      %97 = "stablehlo.reshape"(%96) : (tensor<544x1024xbf16>) -> tensor<4x136x8192xbf16>
      %98 = "stablehlo.all_to_all"(%97) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, concat_dimension = 0 : i64, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>, split_count = 4 : i64, split_dimension = 0 : i64}> : (tensor<4x136x8192xbf16>) -> tensor<4x136x8192xbf16>
      %99 = "stablehlo.slice"(%98) <{limit_indices = array<i64: 1, 136, 8192>, start_indices = array<i64: 0, 0, 0>, strides = array<i64: 1, 1, 1>}> : (tensor<4x136x8192xbf16>) -> tensor<1x136x8192xbf16>
      %100 = "stablehlo.reshape"(%99) : (tensor<1x136x8192xbf16>) -> tensor<136x8192xbf16>
      %101 = "stablehlo.reshape"(%100) : (tensor<136x8192xbf16>) -> tensor<1x136x8x128xbf16>
      %102 = "stablehlo.transpose"(%101) <{permutation = array<i64: 0, 2, 1, 3>}> {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,136,128]{3,1,2,0}"} : (tensor<1x136x8x128xbf16>) -> tensor<1x8x136x128xbf16>
      %103 = "stablehlo.broadcast_in_dim"(%75) <{broadcast_dimensions = array<i64: 2, 3>}> : (tensor<136x128xbf16>) -> tensor<1x8x136x128xbf16>
      %104 = "stablehlo.multiply"(%102, %103) : (tensor<1x8x136x128xbf16>, tensor<1x8x136x128xbf16>) -> tensor<1x8x136x128xbf16>
      %105 = "stablehlo.slice"(%102) <{limit_indices = array<i64: 1, 8, 136, 128>, start_indices = array<i64: 0, 0, 0, 64>, strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x8x136x128xbf16>) -> tensor<1x8x136x64xbf16>
      %106 = "stablehlo.negate"(%105) : (tensor<1x8x136x64xbf16>) -> tensor<1x8x136x64xbf16>
      %107 = "stablehlo.slice"(%102) <{limit_indices = array<i64: 1, 8, 136, 64>, start_indices = array<i64: 0, 0, 0, 0>, strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x8x136x128xbf16>) -> tensor<1x8x136x64xbf16>
      %108 = "stablehlo.concatenate"(%106, %107) <{dimension = 3 : i64}> : (tensor<1x8x136x64xbf16>, tensor<1x8x136x64xbf16>) -> tensor<1x8x136x128xbf16>
      %109 = "stablehlo.broadcast_in_dim"(%84) <{broadcast_dimensions = array<i64: 2, 3>}> : (tensor<136x128xbf16>) -> tensor<1x8x136x128xbf16>
      %110 = "stablehlo.multiply"(%108, %109) : (tensor<1x8x136x128xbf16>, tensor<1x8x136x128xbf16>) -> tensor<1x8x136x128xbf16>
      %111 = "stablehlo.add"(%104, %110) : (tensor<1x8x136x128xbf16>, tensor<1x8x136x128xbf16>) -> tensor<1x8x136x128xbf16>
      %112 = "stablehlo.reshape"(%111) : (tensor<1x8x136x128xbf16>) -> tensor<8x136x128xbf16>
      %113 = "stablehlo.broadcast_in_dim"(%87) <{broadcast_dimensions = array<i64: 0, 1, 3, 4>}> : (tensor<1x1x136x128xbf16>) -> tensor<1x1x8x136x128xbf16>
      %114 = "stablehlo.reshape"(%113) : (tensor<1x1x8x136x128xbf16>) -> tensor<1x8x136x128xbf16>
      %115 = "stablehlo.transpose"(%114) <{permutation = array<i64: 0, 1, 3, 2>}> {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[4,64,128,136]{2,3,1,0}"} : (tensor<1x8x136x128xbf16>) -> tensor<1x8x128x136xbf16>
      %116 = "stablehlo.reshape"(%115) : (tensor<1x8x128x136xbf16>) -> tensor<8x128x136xbf16>
      %117 = "stablehlo.dot_general"(%112, %116) <{dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>}> : (tensor<8x136x128xbf16>, tensor<8x128x136xbf16>) -> tensor<8x136x136xbf16>
      %118 = "stablehlo.reshape"(%117) : (tensor<8x136x136xbf16>) -> tensor<1x8x136x136xbf16>
      %119 = "stablehlo.multiply"(%118, %17) : (tensor<1x8x136x136xbf16>, tensor<1x8x136x136xbf16>) -> tensor<1x8x136x136xbf16>
      %120 = "stablehlo.broadcast_in_dim"(%2) <{broadcast_dimensions = array<i64: 1>}> : (tensor<136xi64>) -> tensor<136x136xi64>
      %121 = "stablehlo.broadcast_in_dim"(%2) <{broadcast_dimensions = array<i64: 0>}> : (tensor<136xi64>) -> tensor<136x136xi64>
      %122 = "stablehlo.subtract"(%120, %121) : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi64>
      %123 = "stablehlo.compare"(%122, %16) <{comparison_direction = #stablehlo<comparison_direction GE>}> : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
      %124 = "stablehlo.select"(%123, %15, %14) : (tensor<136x136xi1>, tensor<136x136xbf16>, tensor<136x136xbf16>) -> tensor<136x136xbf16>
      %125 = "stablehlo.compare"(%120, %121) <{comparison_direction = #stablehlo<comparison_direction GT>}> : (tensor<136x136xi64>, tensor<136x136xi64>) -> tensor<136x136xi1>
      %126 = "stablehlo.convert"(%125) : (tensor<136x136xi1>) -> tensor<136x136xbf16>
      %127 = "stablehlo.multiply"(%124, %126) : (tensor<136x136xbf16>, tensor<136x136xbf16>) -> tensor<136x136xbf16>
      %128 = "stablehlo.reshape"(%127) : (tensor<136x136xbf16>) -> tensor<1x136x136xbf16>
      %129 = "stablehlo.broadcast_in_dim"(%128) <{broadcast_dimensions = array<i64: 1, 2, 3>}> : (tensor<1x136x136xbf16>) -> tensor<1x1x136x136xbf16>
      %130 = "stablehlo.reshape"(%arg25) : (tensor<1x136xi64>) -> tensor<1x1x136xi64>
      %131 = "stablehlo.reshape"(%130) : (tensor<1x1x136xi64>) -> tensor<1x1x1x136xi64>
      %132 = "stablehlo.convert"(%131) : (tensor<1x1x1x136xi64>) -> tensor<1x1x1x136xbf16>
      %133 = "stablehlo.reshape"(%132) : (tensor<1x1x1x136xbf16>) -> tensor<1x1x136xbf16>
      %134 = "stablehlo.broadcast_in_dim"(%133) <{broadcast_dimensions = array<i64: 0, 1, 3>}> : (tensor<1x1x136xbf16>) -> tensor<1x1x136x136xbf16>
      %135 = "stablehlo.add"(%129, %134) : (tensor<1x1x136x136xbf16>, tensor<1x1x136x136xbf16>) -> tensor<1x1x136x136xbf16>
      %136 = "stablehlo.compare"(%135, %13) <{comparison_direction = #stablehlo<comparison_direction EQ>}> : (tensor<1x1x136x136xbf16>, tensor<1x1x136x136xbf16>) -> tensor<1x1x136x136xi1>
      %137 = "stablehlo.select"(%136, %12, %129) : (tensor<1x1x136x136xi1>, tensor<1x1x136x136xbf16>, tensor<1x1x136x136xbf16>) -> tensor<1x1x136x136xbf16>
      %138 = "stablehlo.reshape"(%137) : (tensor<1x1x136x136xbf16>) -> tensor<1x136x136xbf16>
      %139 = "stablehlo.broadcast_in_dim"(%138) <{broadcast_dimensions = array<i64: 0, 2, 3>}> : (tensor<1x136x136xbf16>) -> tensor<1x8x136x136xbf16>
      %140 = "stablehlo.add"(%119, %139) : (tensor<1x8x136x136xbf16>, tensor<1x8x136x136xbf16>) -> tensor<1x8x136x136xbf16>
      %141 = "stablehlo.convert"(%140) : (tensor<1x8x136x136xbf16>) -> tensor<1x8x136x136xf32>
      %142 = "stablehlo.reduce"(%141, %3) <{dimensions = array<i64: 3>}> ({
      ^bb0(%arg46: tensor<f32>, %arg47: tensor<f32>):
        %249 = "stablehlo.maximum"(%arg46, %arg47) : (tensor<f32>, tensor<f32>) -> tensor<f32>
        "stablehlo.return"(%249) : (tensor<f32>) -> ()
      }) : (tensor<1x8x136x136xf32>, tensor<f32>) -> tensor<1x8x136xf32>
      %143 = "stablehlo.broadcast_in_dim"(%142) <{broadcast_dimensions = array<i64: 0, 1, 2>}> : (tensor<1x8x136xf32>) -> tensor<1x8x136x136xf32>
      %144 = "stablehlo.subtract"(%141, %143) : (tensor<1x8x136x136xf32>, tensor<1x8x136x136xf32>) -> tensor<1x8x136x136xf32>
      %145 = "stablehlo.exponential"(%144) : (tensor<1x8x136x136xf32>) -> tensor<1x8x136x136xf32>
      %146 = "stablehlo.reduce"(%145, %1) <{dimensions = array<i64: 3>}> ({
      ^bb0(%arg44: tensor<f32>, %arg45: tensor<f32>):
        %248 = "stablehlo.add"(%arg44, %arg45) : (tensor<f32>, tensor<f32>) -> tensor<f32>
        "stablehlo.return"(%248) : (tensor<f32>) -> ()
      }) : (tensor<1x8x136x136xf32>, tensor<f32>) -> tensor<1x8x136xf32>
      %147 = "stablehlo.broadcast_in_dim"(%146) <{broadcast_dimensions = array<i64: 0, 1, 2>}> : (tensor<1x8x136xf32>) -> tensor<1x8x136x136xf32>
      %148 = "stablehlo.divide"(%145, %147) : (tensor<1x8x136x136xf32>, tensor<1x8x136x136xf32>) -> tensor<1x8x136x136xf32>
      %149 = "stablehlo.convert"(%148) : (tensor<1x8x136x136xf32>) -> tensor<1x8x136x136xbf16>
      %150 = "stablehlo.reshape"(%149) : (tensor<1x8x136x136xbf16>) -> tensor<8x136x136xbf16>
      %151 = "stablehlo.broadcast_in_dim"(%55) <{broadcast_dimensions = array<i64: 0, 1, 3, 4>}> : (tensor<1x1x136x128xbf16>) -> tensor<1x1x8x136x128xbf16>
      %152 = "stablehlo.reshape"(%151) : (tensor<1x1x8x136x128xbf16>) -> tensor<8x136x128xbf16>
      %153 = "stablehlo.dot_general"(%150, %152) <{dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>}> : (tensor<8x136x136xbf16>, tensor<8x136x128xbf16>) -> tensor<8x136x128xbf16>
      %154 = "stablehlo.reshape"(%153) : (tensor<8x136x128xbf16>) -> tensor<1x8x136x128xbf16>
      %155 = "stablehlo.transpose"(%154) <{permutation = array<i64: 0, 2, 1, 3>}> {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[4,136,64,128]{3,1,2,0}"} : (tensor<1x8x136x128xbf16>) -> tensor<1x136x8x128xbf16>
      %156 = "stablehlo.reshape"(%155) : (tensor<1x136x8x128xbf16>) -> tensor<136x1024xbf16>
      %157 = "stablehlo.reshape"(%arg24) : (tensor<2048x1024xbf16>) -> tensor<1x2048x1024xbf16>
      %158 = "stablehlo.reshape"(%157) : (tensor<1x2048x1024xbf16>) -> tensor<2048x1024xbf16>
      %159 = "stablehlo.transpose"(%158) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,8192]{0,1}"} : (tensor<2048x1024xbf16>) -> tensor<1024x2048xbf16>
      %160 = "stablehlo.all_gather"(%156) <{all_gather_dim = 0 : i64, channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>}> : (tensor<136x1024xbf16>) -> tensor<544x1024xbf16>
      %161 = "stablehlo.dot_general"(%160, %159) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<544x1024xbf16>, tensor<1024x2048xbf16>) -> tensor<544x2048xbf16>
      %162 = "stablehlo.all_reduce"(%161) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 4, 8, 12, 16, 20, 24, 28], [1, 5, 9, 13, 17, 21, 25, 29], [2, 6, 10, 14, 18, 22, 26, 30], [3, 7, 11, 15, 19, 23, 27, 31]]> : tensor<4x8xi64>}> ({
      ^bb0(%arg42: tensor<bf16>, %arg43: tensor<bf16>):
        %247 = "stablehlo.add"(%arg42, %arg43) : (tensor<bf16>, tensor<bf16>) -> tensor<bf16>
        "stablehlo.return"(%247) : (tensor<bf16>) -> ()
      }) : (tensor<544x2048xbf16>) -> tensor<544x2048xbf16>
      %163 = "stablehlo.reshape"(%162) : (tensor<544x2048xbf16>) -> tensor<4x136x2048xbf16>
      %164 = "stablehlo.all_to_all"(%163) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, concat_dimension = 2 : i64, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>, split_count = 4 : i64, split_dimension = 0 : i64}> : (tensor<4x136x2048xbf16>) -> tensor<1x136x8192xbf16>
      %165 = "stablehlo.add"(%30, %164) : (tensor<1x136x8192xbf16>, tensor<1x136x8192xbf16>) -> tensor<1x136x8192xbf16>
      %166 = "stablehlo.reshape"(%arg27) : (tensor<8192xbf16>) -> tensor<1x1x8192xbf16>
      %167 = "stablehlo.reshape"(%166) : (tensor<1x1x8192xbf16>) -> tensor<8192xbf16>
      %168 = "stablehlo.broadcast_in_dim"(%167) <{broadcast_dimensions = array<i64: 2>}> : (tensor<8192xbf16>) -> tensor<1x136x8192xbf16>
      %169 = "stablehlo.convert"(%165) : (tensor<1x136x8192xbf16>) -> tensor<1x136x8192xf32>
      %170 = "stablehlo.power"(%169, %20) : (tensor<1x136x8192xf32>, tensor<1x136x8192xf32>) -> tensor<1x136x8192xf32>
      %171 = "stablehlo.reduce"(%170, %1) <{dimensions = array<i64: 2>}> ({
      ^bb0(%arg40: tensor<f32>, %arg41: tensor<f32>):
        %246 = "stablehlo.add"(%arg40, %arg41) : (tensor<f32>, tensor<f32>) -> tensor<f32>
        "stablehlo.return"(%246) : (tensor<f32>) -> ()
      }) : (tensor<1x136x8192xf32>, tensor<f32>) -> tensor<1x136xf32>
      %172 = "stablehlo.multiply"(%171, %19) : (tensor<1x136xf32>, tensor<1x136xf32>) -> tensor<1x136xf32>
      %173 = "stablehlo.reshape"(%172) : (tensor<1x136xf32>) -> tensor<1x136x1xf32>
      %174 = "stablehlo.add"(%173, %18) : (tensor<1x136x1xf32>, tensor<1x136x1xf32>) -> tensor<1x136x1xf32>
      %175 = "stablehlo.rsqrt"(%174) : (tensor<1x136x1xf32>) -> tensor<1x136x1xf32>
      %176 = "stablehlo.reshape"(%175) : (tensor<1x136x1xf32>) -> tensor<1x136xf32>
      %177 = "stablehlo.broadcast_in_dim"(%176) <{broadcast_dimensions = array<i64: 0, 1>}> : (tensor<1x136xf32>) -> tensor<1x136x8192xf32>
      %178 = "stablehlo.multiply"(%169, %177) : (tensor<1x136x8192xf32>, tensor<1x136x8192xf32>) -> tensor<1x136x8192xf32>
      %179 = "stablehlo.convert"(%178) : (tensor<1x136x8192xf32>) -> tensor<1x136x8192xbf16>
      %180 = "stablehlo.multiply"(%168, %179) : (tensor<1x136x8192xbf16>, tensor<1x136x8192xbf16>) -> tensor<1x136x8192xbf16>
      %181 = "stablehlo.reshape"(%180) : (tensor<1x136x8192xbf16>) -> tensor<136x8192xbf16>
      %182 = "stablehlo.reshape"(%arg28) : (tensor<3584x2048xbf16>) -> tensor<1x3584x2048xbf16>
      %183 = "stablehlo.reshape"(%182) : (tensor<1x3584x2048xbf16>) -> tensor<3584x2048xbf16>
      %184 = "stablehlo.transpose"(%183) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<3584x2048xbf16>) -> tensor<2048x3584xbf16>
      %185 = "stablehlo.all_to_all"(%181) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, concat_dimension = 0 : i64, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>, split_count = 4 : i64, split_dimension = 1 : i64}> : (tensor<136x8192xbf16>) -> tensor<544x2048xbf16>
      %186 = "stablehlo.dot_general"(%185, %184) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<544x2048xbf16>, tensor<2048x3584xbf16>) -> tensor<544x3584xbf16>
      %187 = "stablehlo.all_reduce"(%186) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>}> ({
      ^bb0(%arg38: tensor<bf16>, %arg39: tensor<bf16>):
        %245 = "stablehlo.add"(%arg38, %arg39) : (tensor<bf16>, tensor<bf16>) -> tensor<bf16>
        "stablehlo.return"(%245) : (tensor<bf16>) -> ()
      }) : (tensor<544x3584xbf16>) -> tensor<544x3584xbf16>
      %188 = "stablehlo.reshape"(%187) : (tensor<544x3584xbf16>) -> tensor<4x136x28672xbf16>
      %189 = "stablehlo.all_to_all"(%188) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, concat_dimension = 0 : i64, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>, split_count = 4 : i64, split_dimension = 0 : i64}> : (tensor<4x136x28672xbf16>) -> tensor<4x136x28672xbf16>
      %190 = "stablehlo.slice"(%189) <{limit_indices = array<i64: 1, 136, 28672>, start_indices = array<i64: 0, 0, 0>, strides = array<i64: 1, 1, 1>}> : (tensor<4x136x28672xbf16>) -> tensor<1x136x28672xbf16>
      %191 = "stablehlo.reshape"(%190) : (tensor<1x136x28672xbf16>) -> tensor<136x28672xbf16>
      %192 = "stablehlo.reshape"(%191) : (tensor<136x28672xbf16>) -> tensor<1x136x3584xbf16>
      %193 = "stablehlo.logistic"(%192) : (tensor<1x136x3584xbf16>) -> tensor<1x136x3584xbf16>
      %194 = "stablehlo.multiply"(%192, %193) : (tensor<1x136x3584xbf16>, tensor<1x136x3584xbf16>) -> tensor<1x136x3584xbf16>
      %195 = "stablehlo.reshape"(%arg23) : (tensor<3584x2048xbf16>) -> tensor<1x3584x2048xbf16>
      %196 = "stablehlo.reshape"(%195) : (tensor<1x3584x2048xbf16>) -> tensor<3584x2048xbf16>
      %197 = "stablehlo.transpose"(%196) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,28672]{0,1}"} : (tensor<3584x2048xbf16>) -> tensor<2048x3584xbf16>
      %198 = "stablehlo.all_to_all"(%181) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, concat_dimension = 0 : i64, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>, split_count = 4 : i64, split_dimension = 1 : i64}> : (tensor<136x8192xbf16>) -> tensor<544x2048xbf16>
      %199 = "stablehlo.dot_general"(%198, %197) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<544x2048xbf16>, tensor<2048x3584xbf16>) -> tensor<544x3584xbf16>
      %200 = "stablehlo.all_reduce"(%199) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>}> ({
      ^bb0(%arg36: tensor<bf16>, %arg37: tensor<bf16>):
        %244 = "stablehlo.add"(%arg36, %arg37) : (tensor<bf16>, tensor<bf16>) -> tensor<bf16>
        "stablehlo.return"(%244) : (tensor<bf16>) -> ()
      }) : (tensor<544x3584xbf16>) -> tensor<544x3584xbf16>
      %201 = "stablehlo.reshape"(%200) : (tensor<544x3584xbf16>) -> tensor<4x136x28672xbf16>
      %202 = "stablehlo.all_to_all"(%201) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, concat_dimension = 0 : i64, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>, split_count = 4 : i64, split_dimension = 0 : i64}> : (tensor<4x136x28672xbf16>) -> tensor<4x136x28672xbf16>
      %203 = "stablehlo.slice"(%202) <{limit_indices = array<i64: 1, 136, 28672>, start_indices = array<i64: 0, 0, 0>, strides = array<i64: 1, 1, 1>}> : (tensor<4x136x28672xbf16>) -> tensor<1x136x28672xbf16>
      %204 = "stablehlo.reshape"(%203) : (tensor<1x136x28672xbf16>) -> tensor<136x28672xbf16>
      %205 = "stablehlo.reshape"(%204) : (tensor<136x28672xbf16>) -> tensor<1x136x3584xbf16>
      %206 = "stablehlo.multiply"(%194, %205) : (tensor<1x136x3584xbf16>, tensor<1x136x3584xbf16>) -> tensor<1x136x3584xbf16>
      %207 = "stablehlo.reshape"(%206) : (tensor<1x136x3584xbf16>) -> tensor<136x3584xbf16>
      %208 = "stablehlo.reshape"(%arg22) : (tensor<2048x3584xbf16>) -> tensor<1x2048x3584xbf16>
      %209 = "stablehlo.reshape"(%208) : (tensor<1x2048x3584xbf16>) -> tensor<2048x3584xbf16>
      %210 = "stablehlo.transpose"(%209) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[28672,8192]{0,1}"} : (tensor<2048x3584xbf16>) -> tensor<3584x2048xbf16>
      %211 = "stablehlo.all_gather"(%207) <{all_gather_dim = 0 : i64, channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>}> : (tensor<136x3584xbf16>) -> tensor<544x3584xbf16>
      %212 = "stablehlo.dot_general"(%211, %210) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<544x3584xbf16>, tensor<3584x2048xbf16>) -> tensor<544x2048xbf16>
      %213 = "stablehlo.all_reduce"(%212) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 4, 8, 12, 16, 20, 24, 28], [1, 5, 9, 13, 17, 21, 25, 29], [2, 6, 10, 14, 18, 22, 26, 30], [3, 7, 11, 15, 19, 23, 27, 31]]> : tensor<4x8xi64>}> ({
      ^bb0(%arg34: tensor<bf16>, %arg35: tensor<bf16>):
        %243 = "stablehlo.add"(%arg34, %arg35) : (tensor<bf16>, tensor<bf16>) -> tensor<bf16>
        "stablehlo.return"(%243) : (tensor<bf16>) -> ()
      }) : (tensor<544x2048xbf16>) -> tensor<544x2048xbf16>
      %214 = "stablehlo.reshape"(%213) : (tensor<544x2048xbf16>) -> tensor<4x136x2048xbf16>
      %215 = "stablehlo.all_to_all"(%214) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, concat_dimension = 2 : i64, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>, split_count = 4 : i64, split_dimension = 0 : i64}> : (tensor<4x136x2048xbf16>) -> tensor<1x136x8192xbf16>
      %216 = "stablehlo.add"(%165, %215) : (tensor<1x136x8192xbf16>, tensor<1x136x8192xbf16>) -> tensor<1x136x8192xbf16>
      %217 = "stablehlo.convert"(%216) : (tensor<1x136x8192xbf16>) -> tensor<1x136x8192xf32>
      %218 = "stablehlo.power"(%217, %20) : (tensor<1x136x8192xf32>, tensor<1x136x8192xf32>) -> tensor<1x136x8192xf32>
      %219 = "stablehlo.reduce"(%218, %1) <{dimensions = array<i64: 2>}> ({
      ^bb0(%arg32: tensor<f32>, %arg33: tensor<f32>):
        %242 = "stablehlo.add"(%arg32, %arg33) : (tensor<f32>, tensor<f32>) -> tensor<f32>
        "stablehlo.return"(%242) : (tensor<f32>) -> ()
      }) : (tensor<1x136x8192xf32>, tensor<f32>) -> tensor<1x136xf32>
      %220 = "stablehlo.multiply"(%219, %19) : (tensor<1x136xf32>, tensor<1x136xf32>) -> tensor<1x136xf32>
      %221 = "stablehlo.reshape"(%220) : (tensor<1x136xf32>) -> tensor<1x136x1xf32>
      %222 = "stablehlo.add"(%221, %18) : (tensor<1x136x1xf32>, tensor<1x136x1xf32>) -> tensor<1x136x1xf32>
      %223 = "stablehlo.rsqrt"(%222) : (tensor<1x136x1xf32>) -> tensor<1x136x1xf32>
      %224 = "stablehlo.reshape"(%223) : (tensor<1x136x1xf32>) -> tensor<1x136xf32>
      %225 = "stablehlo.broadcast_in_dim"(%224) <{broadcast_dimensions = array<i64: 0, 1>}> : (tensor<1x136xf32>) -> tensor<1x136x8192xf32>
      %226 = "stablehlo.multiply"(%217, %225) : (tensor<1x136x8192xf32>, tensor<1x136x8192xf32>) -> tensor<1x136x8192xf32>
      %227 = "stablehlo.convert"(%226) : (tensor<1x136x8192xf32>) -> tensor<1x136x8192xbf16>
      %228 = "stablehlo.multiply"(%90, %227) : (tensor<1x136x8192xbf16>, tensor<1x136x8192xbf16>) -> tensor<1x136x8192xbf16>
      %229 = "stablehlo.reshape"(%228) : (tensor<1x136x8192xbf16>) -> tensor<136x8192xbf16>
      %230 = "stablehlo.reshape"(%arg21) : (tensor<16032x2048xbf16>) -> tensor<1x16032x2048xbf16>
      %231 = "stablehlo.reshape"(%230) : (tensor<1x16032x2048xbf16>) -> tensor<16032x2048xbf16>
      %232 = "stablehlo.transpose"(%231) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,128256]{0,1}"} : (tensor<16032x2048xbf16>) -> tensor<2048x16032xbf16>
      %233 = "stablehlo.all_to_all"(%229) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, concat_dimension = 0 : i64, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>, split_count = 4 : i64, split_dimension = 1 : i64}> : (tensor<136x8192xbf16>) -> tensor<544x2048xbf16>
      %234 = "stablehlo.dot_general"(%233, %232) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<544x2048xbf16>, tensor<2048x16032xbf16>) -> tensor<544x16032xbf16>
      %235 = "stablehlo.all_reduce"(%234) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>}> ({
      ^bb0(%arg30: tensor<bf16>, %arg31: tensor<bf16>):
        %241 = "stablehlo.add"(%arg30, %arg31) : (tensor<bf16>, tensor<bf16>) -> tensor<bf16>
        "stablehlo.return"(%241) : (tensor<bf16>) -> ()
      }) : (tensor<544x16032xbf16>) -> tensor<544x16032xbf16>
      %236 = "stablehlo.reshape"(%235) : (tensor<544x16032xbf16>) -> tensor<4x136x128256xbf16>
      %237 = "stablehlo.all_to_all"(%236) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, concat_dimension = 0 : i64, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]> : tensor<8x4xi64>, split_count = 4 : i64, split_dimension = 0 : i64}> : (tensor<4x136x128256xbf16>) -> tensor<4x136x128256xbf16>
      %238 = "stablehlo.slice"(%237) <{limit_indices = array<i64: 1, 136, 128256>, start_indices = array<i64: 0, 0, 0>, strides = array<i64: 1, 1, 1>}> : (tensor<4x136x128256xbf16>) -> tensor<1x136x128256xbf16>
      %239 = "stablehlo.reshape"(%238) : (tensor<1x136x128256xbf16>) -> tensor<136x128256xbf16>
      %240 = "stablehlo.reshape"(%239) : (tensor<136x128256xbf16>) -> tensor<1x136x16032xbf16>
      "sdy.return"(%55, %87, %240) : (tensor<1x1x136x128xbf16>, tensor<1x1x136x128xbf16>, tensor<1x136x16032xbf16>) -> ()
    }) : (tensor<1024x8192xbf16>, tensor<4x136xi64>, tensor<128256x8192xbf16>, tensor<8192xbf16>, tensor<64xf32>, tensor<1024x8192xbf16>, tensor<128256x8192xbf16>, tensor<8192x28672xbf16>, tensor<28672x8192xbf16>, tensor<8192x8192xbf16>, tensor<4x136xi64>, tensor<8192x8192xbf16>, tensor<8192xbf16>, tensor<28672x8192xbf16>, tensor<8192xbf16>) -> (tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>)
    "func.return"(%0#0, %0#1, %0#2) : (tensor<4x8x136x128xbf16>, tensor<4x8x136x128xbf16>, tensor<4x136x128256xbf16>) -> ()
  }) : () -> ()
}) {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} : () -> ()


2025-10-27 21:34:21.468 (  26.317s) [        9C771B80]      module_builder.cc:681    ERR| Failed to run stablehlo pipeline
2025-10-27 21:34:21.468 (  26.317s) [        9C771B80]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2025-10-27 21:34:21.468 (  26.317s) [        9C771B80]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2025-10-27 21:34:21.468 (  26.317s) [        9C771B80]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.782s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.783s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.783s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.783s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.783s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.783s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.783s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.783s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.783s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.783s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.783s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.934 (  26.783s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:21.937 (  26.786s) [        9C771B80]     client_instance.cc:616      1| ClientInstance::PJRT_Client_Compile
2025-10-27 21:34:21.938 (  26.786s) [        9C771B80]      module_builder.cc:220      1| ModuleBuilder::buildModule
2025-10-27 21:34:21.938 (  26.786s) [        9C771B80]      module_builder.cc:963      1| MLIR Module vhlo:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<4x136x!vhlo.i64_v1> loc("p0.1")) -> (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) {
    %0 = "vhlo.custom_call_v1"(%arg0) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"xla.sdy.FuncResultSharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<true>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>} : (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.i64_v1> loc(#loc1)
    "vhlo.return_v1"(%0) : (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}">}>]>, res_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
// -----// IR Dump Before VhloToVersionPass (vhlo-to-version) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) {
    %0 = "vhlo.custom_call_v1"(%arg0) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"xla.sdy.FuncResultSharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<true>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>} : (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.i64_v1>
    "vhlo.return_v1"(%0) : (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}">}>]>, res_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, sym_visibility = #vhlo.string_v1<"">}
}


// -----// IR Dump Before VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) {
    %0 = "vhlo.custom_call_v1"(%arg0) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"xla.sdy.FuncResultSharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<true>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>} : (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.i64_v1>
    "vhlo.return_v1"(%0) : (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}">}>]>, res_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, sym_visibility = #vhlo.string_v1<"">}
}


// -----// IR Dump After VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}"}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


2025-10-27 21:34:21.939 (  26.787s) [        9C771B80]      module_builder.cc:963      1| MLIR Module shlo:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}"} loc("p0.1")) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64> loc(#loc1)
    return %0 : tensor<4x136xi64> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2025-10-27 21:34:21.939 (  26.787s) [        9C771B80]      module_builder.cc:963      1| MLIR Module shlo_frontend:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>} loc("p0.1")) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64> loc(#loc1)
    return %0 : tensor<4x136xi64> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before TTPopulateArgumentTypes (tt-populate-argument-types) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before ApplyArgumentShardStatusPass (apply-argument-shard-status) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump After ApplyArgumentShardStatusPass (apply-argument-shard-status) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before ConvertXlaSdyToSdyPass (convert-xla-sdy-to-sdy) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump After ConvertXlaSdyToSdyPass (convert-xla-sdy-to-sdy) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before AnalyzeMeshPass (analyze-mesh) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before ApplyShardingConstraintsPass (sdy-apply-sharding-constraints) ('func.func' operation: @main) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before AggressivePropagationPass (sdy-aggressive-propagate) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before ShardingConstraintToReshardPass (sdy-sharding-constraint-to-reshard) ('func.func' operation: @main) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before InsertExplicitReshardsPass (insert-explicit-reshards) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before WrapUnderManualComputationPass (wrap-under-manual-computation) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before ReshardToCollectivesPass (sdy-reshard-to-collectives) ('func.func' operation: @main) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before UpdateGlobalToLocalShapesPass (update-global-to-local-shapes) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before CloseShardingsPass (sdy-close-shardings) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


2025-10-27 21:34:21.942 (  26.791s) [        9C771B80]      module_builder.cc:963      1| MLIR Module shlo_compiler:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]> loc(#loc)
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("p0.1")) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64> loc(#loc1)
    return %0 : tensor<4x136xi64> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
// -----// IR Dump Before ConvertArithToStableHLO (convert-arith-to-stablehlo) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before LegalizeStableHLOCompositeToTTIR (legalize-stablehlo-composite-to-ttir) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before StablehloLegalizeCompositeToCallPass (stablehlo-legalize-composite-to-call) ('func.func' operation: @main) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before ConvertStableHLOToTTIR (convert-stablehlo-to-ttir) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


error: 'func.func' op arg 0 - unknown mesh: @mesh
// -----// IR Dump After ConvertStableHLOToTTIR Failed (convert-stablehlo-to-ttir) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
"builtin.module"() <{sym_name = "ReplicateShardedData.6"}> ({
  "func.func"() <{arg_attrs = [{sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}], function_type = (tensor<4x136xi64>) -> tensor<4x136xi64>, res_attrs = [{mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}], sym_name = "main"}> ({
  ^bb0(%arg0: tensor<4x136xi64>):
    %0 = "stablehlo.custom_call"(%arg0) <{call_target_name = "xla.sdy.FuncResultSharding", has_side_effect = true}> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    "func.return"(%0) : (tensor<4x136xi64>) -> ()
  }) : () -> ()
}) {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 8x4>]>} : () -> ()


2025-10-27 21:34:21.944 (  26.792s) [        9C771B80]      module_builder.cc:712    ERR| Failed to convert from SHLO to TTIR module
2025-10-27 21:34:21.944 (  26.792s) [        9C771B80]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2025-10-27 21:34:21.944 (  26.792s) [        9C771B80]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2025-10-27 21:34:21.944 (  26.792s) [        9C771B80]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]     buffer_instance.cc:484      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-10-27 21:34:21.945 (  26.793s) [        9C771B80]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-10-27 21:34:21.947 (  26.796s) [        9C771B80]     client_instance.cc:616      1| ClientInstance::PJRT_Client_Compile
2025-10-27 21:34:21.947 (  26.796s) [        9C771B80]      module_builder.cc:220      1| ModuleBuilder::buildModule
2025-10-27 21:34:21.947 (  26.796s) [        9C771B80]      module_builder.cc:963      1| MLIR Module vhlo:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<4x136x!vhlo.i64_v1> loc("p0.1")) -> (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) {
    %0 = "vhlo.custom_call_v1"(%arg0) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"xla.sdy.FuncResultSharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<true>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>} : (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.i64_v1> loc(#loc1)
    "vhlo.return_v1"(%0) : (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}">}>]>, res_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
// -----// IR Dump Before VhloToVersionPass (vhlo-to-version) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) {
    %0 = "vhlo.custom_call_v1"(%arg0) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"xla.sdy.FuncResultSharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<true>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>} : (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.i64_v1>
    "vhlo.return_v1"(%0) : (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}">}>]>, res_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, sym_visibility = #vhlo.string_v1<"">}
}


// -----// IR Dump Before VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) {
    %0 = "vhlo.custom_call_v1"(%arg0) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"xla.sdy.FuncResultSharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<true>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>} : (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x136x!vhlo.i64_v1>
    "vhlo.return_v1"(%0) : (!vhlo.tensor_v1<4x136x!vhlo.i64_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}">}>]>, res_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, sym_visibility = #vhlo.string_v1<"">}
}


// -----// IR Dump After VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}"}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


2025-10-27 21:34:21.948 (  26.797s) [        9C771B80]      module_builder.cc:963      1| MLIR Module shlo:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}"} loc("p0.1")) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64> loc(#loc1)
    return %0 : tensor<4x136xi64> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2025-10-27 21:34:21.948 (  26.797s) [        9C771B80]      module_builder.cc:963      1| MLIR Module shlo_frontend:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>} loc("p0.1")) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64> loc(#loc1)
    return %0 : tensor<4x136xi64> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before TTPopulateArgumentTypes (tt-populate-argument-types) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before ApplyArgumentShardStatusPass (apply-argument-shard-status) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump After ApplyArgumentShardStatusPass (apply-argument-shard-status) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before ConvertXlaSdyToSdyPass (convert-xla-sdy-to-sdy) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=8, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<4x136xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,8]<=[8,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump After ConvertXlaSdyToSdyPass (convert-xla-sdy-to-sdy) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before AnalyzeMeshPass (analyze-mesh) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before ApplyShardingConstraintsPass (sdy-apply-sharding-constraints) ('func.func' operation: @main) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before AggressivePropagationPass (sdy-aggressive-propagate) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before ShardingConstraintToReshardPass (sdy-sharding-constraint-to-reshard) ('func.func' operation: @main) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before InsertExplicitReshardsPass (insert-explicit-reshards) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before WrapUnderManualComputationPass (wrap-under-manual-computation) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before ReshardToCollectivesPass (sdy-reshard-to-collectives) ('func.func' operation: @main) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before UpdateGlobalToLocalShapesPass (update-global-to-local-shapes) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before CloseShardingsPass (sdy-close-shardings) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


2025-10-27 21:34:21.951 (  26.800s) [        9C771B80]      module_builder.cc:963      1| MLIR Module shlo_compiler:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]> loc(#loc)
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("p0.1")) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64> loc(#loc1)
    return %0 : tensor<4x136xi64> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
// -----// IR Dump Before ConvertArithToStableHLO (convert-arith-to-stablehlo) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before LegalizeStableHLOCompositeToTTIR (legalize-stablehlo-composite-to-ttir) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before StablehloLegalizeCompositeToCallPass (stablehlo-legalize-composite-to-call) ('func.func' operation: @main) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


// -----// IR Dump Before ConvertStableHLOToTTIR (convert-stablehlo-to-ttir) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=8, "_axis_1"=4]>
  func.func @main(%arg0: tensor<4x136xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<4x136xi64> {mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    return %0 : tensor<4x136xi64>
  }
}


error: 'func.func' op arg 0 - unknown mesh: @mesh
// -----// IR Dump After ConvertStableHLOToTTIR Failed (convert-stablehlo-to-ttir) ('builtin.module' operation: @ReplicateShardedData.6) //----- //
"builtin.module"() <{sym_name = "ReplicateShardedData.6"}> ({
  "func.func"() <{arg_attrs = [{sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1"}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}], function_type = (tensor<4x136xi64>) -> tensor<4x136xi64>, res_attrs = [{mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}], sym_name = "main"}> ({
  ^bb0(%arg0: tensor<4x136xi64>):
    %0 = "stablehlo.custom_call"(%arg0) <{call_target_name = "xla.sdy.FuncResultSharding", has_side_effect = true}> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<4x136xi64>) -> tensor<4x136xi64>
    "func.return"(%0) : (tensor<4x136xi64>) -> ()
  }) : () -> ()
}) {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 8x4>]>} : () -> ()


2025-10-27 21:34:21.953 (  26.801s) [        9C771B80]      module_builder.cc:712    ERR| Failed to convert from SHLO to TTIR module
2025-10-27 21:34:21.953 (  26.801s) [        9C771B80]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2025-10-27 21:34:21.953 (  26.801s) [        9C771B80]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2025-10-27 21:34:21.953 (  26.801s) [        9C771B80]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
Running tests/runner/test_models.py::test_all_models[llama/causal_lm/pytorch-llama_3_1_70b-tensor_parallel-full-inference] - pytorch_llama_causal_lm_llama_3_1_70b_nlp_causal_lm_huggingface
Created device mesh: (8, 4) with 32 devices.
FAILED2025-10-27 21:34:30.822 | DEBUG    | tests.conftest:cleanup_cache:343 - Cleaned up cache directory: /root/.cache/huggingface


=================================== FAILURES ===================================
_ test_all_models[llama/causal_lm/pytorch-llama_3_1_70b-tensor_parallel-full-inference] _

test_entry = ModelTestEntry(path='/root/tt-xla/third_party/tt_forge_models/llama/causal_lm/pytorch/loader.py', variant_info=(<ModelVariant.LLAMA_3_1_70B: 'llama_3_1_70b'>, <class 'tt-forge-models.llama.causal_lm.pytorch.loader.ModelLoader'>))
run_mode = <RunMode.INFERENCE: 'inference'>, op_by_op = None
parallelism = <Parallelism.TENSOR_PARALLEL: 'tensor_parallel'>
record_property = <function record_property.<locals>.append_property at 0x7fd5eb4df6a0>
test_metadata = <tests.runner.test_utils.ModelTestConfig object at 0x7fd5ebfe8590>
request = <FixtureRequest for <Function test_all_models[llama/causal_lm/pytorch-llama_3_1_70b-tensor_parallel-full-inference]>>
capteesys = <_pytest.capture.CaptureFixture object at 0x7fd5eb37fcd0>

    @pytest.mark.model_test
    @pytest.mark.no_auto_properties
    @pytest.mark.parametrize(
        "run_mode",
        [
            pytest.param(RunMode.INFERENCE, id="inference", marks=pytest.mark.inference),
            pytest.param(RunMode.TRAINING, id="training", marks=pytest.mark.training),
        ],
    )
    @pytest.mark.parametrize(
        "op_by_op",
        [None],
        ids=["full"],  # When op-by-op flow is required/supported, add here.
    )
    @pytest.mark.parametrize(
        "parallelism",
        [
            pytest.param(
                Parallelism.SINGLE_DEVICE,
                id="single_device",
                marks=pytest.mark.single_device,
            ),
            pytest.param(
                Parallelism.DATA_PARALLEL,
                id="data_parallel",
                marks=pytest.mark.data_parallel,
            ),
            pytest.param(
                Parallelism.TENSOR_PARALLEL,
                id="tensor_parallel",
                marks=pytest.mark.tensor_parallel,
            ),
        ],
    )
    @pytest.mark.parametrize(
        "test_entry",
        test_entries,
        ids=create_test_id_generator(MODELS_ROOT),
    )
    def test_all_models(
        test_entry,
        run_mode,
        op_by_op,
        parallelism,
        record_property,
        test_metadata,
        request,
        capteesys,
    ):
    
        loader_path = test_entry.path
        variant, ModelLoader = test_entry.variant_info
    
        # Ensure per-model requirements are installed, and roll back after the test
        with RequirementsManager.for_loader(loader_path):
    
            # Get the model loader and model info from desired model, variant.
            loader = ModelLoader(variant=variant)
            model_info = ModelLoader.get_model_info(variant=variant)
            print(f"Running {request.node.nodeid} - {model_info.name}", flush=True)
    
            succeeded = False
            comparison_result = None
            tester = None
    
            try:
                # Only run the actual model test if not marked for skip. The record properties
                # function in finally block will always be called and handles the pytest.skip.
                if test_metadata.status != ModelTestStatus.NOT_SUPPORTED_SKIP:
                    tester = DynamicTorchModelTester(
                        run_mode,
                        loader=loader,
                        comparison_config=test_metadata.to_comparison_config(),
                        parallelism=parallelism,
                    )
    
>                   comparison_result = tester.test()
                                        ^^^^^^^^^^^^^

tests/runner/test_models.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/infra/testers/single_chip/model/model_tester.py:145: in test
    return self._test_inference()
           ^^^^^^^^^^^^^^^^^^^^^^
tests/infra/testers/single_chip/model/model_tester.py:158: in _test_inference
    tt_res = self._run_on_tt_device(self._workload)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tests/infra/testers/single_chip/model/model_tester.py:168: in _run_on_tt_device
    return self._device_runner.run_on_tt_device(compiled_workload)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tests/infra/runners/device_runner.py:30: in run_on_tt_device
    return self.run_on_device(workload, DeviceType.TT, device_num)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tests/infra/runners/device_runner.py:40: in run_on_device
    return self._run_on_device(device_workload, device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tests/infra/runners/torch_device_runner.py:79: in _run_on_device
    return workload.execute()
           ^^^^^^^^^^^^^^^^^^
tests/infra/workloads/workload.py:68: in execute
    return self.model(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1749: in _wrapped_call_impl
    return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:655: in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.11/site-packages/transformers/utils/generic.py:953: in wrapper
    @wraps(func)
venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:838: in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tt_torch.backend.backend.XLAExecutor object at 0x7fd53e54ea50>
args = (<[RuntimeError('Error code: 13') raised in repr()] Tensor object at 0x7fd53e74eff0>, <[RuntimeError('Error code: 13') raised in repr()] Tensor object at 0x7fd53e74eab0>)
output = (<[RuntimeError('Check failed: data()->tensor_data: ') raised in repr()] Tensor object at 0x7fd53c508170>, <[RuntimeEr...fd53e2d5f10>, <[RuntimeError('Check failed: data()->tensor_data: ') raised in repr()] Tensor object at 0x7fd53c560050>)
gm_has_functional_output_kind = True
el = OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='view_31'), target=None)

    def __call__(self, *args):
    
        if self.inject_metadata:
            # MetadataDispatchMode intercepts tensor operations via TorchDispatchMode and
            # attaches FX metadata (module hierarchy, file, line) to XLA tensors.
            with MetadataDispatchMode(self.node_info):
                output = self.module(*args)
        else:
            output = self.module(*args)
    
        gm_has_functional_output_kind: bool = True
    
        for el in self.signature.output_specs:
            if el.kind is not OutputKind.USER_OUTPUT:
                gm_has_functional_output_kind = False
                break
    
        if gm_has_functional_output_kind:
            # This tells torch-xla to cut the graph at only what is required to
            # compute all tensors in the `output` list.
>           torch_xla._XLAC._xla_sync_multi(list(output), self.devices, wait=False)
E           ValueError: Error code: 13

python_package/tt_torch/backend/backend.py:117: ValueError
=============================== warnings summary ===============================
<frozen importlib._bootstrap>:241
  <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute

<frozen importlib._bootstrap>:241
  <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED tests/runner/test_models.py::test_all_models[llama/causal_lm/pytorch-llama_3_1_70b-tensor_parallel-full-inference] - ValueError: Error code: 13
================== 1 failed, 2 warnings in 164.70s (0:02:44) ===================
sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:33.810 (  38.658s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.386 (  39.234s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.386 (  39.234s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.386 (  39.235s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.386 (  39.235s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.387 (  39.235s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.387 (  39.235s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.387 (  39.235s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.387 (  39.235s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.387 (  39.236s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.387 (  39.236s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.387 (  39.236s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.387 (  39.236s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.387 (  39.236s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.388 (  39.236s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.388 (  39.236s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.388 (  39.236s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.388 (  39.236s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.388 (  39.236s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.388 (  39.236s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.388 (  39.237s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.388 (  39.237s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.388 (  39.237s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.388 (  39.237s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.389 (  39.237s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.389 (  39.237s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.389 (  39.237s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.389 (  39.237s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.389 (  39.237s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.389 (  39.237s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.389 (  39.238s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.389 (  39.238s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.389 (  39.238s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.389 (  39.238s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.389 (  39.238s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.390 (  39.238s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.390 (  39.238s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.390 (  39.238s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.390 (  39.238s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.390 (  39.238s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.390 (  39.238s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.390 (  39.238s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.390 (  39.239s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.390 (  39.239s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.390 (  39.239s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.390 (  39.239s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.390 (  39.239s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.390 (  39.239s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.391 (  39.239s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.391 (  39.239s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.391 (  39.239s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.391 (  39.239s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.391 (  39.239s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.391 (  39.239s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.391 (  39.239s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.391 (  39.239s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.391 (  39.239s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.391 (  39.240s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.391 (  39.240s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.391 (  39.240s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.391 (  39.240s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.391 (  39.240s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.391 (  39.240s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.392 (  39.240s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.392 (  39.240s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.392 (  39.240s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.392 (  39.240s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.392 (  39.240s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.392 (  39.240s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.392 (  39.240s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.392 (  39.240s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.392 (  39.240s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.392 (  39.240s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.392 (  39.241s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.392 (  39.241s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.392 (  39.241s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.392 (  39.241s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.392 (  39.241s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.393 (  39.241s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.393 (  39.241s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.393 (  39.241s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.393 (  39.241s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.393 (  39.241s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.393 (  39.241s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.393 (  39.241s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.393 (  39.241s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.393 (  39.241s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.393 (  39.241s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.393 (  39.242s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.393 (  39.242s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.393 (  39.242s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.393 (  39.242s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.393 (  39.242s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.393 (  39.242s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.394 (  39.242s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.394 (  39.242s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.394 (  39.242s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.394 (  39.242s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.394 (  39.242s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.394 (  39.242s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.394 (  39.242s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.394 (  39.242s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.394 (  39.242s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.394 (  39.243s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.394 (  39.243s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.394 (  39.243s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.394 (  39.243s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.394 (  39.243s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.394 (  39.243s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.394 (  39.243s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.394 (  39.243s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.395 (  39.243s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.395 (  39.243s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.395 (  39.243s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.395 (  39.243s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.395 (  39.243s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.395 (  39.243s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.395 (  39.243s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.395 (  39.243s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.395 (  39.243s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.395 (  39.243s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.395 (  39.244s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.395 (  39.244s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.395 (  39.244s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.395 (  39.244s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.395 (  39.244s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.395 (  39.244s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.395 (  39.244s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.395 (  39.244s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.396 (  39.244s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.466 (  39.314s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.544 (  39.392s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.616 (  39.464s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.685 (  39.533s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.753 (  39.602s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.826 (  39.675s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.906 (  39.755s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:34.976 (  39.825s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:35.039 (  39.888s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:35.110 (  39.958s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:35.186 (  40.034s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:35.255 (  40.103s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:35.322 (  40.171s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:35.393 (  40.241s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:35.465 (  40.313s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:35.536 (  40.385s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:35.605 (  40.454s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:35.677 (  40.525s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:35.748 (  40.597s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:35.817 (  40.665s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:35.880 (  40.728s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:35.950 (  40.798s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.020 (  40.868s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.090 (  40.939s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.159 (  41.008s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.230 (  41.079s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.301 (  41.150s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.370 (  41.219s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.448 (  41.296s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.517 (  41.365s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.589 (  41.437s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.657 (  41.506s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.658 (  41.506s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.658 (  41.506s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.658 (  41.507s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.658 (  41.507s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.658 (  41.507s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.659 (  41.507s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.659 (  41.507s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.659 (  41.507s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.659 (  41.507s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.659 (  41.508s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.659 (  41.508s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.659 (  41.508s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.660 (  41.508s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.660 (  41.508s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.660 (  41.508s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.660 (  41.508s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.660 (  41.508s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.660 (  41.508s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.660 (  41.509s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.660 (  41.509s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.660 (  41.509s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.661 (  41.509s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.661 (  41.509s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.661 (  41.509s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.661 (  41.509s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.661 (  41.509s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.661 (  41.509s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.661 (  41.509s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.661 (  41.510s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.661 (  41.510s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.661 (  41.510s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.661 (  41.510s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.661 (  41.510s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.662 (  41.510s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.662 (  41.510s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.662 (  41.510s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.662 (  41.510s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.662 (  41.510s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.662 (  41.510s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.662 (  41.510s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.662 (  41.510s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.662 (  41.510s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.662 (  41.510s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.662 (  41.511s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.662 (  41.511s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.662 (  41.511s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.662 (  41.511s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.662 (  41.511s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.662 (  41.511s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.662 (  41.511s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.662 (  41.511s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.663 (  41.511s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.663 (  41.511s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.663 (  41.511s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.663 (  41.511s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.663 (  41.511s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.663 (  41.511s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.663 (  41.511s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.663 (  41.511s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.663 (  41.511s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.663 (  41.512s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.663 (  41.512s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.663 (  41.512s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.663 (  41.512s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.663 (  41.512s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.663 (  41.512s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.664 (  41.512s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.664 (  41.512s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.664 (  41.512s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.664 (  41.512s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.664 (  41.512s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.664 (  41.512s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.664 (  41.512s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.664 (  41.513s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.664 (  41.513s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.664 (  41.513s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.664 (  41.513s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.665 (  41.513s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.665 (  41.513s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.665 (  41.513s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.665 (  41.513s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.665 (  41.513s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.665 (  41.513s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.665 (  41.513s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.665 (  41.514s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.665 (  41.514s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.665 (  41.514s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.665 (  41.514s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.665 (  41.514s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.666 (  41.514s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.666 (  41.514s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.666 (  41.514s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.666 (  41.514s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.666 (  41.514s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.666 (  41.514s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.666 (  41.515s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.666 (  41.515s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.666 (  41.515s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.666 (  41.515s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.667 (  41.515s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.667 (  41.515s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.667 (  41.515s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.667 (  41.515s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.667 (  41.515s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.667 (  41.515s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.667 (  41.515s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.667 (  41.516s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.667 (  41.516s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.667 (  41.516s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.667 (  41.516s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.668 (  41.516s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.668 (  41.516s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.668 (  41.516s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.668 (  41.516s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.668 (  41.516s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.668 (  41.516s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.668 (  41.516s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.668 (  41.516s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.668 (  41.517s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.668 (  41.517s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.668 (  41.517s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.668 (  41.517s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.668 (  41.517s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.669 (  41.517s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.669 (  41.517s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.669 (  41.517s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.669 (  41.517s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.669 (  41.517s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.669 (  41.517s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.669 (  41.517s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.669 (  41.518s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.669 (  41.518s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.670 (  41.518s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.670 (  41.518s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.670 (  41.518s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.670 (  41.518s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.670 (  41.518s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.670 (  41.518s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.670 (  41.518s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.670 (  41.519s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.670 (  41.519s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.670 (  41.519s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.670 (  41.519s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.671 (  41.519s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.671 (  41.519s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.671 (  41.519s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.671 (  41.519s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.671 (  41.519s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.671 (  41.519s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.671 (  41.519s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.671 (  41.519s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.671 (  41.520s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.671 (  41.520s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.671 (  41.520s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.671 (  41.520s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.672 (  41.520s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.672 (  41.520s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.672 (  41.520s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.672 (  41.520s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.672 (  41.520s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.672 (  41.520s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.672 (  41.520s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.672 (  41.521s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.672 (  41.521s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.672 (  41.521s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.672 (  41.521s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.672 (  41.521s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.673 (  41.521s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.673 (  41.521s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.673 (  41.521s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.673 (  41.521s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.673 (  41.521s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.673 (  41.521s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.673 (  41.522s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.673 (  41.522s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.673 (  41.522s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.673 (  41.522s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.674 (  41.522s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.674 (  41.522s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.674 (  41.522s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.674 (  41.522s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.674 (  41.522s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.674 (  41.522s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.674 (  41.523s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.674 (  41.523s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.674 (  41.523s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.674 (  41.523s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.674 (  41.523s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.675 (  41.523s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.675 (  41.523s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.675 (  41.523s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.675 (  41.523s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.675 (  41.523s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.675 (  41.523s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.675 (  41.524s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.675 (  41.524s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.675 (  41.524s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.675 (  41.524s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.676 (  41.524s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.676 (  41.524s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.676 (  41.524s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.676 (  41.524s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.676 (  41.524s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.676 (  41.524s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.676 (  41.524s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.676 (  41.524s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.676 (  41.525s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.676 (  41.525s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.676 (  41.525s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.676 (  41.525s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.676 (  41.525s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.676 (  41.525s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.677 (  41.525s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.677 (  41.525s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.677 (  41.525s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.677 (  41.525s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.677 (  41.525s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.677 (  41.525s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.677 (  41.525s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.677 (  41.526s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.677 (  41.526s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.677 (  41.526s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.677 (  41.526s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.711 (  41.560s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.716 (  41.565s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.722 (  41.570s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.727 (  41.575s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.732 (  41.580s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.737 (  41.585s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.742 (  41.590s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.746 (  41.594s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.751 (  41.599s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.756 (  41.604s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.761 (  41.609s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.766 (  41.614s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.771 (  41.620s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.777 (  41.625s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.782 (  41.630s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.787 (  41.636s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.792 (  41.640s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.798 (  41.646s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.803 (  41.651s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.808 (  41.656s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.813 (  41.661s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.818 (  41.667s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.823 (  41.672s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.828 (  41.676s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.831 (  41.680s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.836 (  41.685s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.839 (  41.688s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.843 (  41.691s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.849 (  41.697s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.855 (  41.703s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.859 (  41.708s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
2025-10-27 21:34:36.864 (  41.713s) [        9C771B80]     buffer_instance.cc:402      1| BufferInstance::PJRT_Buffer_Destroy
