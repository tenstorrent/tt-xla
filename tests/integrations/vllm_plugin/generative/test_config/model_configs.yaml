# SPDX-FileCopyrightText: (c) 2025 Tenstorrent AI ULC
#
# SPDX-License-Identifier: Apache-2.0

# vLLM generative model test configurations.
# Defaults are applied in test_config/__init__.py (DEFAULT_GENERATIVE_CONFIG).
# Only "model" is required. "marks" default to [single_device]; add marks only when overriding.
# "status" defaults to "unspecified" when omitted.

model_configs:
  allam_causal_lm_pytorch_allam_7b_instruct:
    model: ALLaM-AI/ALLaM-7B-Instruct-preview
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  deepcogito_pytorch_v1_preview_llama_3b:
    model: deepcogito/cogito-v1-preview-llama-3B
    status: "expected_passing"
  deepseek_deepseek_coder_pytorch_1_3b_instruct:
    model: deepseek-ai/deepseek-coder-1.3b-instruct
    status: "expected_passing"
  falcon-7b:
    model: tiiuae/falcon-7b
    prompts:
    - The best way to learn
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  falcon_pytorch_tiiuae_falcon3_10b_base:
    model: tiiuae/Falcon3-10B-Base
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  falcon_pytorch_tiiuae_falcon3_1b_base:
    model: tiiuae/Falcon3-1B-Base
    status: "expected_passing"
  falcon_pytorch_tiiuae_falcon3_3b_base:
    model: tiiuae/Falcon3-3B-Base
    status: "expected_passing"
  falcon_pytorch_tiiuae_falcon3_7b_base:
    model: tiiuae/Falcon3-7B-Base
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  falcon_pytorch_tiiuae_falcon3_mamba_7b_base:
    model: tiiuae/Falcon3-Mamba-7B-Base
    status: "known_failure_xfail"
    reason: "ZeroDivisionError: integer division or modulo by zero"
  falcon_pytorch_tiiuae_falcon_7b_instruct:
    model: tiiuae/falcon-7b-instruct
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  fuyu_pytorch_adept_fuyu_8b:
    model: adept/fuyu-8b
    status: "known_failure_xfail"
    reason: "Dynamo failed to run FX node with fake tensors"
  gemma_codegemma_pytorch_google_codegemma_2b:
    model: google/codegemma-2b
    max_model_len: 256
    max_num_batched_tokens: 256
    status: "known_failure_xfail"
    reason: "Unknown failure"
  gemma_pytorch_google_gemma_1_1_2b_it:
    model: google/gemma-1.1-2b-it
    status: "known_failure_xfail"
    reason: "Unknown failure"
  gemma_pytorch_google_gemma_1_1_7b_it:
    model: google/gemma-1.1-7b-it
    status: "known_failure_xfail"
    reason: "Unknown failure"
  gemma_pytorch_google_gemma_2_2b_it:
    model: google/gemma-2-2b-it
    status: "known_failure_xfail"
    reason: "Unknown failure"
  gemma_pytorch_google_gemma_2_9b_it:
    model: google/gemma-2-9b-it
    status: "known_failure_xfail"
    reason: "Unknown failure"
  gemma_pytorch_google_gemma_2b:
    model: google/gemma-2b
    max_model_len: 256
    max_num_batched_tokens: 256
    status: "known_failure_xfail"
    reason: "Unknown failure"
  gemma_text_translation_pytorch_translategemma_4b_it:
    model: google/translategemma-4b-it
    status: "known_failure_xfail"
    reason: "Unknown failure"
  gpt2_pytorch_gpt2:
    model: gpt2
    max_model_len: 256
    max_num_batched_tokens: 256
    status: "known_failure_xfail"
    reason: "'GPT2LMHeadModel' object has no attribute 'model'"
  huggyllama_pytorch_llama_7b:
    model: huggyllama/llama-7b
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  llama3-3b:
    model: meta-llama/Llama-3.2-3B
    prompts:
    - I like taking walks in the
    status: "expected_passing"
  llama_causal_lm_pytorch_huggyllama_7b:
    model: huggyllama/llama-7b
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  llama_causal_lm_pytorch_llama_3_1_8b:
    model: meta-llama/Llama-3.1-8B
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  llama_causal_lm_pytorch_llama_3_1_8b_instruct:
    model: meta-llama/Llama-3.1-8B-Instruct
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  llama_causal_lm_pytorch_llama_3_2_1b:
    model: meta-llama/Llama-3.2-1B
    status: "expected_passing"
  llama_causal_lm_pytorch_llama_3_2_1b_instruct:
    model: meta-llama/Llama-3.2-1B-Instruct
    status: "expected_passing"
  llama_causal_lm_pytorch_llama_3_2_3b:
    model: meta-llama/Llama-3.2-3B
    status: "expected_passing"
  llama_causal_lm_pytorch_llama_3_2_3b_instruct:
    model: meta-llama/Llama-3.2-3B-Instruct
    status: "expected_passing"
  llama_causal_lm_pytorch_llama_3_8b:
    model: meta-llama/Meta-Llama-3-8B
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  llama_causal_lm_pytorch_llama_3_8b_instruct:
    model: meta-llama/Meta-Llama-3-8B-Instruct
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  llama_causal_lm_pytorch_tinyllama_v1_1:
    model: TinyLlama/TinyLlama_v1.1
    status: "expected_passing"
  mamba_pytorch_mamba_1_4b_hf:
    model: state-spaces/mamba-1.4b-hf
    status: "known_failure_xfail"
    reason: "ZeroDivisionError: integer division or modulo by zero"
  mamba_pytorch_mamba_2_8b_hf:
    model: state-spaces/mamba-2.8b-hf
    status: "known_failure_xfail"
    reason: "ZeroDivisionError: integer division or modulo by zero"
  mamba_pytorch_mamba_370m_hf:
    model: state-spaces/mamba-370m-hf
    status: "known_failure_xfail"
    reason: "ZeroDivisionError: integer division or modulo by zero"
  mamba_pytorch_mamba_790m_hf:
    model: state-spaces/mamba-790m-hf
    status: "known_failure_xfail"
    reason: "ZeroDivisionError: integer division or modulo by zero"
  mistral-7b:
    model: mistralai/Mistral-7B-v0.1
    gpu_memory_utilization: 0.001
    max_model_len: 64
    max_num_batched_tokens: 64
    prompts:
    - The future of AI is
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  mistral_pytorch_7b_instruct_v03:
    model: mistralai/Mistral-7B-Instruct-v0.3
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  mistral_pytorch_ministral_3b_instruct:
    model: ministral/Ministral-3b-instruct
    status: "known_failure_xfail"
    reason: "L1 Out of Memory"
  mistral_pytorch_mistral_nemo_instruct_2407:
    model: mistralai/Mistral-Nemo-Instruct-2407
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  opt-125m:
    model: facebook/opt-125m
    gpu_memory_utilization: 0.001
    status: "expected_passing"
  opt-125m-multibatch:
    model: facebook/opt-125m
    gpu_memory_utilization: 0.001
    max_num_batched_tokens: 256
    max_num_seqs: 2
    prompts:
    - Hello, my name is
    - Paris is the capital of
    status: "expected_passing"
  opt_causal_lm_pytorch_facebook_opt_125m:
    model: facebook/opt-125m
    max_model_len: 256
    max_num_batched_tokens: 256
    status: "expected_passing"
  opt_causal_lm_pytorch_facebook_opt_1_3b:
    model: facebook/opt-1.3b
    gpu_memory_utilization: 0.005
    max_model_len: 256
    max_num_batched_tokens: 256
    status: "expected_passing"
  opt_causal_lm_pytorch_facebook_opt_350m:
    model: facebook/opt-350m
    max_model_len: 256
    max_num_batched_tokens: 256
    status: "known_failure_xfail"
    reason: "RuntimeError: a and b must have same reduction dim, but got [1, 1024] X [512, 50304]."
  opt_qa_pytorch_facebook_opt_125m:
    model: facebook/opt-125m
    max_model_len: 32
    max_num_batched_tokens: 32
    status: "expected_passing"
  opt_qa_pytorch_facebook_opt_1_3b:
    model: facebook/opt-1.3b
    max_model_len: 32
    max_num_batched_tokens: 32
    status: "expected_passing"
  opt_qa_pytorch_facebook_opt_350m:
    model: facebook/opt-350m
    max_model_len: 32
    max_num_batched_tokens: 32
    status: "known_failure_xfail"
    reason: "RuntimeError: a and b must have same reduction dim, but got [1, 1024] X [512, 50304]."
  phi-2:
    model: microsoft/phi-2
    gpu_memory_utilization: 0.004
    prompts:
    - Write a poem about
    status: "expected_passing"
  phi1_5_causal_lm_pytorch_microsoft_phi_1_5:
    model: microsoft/phi-1_5
    gpu_memory_utilization: 0.005
    max_model_len: 256
    max_num_batched_tokens: 256
    status: "expected_passing"
  phi1_causal_lm_pytorch_microsoft_phi_1:
    model: microsoft/phi-1
    gpu_memory_utilization: 0.005
    max_model_len: 256
    max_num_batched_tokens: 256
    status: "expected_passing"
  phi2_causal_lm_pytorch_microsoft_phi_2:
    model: microsoft/phi-2
    gpu_memory_utilization: 0.004
    status: "expected_passing"
  phi2_causal_lm_pytorch_microsoft_phi_2_pytdml:
    model: microsoft/phi-2-pytdml
    gpu_memory_utilization: 0.004
    status: "expected_passing"
  phi3_causal_lm_pytorch_microsoft_phi_3_mini_128k_instruct:
    model: microsoft/Phi-3-mini-128k-instruct
    status: "known_failure_xfail"
    reason: "RuntimeError: Check failed: casted->xla_shape().dimensions_size() <= 1 (2 vs. 1)"
  phi3_causal_lm_pytorch_microsoft_phi_3_mini_4k_instruct:
    model: microsoft/Phi-3-mini-4k-instruct
    gpu_memory_utilization: 0.006
    status: "expected_passing"
  phi3_phi_3_5_pytorch_mini_instruct:
    model: microsoft/Phi-3.5-mini-instruct
    status: "known_failure_xfail"
    reason: "RuntimeError: Check failed: casted->xla_shape().dimensions_size() <= 1 (2 vs. 1)"
  phi4_causal_lm_pytorch_microsoft_phi_4:
    model: microsoft/phi-4
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  qwen2-0.5b:
    model: Qwen/Qwen2-0.5B
    gpu_memory_utilization: 0.001
    prompts:
    - The capital of China is
    status: "expected_passing"
  qwen_1_5_causal_lm_pytorch_0_5b:
    model: Qwen/Qwen1.5-0.5B
    status: "expected_passing"
  qwen_1_5_causal_lm_pytorch_0_5b_chat:
    model: Qwen/Qwen1.5-0.5B-Chat
    max_model_len: 512
    max_num_batched_tokens: 256
    status: "known_failure_xfail"
    reason: "The max_num_batched_tokens 256 must be larger than or equal to max_model_len (512) * max_num_seqs (1)"
  qwen_2_5_causal_lm_pytorch_0_5b:
    model: Qwen/Qwen2.5-0.5B
    status: "expected_passing"
  qwen_2_5_causal_lm_pytorch_0_5b_instruct:
    model: Qwen/Qwen2.5-0.5B-Instruct
    status: "expected_passing"
  qwen_2_5_causal_lm_pytorch_14b_instruct:
    model: Qwen/Qwen2.5-14B-Instruct
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  qwen_2_5_causal_lm_pytorch_1_5b:
    model: Qwen/Qwen2.5-1.5B
    status: "expected_passing"
  qwen_2_5_causal_lm_pytorch_1_5b_instruct:
    model: Qwen/Qwen2.5-1.5B-Instruct
    status: "expected_passing"
  qwen_2_5_causal_lm_pytorch_3b:
    model: Qwen/Qwen2.5-3B
    status: "expected_passing"
  qwen_2_5_causal_lm_pytorch_3b_instruct:
    model: Qwen/Qwen2.5-3B-Instruct
    status: "expected_passing"
  qwen_2_5_coder_pytorch_0_5b:
    model: Qwen/Qwen2.5-Coder-0.5B
    status: "expected_passing"
  qwen_2_5_coder_pytorch_1_5b:
    model: Qwen/Qwen2.5-Coder-1.5B
    status: "expected_passing"
  qwen_2_5_coder_pytorch_1_5b_instruct:
    model: Qwen/Qwen2.5-Coder-1.5B-Instruct
    status: "expected_passing"
  qwen_2_5_coder_pytorch_3b:
    model: Qwen/Qwen2.5-Coder-3B
    status: "expected_passing"
  qwen_2_5_coder_pytorch_3b_instruct:
    model: Qwen/Qwen2.5-Coder-3B-Instruct
    status: "expected_passing"
  qwen_3_causal_lm_pytorch_0_6b:
    model: Qwen/Qwen3-0.6B
    status: "expected_passing"
  qwen_3_causal_lm_pytorch_14b:
    model: Qwen/Qwen3-14B
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  qwen_3_causal_lm_pytorch_1_7b:
    model: Qwen/Qwen3-1.7B
    status: "expected_passing"
  qwen_3_causal_lm_pytorch_4b:
    model: Qwen/Qwen3-4B
    status: "expected_passing"
  qwen_3_causal_lm_pytorch_8b:
    model: Qwen/Qwen3-8B
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  unet_for_conditional_generation_pytorch_base:
    model: stabilityai/stable-diffusion-xl-base-1.0
    status: "known_failure_xfail"
    reason: "Unknown failure"
  vllm_sweep_arctic:
    model: Snowflake/snowflake-arctic-base
    status: "known_failure_xfail"
    reason: "ImportError: cannot import name 'fused_experts' from 'vllm.model_executor.layers.fused_moe'"
  vllm_sweep_aquila:
    model: BAAI/Aquila-7B
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  vllm_sweep_aquila_chat:
    model: BAAI/AquilaChat-7B
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  vllm_sweep_baichuan:
    model: baichuan-inc/Baichuan-7B
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  vllm_sweep_bloom:
    model: bigscience/bloom-560m
    status: "known_failure_xfail"
    reason: "ValueError: TT backend only supports V1."
  vllm_sweep_bart:
    model: facebook/bart-base
    status: "known_failure_xfail"
    reason: "ValueError: TT backend only supports V1."
  vllm_sweep_chat_glm2:
    model: THUDM/chatglm2-6b
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  vllm_sweep_chat_glm3:
    model: THUDM/chatglm3-6b
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  vllm_sweep_cohere:
    model: CohereForAI/c4ai-command-r-v01
    status: "known_failure_xfail"
    reason: "Unknown failure"
  vllm_sweep_dbrx:
    model: Undi95/dbrx-base
    status: "known_failure_xfail"
    reason: "Unknown failure"
  vllm_sweep_decilm:
    model: Deci/DeciLM-7B
    max_model_len: 64
    max_num_batched_tokens: 64
    status: "known_failure_xfail"
    reason: "AttributeError: 'DeciLMConfig' object has no attribute 'block_configs'"
  vllm_sweep_deepseek:
    model: deepseek-ai/deepseek-llm-7b-chat
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  # vllm_sweep_deepseekcoder:
  #   model: deepseek-ai/deepseek-coder-1.3b-instruct
  #   max_model_len: 256
  #   max_num_batched_tokens: 256
  #   gpu_memory_utilization: 0.005
  #   marks: [vllm_sweep]
  vllm_sweep_deepseekv2:
    model: deepseek-ai/DeepSeek-V2
    max_model_len: 64
    max_num_batched_tokens: 64
    status: "known_failure_xfail"
    reason: "TypeError: TTAttentionBackendImpl.__init__() got an unexpected keyword argument 'q_lora_rank'"
  vllm_sweep_deepseekv3:
    model: deepseek-ai/DeepSeek-V3
    max_model_len: 64
    max_num_batched_tokens: 64
    status: "known_failure_xfail"
    reason: "ValueError: TT backend only supports V1."
  vllm_sweep_exaone:
    model: LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct
    status: "known_failure_xfail"
    reason: "Gated huggingface model" # Need to agree to terms to access
  # vllm_sweep_falcon:
  #   model: tiiuae/falcon-7b
  #   marks: [vllm_sweep]
  # vllm_sweep_falconmamba:
  #   model: tiiuae/falcon-mamba-7b
  #   marks: [vllm_sweep]
  # vllm_sweep_gemma:
  #   model: google/gemma-2b
  #   gpu_memory_utilization: 0.001
  #   marks: [vllm_sweep]
  # vllm_sweep_gemma2:
  #   model: google/gemma-2-2b
  #   marks: [vllm_sweep]
  vllm_sweep_glm:
    model: THUDM/glm-4-9b-chat-hf
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  vllm_sweep_gpt2:
    model: gpt2
    status: "known_failure_xfail"
    reason: "ValueError: TT backend only supports V1."
  vllm_sweep_gptbigcode: # TEST NEXT locally
    model: bigcode/starcoder
    status: "known_failure_xfail"
    reason: "Gated huggingface model" # Need to agree to terms to access
  vllm_sweep_gptj:
    model: EleutherAI/gpt-j-6b
    status: "known_failure_xfail"
    reason: "'GPTJForCausalLM' object has no attribute 'model'"
  vllm_sweep_gptneox:
    model: EleutherAI/pythia-70m
    status: "known_failure_xfail"
    reason: "AttributeError: 'GPTNeoXForCausalLM' object has no attribute 'model'"
  vllm_sweep_granite:
    model: ibm-granite/granite-3.0-2b-base
    status: "expected_passing"
  vllm_sweep_granitemoe:
    model: ibm-granite/granite-3.0-1b-a400m-base
    status: "known_failure_xfail"
    reason: "ValueError: TT backend only supports V1."
  vllm_sweep_gritlm:
    model: parasail-ai/GritLM-7B-vllm
    status: "known_failure_xfail"
    reason: "ZeroDivisionError: integer division or modulo by zero"
  vllm_sweep_internlm:
    model: internlm/internlm-7b
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  vllm_sweep_internlm2:
    model: internlm/internlm2-7b
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  vllm_sweep_internlm3:
    model: internlm/internlm3-8b-instruct
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  # vllm_sweep_jais:
  #   model: inceptionai/jais-13b
  #   max_model_len: 64
  #   max_num_batched_tokens: 64
  #   marks: [vllm_sweep]
  vllm_sweep_jamba: # need to agree to terms to access
    model: ai21labs/AI21-Jamba-Mini-1.5
    status: "known_failure_xfail"
    reason: "ValueError: TT backend only supports V1."
  # vllm_sweep_llama:
  #   model: meta-llama/Llama-3.2-1B
  #   marks: [vllm_sweep]
  vllm_sweep_mamba:
    model: state-spaces/mamba-130m-hf
    status: "known_failure_xfail"
    reason: "ZeroDivisionError: integer division or modulo by zero"
  vllm_sweep_minicpm:
    model: openbmb/MiniCPM-2B-sft-bf16
    gpu_memory_utilization: 0.004
    reason: "Hangs ?"
  vllm_sweep_minicpm3:
    model: openbmb/MiniCPM3-4B
    status: "known_failure_xfail"
    reason: "torch._dynamo.exc.TorchRuntimeError: Dynamo failed to run FX node with fake tensors: call_method view(*(FakeTensor(..., device='xla:0', size=(0, 32)), 0, -1, 32), **{}): got RuntimeError('cannot reshape tensor of 0 elements into shape [0, -1, 32] because the unspecified dimension size -1 can be any value and is ambiguous')"
  # vllm_sweep_mistral:
  #   model: mistralai/Mistral-7B-v0.1
  #   gpu_memory_utilization: 0.001
  #   max_model_len: 64
  #   max_num_batched_tokens: 64
  #   prompts:
  #   - The future of AI is
  #   marks: [vllm_sweep]
  # vllm_sweep_mixtral:
  #   model: mistralai/Mixtral-8x7B-v0.1
  #   max_model_len: 64
  #   max_num_batched_tokens: 64
  #   marks: [vllm_sweep]
  vllm_sweep_mpt:
    model: mosaicml/mpt-7b
    status: "known_failure_xfail"
    reason: "Gated huggingface model"
  vllm_sweep_nemotron:
    model: nvidia/Minitron-8B-Base
    status: "known_failure_xfail"
    reason: "ValueError: TT backend only supports V1."
  vllm_sweep_olmo:
    model: allenai/OLMo-1B-hf
    status: "expected_passing"
  vllm_sweep_olmo2:
    model: allenai/OLMo2-7B-1124
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  vllm_sweep_olmoe:
    model: allenai/OLMoE-1B-7B-0924
    status: "known_failure_xfail"
    reason: "'_OpNamespace' '_moe_C' object has no attribute 'topk_softmax'"
  # vllm_sweep_opt:
  #   model: facebook/opt-125m
  #   marks: [vllm_sweep]
  # vllm_sweep_orion:
  #   model: OrionStarAI/Orion-14B-Base
  #   max_model_len: 64
  #   max_num_batched_tokens: 64
  #   marks: [vllm_sweep]
  # vllm_sweep_phi:
  #   model: microsoft/phi-2
  #   gpu_memory_utilization: 0.004
  #   marks: [vllm_sweep]
  vllm_sweep_phi3:
    model: microsoft/Phi-3-mini-4k-instruct
    status: "known_failure_xfail"
    reason: "ValueError: TT backend only supports V1."
  # vllm_sweep_phi4:
  #   model: microsoft/phi-4
  #   marks: [vllm_sweep]
  vllm_sweep_phi3_small:
    model: microsoft/Phi-3-small-8k-instruct
    status: "known_failure_xfail"
    reason: "Model architecture Phi3SmallForCausalLM was supported in vLLM until v0.9.2, and is not supported anymore."
  # vllm_sweep_phimoe:
  #   model: microsoft/Phi-3.5-MoE-instruct
  #   marks: [vllm_sweep]
  vllm_sweep_persimmon:
    model: adept/persimmon-8b-base
    status: "known_failure_xfail"
    reason: "ValueError: TT backend only supports V1."
  vllm_sweep_qwen:
    model: Qwen/Qwen-7B
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  # vllm_sweep_qwen2:
  #   model: Qwen/Qwen2-0.5B
  #   gpu_memory_utilization: 0.001
  #   marks: [vllm_sweep]
  vllm_sweep_qwen2moe:
    model: Qwen/Qwen1.5-MoE-A2.7B
    status: "known_failure_xfail"
    reason: "ValueError: TT backend only supports V1."
  vllm_sweep_stablelm:
    model: stabilityai/stablelm-3b-4e1t
    gpu_memory_utilization: 0.004
    status: "expected_passing"
  vllm_sweep_starcoder2:
    model: bigcode/starcoder2-3b
    status: "expected_passing"
  vllm_sweep_solar:
    model: upstage/solar-pro-preview-instruct
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  vllm_sweep_telechat:
    model: chuhac/TeleChat2-3B
    status: "known_failure_xfail"
    reason: "Gated huggingface model"
  vllm_sweep_xverse:
    model: xverse/XVERSE-7B-Chat
    status: "known_failure_xfail"
    reason: "Exception: add_prefix_space does not match declared prepend_scheme at line 78 column 3"
