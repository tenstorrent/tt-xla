# SPDX-FileCopyrightText: (c) 2025 Tenstorrent AI ULC
#
# SPDX-License-Identifier: Apache-2.0

# vLLM pooling (embedding) model test configurations.
# Defaults are applied in test_config/__init__.py (DEFAULT_POOLING_CONFIG).
# Only "model" is required. "marks" default to [single_device]; add marks only when overriding.
# "status" defaults to "unspecified" when omitted.

model_configs:
  vllm_sweep_bge_m3:
    model: "BAAI/bge-m3"
    max_model_len: 512
    max_num_batched_tokens: 512
    max_num_seqs: 2
    prompts:
      - "Hello, my name is"
      - "The capital of France is Paris"
    status: "expected_passing"
  vllm_sweep_bge_base:
    model: "BAAI/bge-base-en"
    max_model_len: 64
    max_num_seqs: 2
    prompts:
      - "Hello, my name is"
      - "The capital of France is Paris"
    status: "expected_passing"
  vllm_sweep_bge_small:
    model: "BAAI/bge-small-en"
    max_model_len: 64
    max_num_seqs: 2
    status: "expected_passing"
  vllm_sweep_e5_small:
    model: "intfloat/e5-small-v2"
    max_model_len: 64
    max_num_seqs: 2
    prompts:
      - "Hello, my name is"
      - "The capital of France is Paris"
    status: "expected_passing"
  vllm_sweep_e5_base:
    model: "intfloat/e5-base-v2"
    max_model_len: 64
    max_num_seqs: 2
    status: "expected_passing"
  vllm_sweep_qwen3_embedding_0_6b:
    model: "Qwen/Qwen3-Embedding-0.6B"
    status: "expected_passing"
  vllm_sweep_qwen3_embedding_4b:
    model: "Qwen/Qwen3-Embedding-4B"
    status: "expected_passing"
  vllm_sweep_all_minilm:
    model: "sentence-transformers/all-MiniLM-L6-v2"
    max_model_len: 64
    max_num_seqs: 2
    status: "expected_passing"
  vllm_sweep_multi_qa_minilm:
    model: "sentence-transformers/multi-qa-MiniLM-L6-cos-v1"
    max_model_len: 64
    max_num_seqs: 2
    status: "expected_passing"
  vllm_sweep_e5_mistral_7b_instruct:
    model: "intfloat/e5-mistral-7b-instruct"
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  vllm_sweep_gritlm:
    model: "parasail-ai/GritLM-7B-vllm"
    status: "known_failure_xfail"
    reason: "Model is too large for single chip"
  vllm_sweep_roberta:
    model: "sentence-transformers/nli-roberta-base-v2"
    max_model_len: 64
    max_num_seqs: 2
    status: "expected_passing"
  vllm_sweep_xlm_roberta:
    model: "sentence-transformers/stsb-xlm-r-multilingual"
    max_model_len: 64
    max_num_seqs: 2
    status: "expected_passing"
