# SPDX-FileCopyrightText: (c) 2025 Tenstorrent AI ULC
#
# SPDX-License-Identifier: Apache-2.0


test_config:
  falcon/pytorch-3_7B_Base-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  falcon/pytorch-3_10B_Base-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    required_pcc: 0.977 # https://github.com/tenstorrent/tt-xla/issues/3180

  qwen_2_5/causal_lm/pytorch-7B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "DRAM OOM - shard spec issues - https://github.com/tenstorrent/tt-xla/issues/2150"

  qwen_2_5/causal_lm/pytorch-14B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  qwen_2_5/causal_lm/pytorch-32B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "trisc2 compile failure - https://github.com/tenstorrent/tt-xla/issues/2958"

  qwen_2_5/causal_lm/pytorch-72B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on galaxy"
    bringup_status: FAILED_RUNTIME

  gemma/pytorch-1.1_7B_IT-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    assert_pcc: false # ComputeConfig math_fidelity/fp32_dest_acc_en - https://github.com/tenstorrent/tt-xla/issues/2861

  gemma/pytorch-2_9B_IT-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    assert_pcc: false # https://github.com/tenstorrent/tt-xla/issues/2845

  gemma/pytorch-2_27B_IT-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  llama/causal_lm/pytorch-3.1_70B-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on galaxy"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-3.1_70B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on galaxy"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-3.1_405B-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on galaxy"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-3.3_70B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on galaxy"
    bringup_status: FAILED_RUNTIME

  qwen_3/causal_lm/pytorch-8B-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    required_pcc: 0.985 # https://github.com/tenstorrent/tt-xla/issues/2942
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  qwen_3/causal_lm/pytorch-14B-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "trisc2 compile failure - https://github.com/tenstorrent/tt-xla/issues/2958"

  qwen_3/causal_lm/pytorch-32B-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "trisc2 compile failure - https://github.com/tenstorrent/tt-xla/issues/2958"

  qwen_3/causal_lm/pytorch-30B_A3b-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on n300-llmbox"
    bringup_status: FAILED_RUNTIME
