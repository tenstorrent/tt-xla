# SPDX-FileCopyrightText: (c) 2025 Tenstorrent AI ULC
#
# SPDX-License-Identifier: Apache-2.0


test_config:
  falcon/pytorch-3_7B_Base-llm_decode-seq_1-batch_1-tensor_parallel-mesh_default-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  falcon/pytorch-3_10B_Base-llm_decode-seq_1-batch_1-tensor_parallel-mesh_default-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    required_pcc: 0.977 # https://github.com/tenstorrent/tt-xla/issues/3180

  qwen_2_5/causal_lm/pytorch-7B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-mesh_default-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "DRAM OOM - shard spec issues - https://github.com/tenstorrent/tt-xla/issues/2150"

  qwen_2_5/causal_lm/pytorch-14B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-mesh_default-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  qwen_2_5/causal_lm/pytorch-32B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-mesh_default-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "trisc2 compile failure - https://github.com/tenstorrent/tt-xla/issues/2958"

  qwen_2_5/causal_lm/pytorch-72B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-mesh_default-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on galaxy"
    bringup_status: FAILED_RUNTIME

  gemma/pytorch-1.1_7B_IT-llm_decode-seq_1-batch_1-tensor_parallel-mesh_default-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    assert_pcc: false # ComputeConfig math_fidelity/fp32_dest_acc_en - https://github.com/tenstorrent/tt-xla/issues/2861

  gemma/pytorch-2_9B_IT-llm_decode-seq_1-batch_1-tensor_parallel-mesh_default-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    assert_pcc: false # https://github.com/tenstorrent/tt-xla/issues/2845

  gemma/pytorch-2_27B_IT-llm_decode-seq_1-batch_1-tensor_parallel-mesh_default-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-mesh_default-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  llama/causal_lm/pytorch-3.1_70B-llm_decode-seq_1-batch_1-tensor_parallel-mesh_default-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on galaxy"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-3.1_70B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-mesh_default-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on galaxy"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-3.1_405B-llm_decode-seq_1-batch_1-tensor_parallel-mesh_default-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on galaxy"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-3.3_70B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-mesh_default-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on galaxy"
    bringup_status: FAILED_RUNTIME

  qwen_3/causal_lm/pytorch-8B-llm_decode-seq_1-batch_1-tensor_parallel-mesh_default-inference:
    required_pcc: 0.985 # https://github.com/tenstorrent/tt-xla/issues/2942
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  qwen_3/causal_lm/pytorch-14B-llm_decode-seq_1-batch_1-tensor_parallel-mesh_default-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "trisc2 compile failure - https://github.com/tenstorrent/tt-xla/issues/2958"

  qwen_3/causal_lm/pytorch-32B-llm_decode-seq_1-batch_1-tensor_parallel-mesh_default-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "trisc2 compile failure - https://github.com/tenstorrent/tt-xla/issues/2958"

  qwen_3/causal_lm/pytorch-30B_A3b-llm_decode-seq_1-batch_1-tensor_parallel-mesh_default-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on n300-llmbox"
    bringup_status: FAILED_RUNTIME

  # ============================================================================
  # Llama 3.1 8B Instruct â€” Prefill tensor-parallel tests
  #  - batch_X means per-device batch size.
  # ============================================================================

  # --- Megatron, mesh 1x8, no DP ---
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_128-batch_1-megatron-no_dp-tensor_parallel-mesh_1x8-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_128-batch_2-megatron-no_dp-tensor_parallel-mesh_1x8-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_1024-batch_1-megatron-no_dp-tensor_parallel-mesh_1x8-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_1024-batch_2-megatron-no_dp-tensor_parallel-mesh_1x8-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.94 # Is 0.941
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_2048-batch_1-megatron-no_dp-tensor_parallel-mesh_1x8-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.95 # Is 0.950
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_2048-batch_2-megatron-no_dp-tensor_parallel-mesh_1x8-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.86 # Is 0.863
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_4096-batch_1-megatron-no_dp-tensor_parallel-mesh_1x8-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.81 # Is 0.818
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_4096-batch_2-megatron-no_dp-tensor_parallel-mesh_1x8-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.81 # Is 0.817
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_8192-batch_1-megatron-no_dp-tensor_parallel-mesh_1x8-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.74 # Is 0.747
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_8192-batch_2-megatron-no_dp-tensor_parallel-mesh_1x8-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Out of memory" # See https://github.com/tenstorrent/tt-mlir/issues/6877
    markers: [nightly]

  # --- FSDP, mesh 2x4, no DP ---
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_128-batch_1-fsdp-no_dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.92 # Is 0.928
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_128-batch_2-fsdp-no_dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.92 # Is 0.928
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_1024-batch_1-fsdp-no_dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.92 # Is 0.924
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_1024-batch_2-fsdp-no_dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.87 # Is 0.875
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_2048-batch_1-fsdp-no_dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.92 # Is 0.920
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_2048-batch_2-fsdp-no_dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.75 # Is 0.758
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_4096-batch_1-fsdp-no_dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.81 # Is 0.818
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_4096-batch_2-fsdp-no_dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.80 # Is 0.802
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_8192-batch_1-fsdp-no_dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Out of memory" # See https://github.com/tenstorrent/tt-mlir/issues/6877
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_8192-batch_2-fsdp-no_dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Out of memory" # See https://github.com/tenstorrent/tt-mlir/issues/6877
    markers: [nightly]

  # --- FSDP, mesh 2x4, DP (batch must be >= data dim 2) ---
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_128-batch_1-fsdp-dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.92 # Is 0.928
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_128-batch_2-fsdp-dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.93 # Is 0.933
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_1024-batch_1-fsdp-dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.87 # Is 0.876
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_1024-batch_2-fsdp-dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.89 # Is 0.896
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_2048-batch_1-fsdp-dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.75 # Is 0.758
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_2048-batch_2-fsdp-dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.77 # Is 0.779
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_4096-batch_1-fsdp-dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.80 # Is 0.801
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_4096-batch_2-fsdp-dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Out of memory" # See https://github.com/tenstorrent/tt-mlir/issues/6877
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_8192-batch_1-fsdp-dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Out of memory" # See https://github.com/tenstorrent/tt-mlir/issues/6877
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_8192-batch_2-fsdp-dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Out of memory" # See https://github.com/tenstorrent/tt-mlir/issues/6877
    markers: [nightly]

  # --- Megatron, mesh 2x4, no DP ---
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_128-batch_1-megatron-no_dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_128-batch_2-megatron-no_dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_1024-batch_1-megatron-no_dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.93 # Is 0.938
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_1024-batch_2-megatron-no_dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.96 # Is 0.965
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_2048-batch_1-megatron-no_dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_2048-batch_2-megatron-no_dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_4096-batch_1-megatron-no_dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_4096-batch_2-megatron-no_dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_8192-batch_1-megatron-no_dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_8192-batch_2-megatron-no_dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]

  # --- Megatron, mesh 2x4, DP (batch must be >= data dim 2) ---
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_128-batch_1-megatron-dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_128-batch_2-megatron-dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_1024-batch_1-megatron-dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.93 # Is 0.938
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_1024-batch_2-megatron-dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.96 # Is 0.965
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_2048-batch_1-megatron-dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.86 # Is 0.861
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_2048-batch_2-megatron-dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.87 # Is 0.879
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_4096-batch_1-megatron-dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    required_pcc: 0.81 # Is 0.817
    status: EXPECTED_PASSING
    assert_pcc: false
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_4096-batch_2-megatron-dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Out of memory" # See https://github.com/tenstorrent/tt-mlir/issues/6877
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_8192-batch_1-megatron-dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Out of memory" # See https://github.com/tenstorrent/tt-mlir/issues/6877
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_8192-batch_2-megatron-dp-tensor_parallel-mesh_2x4-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Out of memory" # See https://github.com/tenstorrent/tt-mlir/issues/6877
    markers: [nightly]
