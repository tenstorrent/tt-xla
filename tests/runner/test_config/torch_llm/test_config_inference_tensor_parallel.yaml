# SPDX-FileCopyrightText: (c) 2025 Tenstorrent AI ULC
#
# SPDX-License-Identifier: Apache-2.0


test_config:
  falcon/pytorch-3_7B_Base-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  falcon/pytorch-3_10B_Base-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    required_pcc: 0.977 # https://github.com/tenstorrent/tt-xla/issues/3180

  qwen_2_5/causal_lm/pytorch-7B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "DRAM OOM - shard spec issues - https://github.com/tenstorrent/tt-xla/issues/2150"

  qwen_2_5/causal_lm/pytorch-14B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  qwen_2_5/causal_lm/pytorch-32B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "trisc2 compile failure - https://github.com/tenstorrent/tt-xla/issues/2958"

  qwen_2_5/causal_lm/pytorch-72B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on galaxy"
    bringup_status: FAILED_RUNTIME

  gemma/pytorch-1.1_7B_IT-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    assert_pcc: false # ComputeConfig math_fidelity/fp32_dest_acc_en - https://github.com/tenstorrent/tt-xla/issues/2861

  gemma/pytorch-2_9B_IT-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    assert_pcc: false # https://github.com/tenstorrent/tt-xla/issues/2845

  gemma/pytorch-2_27B_IT-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  llama/causal_lm/pytorch-3.1_70B-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on galaxy"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-3.1_70B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on galaxy"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-3.1_405B-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on galaxy"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-3.3_70B_Instruct-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on galaxy"
    bringup_status: FAILED_RUNTIME

  qwen_3/causal_lm/pytorch-8B-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    required_pcc: 0.985 # https://github.com/tenstorrent/tt-xla/issues/2942
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  qwen_3/causal_lm/pytorch-14B-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "trisc2 compile failure - https://github.com/tenstorrent/tt-xla/issues/2958"

  qwen_3/causal_lm/pytorch-32B-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "trisc2 compile failure - https://github.com/tenstorrent/tt-xla/issues/2958"

  qwen_3/causal_lm/pytorch-30B_A3b-llm_decode-seq_1-batch_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on n300-llmbox"
    bringup_status: FAILED_RUNTIME

  # ============================================================================
  # Llama 3.1 8B Instruct â€” Prefill tensor-parallel tests
  # Constraints:
  #  - Keep only one strategy for 1x8 (Megatron).
  #  - batch_X means batch-per-device. For DP, global batch is X * mesh_data_dim.
  #  - DP is used only with mesh 2x4.
  #  - Cover all prefill sequence lengths through 8192.
  # ============================================================================

  # --- Megatron, mesh 1x8, no DP ---
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_128-batch_1-megatron_mesh_1x8-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_128-batch_2-megatron_mesh_1x8-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_1024-batch_1-megatron_mesh_1x8-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_1024-batch_2-megatron_mesh_1x8-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_2048-batch_1-megatron_mesh_1x8-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_2048-batch_2-megatron_mesh_1x8-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_4096-batch_1-megatron_mesh_1x8-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_4096-batch_2-megatron_mesh_1x8-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_8192-batch_1-megatron_mesh_1x8-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_8192-batch_2-megatron_mesh_1x8-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]

  # --- FSDP, mesh 2x4, no DP ---
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_128-batch_1-fsdp_mesh_2x4-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_128-batch_2-fsdp_mesh_2x4-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_1024-batch_1-fsdp_mesh_2x4-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_1024-batch_2-fsdp_mesh_2x4-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_2048-batch_1-fsdp_mesh_2x4-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_2048-batch_2-fsdp_mesh_2x4-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_4096-batch_1-fsdp_mesh_2x4-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_4096-batch_2-fsdp_mesh_2x4-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_8192-batch_1-fsdp_mesh_2x4-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_8192-batch_2-fsdp_mesh_2x4-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]

  # --- FSDP, mesh 2x4, DP (batch must be >= data dim 2) ---
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_128-batch_1-fsdp_mesh_2x4-dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_128-batch_2-fsdp_mesh_2x4-dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_1024-batch_1-fsdp_mesh_2x4-dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_1024-batch_2-fsdp_mesh_2x4-dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_2048-batch_1-fsdp_mesh_2x4-dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_2048-batch_2-fsdp_mesh_2x4-dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_4096-batch_1-fsdp_mesh_2x4-dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_4096-batch_2-fsdp_mesh_2x4-dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_8192-batch_1-fsdp_mesh_2x4-dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_8192-batch_2-fsdp_mesh_2x4-dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]

  # --- Megatron, mesh 2x4, no DP ---
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_128-batch_1-megatron_mesh_2x4-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_128-batch_2-megatron_mesh_2x4-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_1024-batch_1-megatron_mesh_2x4-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_1024-batch_2-megatron_mesh_2x4-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_2048-batch_1-megatron_mesh_2x4-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_2048-batch_2-megatron_mesh_2x4-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_4096-batch_1-megatron_mesh_2x4-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_4096-batch_2-megatron_mesh_2x4-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_8192-batch_1-megatron_mesh_2x4-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_8192-batch_2-megatron_mesh_2x4-no_dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]

  # --- Megatron, mesh 2x4, DP (batch must be >= data dim 2) ---
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_128-batch_1-megatron_mesh_2x4-dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_128-batch_2-megatron_mesh_2x4-dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_1024-batch_1-megatron_mesh_2x4-dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_1024-batch_2-megatron_mesh_2x4-dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_2048-batch_1-megatron_mesh_2x4-dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_2048-batch_2-megatron_mesh_2x4-dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_4096-batch_1-megatron_mesh_2x4-dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_4096-batch_2-megatron_mesh_2x4-dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_8192-batch_1-megatron_mesh_2x4-dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
  llama/causal_lm/pytorch-3.1_8B_Instruct-llm_prefill-seq_8192-batch_2-megatron_mesh_2x4-dp-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]
