# SPDX-FileCopyrightText: (c) 2025 Tenstorrent AI ULC
#
# SPDX-License-Identifier: Apache-2.0

test_config:

  #==============================================================================
  # KNOWN ISSUE: error: 'sdy.all_reduce' op reduction axis "_axis_0" overlaps
  # with operand dimension sharding or replicated axes
  # STATUS: Het is investigating InsertExplicitReshardsPass
  #==============================================================================
  opt/sequence_classification/pytorch-facebook/opt-1.3b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  opt/sequence_classification/pytorch-facebook/opt-125m-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  opt/sequence_classification/pytorch-facebook/opt-350m-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  gpt_neo/sequence_classification/pytorch-gpt_neo_125M-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  gpt_neo/sequence_classification/pytorch-gpt_neo_1_3B-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  gpt_neo/sequence_classification/pytorch-gpt_neo_2_7B-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.98

  phi3/seq_cls/pytorch-microsoft/Phi-3-mini-128k-instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  phi3/seq_cls/pytorch-microsoft/Phi-3-mini-4k-instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  phi1/sequence_classification/pytorch-microsoft/phi-1-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  phi1_5/sequence_classification/pytorch-microsoft/phi-1_5-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  phi2/sequence_classification/pytorch-microsoft/phi-2-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  phi2/sequence_classification/pytorch-microsoft/phi-2-pytdml-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  phi4/seq_cls/pytorch-microsoft/phi-4-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING


  #==============================================================================
  # KNOWN ISSUE: Dynamo failed to run FX node with fake tensors
  #==============================================================================
  nbeats/pytorch-generic_basis-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  nbeats/pytorch-seasonality_basis-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  nbeats/pytorch-trend_basis-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  #==============================================================================
  # KNOWN ISSUE: 'GenerationConfig' object has no attribute 'rep
  #==============================================================================
  gpt_neo/causal_lm/pytorch-gpt_neo_1_3B-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.98

  gpt_neo/causal_lm/pytorch-gpt_neo_2_7B-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING


  #==============================================================================
  # KNOWN ISSUE: TT_FATAL @ /__w/tt-xla/tt-xla/third_party/tt-mlâ€¦
  #    ERROR | All dimensions are overlapping, cannot find non-overlapping dimension for mesh composer.
  # critical |          Always | dims must be unique (assert.hpp:103)
  #==============================================================================
  dpr/reader/pytorch-facebook/dpr-reader-single-nq-base-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.98

  dpr/reader/pytorch-facebook/dpr-reader-multiset-base-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  #==============================================================================
  # KNOWN ISSUE: Too much memory leaked/Large model/OOM
  # STATUS: James is investigating memory leaks on device
  #==============================================================================

  # True OOM (hits OOM DRAM locally) ============================================

  vit/pytorch-vit_l_16-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  # Passes locally ==============================================================

  mamba/pytorch-mamba-1.4b-hf-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  qwen_2_5_coder/pytorch-3b-data_parallel-full-inference:
    supported_archs: [n300]
    assert_pcc: false
    status: EXPECTED_PASSING
    bringup_status: INCORRECT_RESULT # Calculated: pcc=0.8409987092018127. Required: pcc=0.99.

  qwen_3/causal_lm/pytorch-1_7b-data_parallel-full-inference:
    supported_archs: [n300]
    assert_pcc: false
    status: EXPECTED_PASSING
    bringup_status: INCORRECT_RESULT # Calculated: pcc=0.8567329049110413. Required: pcc=0.99.

  qwen_2_5/casual_lm/pytorch-1_5b_instruct-data_parallel-full-inference:
    supported_archs: [n300]
    assert_pcc: false
    status: EXPECTED_PASSING
    bringup_status: INCORRECT_RESULT # Calculated: pcc=0.9498721361160278. Required: pcc=0.99.

  opt/qa/pytorch-facebook/opt-1.3b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.97 # Left as passing since it's ~0.98 at 0.9797....

  opt/causal_lm/pytorch-facebook/opt-1.3b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  stereo/pytorch-small-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  phi1_5/token_classification/pytorch-microsoft/phi-1_5-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  llama/causal_lm/pytorch-llama_3_2_3b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.98

  vit/pytorch-vit_l_32-data_parallel-full-inference:
    supported_archs: [n300]
    assert_pcc: false
    status: EXPECTED_PASSING
    bringup_status: INCORRECT_RESULT # Calculated: pcc=0.9618761539459229. Required: pcc=0.98

  qwen_1_5/causal_lm/pytorch-0_5b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  mamba/pytorch-mamba-2.8b-hf-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.98

  # Failing locally =============================================================

  # Unsupported binary op for FPU BinaryOpType::BITWISE_OR
  mistral/pytorch-ministral_3b_instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  # Untested locally ============================================================

  mistral/pytorch-7b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  mistral/pytorch-ministral_8b_instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  mistral/pytorch-7b_instruct_v03-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  phi4/causal_lm/pytorch-microsoft/phi-4-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  phi4/token_cls/pytorch-microsoft/phi-4-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  phi3/causal_lm/pytorch-microsoft/Phi-3-mini-128k-instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING # failed with segfault?

  phi3/token_cls/pytorch-microsoft/Phi-3-mini-128k-instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  phi3/token_cls/pytorch-microsoft/Phi-3-mini-4k-instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  phi2/causal_lm/pytorch-microsoft/phi-2-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  qwen_3/embedding/pytorch-embedding_8b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.98

  qwen_2_5/casual_lm/pytorch-14b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  qwen_2_5/casual_lm/pytorch-14b_instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  qwen_2_5/casual_lm/pytorch-14b_instruct_1m-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  qwen_2_5/casual_lm/pytorch-7b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  qwen_2_5/casual_lm/pytorch-7b_instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  qwen_2_5/casual_lm/pytorch-7b_instruct_1m-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  qwen_2_5/casual_lm/pytorch-math_7b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  qwen_2_5_coder/pytorch-7b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  qwen_2_5_coder/pytorch-7b_instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  qwen_3/causal_lm/pytorch-14b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  qwen_3/causal_lm/pytorch-8b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  huggyllama/pytorch-llama_7b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  llama/causal_lm/pytorch-huggyllama_7b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  llama/causal_lm/pytorch-llama_3_1_8b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  llama/causal_lm/pytorch-llama_3_1_8b_instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  llama/causal_lm/pytorch-llama_3_8b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  llama/sequence_classification/pytorch-huggyllama_7b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  llama/sequence_classification/pytorch-llama_3_1_8b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  llama/sequence_classification/pytorch-llama_3_1_8b_instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  llama/sequence_classification/pytorch-llama_3_8b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  llama/sequence_classification/pytorch-llama_3_8b_instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  llama/sequence_classification/pytorch-llama_3_2_1b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  llama/sequence_classification/pytorch-llama_3_2_1b_instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  llama/sequence_classification/pytorch-llama_3_2_3b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  llama/sequence_classification/pytorch-llama_3_2_3b_instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  deepcogito/pytorch-v1_preview_llama_3b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  gemma/pytorch-google/gemma-2-9b-it-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  gemma/pytorch-google/gemma-1.1-7b-it-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  mistral/pixtral/pytorch-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  falcon/pytorch-tiiuae/falcon-7b-instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  falcon/pytorch-tiiuae/Falcon3-1B-Base-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  falcon/pytorch-tiiuae/Falcon3-3B-Base-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  falcon/pytorch-tiiuae/Falcon3-7B-Base-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.98

  falcon/pytorch-tiiuae/Falcon3-10B-Base-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  falcon/pytorch-tiiuae/Falcon3-Mamba-7B-Base-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  deepseek/deepseek_math/pytorch-7b_instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  glpn_kitti/pytorch-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  gemma/pytorch-google/gemma-2-2b-it-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  gemma/pytorch-google/gemma-2b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  qwen_2_5_coder/pytorch-1_5b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  qwen_2_5_coder/pytorch-3b_instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  qwen_3/causal_lm/pytorch-4b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  qwen_2_5/casual_lm/pytorch-0_5b_instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.97

  qwen_2_5/casual_lm/pytorch-3b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  bloom/pytorch-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  phi2/causal_lm/pytorch-microsoft/phi-2-pytdml-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  distilbert/masked_lm/pytorch-distilbert-base-uncased-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  llama/causal_lm/pytorch-llama_3_2_3b_instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  llama/causal_lm/pytorch-llama_3_8b_instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  vit/pytorch-vit_h_14-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  llama/causal_lm/pytorch-llama_3_2_1b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING


  #==============================================================================
  # FAILED AND UNSORTED - not OOM tho
  #==============================================================================
  mlp_mixer/pytorch-mixer_l16_224-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  densenet/pytorch-densenet121-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  densenet/pytorch-densenet161-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  densenet/pytorch-densenet169-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.98

  gpt2/pytorch-gpt2_sequence_classification-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  musicgen_small/pytorch-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  densenet/pytorch-densenet201-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.98

  gpt_neo/causal_lm/pytorch-gpt_neo_125M-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  mlp_mixer/pytorch-mixer_b16_224.goog_in21k-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  yolov9/pytorch-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  hrnet/pytorch-hrnetv2_w44_osmr-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.96

  stereo/pytorch-large-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING # leaking a lot (+15 000 MB)

  resnext/pytorch-resnext26_32x4d_osmr-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  hrnet/pytorch-hrnet_w18_small_v1_osmr-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  hrnet/pytorch-hrnetv2_w48_osmr-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.985

  mobilenetv3/pytorch-mobilenetv3_large_100-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  resnext/pytorch-resnext50_32x4d_osmr-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  yoloworld/pytorch-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  vovnet/pytorch-vovnet27s-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  hrnet/pytorch-hrnetv2_w18_osmr-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  hrnet/pytorch-hrnet_w18_small_v2_osmr-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  inception/pytorch-inceptionv4-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.97

  hrnet/pytorch-hrnetv2_w30_osmr-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.98

  vovnet/pytorch-vovnet39-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.98

  hrnet/pytorch-hrnetv2_w32_osmr-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.985

  flux/pytorch-dev-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  resnext/pytorch-resnext101_64x4d_osmr-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  hrnet/pytorch-hrnetv2_w40_osmr-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.98

  vovnet/pytorch-vovnet57-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.98

  flux/pytorch-schnell-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  resnext/pytorch-resnext14_32x4d_osmr-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  ghostnet/pytorch-ghostnetv2_100.in1k-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  bart/pytorch-large-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.98

  mamba/pytorch-mamba-790m-hf-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING
    required_pcc: 0.96 # not OOM but leaking 2000 MB

  phi3/phi_3_5/pytorch-mini_instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING # not OOM but leaking 6000 MB

  xglm/pytorch-xglm-564M-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING # not OOM but leaking 3000 MB

  vit/pytorch-vit_b_16-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  phi3/causal_lm/pytorch-microsoft/Phi-3-mini-4k-instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING # not OOM but leaking 6000 MB

  qwen_3/causal_lm/pytorch-0_6b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  qwen_2_5/casual_lm/pytorch-1_5b-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  qwen_2_5/casual_lm/pytorch-3b_instruct-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING

  stereo/pytorch-medium-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING # not OOM but leaking 8000 MB

  xglm/pytorch-xglm-1.7B-data_parallel-full-inference:
    supported_archs: [n300]
    status: EXPECTED_PASSING # not OOM but leaking 10000 MB


  #==============================================================================
  # PASSING
  #==============================================================================


  #==============================================================================
  # TO BE TESTED
  #==============================================================================
