# SPDX-FileCopyrightText: (c) 2025 Tenstorrent AI ULC
#
# SPDX-License-Identifier: Apache-2.0

# JAX Inference tensor-parallel test configuration
# Use Python enum names or values for fields below (names preferred for readability):
#   - status: ModelTestStatus names (e.g., EXPECTED_PASSING) or values (e.g., expected_passing)
#   - bringup_status (if present): BringupStatus names (e.g., FAILED_TTMLIR_COMPILATION) or values (e.g., failed_ttmlir_compilation)

test_config:
  alexnet/image_classification/jax-Custom_1x2-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]

  alexnet/image_classification/jax-Custom_1x4-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Hangs in runtime - https://github.com/tenstorrent/tt-xla/issues/2440"

  alexnet/image_classification/jax-Custom_1x8-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Hangs in runtime - https://github.com/tenstorrent/tt-xla/issues/2440"

  falcon/jax-3_1B_Base-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  falcon/jax-3_3B_Base-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  qwen_2_5/causal_lm/jax-0.5B-tensor_parallel-inference:
    supported_archs: ["n300"]
    status: EXPECTED_PASSING

  qwen_2_5/causal_lm/jax-0.5B_Instruct-tensor_parallel-inference:
    supported_archs: ["n300"]
    status: EXPECTED_PASSING

  qwen_2_5/causal_lm/jax-1.5B-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  qwen_2_5/causal_lm/jax-1.5B_Instruct-tensor_parallel-inference:
    supported_archs: ["n300"]
    status: EXPECTED_PASSING

  qwen_2_5/causal_lm/jax-3B-tensor_parallel-inference:
    supported_archs: ["n300"]
    status: EXPECTED_PASSING

  qwen_2_5/causal_lm/jax-3B_Instruct-tensor_parallel-inference:
    supported_archs: ["n300"]
    status: EXPECTED_PASSING

  qwen_2_5/causal_lm/jax-7B-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  qwen_2_5/causal_lm/jax-7B_Instruct-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  qwen_2_5_coder/causal_lm/jax-0.5B-tensor_parallel-inference:
    supported_archs: ["n300"]
    status: EXPECTED_PASSING

  qwen_2_5_coder/causal_lm/jax-1.5B-tensor_parallel-inference:
    supported_archs: ["n300"]
    status: EXPECTED_PASSING

  qwen_2_5_coder/causal_lm/jax-1.5B_Instruct-tensor_parallel-inference:
    supported_archs: ["n300"]
    status: EXPECTED_PASSING

  qwen_2_5_coder/causal_lm/jax-3B-tensor_parallel-inference:
    supported_archs: ["n300"]
    status: EXPECTED_PASSING

  qwen_2_5_coder/causal_lm/jax-3B_Instruct-tensor_parallel-inference:
    supported_archs: ["n300"]
    status: EXPECTED_PASSING

  qwen_2_5_coder/causal_lm/jax-7B-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  qwen_2_5_coder/causal_lm/jax-7B_Instruct-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  qwen_3/causal_lm/jax-0_6B-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  qwen_3/causal_lm/jax-1_7B-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  qwen_3/causal_lm/jax-4B-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  mnist/image_classification/jax-Mlp_Custom_1x2-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
    markers: [nightly]

  mnist/image_classification/jax-Mlp_Custom_1x4-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  mnist/image_classification/jax-Mlp_Custom_1x8-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  gpt2/causal_lm/jax-Base-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  gpt2/causal_lm/jax-Large-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  gpt2/causal_lm/jax-Medium-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  gpt2/causal_lm/jax-Xl-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  llama/causal_lm/jax-1B_Tiny-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  llama/causal_lm/jax-3B_v2-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  phi1/causal_lm/jax-Phi_1-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  phi1_5/causal_lm/jax-Phi_1_5-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  phi2/causal_lm/jax-Phi_2-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  phi2/causal_lm/jax-Phi_2_Pytdml-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  phi3/causal_lm/jax-Phi_3_Mini_128K_Instruct-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING

  phi3/causal_lm/jax-Phi_3_Mini_4K_Instruct-tensor_parallel-inference:
    supported_archs: ["n300-llmbox"]
    status: EXPECTED_PASSING
