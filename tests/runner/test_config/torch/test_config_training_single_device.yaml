# SPDX-FileCopyrightText: (c) 2025 Tenstorrent AI ULC
#
# SPDX-License-Identifier: Apache-2.0
test_config:
  mnist/image_classification/pytorch-Cnn_Dropout-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    markers: [push, nightly, notimeout]
    reason: "Fatal Python error: ElementsAttr does not provide iteration facilities for type `int` (https://github.com/tenstorrent/tt-xla/issues/3109)"
  mnist/image_classification/pytorch-Cnn_Nodropout-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    markers: [push, nightly, notimeout]
    reason: "Fatal Python error: ElementsAttr does not provide iteration facilities for type `int` (https://github.com/tenstorrent/tt-xla/issues/3109)"
  autoencoder/pytorch-linear-single_device-training:
    status: EXPECTED_PASSING
    markers: [push, nightly]
  qwen_1_5/causal_lm/pytorch-0.5B-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  qwen_1_5/causal_lm/pytorch-0_5B_Chat-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  t5/pytorch-Small-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  t5/pytorch-Base-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  t5/pytorch-Large-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  t5/pytorch-Flan_T5_Small-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  t5/pytorch-Flan_T5_Base-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  t5/pytorch-Flan_T5_Large-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  qwen_2_5/causal_lm/pytorch-0.5B-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  qwen_2_5/causal_lm/pytorch-0.5B_Instruct-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  qwen_2_5/causal_lm/pytorch-1.5B-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  qwen_2_5/causal_lm/pytorch-1.5B_Instruct-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Node arity mismatch; expected 339, but got 338"
  llama/causal_lm/pytorch-3.2_1B-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  llama/causal_lm/pytorch-3.2_1B_Instruct-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [large, notimeout]
  qwen_2_5_coder/pytorch-0.5B-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  clip/pytorch-Base_Patch32-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
    reason: "error: failed to legalize operation 'stablehlo.scatter'"
  falcon/pytorch-3_1B_Base-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [large, notimeout]
  nbeats/pytorch-generic_basis-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  nbeats/pytorch-seasonality_basis-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  nbeats/pytorch-trend_basis-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  qwen_3/embedding/pytorch-Embedding_0_6B-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  phi1_5/token_classification/pytorch-Phi_1_5-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  phi1/token_classification/pytorch-Phi_1-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  nanogpt/pytorch-Default-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  dpr/reader/pytorch-Reader_Single_Nq_Base-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  dpr/reader/pytorch-Reader_Multiset_Base-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  musicgen_small/pytorch-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  stereo/pytorch-Small-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  stereo/pytorch-Medium-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  stereo/pytorch-Large-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  oft/pytorch-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Statically allocated circular buffers on core range [(x=0,y=0) - (x=0,y=3)] grow to 1518400 B which is beyond max L1 size of 1499136 B"
  mlp_mixer/pytorch-Mixer_B32_224-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mlp_mixer/pytorch-Mixer_L32_224-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mlp_mixer/pytorch-Mixer_S32_224-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  stable_diffusion_unet/pytorch-Base-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "RuntimeError: Test Hangs"
  centernet/pytorch-ResNet18_Backbone_COCO-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "RuntimeError: 'deformable_im2col' not implemented for 'BFloat16'"
  centernet/pytorch-ResNet101_Backbone_COCO-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "RuntimeError: 'deformable_im2col' not implemented for 'BFloat16'"
  centernet/pytorch-Dla1x_Coco-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "RuntimeError: 'deformable_im2col' not implemented for 'BFloat16'"
  centernet/pytorch-Dla2x_Coco-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "RuntimeError: 'deformable_im2col' not implemented for 'BFloat16'"
  vadv2/pytorch-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "RuntimeError: Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment."
  monodle/pytorch-Dla34-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Dataset 'imagenet-1k' is a gated dataset on the Hub."
  uniad/pytorch-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "TypeError: list indices must be integers or slices, not tuple"
  mobilenetv1/pytorch-Mobilenet_v1_0.75_192-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Dataset 'imagenet-1k' is a gated dataset on the Hub."
  mobilenetv1/pytorch-Mobilenet_v1_1.0_224-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Dataset 'imagenet-1k' is a gated dataset on the Hub."
  speecht5/pytorch-Tts-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "RuntimeError: mat1 and mat2 must have the same dtype, but got Float and BFloat16"
  rmbg/pytorch-2.0-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "ImportError: kornia"
  ssdlite320_mobilenetv3/pytorch-Ssdlite320_Mobilenet_v3_Large-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AssertionError: targets should not be none when in training mode"
  resnext/pytorch-101_64x4d-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "RuntimeError: Cannot find callable resnext101_64x4d in hubconf"
  ssd300_vgg16/pytorch-Default-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AssertionError: targets should not be none when in training mode"
  bi_lstm_crf/pytorch-Default-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "RuntimeError: The tensor has a non-zero number of elements, but its data is not allocated yet."
  ssd300_resnet50/pytorch-Base-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AttributeError: 'NoneType' object has no attribute 'max'"
  oft_stable_diffusion/pytorch-Stable_Diffusion_v1_5-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AttributeError: 'NoneType' object has no attribute 'max'"
  retinanet/pytorch-ResNet50_Backbone_with_FPN_V2-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AttributeError: 'NoneType' object has no attribute 'max'"
  gliner/pytorch-Multi_v2.1-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AttributeError: 'NoneType' object has no attribute 'max'"
  # yolov5/pytorch-yolov5n-single_device-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "TypeError: AutoShape.forward() takes from 2 to 5 positional arguments but 7 were given"
  # yolov5/pytorch-yolov5s-single_device-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "TypeError: AutoShape.forward() takes from 2 to 5 positional arguments but 7 were given"
  # yolov5/pytorch-yolov5m-single_device-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "TypeError: AutoShape.forward() takes from 2 to 5 positional arguments but 7 were given"
  # yolov5/pytorch-yolov5l-single_device-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "TypeError: AutoShape.forward() takes from 2 to 5 positional arguments but 7 were given"
  # yolov5/pytorch-yolov5x-single_device-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "TypeError: AutoShape.forward() takes from 2 to 5 positional arguments but 7 were given"
  whisper/pytorch-Large_v3-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "RuntimeError: Could not load libtorchcodec. Likely causes:"
  yolox/pytorch-X-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "EOFError: Ran out of input"
  unet/pytorch-Segmentation_Models_PyTorch_UNet_ResNet101_Backbone-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "ModuleNotFoundError: No module named 'segmentation_models_pytorch'"
  mobilenetv2/pytorch-Deeplabv3_Mobilenet_v2_1.0_513-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1, 1])"
  bge_m3/encode/pytorch-Base-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "loader.load_model() does not return `nn.Module`"
  stable_diffusion_1_4/pytorch-Base-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "loader.load_model() does not return `nn.Module`"
  gliner/pytorch-Large_v2-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "loader.load_model() does not return `nn.Module`"
  yolox/pytorch-Nano-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Model expects targets to be passed while in training mode"
  yolox/pytorch-Tiny-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Model expects targets to be passed while in training mode"
  yolox/pytorch-S-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Model expects targets to be passed while in training mode"
  yolox/pytorch-M-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Model expects targets to be passed while in training mode"
  yolox/pytorch-L-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Model expects targets to be passed while in training mode"
  yolox/pytorch-Darknet-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Model expects targets to be passed while in training mode"
  hippynn/pytorch-Default-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "loader.load_model() does not return `nn.Module`"
  yolov6/pytorch-N-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  yolov6/pytorch-S-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  yolov6/pytorch-M-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  distilbert/question_answering/pytorch-Base_Cased_Distilled_Squad-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  pointpillars/pytorch-pointpillars-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Statically allocated circular buffers on core range [(x=0,y=0) - (x=7,y=7)] grow to 2003264 B which is beyond max L1 size of 1499136 B"
  fpn/pytorch-ResNet50_Backbone_with_FPN_V2-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  # yolov10/pytorch-yolov10x-single_device-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  # yolov10/pytorch-yolov10n-single_device-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  # yolov11/pytorch-yolo11n-single_device-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  # yolov11/pytorch-yolo11s-single_device-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  # yolov11/pytorch-yolo11m-single_device-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  # yolov11/pytorch-yolo11l-single_device-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  # yolov11/pytorch-yolo11x-single_device-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  albert/question_answering/pytorch-Squad2-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  bge_m3/pytorch-Base-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  opt/qa/pytorch-125M-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  opt/qa/pytorch-350M-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  opt/qa/pytorch-1.3b-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  segformer/semantic_segmentation/pytorch-B0_Finetuned_Ade_512_512-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  segformer/semantic_segmentation/pytorch-B2_Finetuned_Ade_512_512-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  segformer/semantic_segmentation/pytorch-B3_Finetuned_Ade_512_512-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  segformer/semantic_segmentation/pytorch-B4_Finetuned_Ade_512_512-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  mgp_str_base/pytorch-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  yolos/pytorch-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  swin/image_classification/pytorch-Tiny_Patch4_Window7_224-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  swin/image_classification/pytorch-v2_Tiny_Patch4_Window8_256-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  swin/masked_image_modeling/pytorch-v2_Tiny_Patch4_Window8_256-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  # yolov8/pytorch-yolov8x-single_device-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  yolov9/pytorch-T-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  yolov9/pytorch-S-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  yolov9/pytorch-M-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  yolov9/pytorch-C-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  yolov9/pytorch-E-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  retinanet/pytorch-ResNet18_Backbone_with_FPN-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  retinanet/pytorch-ResNet34_Backbone_with_FPN-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  retinanet/pytorch-ResNet50_Backbone_with_FPN-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  retinanet/pytorch-ResNet101_Backbone_with_FPN-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  retinanet/pytorch-ResNet152_Backbone_with_FPN-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  bert/question_answering/pytorch-Large_Finetuned_Squad2-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  bert/question_answering/pytorch-bert-large-cased-whole-word-masking-finetuned-squad-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  bert/sentence_embedding_generation/pytorch-emrecan/bert-base-turkish-cased-mean-nli-stsb-tr-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
    reason: "error: 'ttnn.pad' op Output tensor shape (32,768) must match the inferred shape: (47,768)"
  dpr/context_encoder/pytorch-Ctx_Encoder_Single_Nq_Base-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  dpr/context_encoder/pytorch-Ctx_Encoder_Multiset_Base-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  dpr/question_encoder/pytorch-Question_Encoder_Single_Nq_Base-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  dpr/question_encoder/pytorch-Question_Encoder_Multiset_Base-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  centernet/pytorch-Hourglass_Coco-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Buffer must be allocated on device"
  yolov6/pytorch-L-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  maptr/pytorch-Tiny_R50_24e_Bevformer-single_device-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Not enough space to allocate 20971520000 B DRAM buffer across 8 banks, where each bank needs to store 2621440000 B, but bank size is only 4278190016 B"
  maptr/pytorch-Tiny_R50_24e_Bevformer_T4-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  maptr/pytorch-Tiny_R50_24e-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  maptr/pytorch-Tiny_R50_110e-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  maptr/pytorch-Tiny_R50_24e_T4-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  maptr/pytorch-Nano_R18_110e-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  maptr/pytorch-Tiny_R50_24e_Bevpool-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  maptr/pytorch-Tiny_Fusion_24e-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  yolov3/pytorch-Base-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  transfuser/pytorch-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
    reason: "'func.call' op incorrect number of operands for callee"
  # yoloworld/pytorch-single_device-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  segformer/semantic_segmentation/pytorch-B1_Finetuned_Ade_512_512-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  bevdepth/pytorch-bev_depth_lss_r50_256x704_128x128_24e_2key-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Statically allocated circular buffers on core range [(x=0,y=0) - (x=7,y=7)] grow to 2396480 B which is beyond max L1 size of 1499136 B (assert.hpp:103)"
  bevdepth/pytorch-bev_depth_lss_r50_256x704_128x128_24e_2key_ema-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  bevdepth/pytorch-bev_depth_lss_r50_256x704_128x128_20e_cbgs_2key_da-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  bevdepth/pytorch-bev_depth_lss_r50_256x704_128x128_20e_cbgs_2key_da_ema-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  detr3d/pytorch-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
    reason: "Out of Memory: Not enough space to allocate 285081600 B L1 buffer across 64 banks, where each bank needs to store 4454400 B, but bank size is only 1330944 B"
  # yolov8/pytorch-yolov8n-single_device-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  yolov4/pytorch-Base-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Statically allocated circular buffers on core range [(x=7,y=6) - (x=7,y=6)] grow to 2371840 B which is beyond max L1 size of 1499136 B (assert.hpp:103)"
  detr/object_detection/pytorch-ResNet50_Backbone-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  detr/segmentation/pytorch-ResNet50_Backbone_Panoptic-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  dla/pytorch-34-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  dla/pytorch-46_C-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  dla/pytorch-46x_C-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  dla/pytorch-60-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  dla/pytorch-60x-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  dla/pytorch-60x_C-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  dla/pytorch-102-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  dla/pytorch-102x-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  dla/pytorch-102x2-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  dla/pytorch-169-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  densenet/pytorch-121-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  densenet/pytorch-161-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  densenet/pytorch-169-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  densenet/pytorch-201-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  codegen/pytorch-350M_Mono-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  codegen/pytorch-350M_Multi-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  codegen/pytorch-350M_Nl-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  squeezebert/pytorch-Mnli-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  distilbert/sequence_classification/pytorch-distilbert-base-uncased-finetuned-sst-2-english-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vit/pytorch-Base-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vit/pytorch-Large-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vit/pytorch-B_16-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vit/pytorch-B_32-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vit/pytorch-L_16-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vit/pytorch-L_32-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vit/pytorch-H_14-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  maptr/pytorch-Tiny_R50_24e_Av2-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  phi1_5/sequence_classification/pytorch-Phi_1_5-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  gpt_neo/sequence_classification/pytorch-125M-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  phi2/sequence_classification/pytorch-Phi_2-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  phi2/sequence_classification/pytorch-Phi_2_Pytdml-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  albert/sequence_classification/pytorch-Imdb-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  phi1/sequence_classification/pytorch-Phi_1-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  swin/image_classification/pytorch-T-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  swin/image_classification/pytorch-S-single_device-training:
    status: EXCLUDE_MODEL # Model too large for single device training
  swin/image_classification/pytorch-B-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  swin/image_classification/pytorch-v2_T-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  swin/image_classification/pytorch-v2_S-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  swin/image_classification/pytorch-v2_B-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  deit/pytorch-Base-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  deit/pytorch-Base_Distilled-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  deit/pytorch-Small-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  deit/pytorch-Tiny-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  bart/pytorch-Large-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  roberta/pytorch-Base_Sentiment-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  bert/sequence_classification/pytorch-Base_Uncased_Sst_2-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  sam/pytorch-Vit_Base-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  sam/pytorch-Vit_Large-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  sam/pytorch-Vit_Huge-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  mamba/pytorch-370M_HF-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  mamba/pytorch-790M_HF-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  mamba/pytorch-1.4b_HF-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  roberta/masked_lm/pytorch-Xlm_Base-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  unet/pytorch-Cityscapes-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vilt/masked_lm/pytorch-Mlm-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Fatal Python error: Floating point exception"
  vilt/question_answering/pytorch-Vqa-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Fatal Python error: Floating point exception"
  llama/sequence_classification/pytorch-3.2_1B-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  llama/sequence_classification/pytorch-3.2_1B_Instruct-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  opt/sequence_classification/pytorch-125M-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  opt/sequence_classification/pytorch-350M-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  opt/sequence_classification/pytorch-1.3b-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  gpt2/pytorch-Sequence_Classification-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  resnext/pytorch-50_32x4d-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  resnext/pytorch-101_32x8d-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  resnext/pytorch-101_32x8d_Wsl-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  resnext/pytorch-14_32x4d_Osmr-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  resnext/pytorch-26_32x4d_Osmr-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  resnext/pytorch-50_32x4d_Osmr-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  resnext/pytorch-101_64x4d_Osmr-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  rcnn/pytorch-Alexnet-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vovnet/pytorch-27s-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vovnet/pytorch-39-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vovnet/pytorch-57-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vovnet/pytorch-39_Th-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vovnet/pytorch-57_Th-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vovnet/pytorch-Ese_Vovnet19b_Dw-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vovnet/pytorch-Ese_Vovnet39b-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vovnet/pytorch-Ese_Vovnet99b-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vovnet/pytorch-Ese_Vovnet19b_Dw.ra_In1k-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    markers: [notimeout]
    reason: "Fatal Python error: ElementsAttr does not provide iteration facilities for type `int` (https://github.com/tenstorrent/tt-xla/issues/3109)"
  inception/pytorch-v4-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  inception/pytorch-V4.tf_In1k-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  inception/pytorch-v4_OSMR-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  dla/pytorch-34.in1k-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  googlenet/pytorch-Default-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "RuntimeError: Test Hangs"
  resnet/pytorch-ResNet50_HuggingFace-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  resnet/pytorch-ResNet50_HuggingFace_High_Resolution-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Not enough space to allocate 2147483648 B DRAM buffer across 12 banks, where each bank needs to store 178958336 B, but bank size is only 1073741792 B"
  resnet/pytorch-ResNet50_TIMM-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  resnet/pytorch-ResNet50_TIMM_High_Resolution-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  resnet/pytorch-ResNet18-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  resnet/pytorch-ResNet34-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  resnet/pytorch-ResNet50-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  resnet/pytorch-ResNet50_High_Resolution-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  resnet/pytorch-ResNet101-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  resnet/pytorch-ResNet152-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  hardnet/pytorch-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
    reason: "RuntimeError: TT_FATAL conv2d"
  perceiverio_vision/pytorch-Vision_Perceiver_Conv-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "RuntimeError: Test Hangs"
  wide_resnet/pytorch-50.2-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  wide_resnet/pytorch-101.2-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  wide_resnet/pytorch-50_2.timm-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  wide_resnet/pytorch-101_2.timm-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  alexnet/pytorch-Default-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  alexnet/pytorch-B-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  autoencoder/pytorch-conv-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vgg/pytorch-11-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vgg/pytorch-13-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vgg/pytorch-16-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
    reason: "RuntimeError: TT_FATAL conv2d"
  vgg/pytorch-19-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vgg/pytorch-Bn_Vgg19-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vgg/pytorch-Bn_Vgg19b-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vgg/pytorch-19_Bn-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vgg/pytorch-Timm_Vgg19_Bn-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vgg/pytorch-Torchvision_Vgg11-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vgg/pytorch-Torchvision_Vgg11_Bn-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vgg/pytorch-Torchvision_Vgg13-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vgg/pytorch-Torchvision_Vgg13_Bn-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vgg/pytorch-Torchvision_Vgg16-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vgg/pytorch-Torchvision_Vgg16_Bn-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vgg/pytorch-Torchvision_Vgg19-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vgg/pytorch-Torchvision_Vgg19_Bn-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vgg/pytorch-HF_Vgg19-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  unet/pytorch-Torchhub_Brain_Unet-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  unet/pytorch-Carvana_Unet-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  distilbert/masked_lm/pytorch-Base_Cased-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  distilbert/masked_lm/pytorch-Base_Uncased-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  distilbert/masked_lm/pytorch-Base_Multilingual_Cased-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  distilbert/token_classification/pytorch-Davlan/distilbert-base-multilingual-cased-ner-hrl-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  vgg19_unet/pytorch-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Statically allocated circular buffers in program 284 clash with L1 buffers on core range [(x=0,y=0) - (x=7,y=7)]"
  qwen_3/causal_lm/pytorch-0_6B-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  phi1_5/causal_lm/pytorch-Phi_1_5-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Statically allocated circular buffers in program 284 clash with L1 buffers on core range [(x=0,y=0) - (x=7,y=7)]"
  gpt_neo/causal_lm/pytorch-125M-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  phi2/causal_lm/pytorch-Phi_2-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Statically allocated circular buffers in program 284 clash with L1 buffers on core range [(x=0,y=0) - (x=7,y=7)]"
  phi2/causal_lm/pytorch-Phi_2_Pytdml-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  albert/masked_lm/pytorch-Base_v1-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AssertionError: CPU and TT have different None grad parameters: set() != {'predictions.bias'}"
  albert/masked_lm/pytorch-Xlarge_v1-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AssertionError: CPU and TT have different None grad parameters: set() != {'predictions.bias'}"
  albert/masked_lm/pytorch-Xxlarge_v1-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AssertionError: CPU and TT have different None grad parameters: set() != {'predictions.bias'}"
  albert/masked_lm/pytorch-Base_v2-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  albert/masked_lm/pytorch-Large_v2-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AssertionError: CPU and TT have different None grad parameters: set() != {'predictions.bias'}"
  albert/masked_lm/pytorch-Xlarge_v2-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AssertionError: CPU and TT have different None grad parameters: set() != {'predictions.bias'}"
  albert/masked_lm/pytorch-Xxlarge_v2-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AssertionError: CPU and TT have different None grad parameters: set() != {'predictions.bias'}"
  albert/token_classification/pytorch-Base_v1-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  albert/token_classification/pytorch-Large_v1-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  albert/token_classification/pytorch-Xlarge_v1-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  albert/token_classification/pytorch-Xxlarge_v1-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  albert/token_classification/pytorch-Base_v2-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  albert/token_classification/pytorch-Large_v2-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  albert/token_classification/pytorch-Xlarge_v2-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  albert/token_classification/pytorch-Xxlarge_v2-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  xglm/pytorch-564M-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  xglm/pytorch-1.7b-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  densenet/pytorch-121_Xray-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "RuntimeError: Index put requires the source and destination dtypes match, got Float for the destination and BFloat16 for the source."
  opt/causal_lm/pytorch-125M-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  opt/causal_lm/pytorch-350M-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  opt/causal_lm/pytorch-1.3b-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  beit/pytorch-Base-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  beit/pytorch-Large-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  phi1/causal_lm/pytorch-Phi_1-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [large, notimeout]
  perceiverio_vision/pytorch-Vision_Perceiver_Learned-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  perceiverio_vision/pytorch-Vision_Perceiver_Fourier-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  d_fine/pytorch-Nano-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  d_fine/pytorch-Small-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  d_fine/pytorch-Medium-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  d_fine/pytorch-Large-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  d_fine/pytorch-Xlarge-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  bert/masked_lm/pytorch-Base_Uncased-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AssertionError: CPU and TT have different None grad parameters: set() != {'cls.predictions.bias'}"
  bert/token_classification/pytorch-dbmdz/bert-large-cased-finetuned-conll03-english-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mlp_mixer/pytorch-Mixer_B16_224-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mlp_mixer/pytorch-Mixer_B16_224_In21k-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mlp_mixer/pytorch-Mixer_B16_224_Miil-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mlp_mixer/pytorch-Mixer_B16_224_Miil_In21k-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mlp_mixer/pytorch-Mixer_L16_224-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mlp_mixer/pytorch-Mixer_L16_224_In21k-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mlp_mixer/pytorch-Mixer_S16_224-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mlp_mixer/pytorch-Mixer_B16_224.goog_In21k-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mlp_mixer/pytorch-Mixer_Github-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mlp_mixer/lucidrains/pytorch-Base-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  perceiver/pytorch-Language_Perceiver-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  gpt2/pytorch-Default-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  openpose/v2/pytorch-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  hrnet/pytorch-W18_Small-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  hrnet/pytorch-W18_Small_v2-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  hrnet/pytorch-W18-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  hrnet/pytorch-W30-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  hrnet/pytorch-W32-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  hrnet/pytorch-W40-single_device-training:
    status: NOT_SUPPORTED_SKIP
    reason: "SEGFAULT"
  hrnet/pytorch-W44-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  hrnet/pytorch-W48-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  hrnet/pytorch-W64-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  hrnet/pytorch-W18.ms_Aug_In1k-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  hrnet/pytorch-W18_Small_v1_Osmr-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  hrnet/pytorch-W18_Small_v2_Osmr-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  hrnet/pytorch-v2_W18_Osmr-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  hrnet/pytorch-v2_W30_Osmr-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  hrnet/pytorch-v2_W32_Osmr-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  hrnet/pytorch-v2_W40_Osmr-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  hrnet/pytorch-v2_W44_Osmr-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  hrnet/pytorch-v2_W48_Osmr-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  hrnet/pytorch-v2_W64_Osmr-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  glpn_kitti/pytorch-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  albert/masked_lm/pytorch-Large_v1-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AssertionError: CPU and TT have different None grad parameters: set() != {'predictions.bias'}"
  segformer/pytorch-Mit_B0-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Not enough space to allocate 12435456 B L1 buffer across 3 banks, where each bank needs to store 4145152 B, but bank size is only 1331392 B"
  segformer/pytorch-Mit_B1-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  segformer/pytorch-Mit_B2-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "RuntimeError: Test Hangs (Runs for 3 hours)"
  segformer/pytorch-Mit_B3-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "RuntimeError: Test Hangs"
  segformer/pytorch-Mit_B4-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "RuntimeError: Test Hangs"
  segformer/pytorch-Mit_B5-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "RuntimeError: Test Hangs"
  ghostnet/pytorch-100-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  ghostnet/pytorch-100.in1k-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  ghostnet/pytorch-v2_100.in1k-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  efficientnet_lite/pytorch-Tf_Efficientnet_Lite0.in1k-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  efficientnet_lite/pytorch-Tf_Efficientnet_Lite1.in1k-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  efficientnet_lite/pytorch-Tf_Efficientnet_Lite2.in1k-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  efficientnet_lite/pytorch-Tf_Efficientnet_Lite3.in1k-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  efficientnet_lite/pytorch-Tf_Efficientnet_Lite4.in1k-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  monodepth2/pytorch-Mono_640x192-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  monodepth2/pytorch-Stereo_640x192-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  monodepth2/pytorch-Mono+stereo_640x192-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  monodepth2/pytorch-Mono_No_Pt_640x192-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  monodepth2/pytorch-Stereo_No_Pt_640x192-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Out of Memory: Not enough space to allocate 262144000 B DRAM buffer across 12 banks, where each bank needs to store 21846016 B, but bank size is only 1073741792 B"
  monodepth2/pytorch-Mono+stereo_No_Pt_640x192-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  monodepth2/pytorch-Mono_1024x320-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  monodepth2/pytorch-Stereo_1024x320-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  monodepth2/pytorch-Mono+stereo_1024x320-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  efficientnet/pytorch-B0-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  efficientnet/pytorch-B1-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  efficientnet/pytorch-B2-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  efficientnet/pytorch-B3-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  efficientnet/pytorch-B4-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  efficientnet/pytorch-B5-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  efficientnet/pytorch-B6-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  efficientnet/pytorch-B7-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  efficientnet/pytorch-Timm_B0-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  efficientnet/pytorch-Timm_B4-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  efficientnet/pytorch-Timm_B0_Ra_In1k-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  efficientnet/pytorch-Timm_B4_Ra2_In1k-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  efficientnet/pytorch-Timm_B5_In12k_Ft_In1k-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  efficientnet/pytorch-Timm_Tf_B0_Aa_In1k-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  efficientnet/pytorch-Timm_V2_Rw_S_Ra2_In1k-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  efficientnet/pytorch-Timm_Tf_V2_S_In21k-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  mobilenetv1/pytorch-Mobilenet_v1-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mobilenetv1/pytorch-100.ra4_E3600_R224_In1k-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  unet_for_conditional_generation/pytorch-Base-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Out of Memory: Not enough space to allocate 125829120 B DRAM buffer across 12 banks, where each bank needs to store 10485760 B"
    markers: [large]
  whisper/pytorch-Tiny-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds."
  whisper/pytorch-Base-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds."
  whisper/pytorch-Small-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds."
  whisper/pytorch-Medium-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds."
  whisper/pytorch-Large-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds."
  whisper/pytorch-Large_v3_Turbo-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds."
  mobilenetv3/pytorch-Mobilenet_v3_Large-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mobilenetv3/pytorch-Mobilenet_v3_Small-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mobilenetv3/pytorch-Large_100-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mobilenetv3/pytorch-Small_100-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  xception/pytorch-41-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  xception/pytorch-65-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  xception/pytorch-71-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  xception/pytorch-71.tf_In1k-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  regnet/pytorch-Y_040-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  regnet/pytorch-Y_064-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  regnet/pytorch-Y_080-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  regnet/pytorch-Y_120-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  regnet/pytorch-Y_160-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  regnet/pytorch-Y_320-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
    reason: "error: 'ttir.conv_transpose2d' op Number of input channels from input tensor must match the first dimension of the weight tensor. Got 3712 input channels and 232 in the weight tensor."
  regnet/pytorch-Y_400mf-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  regnet/pytorch-Y_800mf-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  regnet/pytorch-Y_1_6gf-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  regnet/pytorch-Y_3_2gf-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  regnet/pytorch-Y_8gf-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  regnet/pytorch-Y_16gf-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  regnet/pytorch-Y_32gf-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  regnet/pytorch-Y_128gf-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  regnet/pytorch-X_400mf-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  regnet/pytorch-X_800mf-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  regnet/pytorch-X_1_6gf-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  regnet/pytorch-X_3_2gf-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  regnet/pytorch-X_8gf-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  regnet/pytorch-X_16gf-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  regnet/pytorch-X_32gf-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mobilenetv2/pytorch-Mobilenet_v2-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mobilenetv2/pytorch-Mobilenet_v2_0.35_96-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mobilenetv2/pytorch-Mobilenet_v2_0.75_160-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mobilenetv2/pytorch-Mobilenet_v2_1.0_224-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mobilenetv2/pytorch-100-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  mobilenetv2/pytorch-Mobilenet_v2_Torchvision-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  qwen_3/causal_lm/pytorch-1_7B-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Out of Memory: Not enough space to allocate 1048576000 B DRAM buffer across 12 banks"
  phi2/token_classification/pytorch-Phi_2_Pytdml-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  gemma/pytorch-1.1_2B_IT-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Out of Memory: Not enough space to allocate 1048576000 B DRAM buffer across 12 banks"
  gemma/pytorch-2B-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "RuntimeError: Test Hangs"
  gemma/pytorch-2_2B_IT-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Out of Memory: Not enough space to allocate 1048576000 B DRAM buffer across 12 banks"
  mamba/pytorch-2.8b_HF-single_device-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "Model timed out during compilation - https://github.com/tenstorrent/tt-mlir/issues/6563"
    markers: [notimeout]
  qwen_2_5_coder/pytorch-1.5B-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
  qwen_2_5_coder/pytorch-1.5B_Instruct-single_device-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [notimeout]
