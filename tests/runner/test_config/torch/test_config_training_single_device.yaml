# SPDX-FileCopyrightText: (c) 2025 Tenstorrent AI ULC
#
# SPDX-License-Identifier: Apache-2.0
test_config:
  mnist/image_classification/pytorch-cnn_dropout-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [push, nightly]
  mnist/image_classification/pytorch-cnn_nodropout-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [push, nightly]
  autoencoder/pytorch-linear-single_device-full-training:
    status: EXPECTED_PASSING
    markers: [push, nightly]
  qwen_1_5/causal_lm/pytorch-0_5b-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  qwen_1_5/causal_lm/pytorch-0_5b_chat-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  t5/pytorch-t5-small-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  t5/pytorch-t5-base-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  t5/pytorch-t5-large-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  t5/pytorch-google/flan-t5-small-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  t5/pytorch-google/flan-t5-base-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  t5/pytorch-google/flan-t5-large-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  qwen_2_5/causal_lm/pytorch-0_5b-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  qwen_2_5/causal_lm/pytorch-0_5b_instruct-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  qwen_2_5/causal_lm/pytorch-1_5b-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  qwen_2_5/causal_lm/pytorch-1_5b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Node arity mismatch; expected 339, but got 338"
  llama/causal_lm/pytorch-llama_3_2_1b-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  llama/causal_lm/pytorch-llama_3_2_1b_instruct-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  qwen_2_5_coder/pytorch-0_5b-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  clip/pytorch-base_patch32-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
    reason: "error: failed to legalize operation 'stablehlo.scatter'"
  falcon/pytorch-tiiuae/Falcon3-1B-Base-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [large]
  nbeats/pytorch-generic_basis-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  nbeats/pytorch-seasonality_basis-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  nbeats/pytorch-trend_basis-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  qwen_3/embedding/pytorch-embedding_0_6b-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  phi1_5/token_classification/pytorch-microsoft/phi-1_5-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  phi1/token_classification/pytorch-microsoft/phi-1-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  nanogpt/pytorch-FinancialSupport/NanoGPT-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  dpr/reader/pytorch-facebook/dpr-reader-single-nq-base-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  dpr/reader/pytorch-facebook/dpr-reader-multiset-base-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  musicgen_small/pytorch-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  stereo/pytorch-small-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  stereo/pytorch-medium-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  stereo/pytorch-large-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  oft/pytorch-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Statically allocated circular buffers on core range [(x=0,y=0) - (x=0,y=3)] grow to 1518400 B which is beyond max L1 size of 1499136 B"
  mlp_mixer/pytorch-mixer_b32_224-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mlp_mixer/pytorch-mixer_l32_224-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mlp_mixer/pytorch-mixer_s32_224-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  stable_diffusion_unet/pytorch-base-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "RuntimeError: Test Hangs"
  centernet/pytorch-resnet18_coco-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "RuntimeError: 'deformable_im2col' not implemented for 'BFloat16'"
  centernet/pytorch-resnet101_coco-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "RuntimeError: 'deformable_im2col' not implemented for 'BFloat16'"
  centernet/pytorch-dla1x_coco-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "RuntimeError: 'deformable_im2col' not implemented for 'BFloat16'"
  centernet/pytorch-dla2x_coco-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "RuntimeError: 'deformable_im2col' not implemented for 'BFloat16'"
  vadv2/pytorch-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "RuntimeError: Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment."
  monodle/pytorch-dla34-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Dataset 'imagenet-1k' is a gated dataset on the Hub."
  uniad/pytorch-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "TypeError: list indices must be integers or slices, not tuple"
  mobilenetv1/pytorch-google/mobilenet_v1_0.75_192-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Dataset 'imagenet-1k' is a gated dataset on the Hub."
  mobilenetv1/pytorch-google/mobilenet_v1_1.0_224-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Dataset 'imagenet-1k' is a gated dataset on the Hub."
  speecht5/pytorch-tts-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "RuntimeError: mat1 and mat2 must have the same dtype, but got Float and BFloat16"
  rmbg/pytorch-2_0-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "ImportError: kornia"
  ssdlite320_mobilenetv3/pytorch-ssdlite320_mobilenet_v3_large-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AssertionError: targets should not be none when in training mode"
  resnext/pytorch-resnext101_64x4d-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "RuntimeError: Cannot find callable resnext101_64x4d in hubconf"
  ssd300_vgg16/pytorch-ssd300_vgg16-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AssertionError: targets should not be none when in training mode"
  bi_lstm_crf/pytorch-default-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "RuntimeError: The tensor has a non-zero number of elements, but its data is not allocated yet."
  ssd300_resnet50/pytorch-base-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AttributeError: 'NoneType' object has no attribute 'max'"
  oft_stable_diffusion/pytorch-runwayml/stable-diffusion-v1-5-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AttributeError: 'NoneType' object has no attribute 'max'"
  retinanet/pytorch-retinanet_resnet50_fpn_v2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AttributeError: 'NoneType' object has no attribute 'max'"
  gliner/pytorch-urchade/gliner_multi-v2.1-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AttributeError: 'NoneType' object has no attribute 'max'"
  # yolov5/pytorch-yolov5n-single_device-full-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "TypeError: AutoShape.forward() takes from 2 to 5 positional arguments but 7 were given"
  # yolov5/pytorch-yolov5s-single_device-full-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "TypeError: AutoShape.forward() takes from 2 to 5 positional arguments but 7 were given"
  # yolov5/pytorch-yolov5m-single_device-full-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "TypeError: AutoShape.forward() takes from 2 to 5 positional arguments but 7 were given"
  # yolov5/pytorch-yolov5l-single_device-full-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "TypeError: AutoShape.forward() takes from 2 to 5 positional arguments but 7 were given"
  # yolov5/pytorch-yolov5x-single_device-full-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "TypeError: AutoShape.forward() takes from 2 to 5 positional arguments but 7 were given"
  whisper/pytorch-openai/whisper-large-v3-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "RuntimeError: Could not load libtorchcodec. Likely causes:"
  yolox/pytorch-yolox_x-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "EOFError: Ran out of input"
  unet/pytorch-smp_unet_resnet101-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "ModuleNotFoundError: No module named 'segmentation_models_pytorch'"
  mobilenetv2/pytorch-google/deeplabv3_mobilenet_v2_1.0_513-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1, 1])"
  bge_m3/encode/pytorch-base-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "loader.load_model() does not return `nn.Module`"
  stable_diffusion_1_4/pytorch-base-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "loader.load_model() does not return `nn.Module`"
  gliner/pytorch-urchade/gliner_largev2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "loader.load_model() does not return `nn.Module`"
  yolox/pytorch-yolox_nano-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Model expects targets to be passed while in training mode"
  yolox/pytorch-yolox_tiny-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Model expects targets to be passed while in training mode"
  yolox/pytorch-yolox_s-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Model expects targets to be passed while in training mode"
  yolox/pytorch-yolox_m-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Model expects targets to be passed while in training mode"
  yolox/pytorch-yolox_l-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Model expects targets to be passed while in training mode"
  yolox/pytorch-yolox_darknet-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Model expects targets to be passed while in training mode"
  hippynn/pytorch-Hippynn-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "loader.load_model() does not return `nn.Module`"
  yolov6/pytorch-yolov6n-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  yolov6/pytorch-yolov6s-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  yolov6/pytorch-yolov6m-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  distilbert/question_answering/pytorch-distilbert-base-cased-distilled-squad-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  pointpillars/pytorch-pointpillars-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Statically allocated circular buffers on core range [(x=0,y=0) - (x=7,y=7)] grow to 2003264 B which is beyond max L1 size of 1499136 B"
  fpn/pytorch-resnet50_fpn_v2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  # yolov10/pytorch-yolov10x-single_device-full-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  # yolov10/pytorch-yolov10n-single_device-full-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  # yolov11/pytorch-yolo11n-single_device-full-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  # yolov11/pytorch-yolo11s-single_device-full-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  # yolov11/pytorch-yolo11m-single_device-full-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  # yolov11/pytorch-yolo11l-single_device-full-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  # yolov11/pytorch-yolo11x-single_device-full-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  albert/question_answering/pytorch-squad2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  bge_m3/pytorch-base-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  opt/qa/pytorch-facebook/opt-125m-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  opt/qa/pytorch-facebook/opt-350m-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  opt/qa/pytorch-facebook/opt-1.3b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  segformer/semantic_segmentation/pytorch-b0_finetuned_ade_512_512-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  segformer/semantic_segmentation/pytorch-b2_finetuned_ade_512_512-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  segformer/semantic_segmentation/pytorch-b3_finetuned_ade_512_512-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  segformer/semantic_segmentation/pytorch-b4_finetuned_ade_512_512-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  mgp_str_base/pytorch-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  yolos/pytorch-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  swin/image_classification/pytorch-microsoft/swin-tiny-patch4-window7-224-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  swin/image_classification/pytorch-microsoft/swinv2-tiny-patch4-window8-256-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  swin/masked_image_modeling/pytorch-microsoft/swinv2-tiny-patch4-window8-256-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  # yolov8/pytorch-yolov8x-single_device-full-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  yolov9/pytorch-t-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  yolov9/pytorch-s-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  yolov9/pytorch-m-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  yolov9/pytorch-c-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  yolov9/pytorch-e-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  retinanet/pytorch-retinanet_rn18fpn-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  retinanet/pytorch-retinanet_rn34fpn-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  retinanet/pytorch-retinanet_rn50fpn-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  retinanet/pytorch-retinanet_rn101fpn-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  retinanet/pytorch-retinanet_rn152fpn-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  bert/question_answering/pytorch-phiyodr/bert-large-finetuned-squad2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  bert/question_answering/pytorch-bert-large-cased-whole-word-masking-finetuned-squad-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  bert/sentence_embedding_generation/pytorch-emrecan/bert-base-turkish-cased-mean-nli-stsb-tr-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
    reason: "error: 'ttnn.pad' op Output tensor shape (32,768) must match the inferred shape: (47,768)"
  dpr/context_encoder/pytorch-facebook/dpr-ctx_encoder-single-nq-base-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  dpr/context_encoder/pytorch-facebook/dpr-ctx_encoder-multiset-base-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  dpr/question_encoder/pytorch-facebook/dpr-question_encoder-single-nq-base-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  dpr/question_encoder/pytorch-facebook/dpr-question_encoder-multiset-base-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  centernet/pytorch-hourglass_coco-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Buffer must be allocated on device"
  yolov6/pytorch-yolov6l-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  maptr/pytorch-tiny_r50_24e_bevformer-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
    reason: "'func.call' op incorrect number of operands for callee"
  maptr/pytorch-tiny_r50_24e_bevformer_t4-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  maptr/pytorch-tiny_r50_24e-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  maptr/pytorch-tiny_r50_110e-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  maptr/pytorch-tiny_r50_24e_t4-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  maptr/pytorch-nano_r18_110e-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  maptr/pytorch-tiny_r50_24e_bevpool-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  maptr/pytorch-tiny_fusion_24e-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  yolov3/pytorch-base-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  transfuser/pytorch-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
    reason: "'func.call' op incorrect number of operands for callee"
  # yoloworld/pytorch-single_device-full-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  segformer/semantic_segmentation/pytorch-b1_finetuned_ade_512_512-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  bevdepth/pytorch-bev_depth_lss_r50_256x704_128x128_24e_2key-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Statically allocated circular buffers on core range [(x=0,y=0) - (x=7,y=7)] grow to 2396480 B which is beyond max L1 size of 1499136 B (assert.hpp:103)"
  bevdepth/pytorch-bev_depth_lss_r50_256x704_128x128_24e_2key_ema-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  bevdepth/pytorch-bev_depth_lss_r50_256x704_128x128_20e_cbgs_2key_da-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  bevdepth/pytorch-bev_depth_lss_r50_256x704_128x128_20e_cbgs_2key_da_ema-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  detr3d/pytorch-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 285081600 B L1 buffer across 64 banks, where each bank needs to store 4454400 B, but bank size is only 1330944 B"
  # yolov8/pytorch-yolov8n-single_device-full-training:
  #   status: NOT_SUPPORTED_SKIP
  #   bringup_status: FAILED_FE_COMPILATION
  #   reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  yolov4/pytorch-base-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Statically allocated circular buffers on core range [(x=7,y=6) - (x=7,y=6)] grow to 2371840 B which is beyond max L1 size of 1499136 B (assert.hpp:103)"
  detr/object_detection/pytorch-resnet_50-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  detr/segmentation/pytorch-resnet_50_panoptic-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  dla/pytorch-dla34-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  dla/pytorch-dla46_c-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  dla/pytorch-dla46x_c-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  dla/pytorch-dla60-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  dla/pytorch-dla60x-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  dla/pytorch-dla60x_c-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  dla/pytorch-dla102-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  dla/pytorch-dla102x-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  dla/pytorch-dla102x2-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  dla/pytorch-dla169-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  densenet/pytorch-densenet121-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  densenet/pytorch-densenet161-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  densenet/pytorch-densenet169-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  densenet/pytorch-densenet201-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  codegen/pytorch-Salesforce/codegen-350M-mono-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  codegen/pytorch-Salesforce/codegen-350M-multi-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  codegen/pytorch-Salesforce/codegen-350M-nl-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  squeezebert/pytorch-squeezebert-mnli-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  distilbert/sequence_classification/pytorch-distilbert-base-uncased-finetuned-sst-2-english-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vit/pytorch-base-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vit/pytorch-large-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vit/pytorch-vit_b_16-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vit/pytorch-vit_b_32-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vit/pytorch-vit_l_16-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vit/pytorch-vit_l_32-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vit/pytorch-vit_h_14-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  maptr/pytorch-tiny_r50_24e_av2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  phi1_5/sequence_classification/pytorch-microsoft/phi-1_5-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  gpt_neo/sequence_classification/pytorch-gpt_neo_125M-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  phi2/sequence_classification/pytorch-microsoft/phi-2-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  phi2/sequence_classification/pytorch-microsoft/phi-2-pytdml-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  albert/sequence_classification/pytorch-imdb-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  phi1/sequence_classification/pytorch-microsoft/phi-1-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  swin/image_classification/pytorch-swin_t-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  swin/image_classification/pytorch-swin_s-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  swin/image_classification/pytorch-swin_b-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  swin/image_classification/pytorch-swin_v2_t-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  swin/image_classification/pytorch-swin_v2_s-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  swin/image_classification/pytorch-swin_v2_b-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  deit/pytorch-base-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  deit/pytorch-base_distilled-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  deit/pytorch-small-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  deit/pytorch-tiny-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  bart/pytorch-large-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  roberta/pytorch-cardiffnlp/twitter-roberta-base-sentiment-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  bert/sequence_classification/pytorch-textattack/bert-base-uncased-SST-2-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  sam/pytorch-facebook/sam-vit-base-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  sam/pytorch-facebook/sam-vit-large-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  sam/pytorch-facebook/sam-vit-huge-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  mamba/pytorch-mamba-370m-hf-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mamba/pytorch-mamba-790m-hf-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mamba/pytorch-mamba-1.4b-hf-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  roberta/masked_lm/pytorch-xlm_base-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  unet/pytorch-unet_cityscapes-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vilt/masked_lm/pytorch-mlm-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Fatal Python error: Floating point exception"
  vilt/question_answering/pytorch-vqa-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Fatal Python error: Floating point exception"
  llama/sequence_classification/pytorch-llama_3_2_1b-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  llama/sequence_classification/pytorch-llama_3_2_1b_instruct-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  opt/sequence_classification/pytorch-facebook/opt-125m-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  opt/sequence_classification/pytorch-facebook/opt-350m-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  opt/sequence_classification/pytorch-facebook/opt-1.3b-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  gpt2/pytorch-gpt2_sequence_classification-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  resnext/pytorch-resnext50_32x4d-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  resnext/pytorch-resnext101_32x8d-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  resnext/pytorch-resnext101_32x8d_wsl-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  resnext/pytorch-resnext14_32x4d_osmr-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  resnext/pytorch-resnext26_32x4d_osmr-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  resnext/pytorch-resnext50_32x4d_osmr-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  resnext/pytorch-resnext101_64x4d_osmr-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  rcnn/pytorch-alexnet-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vovnet/pytorch-vovnet27s-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vovnet/pytorch-vovnet39-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vovnet/pytorch-vovnet57-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vovnet/pytorch-vovnet39_th-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vovnet/pytorch-vovnet57_th-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vovnet/pytorch-ese_vovnet19b_dw-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vovnet/pytorch-ese_vovnet39b-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vovnet/pytorch-ese_vovnet99b-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vovnet/pytorch-ese_vovnet19b_dw.ra_in1k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  inception/pytorch-inception_v4-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  inception/pytorch-inception_v4.tf_in1k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  inception/pytorch-inceptionv4-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  dla/pytorch-dla34.in1k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  googlenet/pytorch-googlenet-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "RuntimeError: Test Hangs"
  resnet/pytorch-resnet_50_hf-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  resnet/pytorch-resnet_50_hf_high_res-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Not enough space to allocate 2147483648 B DRAM buffer across 12 banks, where each bank needs to store 178958336 B, but bank size is only 1073741792 B"
  resnet/pytorch-resnet50_timm-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  resnet/pytorch-resnet50_timm_high_res-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  resnet/pytorch-resnet18-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  resnet/pytorch-resnet34-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  resnet/pytorch-resnet50-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  resnet/pytorch-resnet50_high_res-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  resnet/pytorch-resnet101-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  resnet/pytorch-resnet152-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  hardnet/pytorch-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError: TT_FATAL conv2d"
  perceiverio_vision/pytorch-deepmind/vision-perceiver-conv-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "RuntimeError: Test Hangs"
  wide_resnet/pytorch-wide_resnet50_2-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  wide_resnet/pytorch-wide_resnet101_2-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  wide_resnet/pytorch-wide_resnet50_2.timm-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  wide_resnet/pytorch-wide_resnet101_2.timm-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  alexnet/pytorch-alexnet-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  alexnet/pytorch-alexnetb-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  autoencoder/pytorch-conv-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vgg/pytorch-vgg11-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vgg/pytorch-vgg13-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vgg/pytorch-vgg16-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError: TT_FATAL conv2d"
  vgg/pytorch-vgg19-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vgg/pytorch-bn_vgg19-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vgg/pytorch-bn_vgg19b-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vgg/pytorch-vgg19_bn-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vgg/pytorch-timm_vgg19_bn-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vgg/pytorch-torchvision_vgg11-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vgg/pytorch-torchvision_vgg11_bn-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vgg/pytorch-torchvision_vgg13-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vgg/pytorch-torchvision_vgg13_bn-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vgg/pytorch-torchvision_vgg16-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vgg/pytorch-torchvision_vgg16_bn-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vgg/pytorch-torchvision_vgg19-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vgg/pytorch-torchvision_vgg19_bn-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vgg/pytorch-hf_vgg19-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  unet/pytorch-torchhub_brain_unet-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  unet/pytorch-carvana_unet-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  distilbert/masked_lm/pytorch-distilbert-base-cased-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  distilbert/masked_lm/pytorch-distilbert-base-uncased-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  distilbert/masked_lm/pytorch-distilbert-base-multilingual-cased-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  distilbert/token_classification/pytorch-Davlan/distilbert-base-multilingual-cased-ner-hrl-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  vgg19_unet/pytorch-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Statically allocated circular buffers in program 284 clash with L1 buffers on core range [(x=0,y=0) - (x=7,y=7)]"
  qwen_3/causal_lm/pytorch-0_6b-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  phi1_5/causal_lm/pytorch-microsoft/phi-1_5-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Statically allocated circular buffers in program 284 clash with L1 buffers on core range [(x=0,y=0) - (x=7,y=7)]"
  gpt_neo/causal_lm/pytorch-gpt_neo_125M-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  phi2/causal_lm/pytorch-microsoft/phi-2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Statically allocated circular buffers in program 284 clash with L1 buffers on core range [(x=0,y=0) - (x=7,y=7)]"
  phi2/causal_lm/pytorch-microsoft/phi-2-pytdml-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  albert/masked_lm/pytorch-base_v1-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AssertionError: CPU and TT have different None grad parameters: set() != {'predictions.bias'}"
  albert/masked_lm/pytorch-xlarge_v1-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AssertionError: CPU and TT have different None grad parameters: set() != {'predictions.bias'}"
  albert/masked_lm/pytorch-xxlarge_v1-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AssertionError: CPU and TT have different None grad parameters: set() != {'predictions.bias'}"
  albert/masked_lm/pytorch-base_v2-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  albert/masked_lm/pytorch-large_v2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AssertionError: CPU and TT have different None grad parameters: set() != {'predictions.bias'}"
  albert/masked_lm/pytorch-xlarge_v2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AssertionError: CPU and TT have different None grad parameters: set() != {'predictions.bias'}"
  albert/masked_lm/pytorch-xxlarge_v2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AssertionError: CPU and TT have different None grad parameters: set() != {'predictions.bias'}"
  albert/token_classification/pytorch-base_v1-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  albert/token_classification/pytorch-large_v1-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  albert/token_classification/pytorch-xlarge_v1-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  albert/token_classification/pytorch-xxlarge_v1-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  albert/token_classification/pytorch-base_v2-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  albert/token_classification/pytorch-large_v2-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  albert/token_classification/pytorch-xlarge_v2-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  albert/token_classification/pytorch-xxlarge_v2-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  xglm/pytorch-xglm-564M-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  xglm/pytorch-xglm-1.7B-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  densenet/pytorch-densenet121_xray-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "RuntimeError: Index put requires the source and destination dtypes match, got Float for the destination and BFloat16 for the source."
  opt/causal_lm/pytorch-facebook/opt-125m-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  opt/causal_lm/pytorch-facebook/opt-350m-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  opt/causal_lm/pytorch-facebook/opt-1.3b-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  beit/pytorch-base-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  beit/pytorch-large-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  phi1/causal_lm/pytorch-microsoft/phi-1-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
    markers: [large]
  perceiverio_vision/pytorch-deepmind/vision-perceiver-learned-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  perceiverio_vision/pytorch-deepmind/vision-perceiver-fourier-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  d_fine/pytorch-nano-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  d_fine/pytorch-small-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  d_fine/pytorch-medium-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  d_fine/pytorch-large-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  d_fine/pytorch-xlarge-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "tt-forge-models doesn't implement unpack_forward_output for this model."
  bert/masked_lm/pytorch-bert-base-uncased-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AssertionError: CPU and TT have different None grad parameters: set() != {'cls.predictions.bias'}"
  bert/token_classification/pytorch-dbmdz/bert-large-cased-finetuned-conll03-english-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mlp_mixer/pytorch-mixer_b16_224-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mlp_mixer/pytorch-mixer_b16_224_in21k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mlp_mixer/pytorch-mixer_b16_224_miil-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mlp_mixer/pytorch-mixer_b16_224_miil_in21k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mlp_mixer/pytorch-mixer_l16_224-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mlp_mixer/pytorch-mixer_l16_224_in21k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mlp_mixer/pytorch-mixer_s16_224-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mlp_mixer/pytorch-mixer_b16_224.goog_in21k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mlp_mixer/pytorch-mixer_github-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mlp_mixer/lucidrains/pytorch-base-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  perceiver/pytorch-deepmind/language-perceiver-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  gpt2/pytorch-gpt2-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  openpose/v2/pytorch-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  hrnet/pytorch-hrnet_w18_small-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  hrnet/pytorch-hrnet_w18_small_v2-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  hrnet/pytorch-hrnet_w18-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  hrnet/pytorch-hrnet_w30-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  hrnet/pytorch-hrnet_w32-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  hrnet/pytorch-hrnet_w40-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "SEGFAULT"
  hrnet/pytorch-hrnet_w44-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  hrnet/pytorch-hrnet_w48-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  hrnet/pytorch-hrnet_w64-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  hrnet/pytorch-hrnet_w18.ms_aug_in1k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  hrnet/pytorch-hrnet_w18_small_v1_osmr-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  hrnet/pytorch-hrnet_w18_small_v2_osmr-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  hrnet/pytorch-hrnetv2_w18_osmr-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  hrnet/pytorch-hrnetv2_w30_osmr-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  hrnet/pytorch-hrnetv2_w32_osmr-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  hrnet/pytorch-hrnetv2_w40_osmr-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  hrnet/pytorch-hrnetv2_w44_osmr-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  hrnet/pytorch-hrnetv2_w48_osmr-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  hrnet/pytorch-hrnetv2_w64_osmr-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  glpn_kitti/pytorch-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  albert/masked_lm/pytorch-large_v1-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "AssertionError: CPU and TT have different None grad parameters: set() != {'predictions.bias'}"
  segformer/pytorch-mit_b0-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Not enough space to allocate 12435456 B L1 buffer across 3 banks, where each bank needs to store 4145152 B, but bank size is only 1331392 B"
  segformer/pytorch-mit_b1-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  segformer/pytorch-mit_b2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "RuntimeError: Test Hangs (Runs for 3 hours)"
  segformer/pytorch-mit_b3-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "RuntimeError: Test Hangs"
  segformer/pytorch-mit_b4-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "RuntimeError: Test Hangs"
  segformer/pytorch-mit_b5-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "RuntimeError: Test Hangs"
  ghostnet/pytorch-ghostnet_100-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  ghostnet/pytorch-ghostnet_100.in1k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  ghostnet/pytorch-ghostnetv2_100.in1k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet_lite/pytorch-tf_efficientnet_lite0.in1k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet_lite/pytorch-tf_efficientnet_lite1.in1k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet_lite/pytorch-tf_efficientnet_lite2.in1k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet_lite/pytorch-tf_efficientnet_lite3.in1k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet_lite/pytorch-tf_efficientnet_lite4.in1k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  monodepth2/pytorch-mono_640x192-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  monodepth2/pytorch-stereo_640x192-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  monodepth2/pytorch-mono+stereo_640x192-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  monodepth2/pytorch-mono_no_pt_640x192-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  monodepth2/pytorch-stereo_no_pt_640x192-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Out of Memory: Not enough space to allocate 262144000 B DRAM buffer across 12 banks, where each bank needs to store 21846016 B, but bank size is only 1073741792 B"
  monodepth2/pytorch-mono+stereo_no_pt_640x192-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  monodepth2/pytorch-mono_1024x320-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  monodepth2/pytorch-stereo_1024x320-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  monodepth2/pytorch-mono+stereo_1024x320-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet/pytorch-efficientnet_b0-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet/pytorch-efficientnet_b1-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet/pytorch-efficientnet_b2-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet/pytorch-efficientnet_b3-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet/pytorch-efficientnet_b4-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet/pytorch-efficientnet_b5-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet/pytorch-efficientnet_b6-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet/pytorch-efficientnet_b7-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet/pytorch-timm_efficientnet_b0-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet/pytorch-timm_efficientnet_b4-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet/pytorch-hf_hub_timm_efficientnet_b0_ra_in1k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet/pytorch-hf_hub_timm_efficientnet_b4_ra2_in1k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet/pytorch-hf_hub_timm_efficientnet_b5_in12k_ft_in1k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet/pytorch-hf_hub_timm_tf_efficientnet_b0_aa_in1k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet/pytorch-hf_hub_timm_efficientnetv2_rw_s_ra2_in1k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  efficientnet/pytorch-hf_hub_timm_tf_efficientnetv2_s_in21k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mobilenetv1/pytorch-mobilenet_v1-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mobilenetv1/pytorch-mobilenetv1_100.ra4_e3600_r224_in1k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  unet_for_conditional_generation/pytorch-base-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Out of Memory: Not enough space to allocate 125829120 B DRAM buffer across 12 banks, where each bank needs to store 10485760 B"
    markers: [large]
  whisper/pytorch-openai/whisper-tiny-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds."
  whisper/pytorch-openai/whisper-base-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds."
  whisper/pytorch-openai/whisper-small-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds."
  whisper/pytorch-openai/whisper-medium-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds."
  whisper/pytorch-openai/whisper-large-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds."
  whisper/pytorch-openai/whisper-large-v3-turbo-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds."
  mobilenetv3/pytorch-mobilenet_v3_large-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mobilenetv3/pytorch-mobilenet_v3_small-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mobilenetv3/pytorch-mobilenetv3_large_100-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mobilenetv3/pytorch-mobilenetv3_small_100-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  xception/pytorch-xception41-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  xception/pytorch-xception65-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  xception/pytorch-xception71-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  xception/pytorch-xception71.tf_in1k-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  regnet/pytorch-regnet_y_040-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  regnet/pytorch-regnet_y_064-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  regnet/pytorch-regnet_y_080-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  regnet/pytorch-regnet_y_120-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  regnet/pytorch-regnet_y_160-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  regnet/pytorch-regnet_y_320-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
    reason: "error: 'ttir.conv_transpose2d' op Number of input channels from input tensor must match the first dimension of the weight tensor. Got 3712 input channels and 232 in the weight tensor."
  regnet/pytorch-regnet_y_400mf-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  regnet/pytorch-regnet_y_800mf-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  regnet/pytorch-regnet_y_1_6gf-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  regnet/pytorch-regnet_y_3_2gf-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  regnet/pytorch-regnet_y_8gf-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  regnet/pytorch-regnet_y_16gf-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  regnet/pytorch-regnet_y_32gf-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  regnet/pytorch-regnet_y_128gf-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  regnet/pytorch-regnet_x_400mf-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  regnet/pytorch-regnet_x_800mf-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  regnet/pytorch-regnet_x_1_6gf-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  regnet/pytorch-regnet_x_3_2gf-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  regnet/pytorch-regnet_x_8gf-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  regnet/pytorch-regnet_x_16gf-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  regnet/pytorch-regnet_x_32gf-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mobilenetv2/pytorch-mobilenet_v2-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mobilenetv2/pytorch-google/mobilenet_v2_0.35_96-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mobilenetv2/pytorch-google/mobilenet_v2_0.75_160-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mobilenetv2/pytorch-google/mobilenet_v2_1.0_224-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mobilenetv2/pytorch-mobilenetv2_100-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  mobilenetv2/pytorch-mobilenet_v2_torchvision-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  qwen_3/causal_lm/pytorch-1_7b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Out of Memory: Not enough space to allocate 1048576000 B DRAM buffer across 12 banks"
  phi2/token_classification/pytorch-microsoft/phi-2-pytdml-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  gemma/pytorch-google/gemma-1.1-2b-it-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Out of Memory: Not enough space to allocate 1048576000 B DRAM buffer across 12 banks"
  gemma/pytorch-google/gemma-2b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "RuntimeError: Test Hangs"
  gemma/pytorch-google/gemma-2-2b-it-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Out of Memory: Not enough space to allocate 1048576000 B DRAM buffer across 12 banks"
  mamba/pytorch-mamba-2.8b-hf-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  qwen_2_5_coder/pytorch-1_5b-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
  qwen_2_5_coder/pytorch-1_5b_instruct-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
