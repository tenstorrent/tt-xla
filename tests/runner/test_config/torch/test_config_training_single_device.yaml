# SPDX-FileCopyrightText: (c) 2025 Tenstorrent AI ULC
#
# SPDX-License-Identifier: Apache-2.0

test_config:
  mnist/pytorch-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
    reason: "error: failed to legalize operation 'stablehlo.rng_bit_generator' https://github.com/tenstorrent/tt-mlir/issues/4793"
    bringup_status: FAILED_TTMLIR_COMPILATION
    markers: [push]

  autoencoder/pytorch-linear-single_device-full-training:
    status: EXPECTED_PASSING
    markers: [push]

  qwen_1_5/causal_lm/pytorch-0_5b-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
    bringup_status: FAILED_FE_COMPILATION
    reason: "ValueError: Node arity mismatch; expected 291, but got 290. failed in Comparator"

  clip/pytorch-openai/clip-vit-base-patch32-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
    bringup_status: FAILED_RUNTIME
    reason: "runtime/lib/ttnn/operations/utils/utils.cpp:363: numElements * elementSize == data->size() when calling toTTNNTensor"

  falcon/pytorch-tiiuae/Falcon3-1B-Base-single_device-full-training:
    status: KNOWN_FAILURE_XFAIL
    bringup_status: FAILED_RUNTIME
    reason: "Not enough space to allocate DRAM"

  resnext/pytorch-resnext50_32x4d-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  resnext/pytorch-resnext101_32x8d-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  resnext/pytorch-resnext101_32x8d_wsl-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  resnext/pytorch-resnext14_32x4d_osmr-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  resnext/pytorch-resnext26_32x4d_osmr-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  resnext/pytorch-resnext50_32x4d_osmr-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  resnext/pytorch-resnext101_64x4d_osmr-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  rcnn/pytorch-alexnet-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vovnet/pytorch-vovnet27s-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vovnet/pytorch-vovnet39-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vovnet/pytorch-vovnet57-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vovnet/pytorch-vovnet39_th-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vovnet/pytorch-vovnet57_th-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vovnet/pytorch-ese_vovnet19b_dw-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vovnet/pytorch-ese_vovnet39b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vovnet/pytorch-ese_vovnet99b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vovnet/pytorch-ese_vovnet19b_dw.ra_in1k-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  inception/pytorch-inception_v4-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  inception/pytorch-inception_v4.tf_in1k-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  inception/pytorch-inceptionv4-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  dla/pytorch-dla34.in1k-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  googlenet/pytorch-googlenet-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  resnet/pytorch-resnet_50_hf-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  resnet/pytorch-resnet_50_hf_high_res-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  resnet/pytorch-resnet50_timm-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  resnet/pytorch-resnet50_timm_high_res-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  resnet/pytorch-resnet18-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  resnet/pytorch-resnet34-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  resnet/pytorch-resnet50-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  resnet/pytorch-resnet50_high_res-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  resnet/pytorch-resnet101-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  resnet/pytorch-resnet152-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  hardnet/pytorch-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  perceiverio_vision/pytorch-deepmind/vision-perceiver-conv-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  wide_resnet/pytorch-wide_resnet50_2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  wide_resnet/pytorch-wide_resnet101_2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  wide_resnet/pytorch-wide_resnet50_2.timm-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  wide_resnet/pytorch-wide_resnet101_2.timm-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  alexnet/pytorch-alexnet-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  alexnet/pytorch-alexnetb-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  autoencoder/pytorch-conv-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vgg/pytorch-vgg11-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vgg/pytorch-vgg13-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vgg/pytorch-vgg16-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vgg/pytorch-vgg19-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vgg/pytorch-bn_vgg19-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vgg/pytorch-bn_vgg19b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vgg/pytorch-vgg19_bn-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vgg/pytorch-timm_vgg19_bn-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vgg/pytorch-torchvision_vgg11-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vgg/pytorch-torchvision_vgg11_bn-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vgg/pytorch-torchvision_vgg13-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vgg/pytorch-torchvision_vgg13_bn-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vgg/pytorch-torchvision_vgg16-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vgg/pytorch-torchvision_vgg16_bn-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vgg/pytorch-torchvision_vgg19-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vgg/pytorch-torchvision_vgg19_bn-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  vgg/pytorch-hf_vgg19-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  unet/pytorch-torchhub_brain_unet-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  unet/pytorch-carvana_unet-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "error: failed to legalize operation 'stablehlo.select_and_scatter' https://github.com/tenstorrent/tt-mlir/issues/4794"

  distilbert/masked_lm/pytorch-distilbert-base-cased-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  distilbert/masked_lm/pytorch-distilbert-base-uncased-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  distilbert/masked_lm/pytorch-distilbert-base-multilingual-cased-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  distilbert/token_classification/pytorch-Davlan/distilbert-base-multilingual-cased-ner-hrl-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  vgg19_unet/pytorch-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  qwen_3/causal_lm/pytorch-0_6b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  phi1_5/causal_lm/pytorch-microsoft/phi-1_5-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  gpt_neo/causal_lm/pytorch-gpt_neo_125M-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  phi2/causal_lm/pytorch-microsoft/phi-2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  phi2/causal_lm/pytorch-microsoft/phi-2-pytdml-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  albert/masked_lm/pytorch-base_v1-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  albert/masked_lm/pytorch-xlarge_v1-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  albert/masked_lm/pytorch-xxlarge_v1-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  albert/masked_lm/pytorch-base_v2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  albert/masked_lm/pytorch-large_v2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  albert/masked_lm/pytorch-xlarge_v2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  albert/masked_lm/pytorch-xxlarge_v2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  albert/token_classification/pytorch-base_v1-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  albert/token_classification/pytorch-large_v1-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  albert/token_classification/pytorch-xlarge_v1-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  albert/token_classification/pytorch-xxlarge_v1-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  albert/token_classification/pytorch-base_v2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  albert/token_classification/pytorch-large_v2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  albert/token_classification/pytorch-xlarge_v2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  albert/token_classification/pytorch-xxlarge_v2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  xglm/pytorch-xglm-564M-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  xglm/pytorch-xglm-1.7B-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  densenet/pytorch-densenet121_xray-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  opt/causal_lm/pytorch-facebook/opt-125m-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  opt/causal_lm/pytorch-facebook/opt-350m-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  opt/causal_lm/pytorch-facebook/opt-1.3b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  beit/pytorch-base-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  beit/pytorch-large-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  phi1/causal_lm/pytorch-microsoft/phi-1-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  perceiverio_vision/pytorch-deepmind/vision-perceiver-learned-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  perceiverio_vision/pytorch-deepmind/vision-perceiver-fourier-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  d_fine/pytorch-nano-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  d_fine/pytorch-small-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  d_fine/pytorch-medium-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  d_fine/pytorch-large-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  d_fine/pytorch-xlarge-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  bert/masked_lm/pytorch-bert-base-uncased-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  bert/token_classification/pytorch-dbmdz/bert-large-cased-finetuned-conll03-english-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  mlp_mixer/pytorch-mixer_b16_224-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  mlp_mixer/pytorch-mixer_b16_224_in21k-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  mlp_mixer/pytorch-mixer_b16_224_miil-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  mlp_mixer/pytorch-mixer_b16_224_miil_in21k-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  mlp_mixer/pytorch-mixer_l16_224-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  mlp_mixer/pytorch-mixer_l16_224_in21k-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  mlp_mixer/pytorch-mixer_s16_224-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  mlp_mixer/pytorch-mixer_b16_224.goog_in21k-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  mlp_mixer/pytorch-mixer_github-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  mlp_mixer/lucidrains/pytorch-base-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  perceiver/pytorch-deepmind/language-perceiver-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"
  gpt2/pytorch-gpt2-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Batch norm with training=true hangs for channels > 64: https://github.com/tenstorrent/tt-metal/issues/30279"

  deepcogito/pytorch-v1_preview_llama_3b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5/causal_lm/pytorch-3b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5/causal_lm/pytorch-3b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5/causal_lm/pytorch-7b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5/causal_lm/pytorch-7b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5/causal_lm/pytorch-7b_instruct_1m-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5/causal_lm/pytorch-14b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5/causal_lm/pytorch-14b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5/causal_lm/pytorch-14b_instruct_1m-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5/causal_lm/pytorch-32b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5/causal_lm/pytorch-72b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5/causal_lm/pytorch-math_7b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  seamless_m4t/pytorch-large-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  mistral/pixtral/pytorch-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  mistral/pytorch-7b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  mistral/pytorch-7b_instruct_v03-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  mistral/pytorch-ministral_3b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  mistral/pytorch-ministral_8b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-llama_3_8b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-llama_3_8b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-llama_3_1_8b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-llama_3_1_8b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-llama_3_1_70b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-llama_3_1_70b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-llama_3_2_3b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-llama_3_2_3b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-llama_3_3_70b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-huggyllama_7b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/sequence_classification/pytorch-llama_3_8b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/sequence_classification/pytorch-llama_3_8b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/sequence_classification/pytorch-llama_3_1_8b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/sequence_classification/pytorch-llama_3_1_8b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/sequence_classification/pytorch-llama_3_1_70b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/sequence_classification/pytorch-llama_3_1_70b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/sequence_classification/pytorch-llama_3_2_3b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/sequence_classification/pytorch-llama_3_2_3b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/sequence_classification/pytorch-llama_3_3_70b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/sequence_classification/pytorch-huggyllama_7b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2/causal_lm/pytorch-qwq_32b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_3/causal_lm/pytorch-4b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_3/causal_lm/pytorch-8b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_3/causal_lm/pytorch-14b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_3/causal_lm/pytorch-32b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_3/causal_lm/pytorch-30b_a3b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_3/embedding/pytorch-embedding_4b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_3/embedding/pytorch-embedding_8b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  phi4/seq_cls/pytorch-microsoft/phi-4-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  phi4/causal_lm/pytorch-microsoft/phi-4-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  phi4/token_cls/pytorch-microsoft/phi-4-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  gpt_neo/causal_lm/pytorch-gpt_neo_1_3B-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  gpt_neo/causal_lm/pytorch-gpt_neo_2_7B-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  gpt_neo/sequence_classification/pytorch-gpt_neo_1_3B-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  gpt_neo/sequence_classification/pytorch-gpt_neo_2_7B-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llava/pytorch-1_5_7b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  mplug_owl2/pytorch-llama2_7b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  huggyllama/pytorch-llama_7b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  openvla/pytorch-openvla_7b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  openvla/pytorch-openvla_v01_7b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  openvla/pytorch-openvla_7b_finetuned_libero_10-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  openvla/pytorch-openvla_7b_finetuned_libero_goal-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  openvla/pytorch-openvla_7b_finetuned_libero_object-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  openvla/pytorch-openvla_7b_finetuned_libero_spatial-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  gemma/pytorch-google/gemma-1.1-7b-it-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  gemma/pytorch-google/gemma-2-9b-it-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  gemma/pytorch-google/gemma-2-27b-it-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5_vl/pytorch-3b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5_vl/pytorch-7b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5_vl/pytorch-3b_instruct_awq-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5_vl/pytorch-7b_instruct_awq-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  deepseek/qwen/pytorch-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  deepseek/deepseek_math/pytorch-7b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  deepseek/pytorch-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  deepseek/deepseek_coder/pytorch-1_3b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  flux/pytorch-schnell-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  flux/pytorch-dev-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  fuyu/pytorch-adept/fuyu-8b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  falcon/pytorch-tiiuae/Falcon3-3B-Base-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  falcon/pytorch-tiiuae/Falcon3-7B-Base-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  falcon/pytorch-tiiuae/Falcon3-10B-Base-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  falcon/pytorch-tiiuae/Falcon3-Mamba-7B-Base-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  falcon/pytorch-tiiuae/falcon-7b-instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  bloom/pytorch-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  stable_diffusion_xl/pytorch-stable-diffusion-xl-base-1.0-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  stable_diffusion/pytorch-stable-diffusion-3.5-medium-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  stable_diffusion/pytorch-stable-diffusion-3.5-large-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  stable_diffusion/pytorch-stable-diffusion-3.5-large-turbo-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  phi3/seq_cls/pytorch-microsoft/Phi-3-mini-128k-instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  phi3/seq_cls/pytorch-microsoft/Phi-3-mini-4k-instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  phi3/phi_3_5/pytorch-mini_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  phi3/phi_3_5/pytorch-microsoft/Phi-3.5-MoE-instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  phi3/causal_lm/pytorch-microsoft/Phi-3-mini-128k-instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  phi3/causal_lm/pytorch-microsoft/Phi-3-mini-4k-instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  phi3/token_cls/pytorch-microsoft/Phi-3-mini-128k-instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  phi3/token_cls/pytorch-microsoft/Phi-3-mini-4k-instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  phi3/phi_3_5_vision/pytorch-instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5_coder/pytorch-3b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5_coder/pytorch-3b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5_coder/pytorch-7b-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5_coder/pytorch-7b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5_coder/pytorch-32b_instruct-single_device-full-training:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME
