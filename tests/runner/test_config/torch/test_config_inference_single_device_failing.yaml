# SPDX-FileCopyrightText: (c) 2025 Tenstorrent AI ULC
#
# SPDX-License-Identifier: Apache-2.0

# Inference single-device test configuration
# Use Python enum names or values for fields below (names preferred for readability):
#   - status: ModelTestStatus names (e.g., EXPECTED_PASSING) or values (e.g., expected_passing)
#   - bringup_status (if present): BringupStatus names (e.g., FAILED_TTMLIR_COMPILATION) or values (e.g., failed_ttmlir_compilation)

test_config:
  vovnet/pytorch-vovnet39_th-single_device-inference:
    assert_pcc: false # https://github.com/tenstorrent/tt-xla/issues/1832
    status: KNOWN_FAILURE_XFAIL
    reason: "Issues with pulling urls - https://github.com/tenstorrent/tt-xla/issues/2390"

  vovnet/pytorch-vovnet57_th-single_device-inference:
    assert_pcc: false # https://github.com/tenstorrent/tt-xla/issues/1832
    status: KNOWN_FAILURE_XFAIL
    reason: "Issues with pulling urls - https://github.com/tenstorrent/tt-xla/issues/2390"

  clip/pytorch-large_patch14-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError('Check failed: handle->HasValue(): Trying to access XLA data for tensor with ID 13185 while an async operation is in flight: UNKNOWN_SCALAR[]') - https://github.com/tenstorrent/tt-xla/issues/1306"

  clip/pytorch-large_patch14_336-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError('Check failed: handle->HasValue(): Trying to access XLA data for tensor with ID 18766 while an async operation is in flight: UNKNOWN_SCALAR[]') - https://github.com/tenstorrent/tt-xla/issues/1306"

  attention_denseunet/pytorch-base-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "TT_FATAL: Output size cannot fit input with offset during TT compile/runtime â€“ tracked in issue https://github.com/tenstorrent/tt-xla/issues/2293"

  minicpm_o_2_6/pytorch-default-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "MiniCPM model has a larger test execution time, hence skipping it for now."

  densenet/pytorch-densenet121_xray-single_device-inference:
    status: KNOWN_FAILURE_XFAIL

  squeezebert/pytorch-squeezebert-mnli-single_device-inference:
    status: KNOWN_FAILURE_XFAIL  # Affected by change in torch=xla wheel - issue is: https://github.com/tenstorrent/tt-xla/issues/1750
    reason: "error: 'stablehlo.reshape' op requires compatible element types for all operands and results  - https://github.com/tenstorrent/tt-xla/issues/1750"

  unet/pytorch-carvana_unet_480x640-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 2537856 B L1_SMALL buffer across 72 banks, where each bank needs to store 35248 B, but bank size is only 65536 B"

  perceiverio_vision/pytorch-deepmind/vision-perceiver-conv-single_device-inference:
    required_pcc: 0.98
    status: NOT_SUPPORTED_SKIP  # Hang exposed by Sept3 tt-mlir uplift (change: Model softmax with numericStable = true)
    reason: "Hang / Runs forever - https://github.com/tenstorrent/tt-xla/issues/1289"
    bringup_status: FAILED_RUNTIME

  perceiverio_vision/pytorch-deepmind/vision-perceiver-fourier-single_device-inference:
    required_pcc: 0.98
    assert_pcc: false  # FIXME - PCC drop to 0.96 on Aug6 due to tt-mlir/tt-xla uplift (passed locally before it)
    status: NOT_SUPPORTED_SKIP  # Hang exposed by Sept3 tt-mlir uplift (change: Model softmax with numericStable = true)
    reason: "Hang / Runs forever - https://github.com/tenstorrent/tt-xla/issues/1289"
    bringup_status: FAILED_RUNTIME

  # yolov8/pytorch-yolov8x-single_device-inference:
  #   status: EXPECTED_PASSING

  perceiverio_vision/pytorch-deepmind/vision-perceiver-learned-single_device-inference:
    assert_pcc: false  # PCC observed: 0.9516052236372167 (below 0.99 threshold)
    status: NOT_SUPPORTED_SKIP  # Hang exposed by Sept3 tt-mlir uplift (change: Model softmax with numericStable = true)
    reason: "Hang / Runs forever - https://github.com/tenstorrent/tt-xla/issues/1289"
    bringup_status: FAILED_RUNTIME

  qwen_2_5_vl/pytorch-72b_instruct-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  qwen_2_5_vl/pytorch-3b_instruct-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "error: failed to legalize operation 'ttir.convolution' - https://github.com/tenstorrent/tt-xla/issues/1662"

  qwen_2_5_vl/pytorch-7b_instruct-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "error: failed to legalize operation 'ttir.convolution' - https://github.com/tenstorrent/tt-xla/issues/1662"
    arch_overrides:
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Multi chip is required"

  stable_diffusion_unet/pytorch-base-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Hangs - https://github.com/tenstorrent/tt-xla/issues/2565"

  deepseek/deepseek_ocr/pytorch-deepseek_ocr-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError: a Tensor with 3145728 elements cannot be converted to Scalar - https://github.com/tenstorrent/tt-xla/issues/1772"

  deepseek/pytorch-single_device-inference:
    status: NOT_SUPPORTED_SKIP  # Exposed by "Remove host-side consteval" change
    bringup_status: FAILED_TTMLIR_COMPILATION
    reason: "ttir.scatter does not work - https://github.com/tenstorrent/tt-xla/issues/2391"

  nbeats/pytorch-generic_basis-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "patoolib.util.PatoolError: error extracting STORAGE/datasets/electricity/LD2011_2014.txt.zip - https://github.com/tenstorrent/tt-xla/issues/2185"

  nbeats/pytorch-seasonality_basis-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Url for dataset is not reachable - https://github.com/tenstorrent/tt-xla/issues/2507"

  nbeats/pytorch-trend_basis-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Url for dataset is not reachable - https://github.com/tenstorrent/tt-xla/issues/2507"

  yolov9/pytorch-m-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Trying to access XLA data for tensor with ID 2590 while an async operation is in flight: UNKNOWN_SCALAR[]') raised in repr() - https://github.com/tenstorrent/tt-xla/issues/2776"

  bi_lstm_crf/pytorch-default-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError: The tensor has a non-zero number of elements, but its data is not allocated yet."

  flux/pytorch-schnell-single_device-inference:
    arch_overrides:
      p150:
        assert_pcc: false
        status: EXPECTED_PASSING
        reason: "AssertionError: PCC comparison failed. Calculated: pcc=0.9095736145973206. Required: pcc=0.99"
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Too large for single chip" # (flux.1-schnell is 12B param model)
        bringup_status: FAILED_RUNTIME

  flux/pytorch-dev-single_device-inference:
    arch_overrides:
      p150:
        status: EXPECTED_PASSING
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Too large for single chip" # (flux.1-dev is 12B param model)
        bringup_status: FAILED_RUNTIME

  gliner/pytorch-urchade/gliner_multi-v2.1-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "TypeError: GLiNER.compile() got an unexpected keyword argument 'backend'"

  stable_diffusion_xl/pytorch-stable-diffusion-xl-base-1.0-single_device-inference:
    status: EXCLUDE_MODEL  # stable_diffusion variants have a hand written test, don't run via test_models.py. TODO(@ppadjinTT): when pipeline becomes supported through test infra, enable this model again.

  oft/pytorch-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError: Out of Memory: Not enough space to allocate 2902982656 B DRAM buffer across 12 banks"

  phi3/phi_3_5_vision/pytorch-instruct-single_device-inference:
    arch_overrides:
      p150:
        status: KNOWN_FAILURE_XFAIL
        reason: "Out of Memory: Not enough space to allocate 52428800 B DRAM buffer across 12 banks, where each bank needs to store 4370432 B, but bank size is only 1073741792 B"
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Running the test CRASHED with signal 9 https://github.com/tenstorrent/tt-xla/issues/2254"

  glpn_kitti/pytorch-single_device-inference:
    arch_overrides:
      p150:
        status: EXPECTED_PASSING

      n150:
        status: KNOWN_FAILURE_XFAIL
        reason: "RuntimeError: Out of Memory: Not enough space to allocate 49971200 B L1 buffer across 64 banks"

  stable_diffusion_1_4/pytorch-base-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "Hangs or takes forever to run - not known to be compile clean anyways."
    bringup_status: FAILED_FE_COMPILATION

  boltz2/pytorch-boltz2-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "Hangs or takes forever to run"
    bringup_status: FAILED_RUNTIME

  detr3d/pytorch-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 1140326400 B DRAM buffer across 12 banks, where each bank needs to store 95027200 B - https://github.com/tenstorrent/tt-xla/issues/1353"

  vadv2/pytorch-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError('Check failed: handle->HasValue(): Trying to access XLA data for tensor with ID 5271 while an async operation is in flight: UNKNOWN_SCALAR[]')"

  llama/causal_lm/pytorch-llama_3_1_70b-single_device-inference:
    status: EXCLUDE_MODEL # Too large for single chip, run as tensor_parallel instead.

  llama/causal_lm/pytorch-llama_3_1_70b_instruct-single_device-inference:
    status: EXCLUDE_MODEL # Too large for single chip, run as tensor_parallel instead.

  llama/causal_lm/pytorch-llama_3_1_405b-single_device-inference:
    status: EXCLUDE_MODEL # Too large for single chip, run as tensor_parallel instead.

  llama/causal_lm/pytorch-llama_3_3_70b_instruct-single_device-inference:
    status: EXCLUDE_MODEL # Too large for single chip, run as tensor_parallel instead.

  llama/sequence_classification/pytorch-llama_3_1_70b-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/sequence_classification/pytorch-llama_3_1_70b_instruct-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/sequence_classification/pytorch-llama_3_3_70b_instruct-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip"
    bringup_status: FAILED_RUNTIME

  llama/sequence_classification/pytorch-llama_3_8b-single_device-inference:
    arch_overrides:
      p150:
        assert_pcc: false
        status: EXPECTED_PASSING
        reason: "AssertionError: PCC comparison failed. Calculated: pcc=-1.0000001192092896. Required: pcc=0.99 - https://github.com/tenstorrent/tt-xla/issues/1472"
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Too large for single chip"
        bringup_status: FAILED_RUNTIME

  mistral/pytorch-7b-single_device-inference:
    arch_overrides:
      p150:
        status: EXPECTED_PASSING
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Too large for single chip"
        bringup_status: FAILED_RUNTIME

  mistral/pytorch-ministral_8b_instruct-single_device-inference:
    arch_overrides:
      p150:
        status: EXPECTED_PASSING

      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Too large for single chip"
        bringup_status: FAILED_RUNTIME

  qwen_2_5/causal_lm/pytorch-14b-single_device-inference:
    arch_overrides:
      p150:
        assert_pcc: false
        status: EXPECTED_PASSING
        reason: "AssertionError: PCC comparison failed. Calculated: pcc=nan. Required: pcc=0.99 - https://github.com/tenstorrent/tt-xla/issues/1474"
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Too large for single chip"
        bringup_status: FAILED_RUNTIME

  qwen_2_5/causal_lm/pytorch-14b_instruct_1m-single_device-inference:
    arch_overrides:
      p150:
        assert_pcc: false
        status: EXPECTED_PASSING
        reason: "AssertionError: PCC comparison failed. Calculated: pcc=0.7706121206283569. Required: pcc=0.99 - https://github.com/tenstorrent/tt-xla/issues/1474"
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Too large for single chip"
        bringup_status: FAILED_RUNTIME

  qwen_2_5/causal_lm/pytorch-32b_instruct-single_device-inference:
    status: EXCLUDE_MODEL # Too large for single chip, run as tensor_parallel instead.

  qwen_2_5/causal_lm/pytorch-7b-single_device-inference:
    arch_overrides:
      p150:
        assert_pcc: false
        status: EXPECTED_PASSING
        reason: "AssertionError: PCC comparison failed. Calculated: pcc=nan. Required: pcc=0.99 - https://github.com/tenstorrent/tt-xla/issues/1474"
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Too large for single chip"
        bringup_status: FAILED_RUNTIME

  qwen_2_5/causal_lm/pytorch-7b_instruct-single_device-inference:
    arch_overrides:
      p150:
        assert_pcc: false
        status: EXPECTED_PASSING
        reason: "AssertionError: PCC comparison failed. Calculated: pcc=0.7253174185752869. Required: pcc=0.99 - https://github.com/tenstorrent/tt-xla/issues/1474"
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Too large for single chip"
        bringup_status: FAILED_RUNTIME

  qwen_2_5/causal_lm/pytorch-7b_instruct_1m-single_device-inference:
    arch_overrides:
      p150:
        assert_pcc: false
        status: EXPECTED_PASSING
        reason: "AssertionError: PCC comparison failed. Calculated: pcc=0.8598132729530334. Required: pcc=0.99 - https://github.com/tenstorrent/tt-xla/issues/1474"
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Too large for single chip"
        bringup_status: FAILED_RUNTIME

  qwen_2_5/causal_lm/pytorch-math_7b-single_device-inference:
    arch_overrides:
      p150:
        assert_pcc: false
        status: EXPECTED_PASSING
        reason: "AssertionError: PCC comparison failed. Calculated: pcc=nan. Required: pcc=0.99 - https://github.com/tenstorrent/tt-xla/issues/1474"
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Too large for single chip"
        bringup_status: FAILED_RUNTIME

  qwen_2_5_coder/pytorch-32b_instruct-single_device-inference:
    status: EXCLUDE_MODEL # Too large for single chip, run as tensor_parallel instead.

  qwen_2_5_coder/pytorch-7b-single_device-inference:
    arch_overrides:
      p150:
        assert_pcc: false
        status: EXPECTED_PASSING
        reason: "AssertionError: PCC comparison failed. Calculated: pcc=nan. Required: pcc=0.99 - https://github.com/tenstorrent/tt-xla/issues/1474"
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Too large for single chip"
        bringup_status: FAILED_RUNTIME

  qwen_2_5_coder/pytorch-7b_instruct-single_device-inference:
    arch_overrides:
      p150:
        assert_pcc: false
        status: EXPECTED_PASSING
        reason: "AssertionError: PCC comparison failed. Calculated: pcc=0.964358925819397. Required: pcc=0.99 - https://github.com/tenstorrent/tt-xla/issues/1474"
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Too large for single chip"
        bringup_status: FAILED_RUNTIME

  qwen_3/causal_lm/pytorch-30b_a3b-single_device-inference:
    status: EXCLUDE_MODEL # Too large for single chip, run as tensor_parallel instead.

  qwen_3/causal_lm/pytorch-32b-single_device-inference:
    status: EXCLUDE_MODEL # Too large for single chip, run as tensor_parallel instead.

  qwen_2/causal_lm/pytorch-qwq_32b-single_device-inference:
    status: EXCLUDE_MODEL # Too large for single chip, run as tensor_parallel instead.

  deepseek/deepseek_math/pytorch-7b_instruct-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip - https://github.com/tenstorrent/tt-xla/issues/2208"
    bringup_status: FAILED_RUNTIME

  llava/pytorch-1_5_7b-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "Running the test CRASHED with signal 9 - uses too much memory need higher memory host."
    bringup_status: FAILED_RUNTIME

  qwen_2_5/causal_lm/pytorch-72b_instruct-single_device-inference:
    status: EXCLUDE_MODEL # Too large for single chip, run as tensor_parallel instead.

  gemma/pytorch-google/gemma-2-27b-it-single_device-inference:
    status: EXCLUDE_MODEL # Too large for single chip, run as tensor_parallel instead.

  d_fine/pytorch-nano-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "d_fine nano hangs forever, removing all of them."
    bringup_status: FAILED_RUNTIME

  d_fine/pytorch-small-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "d_fine small hangs forever, removing all of them."
    bringup_status: FAILED_RUNTIME

  d_fine/pytorch-medium-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "d_fine medium hangs forever, removing all of them."
    bringup_status: FAILED_RUNTIME

  d_fine/pytorch-large-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "d_fine large hangs forever, removing all of them."
    bringup_status: FAILED_RUNTIME

  d_fine/pytorch-xlarge-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "d_fine xlarge hangs forever, removing all of them."
    bringup_status: FAILED_RUNTIME

  bevdepth/pytorch-bev_depth_lss_r50_256x704_128x128_24e_2key-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 69599232 B L1 buffer across 72 banks, where each bank needs to store 966656 B, but bank size is only 1366016 B - https://github.com/tenstorrent/tt-xla/issues/1497"

  bevdepth/pytorch-bev_depth_lss_r50_256x704_128x128_24e_2key_ema-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 69599232 B L1 buffer across 72 banks, where each bank needs to store 966656 B, but bank size is only 1366016 B - https://github.com/tenstorrent/tt-xla/issues/1497"

  bevdepth/pytorch-bev_depth_lss_r50_256x704_128x128_20e_cbgs_2key_da-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 69599232 B L1 buffer across 72 banks, where each bank needs to store 966656 B, but bank size is only 1366016 B - https://github.com/tenstorrent/tt-xla/issues/1497"

  bevdepth/pytorch-bev_depth_lss_r50_256x704_128x128_20e_cbgs_2key_da_ema-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 69599232 B L1 buffer across 72 banks, where each bank needs to store 966656 B, but bank size is only 1366016 B - https://github.com/tenstorrent/tt-xla/issues/1497"

  bevformer/pytorch-BEVFormer-tiny-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 65536000 B L1 buffer across 64 banks, where each bank needs to store 1024000 B, but bank size is only 1364704 B, but bank size is only 1366016 B - https://github.com/tenstorrent/tt-xla/issues/1709"

  bevformer/pytorch-BEVFormer-small-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 65536000 B L1 buffer across 64 banks, where each bank needs to store 1024000 B, but bank size is only 1364704 B, but bank size is only 1366016 B - https://github.com/tenstorrent/tt-xla/issues/1709"

  bevformer/pytorch-BEVFormer-base-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 65536000 B L1 buffer across 64 banks, where each bank needs to store 1024000 B, but bank size is only 1364704 B, but bank size is only 1366016 B - https://github.com/tenstorrent/tt-xla/issues/1709"

  bevformer/pytorch-bevformerv2-r50-t1-base-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 65536000 B L1 buffer across 64 banks, where each bank needs to store 1024000 B, but bank size is only 1364704 B, but bank size is only 1366016 B - https://github.com/tenstorrent/tt-xla/issues/1709"
    arch_overrides:
      p150:
        status: NOT_SUPPORTED_SKIP
        bringup_status: FAILED_RUNTIME
        reason: "Buffer must be allocated on device - https://github.com/tenstorrent/tt-xla/issues/2439"

  bevformer/pytorch-bevformerv2-r50-t1-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 65536000 B L1 buffer across 64 banks, where each bank needs to store 1024000 B, but bank size is only 1364704 B, but bank size is only 1366016 B - https://github.com/tenstorrent/tt-xla/issues/1709"
    arch_overrides:
      p150:
        status: NOT_SUPPORTED_SKIP
        bringup_status: FAILED_RUNTIME
        reason: "Buffer must be allocated on device - https://github.com/tenstorrent/tt-xla/issues/2439"

  bevformer/pytorch-bevformerv2-r50-t2-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 65536000 B L1 buffer across 64 banks, where each bank needs to store 1024000 B, but bank size is only 1364704 B, but bank size is only 1366016 B - https://github.com/tenstorrent/tt-xla/issues/1709"
    arch_overrides:
      p150:
        status: NOT_SUPPORTED_SKIP
        bringup_status: FAILED_RUNTIME
        reason: "Buffer must be allocated on device - https://github.com/tenstorrent/tt-xla/issues/2439"

  bevformer/pytorch-bevformerv2-r50-t8-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 65536000 B L1 buffer across 64 banks, where each bank needs to store 1024000 B, but bank size is only 1364704 B, but bank size is only 1366016 B - https://github.com/tenstorrent/tt-xla/issues/1709"
    arch_overrides:
      p150:
        status: NOT_SUPPORTED_SKIP
        bringup_status: FAILED_RUNTIME
        reason: "Buffer must be allocated on device - https://github.com/tenstorrent/tt-xla/issues/2439"

  ssr/pytorch-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 62179328 B L1 buffer across 64 banks, where each bank needs to store 971552 B, but bank size is only 1364704 B - https://github.com/tenstorrent/tt-xla/issues/1923"

  bge_m3/pytorch-base-single_device-inference:
    status: EXCLUDE_MODEL  # This model has a hand written test, don't run via test_models.py

  bge_m3/encode/pytorch-base-single_device-inference:
    status: EXCLUDE_MODEL  # This model has a hand written test, don't run via test_models.py

  whisper/pytorch-openai/whisper-tiny-single_device-inference:
    status: EXCLUDE_MODEL  # All whisper variants have a hand written test, don't run via test_models.py

  whisper/pytorch-openai/whisper-small-single_device-inference:
    status: EXCLUDE_MODEL

  whisper/pytorch-openai/whisper-base-single_device-inference:
    status: EXCLUDE_MODEL

  whisper/pytorch-openai/whisper-medium-single_device-inference:
    status: EXCLUDE_MODEL

  whisper/pytorch-openai/whisper-large-single_device-inference:
    status: EXCLUDE_MODEL

  whisper/pytorch-openai/whisper-large-v3-single_device-inference:
    status: EXCLUDE_MODEL

  whisper/pytorch-openai/whisper-large-v3-turbo-single_device-inference:
    status: EXCLUDE_MODEL

  uniad/pytorch-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 285081600 B L1 buffer across 64 banks, where each bank needs to store 4454400 B, but bank size is only 1366560 B"

  maptr/pytorch-tiny_r50_24e_av2-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError: The tensor has a non-zero number of elements, but its data is not allocated yet - https://github.com/tenstorrent/tt-xla/issues/1586"

  maptr/pytorch-tiny_r50_24e_bevformer-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError: The tensor has a non-zero number of elements, but its data is not allocated yet - https://github.com/tenstorrent/tt-xla/issues/1586"

  maptr/pytorch-tiny_r50_24e_bevformer_t4-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError: The tensor has a non-zero number of elements, but its data is not allocated yet - https://github.com/tenstorrent/tt-xla/issues/1586"

  maptr/pytorch-tiny_r50_24e-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError: The tensor has a non-zero number of elements, but its data is not allocated yet - https://github.com/tenstorrent/tt-xla/issues/1586"

  maptr/pytorch-tiny_r50_110e-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError: The tensor has a non-zero number of elements, but its data is not allocated yet - https://github.com/tenstorrent/tt-xla/issues/1586"

  maptr/pytorch-tiny_r50_24e_t4-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError: The tensor has a non-zero number of elements, but its data is not allocated yet - https://github.com/tenstorrent/tt-xla/issues/1586"

  maptr/pytorch-nano_r18_110e-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError: The tensor has a non-zero number of elements, but its data is not allocated yet - https://github.com/tenstorrent/tt-xla/issues/1586"

  maptr/pytorch-tiny_r50_24e_bevpool-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 95029248 B L1 buffer across 64 banks, where each bank needs to store 1484832 B, but bank size is only 1364928 B - https://github.com/tenstorrent/tt-xla/issues/1588"

  maptr/pytorch-tiny_fusion_24e-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "AssertionError: SparseSequential encountered by torch._dynamo"

  pointpillars/pytorch-pointpillars-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "error: failed to legalize operation 'ttir.gather' that was explicitly marked illegal' - https://github.com/tenstorrent/tt-xla/issues/1884"

  sam/pytorch-facebook/sam-vit-base-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Hangs - https://github.com/tenstorrent/tt-xla/issues/2565"

  vilt/masked_lm/pytorch-mlm-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Failed to legalize operation 'ttir.gather': ' - https://github.com/tenstorrent/tt-xla/issues/318"

  mplug_owl2/pytorch-llama2_7b-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "running the test CRASHED with signal 9 - uses too much memory need higher memory host"
    bringup_status: FAILED_RUNTIME

  openvla/pytorch-openvla_7b-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 90177536 B DRAM buffer across 12 banks, where each bank needs to store 7516160 B, but bank size is only 1073741792 B"
    arch_overrides:
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Multi chip is required"

  openvla/pytorch-openvla_v01_7b-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 90177536 B DRAM buffer across 12 banks, where each bank needs to store 7516160 B, but bank size is only 1073741792 B"
    arch_overrides:
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Multi chip is required"

  openvla/pytorch-openvla_7b_finetuned_libero_10-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 90177536 B DRAM buffer across 12 banks, where each bank needs to store 7516160 B, but bank size is only 1073741792 B"
    arch_overrides:
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Multi chip is required"

  openvla/pytorch-openvla_7b_finetuned_libero_goal-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 90177536 B DRAM buffer across 12 banks, where each bank needs to store 7516160 B, but bank size is only 1073741792 B"
    arch_overrides:
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Multi chip is required"

  openvla/pytorch-openvla_7b_finetuned_libero_object-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 90177536 B DRAM buffer across 12 banks, where each bank needs to store 7516160 B, but bank size is only 1073741792 B"
    arch_overrides:
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Multi chip is required"

  openvla/pytorch-openvla_7b_finetuned_libero_spatial-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 90177536 B DRAM buffer across 12 banks, where each bank needs to store 7516160 B, but bank size is only 1073741792 B"
    arch_overrides:
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Multi chip is required"

  transfuser/pytorch-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Input tensor data type for ttnn.sort must be BFLOAT16 or UINT16, got DataType::FLOAT32 (https://github.com/tenstorrent/tt-xla/issues/3089)"

  issac_groot/pytorch-GR00T_n1.5-3b-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "Statically allocated circular buffers on core range [(x=6,y=7) - (x=6,y=7)] grow to 2012288 B which is beyond max L1 size of 1499136 B" # https://github.com/tenstorrent/tt-xla/issues/2817
    bringup_status: FAILED_RUNTIME

  # yolov11/pytorch-yolo11n-single_device-full-inference:
  #   status: EXPECTED_PASSING

  # yolov11/pytorch-yolo11s-single_device-inference:
  #   status: EXPECTED_PASSING

  # yolov11/pytorch-yolo11m-single_device-inference:
  #   status: EXPECTED_PASSING

  # yolov11/pytorch-yolo11l-single_device-inference:
  #   status: EXPECTED_PASSING

  # yolov11/pytorch-yolo11x-single_device-inference:
  #   status: EXPECTED_PASSING

  # yolov12/pytorch-yolo12s-single_device-inference:
  #   status: EXPECTED_PASSING

  # yolov12/pytorch-yolo12m-single_device-inference:
  #   status: EXPECTED_PASSING

  # yolov12/pytorch-yolo12l-single_device-inference:
  #   status: EXPECTED_PASSING

  # yolov12/pytorch-yolo12x-single_device-inference:
  #   status: EXPECTED_PASSING

  vgg19_unet/pytorch-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 2162688 B L1_SMALL buffer across 64 banks, where each bank needs to store 33792 B, but bank size is only 32768 B - https://github.com/tenstorrent/tt-xla/issues/1722"

  qwen_2/token_classification/pytorch-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 61079552 B L1 buffer across 64 banks, where each bank needs to store 954368 B, but bank size is only 1364928 B - https://github.com/tenstorrent/tt-xla/issues/1722"

  unet/pytorch-smp_unet_resnet101-single_device-inference:
    status: KNOWN_FAILURE_XFAIL

  sam/pytorch-facebook/sam-vit-large-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "Hangs - https://github.com/tenstorrent/tt-xla/issues/2565"

  deepseek/qwen/pytorch-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "Out of Memory: Not enough space to allocate 283115520 B DRAM buffer across 12 banks, where each bank needs to store 23611392 B, but bank size is only 1073741792 B - https://github.com/tenstorrent/tt-xla/issues/1722"
    markers: [large]
  detr/segmentation/pytorch-resnet_50_panoptic-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 5468979200 B DRAM buffer across 12 banks, where each bank needs to store 455749632 B, but bank size is only 1073741792 B - https://github.com/tenstorrent/tt-xla/issues/1722"

  panoptic_segmentation/pytorch-resnet101_3x_coco-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "torch._inductor.exc.InductorError: DynamicOutputShapeException: aten.repeat_interleave.Tensor, issue link: https://github.com/tenstorrent/tt-xla/issues/2310"

  panoptic_segmentation/pytorch-resnet50_1x_coco-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "torch._inductor.exc.InductorError: DynamicOutputShapeException: aten.repeat_interleave.Tensor, issue link: https://github.com/tenstorrent/tt-xla/issues/2310"

  panoptic_segmentation/pytorch-resnet50_3x_coco-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "torch._inductor.exc.InductorError: DynamicOutputShapeException: aten.repeat_interleave.Tensor, issue link: https://github.com/tenstorrent/tt-xla/issues/2310"

  sam/pytorch-facebook/sam-vit-huge-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Hangs - https://github.com/tenstorrent/tt-xla/issues/2565"

  sentencizer/pytorch-xlm-roberta-base-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "error: 'stablehlo.reshape' op requires compatible element types for all operands and results  - https://github.com/tenstorrent/tt-xla/issues/1750"

  sentencizer/pytorch-xlm-roberta-large-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "error: 'stablehlo.reshape' op requires compatible element types for all operands and results  - https://github.com/tenstorrent/tt-xla/issues/1750"

  stable_diffusion/pytorch-stable-diffusion-3.5-medium-single_device-inference:
    status: EXCLUDE_MODEL  # stable_diffusion variants have a hand written test, don't run via test_models.py. TODO(@ppadjinTT): when pipeline becomes supported through test infra, enable this model again.

  stable_diffusion/pytorch-stable-diffusion-3.5-large-single_device-inference:
    status: EXCLUDE_MODEL  # stable_diffusion variants have a hand written test, don't run via test_models.py. TODO(@ppadjinTT): when pipeline becomes supported through test infra, enable this model again.

  stable_diffusion/pytorch-stable-diffusion-3.5-large-turbo-single_device-inference:
    status: EXCLUDE_MODEL  # stable_diffusion variants have a hand written test, don't run via test_models.py. TODO(@ppadjinTT): when pipeline becomes supported through test infra, enable this model again.

  gliner/pytorch-urchade/gliner_largev2-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "AssertionError: assert isinstance(self._model, torch.nn.Module) - https://github.com/tenstorrent/tt-xla/issues/1815"

  hippynn/pytorch-Hippynn-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "AssertionError: assert isinstance(self._model, torch.nn.Module) - https://github.com/tenstorrent/tt-xla/issues/1815"

  vilt/question_answering/pytorch-vqa-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "failed to legalize operation 'ttir.gather' - https://github.com/tenstorrent/tt-xla/issues/318"

  ssdlite320_mobilenetv3/pytorch-ssdlite320_mobilenet_v3_large-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_FE_COMPILATION
    reason: "Can't convert shape rank  - https://github.com/tenstorrent/tt-xla/issues/2456"

  retinanet/pytorch-retinanet_resnet50_fpn_v2-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "Statically allocated circular buffers on core range [(x=0,y=0) - (x=7,y=6)] grow to 22732608 B which is beyond max L1 size of 1499136 B"
    bringup_status: FAILED_RUNTIME

  ssd300_vgg16/pytorch-ssd300_vgg16-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "Can't convert shape rank - https://github.com/tenstorrent/tt-xla/issues/2456"

  yolop/pytorch-yolop-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "error: 'ttnn.max_pool2d' op Kernel height 13 is greater than input height 12. This ttnn.max_pool2d configuration is invalid - https://github.com/tenstorrent/tt-xla/issues/2007"


  faster_rcnn/pytorch-resnet50_fpn-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "Out of Memory: Not enough space to allocate 62521344 B L1 buffer across 72 banks, where each bank needs to store 868352 B, but bank size is only 1331936 B"

  deformable_detr/pytorch-deformable-detr-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 18686672896 B DRAM buffer across 12 banks, where each bank needs to store 1557225472 B, but bank size is only 1073741792 B"

  deformable_detr/pytorch-deformable-detr-single-scale-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 445644800 B DRAM buffer across 12 banks, where each bank needs to store 37138432 B, but bank size is only 1073741792 B"

  deformable_detr/pytorch-deformable-detr-with-box-refine-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 18686672896 B DRAM buffer across 12 banks, where each bank needs to store 1557225472 B, but bank size is only 1073741792 B"

  deformable_detr/pytorch-deformable-detr-with-box-refine-two-stage-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 18686672896 B DRAM buffer across 12 banks, where each bank needs to store 1557225472 B, but bank size is only 1073741792 B"

  rt_detr/pytorch-rtdetr-r18vd-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 314572800 B DRAM buffer across 12 banks, where each bank needs to store 26214400 B, but bank size is only 1073741792 B"

  rt_detr/pytorch-rtdetr-r34vd-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 157286400 B DRAM buffer across 12 banks, where each bank needs to store 13107200 B, but bank size is only 1073741792 B"

  rt_detr/pytorch-rtdetr-r50vd-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 157286400 B DRAM buffer across 12 banks, where each bank needs to store 13107200 B, but bank size is only 1073741792 B"

  rt_detr/pytorch-rtdetr-r101vd-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 157286400 B DRAM buffer across 12 banks, where each bank needs to store 13107200 B, but bank size is only 1073741792 B"

  llama/llama_3_2_vision/pytorch-llama_3_2_11b_vision-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    arch_overrides:
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Multi chip is required"

  llama/llama_3_2_vision/pytorch-llama_3_2_11b_vision_instruct-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError('Check failed: handle->HasValue(): Trying to access XLA data for tensor while an async operation is in flight: UNKNOWN_SCALAR[]')"
    arch_overrides:
      n150:
        status: NOT_SUPPORTED_SKIP
        reason: "Multi chip is required"

  petr/pytorch-vovnet_gridmask_p4_800x320-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "Out of Memory: Not enough space to allocate 57952512 B L1 buffer across 72 banks, where each bank needs to store 804896 B, but bank size is only 1331936 B"
    bringup_status: FAILED_RUNTIME

  petr/pytorch-vovnet_gridmask_p4_1600x640-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "Out of Memory: Not enough space to allocate 138461184 B L1 buffer across 72 banks, where each bank needs to store 1923072 B, but bank size is only 1331936 B"
    bringup_status: FAILED_RUNTIME

  petr/pytorch-r50dcn_gridmask_c5-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 138461184 B L1 buffer across 72 banks, where each bank needs to store 1923072 B, but bank size is only 1331936 B"
    bringup_status: FAILED_RUNTIME

  petr/pytorch-r50dcn_gridmask_p4-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 138461184 B L1 buffer across 72 banks, where each bank needs to store 1923072 B, but bank size is only 1331936 B"
    bringup_status: FAILED_RUNTIME

  efficientdet/pytorch-d0-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError: Shapes are not compatible for broadcasting: bf16[1,64,8,8] vs. bf16[2]. Expected dimension 3 of shape bf16[1,64,8,8] (8) to match dimension 0 of shape bf16[2] (2). Either that or that any of them is either 1 or unbounded. Try reshaping one of the tensors to match the other. - https://github.com/tenstorrent/tt-xla/issues/2206"

  efficientdet/pytorch-d1-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError: Shapes are not compatible for broadcasting: bf16[1,88,10,10] vs. bf16[2]. Expected dimension 3 of shape bf16[1,88,10,10] (10) to match dimension 0 of shape bf16[2] (2). Either that or that any of them is either 1 or unbounded. Try reshaping one of the tensors to match the other. - https://github.com/tenstorrent/tt-xla/issues/2206"

  efficientdet/pytorch-d2-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError: Shapes are not compatible for broadcasting: bf16[1,112,12,12] vs. bf16[2]. Expected dimension 3 of shape bf16[1,112,12,12] (12) to match dimension 0 of shape bf16[2] (2). Either that or that any of them is either 1 or unbounded. Try reshaping one of the tensors to match the other. - https://github.com/tenstorrent/tt-xla/issues/2206"

  efficientdet/pytorch-d3-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError: Shapes are not compatible for broadcasting: bf16[1,160,14,14] vs. bf16[2]. Expected dimension 3 of shape bf16[1,160,14,14] (14) to match dimension 0 of shape bf16[2] (2). Either that or that any of them is either 1 or unbounded. Try reshaping one of the tensors to match the other. - https://github.com/tenstorrent/tt-xla/issues/2206"

  efficientdet/pytorch-d4-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError: Shapes are not compatible for broadcasting: bf16[1,224,16,16] vs. bf16[2]. Expected dimension 3 of shape bf16[1,224,16,16] (16) to match dimension 0 of shape bf16[2] (2). Either that or that any of them is either 1 or unbounded. Try reshaping one of the tensors to match the other. - https://github.com/tenstorrent/tt-xla/issues/2206"

  efficientdet/pytorch-d5-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError: Shapes are not compatible for broadcasting: bf16[1,288,20,20] vs. bf16[2]. Expected dimension 3 of shape bf16[1,288,20,20] (20) to match dimension 0 of shape bf16[2] (2). Either that or that any of them is either 1 or unbounded. Try reshaping one of the tensors to match the other. - https://github.com/tenstorrent/tt-xla/issues/2206"

  efficientdet/pytorch-d6-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 52428800 B L1 buffer across 64 banks, where each bank needs to store 819200 B, but bank size is only 1331936 B"

  efficientdet/pytorch-d7-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 33030144 B L1 buffer across 56 banks, where each bank needs to store 589824 B, but bank size is only 1331936 B"

  efficientdet/pytorch-d7x-single_device-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 5760 B L1_SMALL buffer across 36 banks, where each bank needs to store 160 B, but bank size is only 65536 B"

  dense_unet_3d/pytorch-base-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "RuntimeError: torch._dynamo.exc.TorchRuntimeError: Dynamo failed to run FX node with fake tensors: call_module L__self___maxpool1(*(FakeTensor(..., device='xla:0', size=(1, 96, 16, 128, 128), dtype=torch.bfloat16),), https://github.com/tenstorrent/tt-xla/issues/2567"

  wan/pytorch-wan2.2-ti2v-5b-single_device-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "Wan2.2 model requires a lot of memeory and takes a lot of time to load hence skipping it for now."
