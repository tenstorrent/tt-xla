# SPDX-FileCopyrightText: (c) 2025 Tenstorrent AI ULC
#
# SPDX-License-Identifier: Apache-2.0


test_config:
  falcon/pytorch-3_7B_Base-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING

  falcon/pytorch-3_10B_Base-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING

  falcon/pytorch-3_Mamba_7B_Base-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: KNOWN_FAILURE_XFAIL
    reason: " Error: loc('compare.1209'): error: Compare operation is not supported in stablehlo-pipeline for meshes not 1x1 - https://github.com/tenstorrent/tt-mlir/issues/3497"

  gemma/pytorch-1.1_7B_IT-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING
    required_pcc: 0.985 # Calculated: pcc=0.9898088782430592 https://github.com/tenstorrent/tt-xla/issues/3212

  gemma/pytorch-2_9B_IT-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING
    markers: [extended]

  gemma/pytorch-2_27B_IT-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: NOT_SUPPORTED_SKIP
    reason: "Too large for single chip or even n300-llmbox either, needs debug - https://github.com/tenstorrent/tt-xla/issues/1494"
    bringup_status: FAILED_RUNTIME

  gpt_oss/pytorch-20B-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING
    required_pcc: 0.935 # https://github.com/tenstorrent/tt-xla/issues/3181

  falcon/pytorch-7B_Instruct-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING

  llama/causal_lm/pytorch-3.1_8B-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING

  llama/causal_lm/pytorch-3.1_8B_Instruct-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING

  llama/causal_lm/pytorch-3.0_8B_Instruct-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING

  mistral/pixtral/pytorch-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING
    assert_pcc: false

  mistral/pytorch-7B_INSTRUCT_v03-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING
    markers: [extended]

  qwen_3/causal_lm/pytorch-0_6B-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING
    assert_pcc: false # https://github.com/tenstorrent/tt-xla/issues/2550

  qwen_3/causal_lm/pytorch-14B-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING

  qwen_3/causal_lm/pytorch-1_7B-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING
    assert_pcc: false # https://github.com/tenstorrent/tt-xla/issues/2550

  qwen_3/causal_lm/pytorch-32B-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING

  qwen_3/causal_lm/pytorch-8B-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING

  qwen_3/embedding/pytorch-Embedding_8B-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING
    markers: [extended]

  mistral/pytorch-Ministral_8B_Instruct-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING

  mistral/pytorch-Small_24B_INSTRUCT_2501-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING

  mistral/pytorch-Nemo_INSTRUCT_2407-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING

  mistral/pytorch-Large_INSTRUCT_2411-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: NOT_SUPPORTED_SKIP
    reason: "xr.global_runtime_device_count() - Expected 2 eth links from physical chip 4 to physical chip 0 - https://github.com/tenstorrent/tt-xla/issues/1975"

  mistral/pytorch-Devstral_Small_2505-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING

  mistral/pytorch-Magistral_Small_2506-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING

  qwen_2_5/causal_lm/pytorch-7B_Instruct-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    # bringup_status: INCORRECT_RESULT
    # assert_pcc: false # https://github.com/tenstorrent/tt-xla/issues/1474
    status: NOT_SUPPORTED_SKIP
    bringup_status: FAILED_RUNTIME
    reason: "DRAM OOM - recently regressed around Nov 4 - https://github.com/tenstorrent/tt-xla/issues/2150"

  qwen_2_5/causal_lm/pytorch-14B_Instruct-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING

  qwen_2_5/causal_lm/pytorch-32B_Instruct-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING

  qwen_2_5_coder/pytorch-32B_Instruct-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: EXPECTED_PASSING

  qwen_2_5/causal_lm/pytorch-Math_7B-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    # bringup_status: INCORRECT_RESULT
    # assert_pcc: false # https://github.com/tenstorrent/tt-xla/issues/1474
    status: NOT_SUPPORTED_SKIP
    reason: "DRAM OOM - recently regressed around Nov 4 - https://github.com/tenstorrent/tt-xla/issues/2150"

  # Models that need work....

  llama/causal_lm/pytorch-3.1_405B-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on galaxy"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-3.1_70B-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on galaxy"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-3.1_70B_Instruct-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on galaxy"
    bringup_status: FAILED_RUNTIME

  llama/causal_lm/pytorch-3.3_70B_Instruct-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on galaxy"
    bringup_status: FAILED_RUNTIME

  phi4/causal_lm/pytorch-Phi_4-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on n300-llmbox 14B param"
    bringup_status: FAILED_RUNTIME

  qwen_2/causal_lm/pytorch-Qwq_32B-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on n300-llmbox"
    bringup_status: FAILED_RUNTIME

  qwen_2_5/causal_lm/pytorch-72B_Instruct-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on galaxy"
    bringup_status: FAILED_RUNTIME

  qwen_3/causal_lm/pytorch-30B_A3b-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: NOT_SUPPORTED_SKIP
    reason: "Needs bringup on n300-llmbox"
    bringup_status: FAILED_RUNTIME

  olmo3/causal_lm/pytorch-3_32b_think-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    assert_pcc: false # PCC comparison failed. Calculated: pcc=0.3691241923630818. Required: pcc=0.99
    status: EXPECTED_PASSING

  olmo3/causal_lm/pytorch-3_1125_32b-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    assert_pcc: false # PCC comparison failed. Calculated: pcc=0.701951301689392. Required: pcc=0.99
    status: EXPECTED_PASSING

  mistral/pytorch-mistral_small_3.1_24b_instruct_2503-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    assert_pcc: false # PCC comparison failed. Calculated: pcc=0.9757716745992953. Required: pcc=0.99
    status: EXPECTED_PASSING

  mistral/pytorch-mistral_small_3.2_24b_instruct_2506-tensor_parallel-inference:
    supported_archs: [n300-llmbox]
    status: KNOWN_FAILURE_XFAIL
    reason: "KeyError: c_lifted_tensor_1"
