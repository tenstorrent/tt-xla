# SPDX-FileCopyrightText: (c) 2025 Tenstorrent AI ULC
#
# SPDX-License-Identifier: Apache-2.0

# Inference single-device test configuration
# Use Python enum names or values for fields below (names preferred for readability):
#   - status: ModelTestStatus names (e.g., EXPECTED_PASSING) or values (e.g., expected_passing)
#   - bringup_status (if present): BringupStatus names (e.g., FAILED_TTMLIR_COMPILATION) or values (e.g., failed_ttmlir_compilation)

test_config:

  clip/pytorch-base_patch16-single_device-full-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "RuntimeError('Check failed: handle->HasValue(): Trying to access XLA data for tensor with ID 3802 while an async operation is in flight: UNKNOWN_SCALAR[]') - https://github.com/tenstorrent/tt-xla/issues/1306"

  yolov5/pytorch-yolov5s-single_device-full-inference:
    status: KNOWN_FAILURE_XFAIL  # Newly exposed in Aug26 tt-forge-models uplift.
    reason: "TypeError: AutoShape.forward() takes from 2 to 5 positional arguments but 7 were given - https://github.com/tenstorrent/tt-forge-models/issues/136"

  squeezebert/pytorch-squeezebert-mnli-single_device-full-inference:
    status: KNOWN_FAILURE_XFAIL  # Affected by change in torch=xla wheel - issue is: https://github.com/tenstorrent/tt-xla/issues/1750
    reason: "error: 'stablehlo.reshape' op requires compatible element types for all operands and results  - https://github.com/tenstorrent/tt-xla/issues/1750"

  perceiverio_vision/pytorch-deepmind/vision-perceiver-conv-single_device-full-inference:
    required_pcc: 0.98
    status: NOT_SUPPORTED_SKIP  # Hang exposed by Sept3 tt-mlir uplift (change: Model softmax with numericStable = true)
    reason: "Hang / Runs forever - https://github.com/tenstorrent/tt-xla/issues/1289"
    bringup_status: FAILED_RUNTIME

  perceiverio_vision/pytorch-deepmind/vision-perceiver-fourier-single_device-full-inference:
    required_pcc: 0.98
    assert_pcc: false  # FIXME - PCC drop to 0.96 on Aug6 due to tt-mlir/tt-xla uplift (passed locally before it)
    status: NOT_SUPPORTED_SKIP  # Hang exposed by Sept3 tt-mlir uplift (change: Model softmax with numericStable = true)
    reason: "Hang / Runs forever - https://github.com/tenstorrent/tt-xla/issues/1289"
    bringup_status: FAILED_RUNTIME

  yolox/pytorch-yolox_nano-single_device-full-inference:
    status: NOT_SUPPORTED_SKIP
    reason: "Yolo models have issues with loading yolox https://github.com/tenstorrent/tt-xla/issues/1929"
    bringup_status: FAILED_FE_COMPILATION

  yolox/pytorch-yolox_s-single_device-full-inference:
    status: KNOWN_FAILURE_XFAIL  # Exposed by "Remove host-side consteval" change
    reason: "torch._dynamo.exc.TorchRuntimeError: Dynamo failed to run FX node with fake tensors - https://github.com/tenstorrent/tt-xla/issues/1243"

  yolox/pytorch-yolox_l-single_device-full-inference:
    status: NOT_SUPPORTED_SKIP  # Exposed by "Remove host-side consteval" change
    reason: "Yolo models have issues with loading yolox https://github.com/tenstorrent/tt-xla/issues/1929"
    bringup_status: FAILED_FE_COMPILATION

  bevformer/pytorch-bevformerv2-r50-t1-single_device-full-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Out of Memory: Not enough space to allocate 65536000 B L1 buffer across 64 banks, where each bank needs to store 1024000 B, but bank size is only 1364704 B, but bank size is only 1366016 B - https://github.com/tenstorrent/tt-xla/issues/1709"

  maptr/pytorch-tiny_fusion_24e-single_device-full-inference:
    status: KNOWN_FAILURE_XFAIL
    reason: "Invalid type annotations in generated GraphModule forward cause torch.compile failure - https://github.com/tenstorrent/tt-xla/issues/1587"
