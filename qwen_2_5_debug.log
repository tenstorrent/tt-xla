WARNING:root:Defaulting to PJRT_DEVICE=CPU
Using TT-Metal from the source tree: /localdev/hshah/tt-xla/third_party/tt-mlir/src/tt-mlir/third_party/tt-metal/src/tt-metal
WARNING: TT plugin is setting XLA_STABLEHLO_COMPILE to 1. This is required for TT PJRT plugin to work correctly.
============================= test session starts ==============================
platform linux -- Python 3.11.13, pytest-8.4.2, pluggy-1.6.0 -- /localdev/hshah/tt-xla/venv/bin/python
cachedir: .pytest_cache
rootdir: /localdev/hshah/tt-xla
configfile: pytest.ini
plugins: jaxtyping-0.3.3, forked-1.6.0, split-0.10.0
collecting ... Workaround to exclude model: suryaocr from discovery. Issue #1166
Cannot import path: /localdev/hshah/tt-xla/third_party/tt_forge_models/yolov4/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
Cannot import path: /localdev/hshah/tt-xla/third_party/tt_forge_models/centernet/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
Cannot import path: /localdev/hshah/tt-xla/third_party/tt_forge_models/maptr/pytorch/loader.py: No module named 'mmcv'
Cannot import path: /localdev/hshah/tt-xla/third_party/tt_forge_models/uniad/pytorch/loader.py: No module named 'casadi'
Cannot import path: /localdev/hshah/tt-xla/third_party/tt_forge_models/yolov6/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
Cannot import path: /localdev/hshah/tt-xla/third_party/tt_forge_models/yolov9/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
Cannot import path: /localdev/hshah/tt-xla/third_party/tt_forge_models/yoloworld/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
Cannot import path: /localdev/hshah/tt-xla/third_party/tt_forge_models/yolov10/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
Cannot import path: /localdev/hshah/tt-xla/third_party/tt_forge_models/vadv2/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
Cannot import path: /localdev/hshah/tt-xla/third_party/tt_forge_models/yolov5/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
Cannot import path: /localdev/hshah/tt-xla/third_party/tt_forge_models/yolov8/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
Cannot import path: /localdev/hshah/tt-xla/third_party/tt_forge_models/rcnn/pytorch/loader.py: libGL.so.1: cannot open shared object file: No such file or directory
collected 1 item

tests/runner/test_models.py::test_all_models[full-inference] Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 554.29it/s]
Some weights of the model checkpoint at Qwen/Qwen2.5-7B-Instruct were not used when initializing Qwen2ForCausalLM: ['model.layers.1.input_layernorm.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.1.post_attention_layernorm.weight', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.input_layernorm.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.10.post_attention_layernorm.weight', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.input_layernorm.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.11.mlp.up_proj.weight', 'model.layers.11.post_attention_layernorm.weight', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.input_layernorm.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.12.post_attention_layernorm.weight', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.input_layernorm.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.13.post_attention_layernorm.weight', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.14.input_layernorm.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.14.post_attention_layernorm.weight', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.input_layernorm.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.15.mlp.gate_proj.weight', 'model.layers.15.mlp.up_proj.weight', 'model.layers.15.post_attention_layernorm.weight', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.16.input_layernorm.weight', 'model.layers.16.mlp.down_proj.weight', 'model.layers.16.mlp.gate_proj.weight', 'model.layers.16.mlp.up_proj.weight', 'model.layers.16.post_attention_layernorm.weight', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.17.input_layernorm.weight', 'model.layers.17.mlp.down_proj.weight', 'model.layers.17.mlp.gate_proj.weight', 'model.layers.17.mlp.up_proj.weight', 'model.layers.17.post_attention_layernorm.weight', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.input_layernorm.weight', 'model.layers.18.mlp.down_proj.weight', 'model.layers.18.mlp.gate_proj.weight', 'model.layers.18.mlp.up_proj.weight', 'model.layers.18.post_attention_layernorm.weight', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.19.input_layernorm.weight', 'model.layers.19.mlp.down_proj.weight', 'model.layers.19.mlp.gate_proj.weight', 'model.layers.19.mlp.up_proj.weight', 'model.layers.19.post_attention_layernorm.weight', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.2.input_layernorm.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.2.post_attention_layernorm.weight', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.20.input_layernorm.weight', 'model.layers.20.mlp.down_proj.weight', 'model.layers.20.mlp.gate_proj.weight', 'model.layers.20.mlp.up_proj.weight', 'model.layers.20.post_attention_layernorm.weight', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.21.input_layernorm.weight', 'model.layers.21.mlp.down_proj.weight', 'model.layers.21.mlp.gate_proj.weight', 'model.layers.21.mlp.up_proj.weight', 'model.layers.21.post_attention_layernorm.weight', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.input_layernorm.weight', 'model.layers.22.mlp.down_proj.weight', 'model.layers.22.mlp.gate_proj.weight', 'model.layers.22.mlp.up_proj.weight', 'model.layers.22.post_attention_layernorm.weight', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.input_layernorm.weight', 'model.layers.23.mlp.down_proj.weight', 'model.layers.23.mlp.gate_proj.weight', 'model.layers.23.mlp.up_proj.weight', 'model.layers.23.post_attention_layernorm.weight', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.24.input_layernorm.weight', 'model.layers.24.mlp.down_proj.weight', 'model.layers.24.mlp.gate_proj.weight', 'model.layers.24.mlp.up_proj.weight', 'model.layers.24.post_attention_layernorm.weight', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.input_layernorm.weight', 'model.layers.25.mlp.down_proj.weight', 'model.layers.25.mlp.gate_proj.weight', 'model.layers.25.mlp.up_proj.weight', 'model.layers.25.post_attention_layernorm.weight', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.input_layernorm.weight', 'model.layers.26.mlp.down_proj.weight', 'model.layers.26.mlp.gate_proj.weight', 'model.layers.26.mlp.up_proj.weight', 'model.layers.26.post_attention_layernorm.weight', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.27.input_layernorm.weight', 'model.layers.27.mlp.down_proj.weight', 'model.layers.27.mlp.gate_proj.weight', 'model.layers.27.mlp.up_proj.weight', 'model.layers.27.post_attention_layernorm.weight', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.o_proj.weight', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.3.input_layernorm.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.3.post_attention_layernorm.weight', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.4.input_layernorm.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.4.post_attention_layernorm.weight', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.5.input_layernorm.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.5.post_attention_layernorm.weight', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.6.input_layernorm.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.6.post_attention_layernorm.weight', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.input_layernorm.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.7.post_attention_layernorm.weight', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.input_layernorm.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.8.post_attention_layernorm.weight', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.9.input_layernorm.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.9.post_attention_layernorm.weight', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.9.self_attn.v_proj.weight']
- This IS expected if you are initializing Qwen2ForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Qwen2ForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Read unexpected run_mailbox value: 0x40 (expected 0x80 or 0x0)
2025-10-08 21:10:41.352 | critical |          Always | Read unexpected run_mailbox value from core (x=25,y=16) (assert.hpp:103)
2025-10-08 21:10:53.071408: W torch_xla/csrc/runtime/profiler.cpp:88] Profiler API not found for PJRT plugin
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
#loc1 = loc("xla__device_data")
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<2x39x!vhlo.i64_v1> loc("xla__device_data"), %arg1: !vhlo.tensor_v1<152064x3584x!vhlo.bf16_v1> loc("xla__device_data")) -> (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<39x!vhlo.i64_v1>, !vhlo.tensor_v1<1x39x!vhlo.i64_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>>}> : () -> !vhlo.tensor_v1<1x39x!vhlo.i64_v1> loc(#loc)
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>>}> : () -> !vhlo.tensor_v1<39x!vhlo.i64_v1> loc(#loc)
    %2 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<152064x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x152064x3584x!vhlo.bf16_v1> loc(#loc2)
    %3 = "vhlo.custom_call_v1"(%2) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___embed_tokens_weight">}>} : (!vhlo.tensor_v1<1x152064x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x152064x3584x!vhlo.bf16_v1> loc(#loc3)
    %4 = "vhlo.reshape_v1"(%3) : (!vhlo.tensor_v1<1x152064x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<152064x3584x!vhlo.bf16_v1> loc(#loc2)
    %5 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<2x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x2x39x!vhlo.i64_v1> loc(#loc2)
    %6 = "vhlo.custom_call_v1"(%5) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x2x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x2x39x!vhlo.i64_v1> loc(#loc3)
    %7 = "vhlo.reshape_v1"(%6) : (!vhlo.tensor_v1<1x2x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<78x!vhlo.i64_v1> loc(#loc2)
    %8 = "vhlo.convert_v1"(%7) : (!vhlo.tensor_v1<78x!vhlo.i64_v1>) -> !vhlo.tensor_v1<78x!vhlo.ui32_v1> loc(#loc4)
    %9 = "vhlo.gather_v2"(%4, %8) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 3584]> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<152064x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<78x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1> loc(#loc4)
    %10 = "vhlo.reshape_v1"(%9) : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1> loc(#loc2)
    "vhlo.return_v1"(%10, %1, %0) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<39x!vhlo.i64_v1>, !vhlo.tensor_v1<1x39x!vhlo.i64_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1,4]<=[8] last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("aten__view")
#loc3 = loc("xla__custom_call")
#loc4 = loc("aten__index_select")
// -----// IR Dump Before VhloToVersionPass (vhlo-to-version) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<2x39x!vhlo.i64_v1>, %arg1: !vhlo.tensor_v1<152064x3584x!vhlo.bf16_v1>) -> (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<39x!vhlo.i64_v1>, !vhlo.tensor_v1<1x39x!vhlo.i64_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>>}> : () -> !vhlo.tensor_v1<1x39x!vhlo.i64_v1>
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>>}> : () -> !vhlo.tensor_v1<39x!vhlo.i64_v1>
    %2 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<152064x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x152064x3584x!vhlo.bf16_v1>
    %3 = "vhlo.custom_call_v1"(%2) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___embed_tokens_weight">}>} : (!vhlo.tensor_v1<1x152064x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x152064x3584x!vhlo.bf16_v1>
    %4 = "vhlo.reshape_v1"(%3) : (!vhlo.tensor_v1<1x152064x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<152064x3584x!vhlo.bf16_v1>
    %5 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<2x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x2x39x!vhlo.i64_v1>
    %6 = "vhlo.custom_call_v1"(%5) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x2x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x2x39x!vhlo.i64_v1>
    %7 = "vhlo.reshape_v1"(%6) : (!vhlo.tensor_v1<1x2x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<78x!vhlo.i64_v1>
    %8 = "vhlo.convert_v1"(%7) : (!vhlo.tensor_v1<78x!vhlo.i64_v1>) -> !vhlo.tensor_v1<78x!vhlo.ui32_v1>
    %9 = "vhlo.gather_v2"(%4, %8) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 3584]> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<152064x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<78x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>
    %10 = "vhlo.reshape_v1"(%9) : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    "vhlo.return_v1"(%10, %1, %0) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<39x!vhlo.i64_v1>, !vhlo.tensor_v1<1x39x!vhlo.i64_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1,4]<=[8] last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}


// -----// IR Dump Before VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<2x39x!vhlo.i64_v1>, %arg1: !vhlo.tensor_v1<152064x3584x!vhlo.bf16_v1>) -> (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<39x!vhlo.i64_v1>, !vhlo.tensor_v1<1x39x!vhlo.i64_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>>}> : () -> !vhlo.tensor_v1<1x39x!vhlo.i64_v1>
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>>}> : () -> !vhlo.tensor_v1<39x!vhlo.i64_v1>
    %2 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<152064x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x152064x3584x!vhlo.bf16_v1>
    %3 = "vhlo.custom_call_v1"(%2) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___embed_tokens_weight">}>} : (!vhlo.tensor_v1<1x152064x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x152064x3584x!vhlo.bf16_v1>
    %4 = "vhlo.reshape_v1"(%3) : (!vhlo.tensor_v1<1x152064x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<152064x3584x!vhlo.bf16_v1>
    %5 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<2x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x2x39x!vhlo.i64_v1>
    %6 = "vhlo.custom_call_v1"(%5) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x2x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x2x39x!vhlo.i64_v1>
    %7 = "vhlo.reshape_v1"(%6) : (!vhlo.tensor_v1<1x2x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<78x!vhlo.i64_v1>
    %8 = "vhlo.convert_v1"(%7) : (!vhlo.tensor_v1<78x!vhlo.i64_v1>) -> !vhlo.tensor_v1<78x!vhlo.ui32_v1>
    %9 = "vhlo.gather_v2"(%4, %8) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 3584]> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<152064x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<78x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>
    %10 = "vhlo.reshape_v1"(%9) : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    "vhlo.return_v1"(%10, %1, %0) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<39x!vhlo.i64_v1>, !vhlo.tensor_v1<1x39x!vhlo.i64_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1,4]<=[8] last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}


// -----// IR Dump After VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}"}, %arg1: tensor<152064x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"}) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>) {
    %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %0 = stablehlo.reshape %arg1 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
    %1 = stablehlo.custom_call @tt.mark_argument(%0) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___embed_tokens_weight"}} : (tensor<1x152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
    %2 = stablehlo.reshape %1 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %3 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<1x2x39xi64>
    %4 = stablehlo.custom_call @tt.mark_argument(%3) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<1x2x39xi64>) -> tensor<1x2x39xi64>
    %5 = stablehlo.reshape %4 : (tensor<1x2x39xi64>) -> tensor<78xi64>
    %6 = stablehlo.convert %5 : (tensor<78xi64>) -> tensor<78xui32>
    %7 = "stablehlo.gather"(%2, %6) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<78xui32>) -> tensor<78x3584xbf16>
    %8 = stablehlo.reshape %7 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    return %8, %c_0, %c : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


#loc1 = loc("xla__device_data")
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}"} loc("xla__device_data"), %arg1: tensor<152064x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("xla__device_data")) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>) {
    %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64> loc(#loc)
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64> loc(#loc)
    %0 = stablehlo.reshape %arg1 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16> loc(#loc2)
    %1 = stablehlo.custom_call @tt.mark_argument(%0) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___embed_tokens_weight"}} : (tensor<1x152064x3584xbf16>) -> tensor<1x152064x3584xbf16> loc(#loc3)
    %2 = stablehlo.reshape %1 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16> loc(#loc2)
    %3 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<1x2x39xi64> loc(#loc2)
    %4 = stablehlo.custom_call @tt.mark_argument(%3) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<1x2x39xi64>) -> tensor<1x2x39xi64> loc(#loc3)
    %5 = stablehlo.reshape %4 : (tensor<1x2x39xi64>) -> tensor<78xi64> loc(#loc2)
    %6 = stablehlo.convert %5 : (tensor<78xi64>) -> tensor<78xui32> loc(#loc4)
    %7 = "stablehlo.gather"(%2, %6) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<78xui32>) -> tensor<78x3584xbf16> loc(#loc4)
    %8 = stablehlo.reshape %7 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16> loc(#loc2)
    return %8, %c_0, %c : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("aten__view")
#loc3 = loc("xla__custom_call")
#loc4 = loc("aten__index_select")
#loc1 = loc("xla__device_data")
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"} loc("xla__device_data"), %arg1: tensor<152064x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___embed_tokens_weight"} loc("xla__device_data")) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>) {
    %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64> loc(#loc)
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64> loc(#loc)
    %0 = stablehlo.reshape %arg1 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16> loc(#loc2)
    %1 = stablehlo.reshape %0 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16> loc(#loc2)
    %2 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<1x2x39xi64> loc(#loc2)
    %3 = stablehlo.reshape %2 : (tensor<1x2x39xi64>) -> tensor<78xi64> loc(#loc2)
    %4 = stablehlo.convert %3 : (tensor<78xi64>) -> tensor<78xui32> loc(#loc3)
    %5 = "stablehlo.gather"(%1, %4) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<78xui32>) -> tensor<78x3584xbf16> loc(#loc3)
    %6 = stablehlo.reshape %5 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16> loc(#loc2)
    return %6, %c_0, %c : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("aten__view")
#loc3 = loc("aten__index_select")
// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>) {
    %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %0 = stablehlo.reshape %arg1 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
    %1 = stablehlo.reshape %0 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %2 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<1x2x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x2x39xi64>) -> tensor<78xi64>
    %4 = stablehlo.convert %3 : (tensor<78xi64>) -> tensor<78xui32>
    %5 = "stablehlo.gather"(%1, %4) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<78xui32>) -> tensor<78x3584xbf16>
    %6 = stablehlo.reshape %5 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    return %6, %c_0, %c : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>) {
    %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %0 = stablehlo.reshape %arg1 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
    %1 = stablehlo.reshape %0 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %2 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<1x2x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x2x39xi64>) -> tensor<78xi64>
    %4 = stablehlo.convert %3 : (tensor<78xi64>) -> tensor<78xui32>
    %5 = "stablehlo.gather"(%1, %4) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<78xui32>) -> tensor<78x3584xbf16>
    %6 = stablehlo.reshape %5 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    return %6, %c_0, %c : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump Before TTPopulateArgumentTypes (tt-populate-argument-types) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>) {
    %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %0 = stablehlo.reshape %arg1 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
    %1 = stablehlo.reshape %0 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %2 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<1x2x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x2x39xi64>) -> tensor<78xi64>
    %4 = stablehlo.convert %3 : (tensor<78xi64>) -> tensor<78xui32>
    %5 = "stablehlo.gather"(%1, %4) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<78xui32>) -> tensor<78x3584xbf16>
    %6 = stablehlo.reshape %5 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    return %6, %c_0, %c : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump Before ApplyArgumentShardStatusPass (apply-argument-shard-status) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>) {
    %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %0 = stablehlo.reshape %arg1 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
    %1 = stablehlo.reshape %0 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %2 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<1x2x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x2x39xi64>) -> tensor<78xi64>
    %4 = stablehlo.convert %3 : (tensor<78xi64>) -> tensor<78xui32>
    %5 = "stablehlo.gather"(%1, %4) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<78xui32>) -> tensor<78x3584xbf16>
    %6 = stablehlo.reshape %5 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    return %6, %c_0, %c : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump After ApplyArgumentShardStatusPass (apply-argument-shard-status) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %0 = stablehlo.reshape %arg1 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
    %1 = stablehlo.reshape %0 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %2 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<1x2x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x2x39xi64>) -> tensor<78xi64>
    %4 = stablehlo.convert %3 : (tensor<78xi64>) -> tensor<78xui32>
    %5 = "stablehlo.gather"(%1, %4) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<78xui32>) -> tensor<78x3584xbf16>
    %6 = stablehlo.reshape %5 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    return %6, %c_0, %c : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump Before ConvertXlaSdyToSdyPass (convert-xla-sdy-to-sdy) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %0 = stablehlo.reshape %arg1 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
    %1 = stablehlo.reshape %0 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %2 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<1x2x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x2x39xi64>) -> tensor<78xi64>
    %4 = stablehlo.convert %3 : (tensor<78xi64>) -> tensor<78xui32>
    %5 = "stablehlo.gather"(%1, %4) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<78xui32>) -> tensor<78x3584xbf16>
    %6 = stablehlo.reshape %5 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    return %6, %c_0, %c : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump After ConvertXlaSdyToSdyPass (convert-xla-sdy-to-sdy) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %0 = stablehlo.reshape %arg1 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
    %1 = stablehlo.reshape %0 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %2 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<1x2x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x2x39xi64>) -> tensor<78xi64>
    %4 = stablehlo.convert %3 : (tensor<78xi64>) -> tensor<78xui32>
    %5 = "stablehlo.gather"(%1, %4) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<78xui32>) -> tensor<78x3584xbf16>
    %6 = stablehlo.reshape %5 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    return %6, %c_0, %c : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump Before AnalyzeMeshPass (analyze-mesh) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %0 = stablehlo.reshape %arg1 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
    %1 = stablehlo.reshape %0 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %2 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<1x2x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x2x39xi64>) -> tensor<78xi64>
    %4 = stablehlo.convert %3 : (tensor<78xi64>) -> tensor<78xui32>
    %5 = "stablehlo.gather"(%1, %4) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<78xui32>) -> tensor<78x3584xbf16>
    %6 = stablehlo.reshape %5 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    return %6, %c_0, %c : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump Before ApplyShardingConstraintsPass (sdy-apply-sharding-constraints) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %0 = stablehlo.reshape %arg1 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
    %1 = stablehlo.reshape %0 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %2 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<1x2x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x2x39xi64>) -> tensor<78xi64>
    %4 = stablehlo.convert %3 : (tensor<78xi64>) -> tensor<78xui32>
    %5 = "stablehlo.gather"(%1, %4) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<78xui32>) -> tensor<78x3584xbf16>
    %6 = stablehlo.reshape %5 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    return %6, %c_0, %c : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump Before AggressivePropagationPass (sdy-aggressive-propagate) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %0 = stablehlo.reshape %arg1 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
    %1 = stablehlo.reshape %0 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %2 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<1x2x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x2x39xi64>) -> tensor<78xi64>
    %4 = stablehlo.convert %3 : (tensor<78xi64>) -> tensor<78xui32>
    %5 = "stablehlo.gather"(%1, %4) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<78xui32>) -> tensor<78x3584xbf16>
    %6 = stablehlo.reshape %5 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    return %6, %c_0, %c : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump After AggressivePropagationPass (sdy-aggressive-propagate) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %0 = stablehlo.reshape %arg1 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
    %1 = stablehlo.reshape %0 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %2 = stablehlo.reshape %arg0 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<1x2x39xi64>
    %3 = stablehlo.reshape %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x2x39xi64>) -> tensor<78xi64>
    %4 = stablehlo.convert %3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<78xi64>) -> tensor<78xui32>
    %5 = "stablehlo.gather"(%1, %4) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<152064x3584xbf16>, tensor<78xui32>) -> tensor<78x3584xbf16>
    %6 = stablehlo.reshape %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    return %6, %c_0, %c : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump Before ShardingConstraintToReshardPass (sdy-sharding-constraint-to-reshard) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %0 = stablehlo.reshape %arg1 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
    %1 = stablehlo.reshape %0 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %2 = stablehlo.reshape %arg0 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<1x2x39xi64>
    %3 = stablehlo.reshape %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x2x39xi64>) -> tensor<78xi64>
    %4 = stablehlo.convert %3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<78xi64>) -> tensor<78xui32>
    %5 = "stablehlo.gather"(%1, %4) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<152064x3584xbf16>, tensor<78xui32>) -> tensor<78x3584xbf16>
    %6 = stablehlo.reshape %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    return %6, %c_0, %c : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump Before InsertExplicitReshardsPass (sdy-insert-explicit-reshards) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %0 = stablehlo.reshape %arg1 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
    %1 = stablehlo.reshape %0 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %2 = stablehlo.reshape %arg0 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<1x2x39xi64>
    %3 = stablehlo.reshape %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x2x39xi64>) -> tensor<78xi64>
    %4 = stablehlo.convert %3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<78xi64>) -> tensor<78xui32>
    %5 = "stablehlo.gather"(%1, %4) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<152064x3584xbf16>, tensor<78xui32>) -> tensor<78x3584xbf16>
    %6 = stablehlo.reshape %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    return %6, %c_0, %c : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump Before WrapUnderManualComputationPass (wrap-under-manual-computation) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %0 = stablehlo.reshape %arg1 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
    %1 = stablehlo.reshape %0 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %2 = stablehlo.reshape %arg0 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<1x2x39xi64>
    %3 = stablehlo.reshape %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x2x39xi64>) -> tensor<78xi64>
    %4 = stablehlo.convert %3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<78xi64>) -> tensor<78xui32>
    %5 = "stablehlo.gather"(%1, %4) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<152064x3584xbf16>, tensor<78xui32>) -> tensor<78x3584xbf16>
    %6 = stablehlo.reshape %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    return %6, %c_0, %c : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump After WrapUnderManualComputationPass (wrap-under-manual-computation) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1) in_shardings=[<@mesh, [{"_axis_0", ?}, {?}]>, <@mesh, [{?}, {?}]>] out_shardings=[<@mesh, [{"_axis_0", ?}, {?}, {?}]>, <@mesh, [{?}]>, <@mesh, [{?}, {?}]>] manual_axes={} (%arg2: tensor<2x39xi64>, %arg3: tensor<152064x3584xbf16>) {
      %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
      %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
      %1 = stablehlo.reshape %arg3 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
      %2 = stablehlo.reshape %1 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
      %3 = stablehlo.reshape %arg2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<1x2x39xi64>
      %4 = stablehlo.reshape %3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x2x39xi64>) -> tensor<78xi64>
      %5 = stablehlo.convert %4 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<78xi64>) -> tensor<78xui32>
      %6 = "stablehlo.gather"(%2, %5) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<152064x3584xbf16>, tensor<78xui32>) -> tensor<78x3584xbf16>
      %7 = stablehlo.reshape %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
      sdy.return %7, %c_0, %c : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
    } : (tensor<2x39xi64>, tensor<152064x3584xbf16>) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>)
    return %0#0, %0#1, %0#2 : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump Before ReshardToCollectivesPass (sdy-reshard-to-collectives) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1) in_shardings=[<@mesh, [{"_axis_0", ?}, {?}]>, <@mesh, [{?}, {?}]>] out_shardings=[<@mesh, [{"_axis_0", ?}, {?}, {?}]>, <@mesh, [{?}]>, <@mesh, [{?}, {?}]>] manual_axes={} (%arg2: tensor<2x39xi64>, %arg3: tensor<152064x3584xbf16>) {
      %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
      %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
      %1 = stablehlo.reshape %arg3 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
      %2 = stablehlo.reshape %1 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
      %3 = stablehlo.reshape %arg2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<1x2x39xi64>
      %4 = stablehlo.reshape %3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x2x39xi64>) -> tensor<78xi64>
      %5 = stablehlo.convert %4 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<78xi64>) -> tensor<78xui32>
      %6 = "stablehlo.gather"(%2, %5) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<152064x3584xbf16>, tensor<78xui32>) -> tensor<78x3584xbf16>
      %7 = stablehlo.reshape %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
      sdy.return %7, %c_0, %c : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
    } : (tensor<2x39xi64>, tensor<152064x3584xbf16>) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>)
    return %0#0, %0#1, %0#2 : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump Before UpdateGlobalToLocalShapesPass (update-global-to-local-shapes) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1) in_shardings=[<@mesh, [{"_axis_0", ?}, {?}]>, <@mesh, [{?}, {?}]>] out_shardings=[<@mesh, [{"_axis_0", ?}, {?}, {?}]>, <@mesh, [{?}]>, <@mesh, [{?}, {?}]>] manual_axes={} (%arg2: tensor<2x39xi64>, %arg3: tensor<152064x3584xbf16>) {
      %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
      %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
      %1 = stablehlo.reshape %arg3 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
      %2 = stablehlo.reshape %1 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
      %3 = stablehlo.reshape %arg2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<1x2x39xi64>
      %4 = stablehlo.reshape %3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x2x39xi64>) -> tensor<78xi64>
      %5 = stablehlo.convert %4 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<78xi64>) -> tensor<78xui32>
      %6 = "stablehlo.gather"(%2, %5) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<152064x3584xbf16>, tensor<78xui32>) -> tensor<78x3584xbf16>
      %7 = stablehlo.reshape %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
      sdy.return %7, %c_0, %c : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
    } : (tensor<2x39xi64>, tensor<152064x3584xbf16>) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>)
    return %0#0, %0#1, %0#2 : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump After UpdateGlobalToLocalShapesPass (update-global-to-local-shapes) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1) in_shardings=[<@mesh, [{"_axis_0", ?}, {?}]>, <@mesh, [{?}, {?}]>] out_shardings=[<@mesh, [{"_axis_0", ?}, {?}, {?}]>, <@mesh, [{?}]>, <@mesh, [{?}, {?}]>] manual_axes={"_axis_0", "_axis_1"} (%arg2: tensor<1x39xi64>, %arg3: tensor<152064x3584xbf16>) {
      %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
      %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
      %1 = stablehlo.reshape %arg3 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
      %2 = stablehlo.reshape %1 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
      %3 = stablehlo.reshape %arg2 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
      %4 = stablehlo.reshape %3 : (tensor<1x1x39xi64>) -> tensor<39xi64>
      %5 = stablehlo.convert %4 : (tensor<39xi64>) -> tensor<39xui32>
      %6 = "stablehlo.gather"(%2, %5) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<39xui32>) -> tensor<39x3584xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x3584xbf16>) -> tensor<1x39x3584xbf16>
      sdy.return %7, %c_0, %c : tensor<1x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
    } : (tensor<2x39xi64>, tensor<152064x3584xbf16>) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>)
    return %0#0, %0#1, %0#2 : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump Before CloseShardingsPass (sdy-close-shardings) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1) in_shardings=[<@mesh, [{"_axis_0", ?}, {?}]>, <@mesh, [{?}, {?}]>] out_shardings=[<@mesh, [{"_axis_0", ?}, {?}, {?}]>, <@mesh, [{?}]>, <@mesh, [{?}, {?}]>] manual_axes={"_axis_0", "_axis_1"} (%arg2: tensor<1x39xi64>, %arg3: tensor<152064x3584xbf16>) {
      %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
      %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
      %1 = stablehlo.reshape %arg3 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
      %2 = stablehlo.reshape %1 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
      %3 = stablehlo.reshape %arg2 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
      %4 = stablehlo.reshape %3 : (tensor<1x1x39xi64>) -> tensor<39xi64>
      %5 = stablehlo.convert %4 : (tensor<39xi64>) -> tensor<39xui32>
      %6 = "stablehlo.gather"(%2, %5) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<39xui32>) -> tensor<39x3584xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x3584xbf16>) -> tensor<1x39x3584xbf16>
      sdy.return %7, %c_0, %c : tensor<1x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
    } : (tensor<2x39xi64>, tensor<152064x3584xbf16>) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>)
    return %0#0, %0#1, %0#2 : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump After CloseShardingsPass (sdy-close-shardings) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1) in_shardings=[<@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>] out_shardings=[<@mesh, [{"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg2: tensor<1x39xi64>, %arg3: tensor<152064x3584xbf16>) {
      %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
      %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
      %1 = stablehlo.reshape %arg3 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
      %2 = stablehlo.reshape %1 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
      %3 = stablehlo.reshape %arg2 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
      %4 = stablehlo.reshape %3 : (tensor<1x1x39xi64>) -> tensor<39xi64>
      %5 = stablehlo.convert %4 : (tensor<39xi64>) -> tensor<39xui32>
      %6 = "stablehlo.gather"(%2, %5) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<39xui32>) -> tensor<39x3584xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x3584xbf16>) -> tensor<1x39x3584xbf16>
      sdy.return %7, %c_0, %c : tensor<1x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
    } : (tensor<2x39xi64>, tensor<152064x3584xbf16>) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>)
    return %0#0, %0#1, %0#2 : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1) in_shardings=[<@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>] out_shardings=[<@mesh, [{"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg2: tensor<1x39xi64>, %arg3: tensor<152064x3584xbf16>) {
      %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
      %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
      %1 = stablehlo.reshape %arg3 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
      %2 = stablehlo.reshape %1 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
      %3 = stablehlo.reshape %arg2 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
      %4 = stablehlo.reshape %3 : (tensor<1x1x39xi64>) -> tensor<39xi64>
      %5 = stablehlo.convert %4 : (tensor<39xi64>) -> tensor<39xui32>
      %6 = "stablehlo.gather"(%2, %5) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<39xui32>) -> tensor<39x3584xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x3584xbf16>) -> tensor<1x39x3584xbf16>
      sdy.return %7, %c_0, %c : tensor<1x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
    } : (tensor<2x39xi64>, tensor<152064x3584xbf16>) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>)
    return %0#0, %0#1, %0#2 : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


#loc1 = loc("xla__device_data")
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]> loc(#loc)
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("xla__device_data"), %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"} loc("xla__device_data")) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1) in_shardings=[<@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>] out_shardings=[<@mesh, [{"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg2: tensor<1x39xi64> loc("xla__device_data"), %arg3: tensor<152064x3584xbf16> loc("xla__device_data")) {
      %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64> loc(#loc)
      %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64> loc(#loc)
      %1 = stablehlo.reshape %arg3 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16> loc(#loc2)
      %2 = stablehlo.reshape %1 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16> loc(#loc2)
      %3 = stablehlo.reshape %arg2 : (tensor<1x39xi64>) -> tensor<1x1x39xi64> loc(#loc2)
      %4 = stablehlo.reshape %3 : (tensor<1x1x39xi64>) -> tensor<39xi64> loc(#loc2)
      %5 = stablehlo.convert %4 : (tensor<39xi64>) -> tensor<39xui32> loc(#loc3)
      %6 = "stablehlo.gather"(%2, %5) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<39xui32>) -> tensor<39x3584xbf16> loc(#loc3)
      %7 = stablehlo.reshape %6 : (tensor<39x3584xbf16>) -> tensor<1x39x3584xbf16> loc(#loc2)
      sdy.return %7, %c_0, %c : tensor<1x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64> loc(#loc)
    } : (tensor<2x39xi64>, tensor<152064x3584xbf16>) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>) loc(#loc)
    return %0#0, %0#1, %0#2 : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("aten__view")
#loc3 = loc("aten__index_select")
// -----// IR Dump Before ConvertArithToStableHLO (convert-arith-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1) in_shardings=[<@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>] out_shardings=[<@mesh, [{"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg2: tensor<1x39xi64>, %arg3: tensor<152064x3584xbf16>) {
      %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
      %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
      %1 = stablehlo.reshape %arg3 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
      %2 = stablehlo.reshape %1 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
      %3 = stablehlo.reshape %arg2 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
      %4 = stablehlo.reshape %3 : (tensor<1x1x39xi64>) -> tensor<39xi64>
      %5 = stablehlo.convert %4 : (tensor<39xi64>) -> tensor<39xui32>
      %6 = "stablehlo.gather"(%2, %5) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<39xui32>) -> tensor<39x3584xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x3584xbf16>) -> tensor<1x39x3584xbf16>
      sdy.return %7, %c_0, %c : tensor<1x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
    } : (tensor<2x39xi64>, tensor<152064x3584xbf16>) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>)
    return %0#0, %0#1, %0#2 : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump Before LegalizeStableHLOCompositeToTTIR (legalize-stablehlo-composite-to-ttir) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1) in_shardings=[<@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>] out_shardings=[<@mesh, [{"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg2: tensor<1x39xi64>, %arg3: tensor<152064x3584xbf16>) {
      %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
      %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
      %1 = stablehlo.reshape %arg3 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
      %2 = stablehlo.reshape %1 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
      %3 = stablehlo.reshape %arg2 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
      %4 = stablehlo.reshape %3 : (tensor<1x1x39xi64>) -> tensor<39xi64>
      %5 = stablehlo.convert %4 : (tensor<39xi64>) -> tensor<39xui32>
      %6 = "stablehlo.gather"(%2, %5) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<39xui32>) -> tensor<39x3584xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x3584xbf16>) -> tensor<1x39x3584xbf16>
      sdy.return %7, %c_0, %c : tensor<1x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
    } : (tensor<2x39xi64>, tensor<152064x3584xbf16>) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>)
    return %0#0, %0#1, %0#2 : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump Before StablehloLegalizeCompositeToCallPass (stablehlo-legalize-composite-to-call) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1) in_shardings=[<@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>] out_shardings=[<@mesh, [{"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg2: tensor<1x39xi64>, %arg3: tensor<152064x3584xbf16>) {
      %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
      %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
      %1 = stablehlo.reshape %arg3 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
      %2 = stablehlo.reshape %1 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
      %3 = stablehlo.reshape %arg2 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
      %4 = stablehlo.reshape %3 : (tensor<1x1x39xi64>) -> tensor<39xi64>
      %5 = stablehlo.convert %4 : (tensor<39xi64>) -> tensor<39xui32>
      %6 = "stablehlo.gather"(%2, %5) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<39xui32>) -> tensor<39x3584xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x3584xbf16>) -> tensor<1x39x3584xbf16>
      sdy.return %7, %c_0, %c : tensor<1x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
    } : (tensor<2x39xi64>, tensor<152064x3584xbf16>) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>)
    return %0#0, %0#1, %0#2 : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1) in_shardings=[<@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>] out_shardings=[<@mesh, [{"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg2: tensor<1x39xi64>, %arg3: tensor<152064x3584xbf16>) {
      %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
      %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
      %1 = stablehlo.reshape %arg3 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
      %2 = stablehlo.reshape %1 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
      %3 = stablehlo.reshape %arg2 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
      %4 = stablehlo.reshape %3 : (tensor<1x1x39xi64>) -> tensor<39xi64>
      %5 = stablehlo.convert %4 : (tensor<39xi64>) -> tensor<39xui32>
      %6 = "stablehlo.gather"(%2, %5) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<39xui32>) -> tensor<39x3584xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x3584xbf16>) -> tensor<1x39x3584xbf16>
      sdy.return %7, %c_0, %c : tensor<1x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
    } : (tensor<2x39xi64>, tensor<152064x3584xbf16>) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>)
    return %0#0, %0#1, %0#2 : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1) in_shardings=[<@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>] out_shardings=[<@mesh, [{"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg2: tensor<1x39xi64>, %arg3: tensor<152064x3584xbf16>) {
      %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
      %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
      %1 = stablehlo.reshape %arg3 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
      %2 = stablehlo.reshape %1 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
      %3 = stablehlo.reshape %arg2 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
      %4 = stablehlo.reshape %3 : (tensor<1x1x39xi64>) -> tensor<39xi64>
      %5 = stablehlo.convert %4 : (tensor<39xi64>) -> tensor<39xui32>
      %6 = "stablehlo.gather"(%2, %5) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<39xui32>) -> tensor<39x3584xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x3584xbf16>) -> tensor<1x39x3584xbf16>
      sdy.return %7, %c_0, %c : tensor<1x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
    } : (tensor<2x39xi64>, tensor<152064x3584xbf16>) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>)
    return %0#0, %0#1, %0#2 : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump Before ConvertStableHLOToTTIR (convert-stablehlo-to-ttir) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1) in_shardings=[<@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>] out_shardings=[<@mesh, [{"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg2: tensor<1x39xi64>, %arg3: tensor<152064x3584xbf16>) {
      %c = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>
      %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
      %1 = stablehlo.reshape %arg3 : (tensor<152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
      %2 = stablehlo.reshape %1 : (tensor<1x152064x3584xbf16>) -> tensor<152064x3584xbf16>
      %3 = stablehlo.reshape %arg2 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
      %4 = stablehlo.reshape %3 : (tensor<1x1x39xi64>) -> tensor<39xi64>
      %5 = stablehlo.convert %4 : (tensor<39xi64>) -> tensor<39xui32>
      %6 = "stablehlo.gather"(%2, %5) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3584>}> : (tensor<152064x3584xbf16>, tensor<39xui32>) -> tensor<39x3584xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x3584xbf16>) -> tensor<1x39x3584xbf16>
      sdy.return %7, %c_0, %c : tensor<1x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
    } : (tensor<2x39xi64>, tensor<152064x3584xbf16>) -> (tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>)
    return %0#0, %0#1, %0#2 : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump After ConvertStableHLOToTTIR (convert-stablehlo-to-ttir) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xi64>) -> tensor<1x39xi64>
    %1 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %2 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>}> : () -> tensor<1x39xi64>
    %3 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>}> : () -> tensor<39xi64>
    %4 = ttir.empty() : tensor<1x152064x3584xbf16>
    %5 = "ttir.reshape"(%1, %4) <{shape = [1 : i32, 152064 : i32, 3584 : i32]}> : (tensor<152064x3584xbf16>, tensor<1x152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
    %6 = ttir.empty() : tensor<152064x3584xbf16>
    %7 = "ttir.reshape"(%5, %6) <{shape = [152064 : i32, 3584 : i32]}> : (tensor<1x152064x3584xbf16>, tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %8 = ttir.empty() : tensor<1x1x39xi64>
    %9 = "ttir.reshape"(%0, %8) <{shape = [1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xi64>, tensor<1x1x39xi64>) -> tensor<1x1x39xi64>
    %10 = ttir.empty() : tensor<39xi64>
    %11 = "ttir.reshape"(%9, %10) <{shape = [39 : i32]}> : (tensor<1x1x39xi64>, tensor<39xi64>) -> tensor<39xi64>
    %12 = ttir.empty() : tensor<39xui32>
    %13 = "ttir.typecast"(%11, %12) <{conservative_folding = false}> : (tensor<39xi64>, tensor<39xui32>) -> tensor<39xui32>
    %14 = ttir.empty() : tensor<39x3584xbf16>
    %15 = "ttir.gather"(%7, %13, %14) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3584>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<152064x3584xbf16>, tensor<39xui32>, tensor<39x3584xbf16>) -> tensor<39x3584xbf16>
    %16 = ttir.empty() : tensor<1x39x3584xbf16>
    %17 = "ttir.reshape"(%15, %16) <{shape = [1 : i32, 39 : i32, 3584 : i32]}> : (tensor<39x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
    %18 = "ttir.mesh_shard"(%17) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
    %19 = "ttir.mesh_shard"(%3) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xi64>) -> tensor<39xi64>
    %20 = "ttir.mesh_shard"(%2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xi64>) -> tensor<1x39xi64>
    return %18, %19, %20 : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


#loc1 = loc("xla__device_data")
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("xla__device_data"), %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"} loc("xla__device_data")) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xi64>) -> tensor<1x39xi64> loc(#loc)
    %1 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16> loc(#loc)
    %2 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>}> : () -> tensor<1x39xi64> loc(#loc)
    %3 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>}> : () -> tensor<39xi64> loc(#loc)
    %4 = ttir.empty() : tensor<1x152064x3584xbf16> loc(#loc2)
    %5 = "ttir.reshape"(%1, %4) <{shape = [1 : i32, 152064 : i32, 3584 : i32]}> : (tensor<152064x3584xbf16>, tensor<1x152064x3584xbf16>) -> tensor<1x152064x3584xbf16> loc(#loc2)
    %6 = ttir.empty() : tensor<152064x3584xbf16> loc(#loc2)
    %7 = "ttir.reshape"(%5, %6) <{shape = [152064 : i32, 3584 : i32]}> : (tensor<1x152064x3584xbf16>, tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16> loc(#loc2)
    %8 = ttir.empty() : tensor<1x1x39xi64> loc(#loc2)
    %9 = "ttir.reshape"(%0, %8) <{shape = [1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xi64>, tensor<1x1x39xi64>) -> tensor<1x1x39xi64> loc(#loc2)
    %10 = ttir.empty() : tensor<39xi64> loc(#loc2)
    %11 = "ttir.reshape"(%9, %10) <{shape = [39 : i32]}> : (tensor<1x1x39xi64>, tensor<39xi64>) -> tensor<39xi64> loc(#loc2)
    %12 = ttir.empty() : tensor<39xui32> loc(#loc3)
    %13 = "ttir.typecast"(%11, %12) <{conservative_folding = false}> : (tensor<39xi64>, tensor<39xui32>) -> tensor<39xui32> loc(#loc3)
    %14 = ttir.empty() : tensor<39x3584xbf16> loc(#loc3)
    %15 = "ttir.gather"(%7, %13, %14) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3584>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<152064x3584xbf16>, tensor<39xui32>, tensor<39x3584xbf16>) -> tensor<39x3584xbf16> loc(#loc3)
    %16 = ttir.empty() : tensor<1x39x3584xbf16> loc(#loc2)
    %17 = "ttir.reshape"(%15, %16) <{shape = [1 : i32, 39 : i32, 3584 : i32]}> : (tensor<39x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16> loc(#loc2)
    %18 = "ttir.mesh_shard"(%17) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16> loc(#loc)
    %19 = "ttir.mesh_shard"(%3) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xi64>) -> tensor<39xi64> loc(#loc)
    %20 = "ttir.mesh_shard"(%2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xi64>) -> tensor<1x39xi64> loc(#loc)
    return %18, %19, %20 : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("aten__view")
#loc3 = loc("aten__index_select")
// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xi64>) -> tensor<1x39xi64>
    %1 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %2 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>}> : () -> tensor<1x39xi64>
    %3 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>}> : () -> tensor<39xi64>
    %4 = ttir.empty() : tensor<1x152064x3584xbf16>
    %5 = "ttir.reshape"(%1, %4) <{shape = [1 : i32, 152064 : i32, 3584 : i32]}> : (tensor<152064x3584xbf16>, tensor<1x152064x3584xbf16>) -> tensor<1x152064x3584xbf16>
    %6 = ttir.empty() : tensor<152064x3584xbf16>
    %7 = "ttir.reshape"(%5, %6) <{shape = [152064 : i32, 3584 : i32]}> : (tensor<1x152064x3584xbf16>, tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %8 = ttir.empty() : tensor<1x1x39xi64>
    %9 = "ttir.reshape"(%0, %8) <{shape = [1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xi64>, tensor<1x1x39xi64>) -> tensor<1x1x39xi64>
    %10 = ttir.empty() : tensor<39xi64>
    %11 = "ttir.reshape"(%9, %10) <{shape = [39 : i32]}> : (tensor<1x1x39xi64>, tensor<39xi64>) -> tensor<39xi64>
    %12 = ttir.empty() : tensor<39xui32>
    %13 = "ttir.typecast"(%11, %12) <{conservative_folding = false}> : (tensor<39xi64>, tensor<39xui32>) -> tensor<39xui32>
    %14 = ttir.empty() : tensor<39x3584xbf16>
    %15 = "ttir.gather"(%7, %13, %14) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3584>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<152064x3584xbf16>, tensor<39xui32>, tensor<39x3584xbf16>) -> tensor<39x3584xbf16>
    %16 = ttir.empty() : tensor<1x39x3584xbf16>
    %17 = "ttir.reshape"(%15, %16) <{shape = [1 : i32, 39 : i32, 3584 : i32]}> : (tensor<39x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
    %18 = "ttir.mesh_shard"(%17) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
    %19 = "ttir.mesh_shard"(%3) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xi64>) -> tensor<39xi64>
    %20 = "ttir.mesh_shard"(%2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xi64>) -> tensor<1x39xi64>
    return %18, %19, %20 : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>}> : () -> tensor<39xi64>
    %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>}> : () -> tensor<1x39xi64>
    %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xi64>) -> tensor<1x39xi64>
    %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %4 = ttir.empty() : tensor<39xi64>
    %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xi64>, tensor<39xi64>) -> tensor<39xi64>
    %6 = ttir.empty() : tensor<39xui32>
    %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xi64>, tensor<39xui32>) -> tensor<39xui32>
    %8 = ttir.empty() : tensor<39x3584xbf16>
    %9 = "ttir.gather"(%3, %7, %8) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3584>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<152064x3584xbf16>, tensor<39xui32>, tensor<39x3584xbf16>) -> tensor<39x3584xbf16>
    %10 = ttir.empty() : tensor<1x39x3584xbf16>
    %11 = "ttir.reshape"(%9, %10) <{shape = [1 : i32, 39 : i32, 3584 : i32]}> : (tensor<39x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
    %12 = "ttir.mesh_shard"(%11) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
    %13 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xi64>) -> tensor<39xi64>
    %14 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xi64>) -> tensor<1x39xi64>
    return %12, %13, %14 : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump Before ElementTypeNormalization (ttir-element-type-normalization) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xi64> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>}> : () -> tensor<39xi64>
    %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xi64>}> : () -> tensor<1x39xi64>
    %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xi64>) -> tensor<1x39xi64>
    %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %4 = ttir.empty() : tensor<39xi64>
    %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xi64>, tensor<39xi64>) -> tensor<39xi64>
    %6 = ttir.empty() : tensor<39xui32>
    %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xi64>, tensor<39xui32>) -> tensor<39xui32>
    %8 = ttir.empty() : tensor<39x3584xbf16>
    %9 = "ttir.gather"(%3, %7, %8) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3584>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<152064x3584xbf16>, tensor<39xui32>, tensor<39x3584xbf16>) -> tensor<39x3584xbf16>
    %10 = ttir.empty() : tensor<1x39x3584xbf16>
    %11 = "ttir.reshape"(%9, %10) <{shape = [1 : i32, 39 : i32, 3584 : i32]}> : (tensor<39x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
    %12 = "ttir.mesh_shard"(%11) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
    %13 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xi64>) -> tensor<39xi64>
    %14 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xi64>) -> tensor<1x39xi64>
    return %12, %13, %14 : tensor<2x39x3584xbf16>, tensor<39xi64>, tensor<1x39xi64>
  }
}


// -----// IR Dump After ElementTypeNormalization (ttir-element-type-normalization) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
    %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
    %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
    %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %4 = ttir.empty() : tensor<39xsi32>
    %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xsi32>, tensor<39xsi32>) -> tensor<39xsi32>
    %6 = ttir.empty() : tensor<39xui32>
    %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xsi32>, tensor<39xui32>) -> tensor<39xui32>
    %8 = ttir.empty() : tensor<39x3584xbf16>
    %9 = "ttir.gather"(%3, %7, %8) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3584>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<152064x3584xbf16>, tensor<39xui32>, tensor<39x3584xbf16>) -> tensor<39x3584xbf16>
    %10 = ttir.empty() : tensor<1x39x3584xbf16>
    %11 = "ttir.reshape"(%9, %10) <{shape = [1 : i32, 39 : i32, 3584 : i32]}> : (tensor<39x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
    %12 = "ttir.mesh_shard"(%11) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
    %13 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
    %14 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
    return %12, %13, %14 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
  }
}


// -----// IR Dump Before TTCoreWrapDeviceModulePass (ttcore-wrap-device-module) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
    %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
    %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
    %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
    %4 = ttir.empty() : tensor<39xsi32>
    %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xsi32>, tensor<39xsi32>) -> tensor<39xsi32>
    %6 = ttir.empty() : tensor<39xui32>
    %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xsi32>, tensor<39xui32>) -> tensor<39xui32>
    %8 = ttir.empty() : tensor<39x3584xbf16>
    %9 = "ttir.gather"(%3, %7, %8) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3584>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<152064x3584xbf16>, tensor<39xui32>, tensor<39x3584xbf16>) -> tensor<39x3584xbf16>
    %10 = ttir.empty() : tensor<1x39x3584xbf16>
    %11 = "ttir.reshape"(%9, %10) <{shape = [1 : i32, 39 : i32, 3584 : i32]}> : (tensor<39x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
    %12 = "ttir.mesh_shard"(%11) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
    %13 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
    %14 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
    return %12, %13, %14 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
  }
}


// -----// IR Dump After TTCoreWrapDeviceModulePass (ttcore-wrap-device-module) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<39xsi32>
        %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xsi32>, tensor<39xsi32>) -> tensor<39xsi32>
        %6 = ttir.empty() : tensor<39xui32>
        %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xsi32>, tensor<39xui32>) -> tensor<39xui32>
        %8 = ttir.empty() : tensor<39x3584xbf16>
        %9 = "ttir.gather"(%3, %7, %8) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3584>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<152064x3584xbf16>, tensor<39xui32>, tensor<39x3584xbf16>) -> tensor<39x3584xbf16>
        %10 = ttir.empty() : tensor<1x39x3584xbf16>
        %11 = "ttir.reshape"(%9, %10) <{shape = [1 : i32, 39 : i32, 3584 : i32]}> : (tensor<39x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %12 = "ttir.mesh_shard"(%11) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %13 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %14 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %12, %13, %14 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump Before TTIRHoistTransform (ttir-cpu-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<39xsi32>
        %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xsi32>, tensor<39xsi32>) -> tensor<39xsi32>
        %6 = ttir.empty() : tensor<39xui32>
        %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xsi32>, tensor<39xui32>) -> tensor<39xui32>
        %8 = ttir.empty() : tensor<39x3584xbf16>
        %9 = "ttir.gather"(%3, %7, %8) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3584>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<152064x3584xbf16>, tensor<39xui32>, tensor<39x3584xbf16>) -> tensor<39x3584xbf16>
        %10 = ttir.empty() : tensor<1x39x3584xbf16>
        %11 = "ttir.reshape"(%9, %10) <{shape = [1 : i32, 39 : i32, 3584 : i32]}> : (tensor<39x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %12 = "ttir.mesh_shard"(%11) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %13 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %14 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %12, %13, %14 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump Before TTCoreRegisterDevicePass (ttcore-register-device) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<39xsi32>
        %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xsi32>, tensor<39xsi32>) -> tensor<39xsi32>
        %6 = ttir.empty() : tensor<39xui32>
        %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xsi32>, tensor<39xui32>) -> tensor<39xui32>
        %8 = ttir.empty() : tensor<39x3584xbf16>
        %9 = "ttir.gather"(%3, %7, %8) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3584>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<152064x3584xbf16>, tensor<39xui32>, tensor<39x3584xbf16>) -> tensor<39x3584xbf16>
        %10 = ttir.empty() : tensor<1x39x3584xbf16>
        %11 = "ttir.reshape"(%9, %10) <{shape = [1 : i32, 39 : i32, 3584 : i32]}> : (tensor<39x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %12 = "ttir.mesh_shard"(%11) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %13 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %14 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %12, %13, %14 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump After TTCoreRegisterDevicePass (ttcore-register-device) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<39xsi32>
        %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xsi32>, tensor<39xsi32>) -> tensor<39xsi32>
        %6 = ttir.empty() : tensor<39xui32>
        %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xsi32>, tensor<39xui32>) -> tensor<39xui32>
        %8 = ttir.empty() : tensor<39x3584xbf16>
        %9 = "ttir.gather"(%3, %7, %8) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3584>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<152064x3584xbf16>, tensor<39xui32>, tensor<39x3584xbf16>) -> tensor<39x3584xbf16>
        %10 = ttir.empty() : tensor<1x39x3584xbf16>
        %11 = "ttir.reshape"(%9, %10) <{shape = [1 : i32, 39 : i32, 3584 : i32]}> : (tensor<39x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %12 = "ttir.mesh_shard"(%11) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %13 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %14 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %12, %13, %14 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump Before TTPopulateArgumentTypes (tt-populate-argument-types) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<39xsi32>
        %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xsi32>, tensor<39xsi32>) -> tensor<39xsi32>
        %6 = ttir.empty() : tensor<39xui32>
        %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xsi32>, tensor<39xui32>) -> tensor<39xui32>
        %8 = ttir.empty() : tensor<39x3584xbf16>
        %9 = "ttir.gather"(%3, %7, %8) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3584>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<152064x3584xbf16>, tensor<39xui32>, tensor<39x3584xbf16>) -> tensor<39x3584xbf16>
        %10 = ttir.empty() : tensor<1x39x3584xbf16>
        %11 = "ttir.reshape"(%9, %10) <{shape = [1 : i32, 39 : i32, 3584 : i32]}> : (tensor<39x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %12 = "ttir.mesh_shard"(%11) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %13 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %14 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %12, %13, %14 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<39xsi32>
        %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xsi32>, tensor<39xsi32>) -> tensor<39xsi32>
        %6 = ttir.empty() : tensor<39xui32>
        %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xsi32>, tensor<39xui32>) -> tensor<39xui32>
        %8 = ttir.empty() : tensor<39x3584xbf16>
        %9 = "ttir.gather"(%3, %7, %8) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3584>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<152064x3584xbf16>, tensor<39xui32>, tensor<39x3584xbf16>) -> tensor<39x3584xbf16>
        %10 = ttir.empty() : tensor<1x39x3584xbf16>
        %11 = "ttir.reshape"(%9, %10) <{shape = [1 : i32, 39 : i32, 3584 : i32]}> : (tensor<39x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %12 = "ttir.mesh_shard"(%11) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %13 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %14 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %12, %13, %14 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump Before TTIRFusing (ttir-fusing) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<39xsi32>
        %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xsi32>, tensor<39xsi32>) -> tensor<39xsi32>
        %6 = ttir.empty() : tensor<39xui32>
        %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xsi32>, tensor<39xui32>) -> tensor<39xui32>
        %8 = ttir.empty() : tensor<39x3584xbf16>
        %9 = "ttir.gather"(%3, %7, %8) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3584>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<152064x3584xbf16>, tensor<39xui32>, tensor<39x3584xbf16>) -> tensor<39x3584xbf16>
        %10 = ttir.empty() : tensor<1x39x3584xbf16>
        %11 = "ttir.reshape"(%9, %10) <{shape = [1 : i32, 39 : i32, 3584 : i32]}> : (tensor<39x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %12 = "ttir.mesh_shard"(%11) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %13 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %14 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %12, %13, %14 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump Before TTIRQuantDequantConversion (ttir-quant-dequant-conversion) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<39xsi32>
        %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xsi32>, tensor<39xsi32>) -> tensor<39xsi32>
        %6 = ttir.empty() : tensor<39xui32>
        %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xsi32>, tensor<39xui32>) -> tensor<39xui32>
        %8 = ttir.empty() : tensor<39x3584xbf16>
        %9 = "ttir.gather"(%3, %7, %8) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3584>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<152064x3584xbf16>, tensor<39xui32>, tensor<39x3584xbf16>) -> tensor<39x3584xbf16>
        %10 = ttir.empty() : tensor<1x39x3584xbf16>
        %11 = "ttir.reshape"(%9, %10) <{shape = [1 : i32, 39 : i32, 3584 : i32]}> : (tensor<39x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %12 = "ttir.mesh_shard"(%11) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %13 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %14 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %12, %13, %14 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump Before TTIRToTTIRDecomposition (ttir-to-ttir-decomposition) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<39xsi32>
        %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xsi32>, tensor<39xsi32>) -> tensor<39xsi32>
        %6 = ttir.empty() : tensor<39xui32>
        %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xsi32>, tensor<39xui32>) -> tensor<39xui32>
        %8 = ttir.empty() : tensor<39x3584xbf16>
        %9 = "ttir.gather"(%3, %7, %8) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3584>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<152064x3584xbf16>, tensor<39xui32>, tensor<39x3584xbf16>) -> tensor<39x3584xbf16>
        %10 = ttir.empty() : tensor<1x39x3584xbf16>
        %11 = "ttir.reshape"(%9, %10) <{shape = [1 : i32, 39 : i32, 3584 : i32]}> : (tensor<39x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %12 = "ttir.mesh_shard"(%11) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %13 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %14 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %12, %13, %14 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump After TTIRToTTIRDecomposition (ttir-to-ttir-decomposition) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<39xsi32>
        %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xsi32>, tensor<39xsi32>) -> tensor<39xsi32>
        %6 = ttir.empty() : tensor<39xui32>
        %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xsi32>, tensor<39xui32>) -> tensor<39xui32>
        %8 = ttir.empty() : tensor<39x3584xbf16>
        %9 = ttir.empty() : tensor<152064x3584xbf16>
        %10 = "ttir.permute"(%3, %9) <{permutation = array<i64: 0, 1>}> : (tensor<152064x3584xbf16>, tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %11 = ttir.empty() : tensor<152064x3584xbf16>
        %12 = "ttir.reshape"(%10, %11) <{shape = [152064 : i32, 3584 : i32]}> : (tensor<152064x3584xbf16>, tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %13 = ttir.empty() : tensor<1x39xui32>
        %14 = "ttir.reshape"(%7, %13) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xui32>, tensor<1x39xui32>) -> tensor<1x39xui32>
        %15 = ttir.empty() : tensor<1x39x3584xbf16>
        %16 = "ttir.embedding"(%14, %12, %15) : (tensor<1x39xui32>, tensor<152064x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %17 = ttir.empty() : tensor<39x3584xbf16>
        %18 = "ttir.reshape"(%16, %17) <{shape = [39 : i32, 3584 : i32]}> : (tensor<1x39x3584xbf16>, tensor<39x3584xbf16>) -> tensor<39x3584xbf16>
        %19 = ttir.empty() : tensor<39x3584xbf16>
        %20 = "ttir.permute"(%18, %19) <{permutation = array<i64: 0, 1>}> : (tensor<39x3584xbf16>, tensor<39x3584xbf16>) -> tensor<39x3584xbf16>
        %21 = ttir.empty() : tensor<1x39x3584xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 39 : i32, 3584 : i32]}> : (tensor<39x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %23 = "ttir.mesh_shard"(%22) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %24 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %25 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %23, %24, %25 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump Before TTIRFusing (ttir-fusing) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<39xsi32>
        %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xsi32>, tensor<39xsi32>) -> tensor<39xsi32>
        %6 = ttir.empty() : tensor<39xui32>
        %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xsi32>, tensor<39xui32>) -> tensor<39xui32>
        %8 = ttir.empty() : tensor<39x3584xbf16>
        %9 = ttir.empty() : tensor<152064x3584xbf16>
        %10 = "ttir.permute"(%3, %9) <{permutation = array<i64: 0, 1>}> : (tensor<152064x3584xbf16>, tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %11 = ttir.empty() : tensor<152064x3584xbf16>
        %12 = "ttir.reshape"(%10, %11) <{shape = [152064 : i32, 3584 : i32]}> : (tensor<152064x3584xbf16>, tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %13 = ttir.empty() : tensor<1x39xui32>
        %14 = "ttir.reshape"(%7, %13) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xui32>, tensor<1x39xui32>) -> tensor<1x39xui32>
        %15 = ttir.empty() : tensor<1x39x3584xbf16>
        %16 = "ttir.embedding"(%14, %12, %15) : (tensor<1x39xui32>, tensor<152064x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %17 = ttir.empty() : tensor<39x3584xbf16>
        %18 = "ttir.reshape"(%16, %17) <{shape = [39 : i32, 3584 : i32]}> : (tensor<1x39x3584xbf16>, tensor<39x3584xbf16>) -> tensor<39x3584xbf16>
        %19 = ttir.empty() : tensor<39x3584xbf16>
        %20 = "ttir.permute"(%18, %19) <{permutation = array<i64: 0, 1>}> : (tensor<39x3584xbf16>, tensor<39x3584xbf16>) -> tensor<39x3584xbf16>
        %21 = ttir.empty() : tensor<1x39x3584xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 39 : i32, 3584 : i32]}> : (tensor<39x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %23 = "ttir.mesh_shard"(%22) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %24 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %25 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %23, %24, %25 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump After TTIRFusing (ttir-fusing) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<39xsi32>
        %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xsi32>, tensor<39xsi32>) -> tensor<39xsi32>
        %6 = ttir.empty() : tensor<39xui32>
        %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xsi32>, tensor<39xui32>) -> tensor<39xui32>
        %8 = ttir.empty() : tensor<1x39xui32>
        %9 = "ttir.reshape"(%7, %8) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xui32>, tensor<1x39xui32>) -> tensor<1x39xui32>
        %10 = ttir.empty() : tensor<1x39x3584xbf16>
        %11 = "ttir.embedding"(%9, %3, %10) : (tensor<1x39xui32>, tensor<152064x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %12 = "ttir.mesh_shard"(%11) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %13 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %14 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %12, %13, %14 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<39xsi32>
        %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xsi32>, tensor<39xsi32>) -> tensor<39xsi32>
        %6 = ttir.empty() : tensor<39xui32>
        %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xsi32>, tensor<39xui32>) -> tensor<39xui32>
        %8 = ttir.empty() : tensor<1x39xui32>
        %9 = "ttir.reshape"(%7, %8) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xui32>, tensor<1x39xui32>) -> tensor<1x39xui32>
        %10 = ttir.empty() : tensor<1x39x3584xbf16>
        %11 = "ttir.embedding"(%9, %3, %10) : (tensor<1x39xui32>, tensor<152064x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %12 = "ttir.mesh_shard"(%11) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %13 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %14 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %12, %13, %14 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<39xsi32>
        %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xsi32>, tensor<39xsi32>) -> tensor<39xsi32>
        %6 = ttir.empty() : tensor<39xui32>
        %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xsi32>, tensor<39xui32>) -> tensor<39xui32>
        %8 = ttir.empty() : tensor<1x39xui32>
        %9 = "ttir.reshape"(%7, %8) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xui32>, tensor<1x39xui32>) -> tensor<1x39xui32>
        %10 = ttir.empty() : tensor<1x39x3584xbf16>
        %11 = "ttir.embedding"(%9, %3, %10) : (tensor<1x39xui32>, tensor<152064x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %12 = "ttir.mesh_shard"(%11) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %13 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %14 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %12, %13, %14 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<39xsi32>
        %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xsi32>, tensor<39xsi32>) -> tensor<39xsi32>
        %6 = ttir.empty() : tensor<39xui32>
        %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xsi32>, tensor<39xui32>) -> tensor<39xui32>
        %8 = ttir.empty() : tensor<1x39xui32>
        %9 = "ttir.reshape"(%7, %8) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xui32>, tensor<1x39xui32>) -> tensor<1x39xui32>
        %10 = ttir.empty() : tensor<1x39x3584xbf16>
        %11 = "ttir.embedding"(%9, %3, %10) : (tensor<1x39xui32>, tensor<152064x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %12 = "ttir.mesh_shard"(%11) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %13 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %14 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %12, %13, %14 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump Before TTIRFlattenSlidingWindow (ttir-flatten-sliding-window) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<39xsi32>
        %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xsi32>, tensor<39xsi32>) -> tensor<39xsi32>
        %6 = ttir.empty() : tensor<39xui32>
        %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xsi32>, tensor<39xui32>) -> tensor<39xui32>
        %8 = ttir.empty() : tensor<1x39xui32>
        %9 = "ttir.reshape"(%7, %8) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xui32>, tensor<1x39xui32>) -> tensor<1x39xui32>
        %10 = ttir.empty() : tensor<1x39x3584xbf16>
        %11 = "ttir.embedding"(%9, %3, %10) : (tensor<1x39xui32>, tensor<152064x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %12 = "ttir.mesh_shard"(%11) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %13 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %14 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %12, %13, %14 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump Before TTIRExplicateTMs (ttir-explicate-tms) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<39xsi32>
        %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xsi32>, tensor<39xsi32>) -> tensor<39xsi32>
        %6 = ttir.empty() : tensor<39xui32>
        %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xsi32>, tensor<39xui32>) -> tensor<39xui32>
        %8 = ttir.empty() : tensor<1x39xui32>
        %9 = "ttir.reshape"(%7, %8) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xui32>, tensor<1x39xui32>) -> tensor<1x39xui32>
        %10 = ttir.empty() : tensor<1x39x3584xbf16>
        %11 = "ttir.embedding"(%9, %3, %10) : (tensor<1x39xui32>, tensor<152064x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %12 = "ttir.mesh_shard"(%11) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %13 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %14 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %12, %13, %14 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump Before TTIREraseInverseOps (ttir-erase-inverse-ops) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<39xsi32>
        %5 = "ttir.reshape"(%2, %4) <{shape = [39 : i32]}> : (tensor<1x39xsi32>, tensor<39xsi32>) -> tensor<39xsi32>
        %6 = ttir.empty() : tensor<39xui32>
        %7 = "ttir.typecast"(%5, %6) <{conservative_folding = false}> : (tensor<39xsi32>, tensor<39xui32>) -> tensor<39xui32>
        %8 = ttir.empty() : tensor<1x39xui32>
        %9 = "ttir.reshape"(%7, %8) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xui32>, tensor<1x39xui32>) -> tensor<1x39xui32>
        %10 = ttir.empty() : tensor<1x39x3584xbf16>
        %11 = "ttir.embedding"(%9, %3, %10) : (tensor<1x39xui32>, tensor<152064x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %12 = "ttir.mesh_shard"(%11) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %13 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %14 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %12, %13, %14 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump After TTIREraseInverseOps (ttir-erase-inverse-ops) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<1x39xui32>
        %5 = "ttir.typecast"(%2, %4) <{conservative_folding = false}> : (tensor<1x39xsi32>, tensor<1x39xui32>) -> tensor<1x39xui32>
        %6 = ttir.empty() : tensor<1x39x3584xbf16>
        %7 = "ttir.embedding"(%5, %3, %6) : (tensor<1x39xui32>, tensor<152064x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %8 = "ttir.mesh_shard"(%7) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %9 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %10 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %8, %9, %10 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump Before TTIRFusing (ttir-fusing) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<1x39xui32>
        %5 = "ttir.typecast"(%2, %4) <{conservative_folding = false}> : (tensor<1x39xsi32>, tensor<1x39xui32>) -> tensor<1x39xui32>
        %6 = ttir.empty() : tensor<1x39x3584xbf16>
        %7 = "ttir.embedding"(%5, %3, %6) : (tensor<1x39xui32>, tensor<152064x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %8 = "ttir.mesh_shard"(%7) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %9 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %10 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %8, %9, %10 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump Before TTIRImplicitBroadcastFold (ttir-implicit-broadcast-fold) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<1x39xui32>
        %5 = "ttir.typecast"(%2, %4) <{conservative_folding = false}> : (tensor<1x39xsi32>, tensor<1x39xui32>) -> tensor<1x39xui32>
        %6 = ttir.empty() : tensor<1x39x3584xbf16>
        %7 = "ttir.embedding"(%5, %3, %6) : (tensor<1x39xui32>, tensor<152064x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %8 = "ttir.mesh_shard"(%7) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %9 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %10 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %8, %9, %10 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump Before TTIRQuantDataTypeConversionPass (ttir-quant-data-type-conversion) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<1x39xui32>
        %5 = "ttir.typecast"(%2, %4) <{conservative_folding = false}> : (tensor<1x39xsi32>, tensor<1x39xui32>) -> tensor<1x39xui32>
        %6 = ttir.empty() : tensor<1x39x3584xbf16>
        %7 = "ttir.embedding"(%5, %3, %6) : (tensor<1x39xui32>, tensor<152064x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %8 = "ttir.mesh_shard"(%7) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %9 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %10 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %8, %9, %10 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump Before TTNNLayout (ttnn-layout) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16>) -> tensor<152064x3584xbf16>
        %4 = ttir.empty() : tensor<1x39xui32>
        %5 = "ttir.typecast"(%2, %4) <{conservative_folding = false}> : (tensor<1x39xsi32>, tensor<1x39xui32>) -> tensor<1x39xui32>
        %6 = ttir.empty() : tensor<1x39x3584xbf16>
        %7 = "ttir.embedding"(%5, %3, %6) : (tensor<1x39xui32>, tensor<152064x3584xbf16>, tensor<1x39x3584xbf16>) -> tensor<1x39x3584xbf16>
        %8 = "ttir.mesh_shard"(%7) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16>) -> tensor<2x39x3584xbf16>
        %9 = "ttir.mesh_shard"(%0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32>) -> tensor<39xsi32>
        %10 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32>) -> tensor<1x39xsi32>
        return %8, %9, %10 : tensor<2x39x3584xbf16>, tensor<39xsi32>, tensor<1x39xsi32>
      }
    }
  }
}


// -----// IR Dump After TTNNLayout (ttnn-layout) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4752x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<78x3584xbf16, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #system_memory>>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32, #ttnn_layout3> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32, #ttnn_layout5>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32, #ttnn_layout>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout>) -> tensor<1x39xsi32, #ttnn_layout>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16, #ttnn_layout1>) -> tensor<152064x3584xbf16, #ttnn_layout1>
        %4 = ttir.empty() : tensor<1x39xui32, #ttnn_layout6>
        %5 = "ttir.typecast"(%2, %4) <{conservative_folding = false}> : (tensor<1x39xsi32, #ttnn_layout>, tensor<1x39xui32, #ttnn_layout6>) -> tensor<1x39xui32, #ttnn_layout6>
        %6 = ttir.empty() : tensor<1x39x3584xbf16, #ttnn_layout7>
        %7 = "ttir.embedding"(%5, %3, %6) : (tensor<1x39xui32, #ttnn_layout6>, tensor<152064x3584xbf16, #ttnn_layout1>, tensor<1x39x3584xbf16, #ttnn_layout7>) -> tensor<1x39x3584xbf16, #ttnn_layout7>
        %8 = ttir.empty() : tensor<1x39x3584xbf16, #ttnn_layout8>
        %9 = ttir.to_layout %7, %8 : tensor<1x39x3584xbf16, #ttnn_layout7> into tensor<1x39x3584xbf16, #ttnn_layout8> -> tensor<1x39x3584xbf16, #ttnn_layout8>
        %10 = "ttir.mesh_shard"(%9) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16, #ttnn_layout8>) -> tensor<2x39x3584xbf16, #ttnn_layout2>
        %11 = ttir.empty() : tensor<39xsi32, #ttnn_layout3>
        %12 = ttir.to_layout %0, %11 : tensor<39xsi32, #ttnn_layout5> into tensor<39xsi32, #ttnn_layout3> -> tensor<39xsi32, #ttnn_layout3>
        %13 = "ttir.mesh_shard"(%12) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32, #ttnn_layout3>) -> tensor<39xsi32, #ttnn_layout3>
        %14 = ttir.empty() : tensor<1x39xsi32, #ttnn_layout4>
        %15 = ttir.to_layout %1, %14 : tensor<1x39xsi32, #ttnn_layout> into tensor<1x39xsi32, #ttnn_layout4> -> tensor<1x39xsi32, #ttnn_layout4>
        %16 = "ttir.mesh_shard"(%15) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32, #ttnn_layout4>) -> tensor<1x39xsi32, #ttnn_layout4>
        return %10, %13, %16 : tensor<2x39x3584xbf16, #ttnn_layout2>, tensor<39xsi32, #ttnn_layout3>, tensor<1x39xsi32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump Before ConvertTTIRToTTNN (convert-ttir-to-ttnn) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4752x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<78x3584xbf16, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #system_memory>>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32, #ttnn_layout3> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32, #ttnn_layout5>
        %1 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32, #ttnn_layout>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout>) -> tensor<1x39xsi32, #ttnn_layout>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16, #ttnn_layout1>) -> tensor<152064x3584xbf16, #ttnn_layout1>
        %4 = ttir.empty() : tensor<1x39xui32, #ttnn_layout6>
        %5 = "ttir.typecast"(%2, %4) <{conservative_folding = false}> : (tensor<1x39xsi32, #ttnn_layout>, tensor<1x39xui32, #ttnn_layout6>) -> tensor<1x39xui32, #ttnn_layout6>
        %6 = ttir.empty() : tensor<1x39x3584xbf16, #ttnn_layout7>
        %7 = "ttir.embedding"(%5, %3, %6) : (tensor<1x39xui32, #ttnn_layout6>, tensor<152064x3584xbf16, #ttnn_layout1>, tensor<1x39x3584xbf16, #ttnn_layout7>) -> tensor<1x39x3584xbf16, #ttnn_layout7>
        %8 = ttir.empty() : tensor<1x39x3584xbf16, #ttnn_layout8>
        %9 = ttir.to_layout %7, %8 : tensor<1x39x3584xbf16, #ttnn_layout7> into tensor<1x39x3584xbf16, #ttnn_layout8> -> tensor<1x39x3584xbf16, #ttnn_layout8>
        %10 = "ttir.mesh_shard"(%9) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16, #ttnn_layout8>) -> tensor<2x39x3584xbf16, #ttnn_layout2>
        %11 = ttir.empty() : tensor<39xsi32, #ttnn_layout3>
        %12 = ttir.to_layout %0, %11 : tensor<39xsi32, #ttnn_layout5> into tensor<39xsi32, #ttnn_layout3> -> tensor<39xsi32, #ttnn_layout3>
        %13 = "ttir.mesh_shard"(%12) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32, #ttnn_layout3>) -> tensor<39xsi32, #ttnn_layout3>
        %14 = ttir.empty() : tensor<1x39xsi32, #ttnn_layout4>
        %15 = ttir.to_layout %1, %14 : tensor<1x39xsi32, #ttnn_layout> into tensor<1x39xsi32, #ttnn_layout4> -> tensor<1x39xsi32, #ttnn_layout4>
        %16 = "ttir.mesh_shard"(%15) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32, #ttnn_layout4>) -> tensor<1x39xsi32, #ttnn_layout4>
        return %10, %13, %16 : tensor<2x39x3584xbf16, #ttnn_layout2>, tensor<39xsi32, #ttnn_layout3>, tensor<1x39xsi32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump After ConvertTTIRToTTNN (convert-ttir-to-ttnn) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4752x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<78x3584xbf16, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #system_memory>>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32, #ttnn_layout3> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : (!ttnn.device) -> tensor<39xsi32, #ttnn_layout5>
        %2 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : (!ttnn.device) -> tensor<1x39xsi32, #ttnn_layout>
        %3 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout>
        %4 = "ttnn.mesh_shard"(%arg1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<152064x3584xbf16, #ttnn_layout1>
        %5 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<u32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x39>}> : (!ttnn.device) -> tensor<1x39xui32, #ttnn_layout6>
        %6 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x39xsi32, #ttnn_layout>) -> tensor<1x39xui32, #ttnn_layout6>
        %7 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x39x3584>}> : (!ttnn.device) -> tensor<1x39x3584xbf16, #ttnn_layout7>
        %8 = "ttnn.embedding"(%6, %4) : (tensor<1x39xui32, #ttnn_layout6>, tensor<152064x3584xbf16, #ttnn_layout1>) -> tensor<1x39x3584xbf16, #ttnn_layout7>
        %9 = "ttnn.zeros"() <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, shape = #ttnn.shape<1x39x3584>}> : () -> tensor<1x39x3584xbf16, #ttnn_layout8>
        %10 = "ttnn.to_layout"(%8) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x39x3584xbf16, #ttnn_layout7>) -> tensor<1x39x3584xbf16, #ttnn_layout8>
        %11 = "ttnn.mesh_shard"(%10, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16, #ttnn_layout8>, !ttnn.device) -> tensor<2x39x3584xbf16, #ttnn_layout2>
        %12 = "ttnn.zeros"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, shape = #ttnn.shape<39>}> : () -> tensor<39xsi32, #ttnn_layout3>
        %13 = "ttnn.to_layout"(%1) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<39xsi32, #ttnn_layout5>) -> tensor<39xsi32, #ttnn_layout3>
        %14 = "ttnn.mesh_shard"(%13, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<39xsi32, #ttnn_layout3>
        %15 = "ttnn.zeros"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, shape = #ttnn.shape<1x39>}> : () -> tensor<1x39xsi32, #ttnn_layout4>
        %16 = "ttnn.to_layout"(%2) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x39xsi32, #ttnn_layout>) -> tensor<1x39xsi32, #ttnn_layout4>
        %17 = "ttnn.mesh_shard"(%16, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32, #ttnn_layout4>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout4>
        return %11, %14, %17 : tensor<2x39x3584xbf16, #ttnn_layout2>, tensor<39xsi32, #ttnn_layout3>, tensor<1x39xsi32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump Before TTNNFusing (ttnn-fusing) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4752x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<78x3584xbf16, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #system_memory>>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32, #ttnn_layout3> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : (!ttnn.device) -> tensor<39xsi32, #ttnn_layout5>
        %2 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : (!ttnn.device) -> tensor<1x39xsi32, #ttnn_layout>
        %3 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout>
        %4 = "ttnn.mesh_shard"(%arg1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<152064x3584xbf16, #ttnn_layout1>
        %5 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<u32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x39>}> : (!ttnn.device) -> tensor<1x39xui32, #ttnn_layout6>
        %6 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x39xsi32, #ttnn_layout>) -> tensor<1x39xui32, #ttnn_layout6>
        %7 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x39x3584>}> : (!ttnn.device) -> tensor<1x39x3584xbf16, #ttnn_layout7>
        %8 = "ttnn.embedding"(%6, %4) : (tensor<1x39xui32, #ttnn_layout6>, tensor<152064x3584xbf16, #ttnn_layout1>) -> tensor<1x39x3584xbf16, #ttnn_layout7>
        %9 = "ttnn.zeros"() <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, shape = #ttnn.shape<1x39x3584>}> : () -> tensor<1x39x3584xbf16, #ttnn_layout8>
        %10 = "ttnn.to_layout"(%8) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x39x3584xbf16, #ttnn_layout7>) -> tensor<1x39x3584xbf16, #ttnn_layout8>
        %11 = "ttnn.mesh_shard"(%10, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16, #ttnn_layout8>, !ttnn.device) -> tensor<2x39x3584xbf16, #ttnn_layout2>
        %12 = "ttnn.zeros"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, shape = #ttnn.shape<39>}> : () -> tensor<39xsi32, #ttnn_layout3>
        %13 = "ttnn.to_layout"(%1) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<39xsi32, #ttnn_layout5>) -> tensor<39xsi32, #ttnn_layout3>
        %14 = "ttnn.mesh_shard"(%13, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<39xsi32, #ttnn_layout3>
        %15 = "ttnn.zeros"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, shape = #ttnn.shape<1x39>}> : () -> tensor<1x39xsi32, #ttnn_layout4>
        %16 = "ttnn.to_layout"(%2) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x39xsi32, #ttnn_layout>) -> tensor<1x39xsi32, #ttnn_layout4>
        %17 = "ttnn.mesh_shard"(%16, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32, #ttnn_layout4>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout4>
        return %11, %14, %17 : tensor<2x39x3584xbf16, #ttnn_layout2>, tensor<39xsi32, #ttnn_layout3>, tensor<1x39xsi32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump After TTNNFusing (ttnn-fusing) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4752x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<78x3584xbf16, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #system_memory>>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32, #ttnn_layout3> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : (!ttnn.device) -> tensor<39xsi32, #ttnn_layout5>
        %2 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : (!ttnn.device) -> tensor<1x39xsi32, #ttnn_layout>
        %3 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout>
        %4 = "ttnn.mesh_shard"(%arg1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<152064x3584xbf16, #ttnn_layout1>
        %5 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x39xsi32, #ttnn_layout>) -> tensor<1x39xui32, #ttnn_layout6>
        %6 = "ttnn.embedding"(%5, %4) : (tensor<1x39xui32, #ttnn_layout6>, tensor<152064x3584xbf16, #ttnn_layout1>) -> tensor<1x39x3584xbf16, #ttnn_layout7>
        %7 = "ttnn.to_layout"(%6) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x39x3584xbf16, #ttnn_layout7>) -> tensor<1x39x3584xbf16, #ttnn_layout8>
        %8 = "ttnn.mesh_shard"(%7, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16, #ttnn_layout8>, !ttnn.device) -> tensor<2x39x3584xbf16, #ttnn_layout2>
        %9 = "ttnn.to_layout"(%1) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<39xsi32, #ttnn_layout5>) -> tensor<39xsi32, #ttnn_layout3>
        %10 = "ttnn.mesh_shard"(%9, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<39xsi32, #ttnn_layout3>
        %11 = "ttnn.to_layout"(%2) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x39xsi32, #ttnn_layout>) -> tensor<1x39xsi32, #ttnn_layout4>
        %12 = "ttnn.mesh_shard"(%11, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32, #ttnn_layout4>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout4>
        return %8, %10, %12 : tensor<2x39x3584xbf16, #ttnn_layout2>, tensor<39xsi32, #ttnn_layout3>, tensor<1x39xsi32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump Before TTNNWorkarounds (ttnn-workaround) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4752x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<78x3584xbf16, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #system_memory>>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32, #ttnn_layout3> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : (!ttnn.device) -> tensor<39xsi32, #ttnn_layout5>
        %2 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : (!ttnn.device) -> tensor<1x39xsi32, #ttnn_layout>
        %3 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout>
        %4 = "ttnn.mesh_shard"(%arg1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<152064x3584xbf16, #ttnn_layout1>
        %5 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x39xsi32, #ttnn_layout>) -> tensor<1x39xui32, #ttnn_layout6>
        %6 = "ttnn.embedding"(%5, %4) : (tensor<1x39xui32, #ttnn_layout6>, tensor<152064x3584xbf16, #ttnn_layout1>) -> tensor<1x39x3584xbf16, #ttnn_layout7>
        %7 = "ttnn.to_layout"(%6) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x39x3584xbf16, #ttnn_layout7>) -> tensor<1x39x3584xbf16, #ttnn_layout8>
        %8 = "ttnn.mesh_shard"(%7, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16, #ttnn_layout8>, !ttnn.device) -> tensor<2x39x3584xbf16, #ttnn_layout2>
        %9 = "ttnn.to_layout"(%1) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<39xsi32, #ttnn_layout5>) -> tensor<39xsi32, #ttnn_layout3>
        %10 = "ttnn.mesh_shard"(%9, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<39xsi32, #ttnn_layout3>
        %11 = "ttnn.to_layout"(%2) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x39xsi32, #ttnn_layout>) -> tensor<1x39xsi32, #ttnn_layout4>
        %12 = "ttnn.mesh_shard"(%11, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32, #ttnn_layout4>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout4>
        return %8, %10, %12 : tensor<2x39x3584xbf16, #ttnn_layout2>, tensor<39xsi32, #ttnn_layout3>, tensor<1x39xsi32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump After TTNNWorkarounds (ttnn-workaround) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4752x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<78x3584xbf16, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xui32, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #system_memory>>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32, #ttnn_layout3> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32, #ttnn_layout3>
        %2 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32, #ttnn_layout4>
        %3 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout>
        %4 = "ttnn.mesh_shard"(%arg1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<152064x3584xbf16, #ttnn_layout1>
        %5 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x39xsi32, #ttnn_layout>) -> tensor<1x39xui32, #ttnn_layout5>
        %6 = "ttnn.to_layout"(%5) <{dtype = #ttcore.supportedDataTypes<u32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x39xui32, #ttnn_layout5>) -> tensor<1x39xui32, #ttnn_layout6>
        %7 = "ttnn.embedding"(%6, %4) : (tensor<1x39xui32, #ttnn_layout6>, tensor<152064x3584xbf16, #ttnn_layout1>) -> tensor<1x39x3584xbf16, #ttnn_layout7>
        %8 = "ttnn.to_layout"(%7) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x39x3584xbf16, #ttnn_layout7>) -> tensor<1x39x3584xbf16, #ttnn_layout8>
        %9 = "ttnn.mesh_shard"(%8, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16, #ttnn_layout8>, !ttnn.device) -> tensor<2x39x3584xbf16, #ttnn_layout2>
        %10 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<39xsi32, #ttnn_layout3>
        %11 = "ttnn.mesh_shard"(%2, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32, #ttnn_layout4>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout4>
        return %9, %10, %11 : tensor<2x39x3584xbf16, #ttnn_layout2>, tensor<39xsi32, #ttnn_layout3>, tensor<1x39xsi32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4752x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<78x3584xbf16, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xui32, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #system_memory>>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32, #ttnn_layout3> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32, #ttnn_layout3>
        %2 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32, #ttnn_layout4>
        %3 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout>
        %4 = "ttnn.mesh_shard"(%arg1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<152064x3584xbf16, #ttnn_layout1>
        %5 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x39xsi32, #ttnn_layout>) -> tensor<1x39xui32, #ttnn_layout5>
        %6 = "ttnn.to_layout"(%5) <{dtype = #ttcore.supportedDataTypes<u32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x39xui32, #ttnn_layout5>) -> tensor<1x39xui32, #ttnn_layout6>
        %7 = "ttnn.embedding"(%6, %4) : (tensor<1x39xui32, #ttnn_layout6>, tensor<152064x3584xbf16, #ttnn_layout1>) -> tensor<1x39x3584xbf16, #ttnn_layout7>
        %8 = "ttnn.to_layout"(%7) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x39x3584xbf16, #ttnn_layout7>) -> tensor<1x39x3584xbf16, #ttnn_layout8>
        %9 = "ttnn.mesh_shard"(%8, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16, #ttnn_layout8>, !ttnn.device) -> tensor<2x39x3584xbf16, #ttnn_layout2>
        %10 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<39xsi32, #ttnn_layout3>
        %11 = "ttnn.mesh_shard"(%2, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32, #ttnn_layout4>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout4>
        return %9, %10, %11 : tensor<2x39x3584xbf16, #ttnn_layout2>, tensor<39xsi32, #ttnn_layout3>, tensor<1x39xsi32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump Before ConstEvalHoistTransform (const-eval-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4752x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<78x3584xbf16, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xui32, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #system_memory>>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32, #ttnn_layout3> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32, #ttnn_layout3>
        %2 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32, #ttnn_layout4>
        %3 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout>
        %4 = "ttnn.mesh_shard"(%arg1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<152064x3584xbf16, #ttnn_layout1>
        %5 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x39xsi32, #ttnn_layout>) -> tensor<1x39xui32, #ttnn_layout5>
        %6 = "ttnn.to_layout"(%5) <{dtype = #ttcore.supportedDataTypes<u32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x39xui32, #ttnn_layout5>) -> tensor<1x39xui32, #ttnn_layout6>
        %7 = "ttnn.embedding"(%6, %4) : (tensor<1x39xui32, #ttnn_layout6>, tensor<152064x3584xbf16, #ttnn_layout1>) -> tensor<1x39x3584xbf16, #ttnn_layout7>
        %8 = "ttnn.to_layout"(%7) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x39x3584xbf16, #ttnn_layout7>) -> tensor<1x39x3584xbf16, #ttnn_layout8>
        %9 = "ttnn.mesh_shard"(%8, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16, #ttnn_layout8>, !ttnn.device) -> tensor<2x39x3584xbf16, #ttnn_layout2>
        %10 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<39xsi32, #ttnn_layout3>
        %11 = "ttnn.mesh_shard"(%2, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32, #ttnn_layout4>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout4>
        return %9, %10, %11 : tensor<2x39x3584xbf16, #ttnn_layout2>, tensor<39xsi32, #ttnn_layout3>, tensor<1x39xsi32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump After ConstEvalHoistTransform (const-eval-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4752x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<78x3584xbf16, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xui32, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #system_memory>>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0(%arg0: tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<152064x3584xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16, #ttnn_layout>, !ttnn.device) -> tensor<152064x3584xbf16, #ttnn_layout>
        return %1 : tensor<152064x3584xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<1x39xsi32, #ttnn_layout1> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32, #ttnn_layout1>
        %2 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32, #ttnn_layout1>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout1>
        return %2 : tensor<1x39xsi32, #ttnn_layout1>
      }
      func.func @main_const_eval_2() -> tensor<39xsi32, #ttnn_layout2> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32, #ttnn_layout2>
        %2 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32, #ttnn_layout2>, !ttnn.device) -> tensor<39xsi32, #ttnn_layout2>
        return %2 : tensor<39xsi32, #ttnn_layout2>
      }
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, [%arg1]) : (tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<152064x3584xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x39xsi32, #ttnn_layout1>
        %2 = ttcore.load_cached(@main_const_eval_2, []) : () -> tensor<39xsi32, #ttnn_layout2>
        %3 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %4 = "ttnn.mesh_shard"(%arg0, %3) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout3>
        %5 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x39xsi32, #ttnn_layout3>) -> tensor<1x39xui32, #ttnn_layout5>
        %6 = "ttnn.to_layout"(%5) <{dtype = #ttcore.supportedDataTypes<u32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x39xui32, #ttnn_layout5>) -> tensor<1x39xui32, #ttnn_layout6>
        %7 = "ttnn.embedding"(%6, %0) : (tensor<1x39xui32, #ttnn_layout6>, tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<1x39x3584xbf16, #ttnn_layout7>
        %8 = "ttnn.to_layout"(%7) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x39x3584xbf16, #ttnn_layout7>) -> tensor<1x39x3584xbf16, #ttnn_layout8>
        %9 = "ttnn.mesh_shard"(%8, %3) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16, #ttnn_layout8>, !ttnn.device) -> tensor<2x39x3584xbf16, #ttnn_layout4>
        return %9, %2, %1 : tensor<2x39x3584xbf16, #ttnn_layout4>, tensor<39xsi32, #ttnn_layout2>, tensor<1x39xsi32, #ttnn_layout1>
      }
    }
  }
}


// -----// IR Dump Before ConstEvalHoistTransform (const-eval-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4752x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<78x3584xbf16, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xui32, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #system_memory>>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0(%arg0: tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<152064x3584xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16, #ttnn_layout>, !ttnn.device) -> tensor<152064x3584xbf16, #ttnn_layout>
        return %1 : tensor<152064x3584xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<1x39xsi32, #ttnn_layout1> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32, #ttnn_layout1>
        %2 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32, #ttnn_layout1>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout1>
        return %2 : tensor<1x39xsi32, #ttnn_layout1>
      }
      func.func @main_const_eval_2() -> tensor<39xsi32, #ttnn_layout2> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32, #ttnn_layout2>
        %2 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32, #ttnn_layout2>, !ttnn.device) -> tensor<39xsi32, #ttnn_layout2>
        return %2 : tensor<39xsi32, #ttnn_layout2>
      }
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, [%arg1]) : (tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<152064x3584xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x39xsi32, #ttnn_layout1>
        %2 = ttcore.load_cached(@main_const_eval_2, []) : () -> tensor<39xsi32, #ttnn_layout2>
        %3 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %4 = "ttnn.mesh_shard"(%arg0, %3) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout3>
        %5 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x39xsi32, #ttnn_layout3>) -> tensor<1x39xui32, #ttnn_layout5>
        %6 = "ttnn.to_layout"(%5) <{dtype = #ttcore.supportedDataTypes<u32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x39xui32, #ttnn_layout5>) -> tensor<1x39xui32, #ttnn_layout6>
        %7 = "ttnn.embedding"(%6, %0) : (tensor<1x39xui32, #ttnn_layout6>, tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<1x39x3584xbf16, #ttnn_layout7>
        %8 = "ttnn.to_layout"(%7) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x39x3584xbf16, #ttnn_layout7>) -> tensor<1x39x3584xbf16, #ttnn_layout8>
        %9 = "ttnn.mesh_shard"(%8, %3) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16, #ttnn_layout8>, !ttnn.device) -> tensor<2x39x3584xbf16, #ttnn_layout4>
        return %9, %2, %1 : tensor<2x39x3584xbf16, #ttnn_layout4>, tensor<39xsi32, #ttnn_layout2>, tensor<1x39xsi32, #ttnn_layout1>
      }
    }
  }
}


// -----// IR Dump After ConstEvalHoistTransform (const-eval-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4752x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<78x3584xbf16, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xui32, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #system_memory>>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0(%arg0: tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<152064x3584xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16, #ttnn_layout>, !ttnn.device) -> tensor<152064x3584xbf16, #ttnn_layout>
        return %1 : tensor<152064x3584xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<39xsi32, #ttnn_layout1> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32, #ttnn_layout1>
        %2 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32, #ttnn_layout1>, !ttnn.device) -> tensor<39xsi32, #ttnn_layout1>
        return %2 : tensor<39xsi32, #ttnn_layout1>
      }
      func.func @main_const_eval_2() -> tensor<1x39xsi32, #ttnn_layout2> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32, #ttnn_layout2>
        %2 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32, #ttnn_layout2>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout2>
        return %2 : tensor<1x39xsi32, #ttnn_layout2>
      }
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, [%arg1]) : (tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<152064x3584xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<39xsi32, #ttnn_layout1>
        %2 = ttcore.load_cached(@main_const_eval_2, []) : () -> tensor<1x39xsi32, #ttnn_layout2>
        %3 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %4 = "ttnn.mesh_shard"(%arg0, %3) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout3>
        %5 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x39xsi32, #ttnn_layout3>) -> tensor<1x39xui32, #ttnn_layout5>
        %6 = "ttnn.to_layout"(%5) <{dtype = #ttcore.supportedDataTypes<u32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x39xui32, #ttnn_layout5>) -> tensor<1x39xui32, #ttnn_layout6>
        %7 = "ttnn.embedding"(%6, %0) : (tensor<1x39xui32, #ttnn_layout6>, tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<1x39x3584xbf16, #ttnn_layout7>
        %8 = "ttnn.to_layout"(%7) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x39x3584xbf16, #ttnn_layout7>) -> tensor<1x39x3584xbf16, #ttnn_layout8>
        %9 = "ttnn.mesh_shard"(%8, %3) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16, #ttnn_layout8>, !ttnn.device) -> tensor<2x39x3584xbf16, #ttnn_layout4>
        return %9, %1, %2 : tensor<2x39x3584xbf16, #ttnn_layout4>, tensor<39xsi32, #ttnn_layout1>, tensor<1x39xsi32, #ttnn_layout2>
      }
    }
  }
}


// -----// IR Dump Before TTNNDecomposeLayouts (ttnn-decompose-layouts) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4752x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<78x3584xbf16, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xui32, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #system_memory>>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0(%arg0: tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<152064x3584xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16, #ttnn_layout>, !ttnn.device) -> tensor<152064x3584xbf16, #ttnn_layout>
        return %1 : tensor<152064x3584xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<39xsi32, #ttnn_layout1> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32, #ttnn_layout1>
        %2 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32, #ttnn_layout1>, !ttnn.device) -> tensor<39xsi32, #ttnn_layout1>
        return %2 : tensor<39xsi32, #ttnn_layout1>
      }
      func.func @main_const_eval_2() -> tensor<1x39xsi32, #ttnn_layout2> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32, #ttnn_layout2>
        %2 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32, #ttnn_layout2>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout2>
        return %2 : tensor<1x39xsi32, #ttnn_layout2>
      }
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, [%arg1]) : (tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<152064x3584xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<39xsi32, #ttnn_layout1>
        %2 = ttcore.load_cached(@main_const_eval_2, []) : () -> tensor<1x39xsi32, #ttnn_layout2>
        %3 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %4 = "ttnn.mesh_shard"(%arg0, %3) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout3>
        %5 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x39xsi32, #ttnn_layout3>) -> tensor<1x39xui32, #ttnn_layout5>
        %6 = "ttnn.to_layout"(%5) <{dtype = #ttcore.supportedDataTypes<u32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x39xui32, #ttnn_layout5>) -> tensor<1x39xui32, #ttnn_layout6>
        %7 = "ttnn.embedding"(%6, %0) : (tensor<1x39xui32, #ttnn_layout6>, tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<1x39x3584xbf16, #ttnn_layout7>
        %8 = "ttnn.to_layout"(%7) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x39x3584xbf16, #ttnn_layout7>) -> tensor<1x39x3584xbf16, #ttnn_layout8>
        %9 = "ttnn.mesh_shard"(%8, %3) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16, #ttnn_layout8>, !ttnn.device) -> tensor<2x39x3584xbf16, #ttnn_layout4>
        return %9, %1, %2 : tensor<2x39x3584xbf16, #ttnn_layout4>, tensor<39xsi32, #ttnn_layout1>, tensor<1x39xsi32, #ttnn_layout2>
      }
    }
  }
}


// -----// IR Dump After TTNNDecomposeLayouts (ttnn-decompose-layouts) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4752x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<78x3584xbf16, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #system_memory>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xui32, #system_memory>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xui32, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout10 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #dram>, <interleaved>>
#ttnn_layout11 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #system_memory>>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0(%arg0: tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<152064x3584xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16, #ttnn_layout>, !ttnn.device) -> tensor<152064x3584xbf16, #ttnn_layout>
        return %1 : tensor<152064x3584xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<39xsi32, #ttnn_layout1> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32, #ttnn_layout1>
        %2 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32, #ttnn_layout1>, !ttnn.device) -> tensor<39xsi32, #ttnn_layout1>
        return %2 : tensor<39xsi32, #ttnn_layout1>
      }
      func.func @main_const_eval_2() -> tensor<1x39xsi32, #ttnn_layout2> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32, #ttnn_layout2>
        %2 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32, #ttnn_layout2>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout2>
        return %2 : tensor<1x39xsi32, #ttnn_layout2>
      }
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, [%arg1]) : (tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<152064x3584xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<39xsi32, #ttnn_layout1>
        %2 = ttcore.load_cached(@main_const_eval_2, []) : () -> tensor<1x39xsi32, #ttnn_layout2>
        %3 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %4 = "ttnn.mesh_shard"(%arg0, %3) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout3>
        %5 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x39xsi32, #ttnn_layout3>) -> tensor<1x39xui32, #ttnn_layout5>
        %6 = "ttnn.from_device"(%5) : (tensor<1x39xui32, #ttnn_layout5>) -> tensor<1x39xui32, #ttnn_layout6>
        %7 = "ttnn.to_layout"(%6) <{layout = #ttnn.layout<row_major>}> : (tensor<1x39xui32, #ttnn_layout6>) -> tensor<1x39xui32, #ttnn_layout7>
        %8 = "ttnn.to_device"(%7, %3) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x39xui32, #ttnn_layout7>, !ttnn.device) -> tensor<1x39xui32, #ttnn_layout8>
        %9 = "ttnn.embedding"(%8, %0) : (tensor<1x39xui32, #ttnn_layout8>, tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<1x39x3584xbf16, #ttnn_layout9>
        %10 = "ttnn.to_layout"(%9) <{layout = #ttnn.layout<row_major>}> : (tensor<1x39x3584xbf16, #ttnn_layout9>) -> tensor<1x39x3584xbf16, #ttnn_layout10>
        %11 = "ttnn.from_device"(%10) : (tensor<1x39x3584xbf16, #ttnn_layout10>) -> tensor<1x39x3584xbf16, #ttnn_layout11>
        %12 = "ttnn.mesh_shard"(%11, %3) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<2x39x3584xbf16, #ttnn_layout4>
        return %12, %1, %2 : tensor<2x39x3584xbf16, #ttnn_layout4>, tensor<39xsi32, #ttnn_layout1>, tensor<1x39xsi32, #ttnn_layout2>
      }
    }
  }
}


// -----// IR Dump Before TTCoreOptimizationBarrierFold (ttcore-optimization-barrier-fold) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4752x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<78x3584xbf16, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #system_memory>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xui32, #system_memory>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xui32, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout10 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #dram>, <interleaved>>
#ttnn_layout11 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #system_memory>>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0(%arg0: tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<152064x3584xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16, #ttnn_layout>, !ttnn.device) -> tensor<152064x3584xbf16, #ttnn_layout>
        return %1 : tensor<152064x3584xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<39xsi32, #ttnn_layout1> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32, #ttnn_layout1>
        %2 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32, #ttnn_layout1>, !ttnn.device) -> tensor<39xsi32, #ttnn_layout1>
        return %2 : tensor<39xsi32, #ttnn_layout1>
      }
      func.func @main_const_eval_2() -> tensor<1x39xsi32, #ttnn_layout2> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32, #ttnn_layout2>
        %2 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32, #ttnn_layout2>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout2>
        return %2 : tensor<1x39xsi32, #ttnn_layout2>
      }
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, [%arg1]) : (tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<152064x3584xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<39xsi32, #ttnn_layout1>
        %2 = ttcore.load_cached(@main_const_eval_2, []) : () -> tensor<1x39xsi32, #ttnn_layout2>
        %3 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %4 = "ttnn.mesh_shard"(%arg0, %3) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout3>
        %5 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x39xsi32, #ttnn_layout3>) -> tensor<1x39xui32, #ttnn_layout5>
        %6 = "ttnn.from_device"(%5) : (tensor<1x39xui32, #ttnn_layout5>) -> tensor<1x39xui32, #ttnn_layout6>
        %7 = "ttnn.to_layout"(%6) <{layout = #ttnn.layout<row_major>}> : (tensor<1x39xui32, #ttnn_layout6>) -> tensor<1x39xui32, #ttnn_layout7>
        %8 = "ttnn.to_device"(%7, %3) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x39xui32, #ttnn_layout7>, !ttnn.device) -> tensor<1x39xui32, #ttnn_layout8>
        %9 = "ttnn.embedding"(%8, %0) : (tensor<1x39xui32, #ttnn_layout8>, tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<1x39x3584xbf16, #ttnn_layout9>
        %10 = "ttnn.to_layout"(%9) <{layout = #ttnn.layout<row_major>}> : (tensor<1x39x3584xbf16, #ttnn_layout9>) -> tensor<1x39x3584xbf16, #ttnn_layout10>
        %11 = "ttnn.from_device"(%10) : (tensor<1x39x3584xbf16, #ttnn_layout10>) -> tensor<1x39x3584xbf16, #ttnn_layout11>
        %12 = "ttnn.mesh_shard"(%11, %3) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<2x39x3584xbf16, #ttnn_layout4>
        return %12, %1, %2 : tensor<2x39x3584xbf16, #ttnn_layout4>, tensor<39xsi32, #ttnn_layout1>, tensor<1x39xsi32, #ttnn_layout2>
      }
    }
  }
}


// -----// IR Dump Before TTNNDeallocate (ttnn-deallocate) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4752x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<78x3584xbf16, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #system_memory>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xui32, #system_memory>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xui32, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout10 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #dram>, <interleaved>>
#ttnn_layout11 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #system_memory>>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0(%arg0: tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<152064x3584xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16, #ttnn_layout>, !ttnn.device) -> tensor<152064x3584xbf16, #ttnn_layout>
        return %1 : tensor<152064x3584xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<39xsi32, #ttnn_layout1> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32, #ttnn_layout1>
        %2 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32, #ttnn_layout1>, !ttnn.device) -> tensor<39xsi32, #ttnn_layout1>
        return %2 : tensor<39xsi32, #ttnn_layout1>
      }
      func.func @main_const_eval_2() -> tensor<1x39xsi32, #ttnn_layout2> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32, #ttnn_layout2>
        %2 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32, #ttnn_layout2>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout2>
        return %2 : tensor<1x39xsi32, #ttnn_layout2>
      }
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, [%arg1]) : (tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<152064x3584xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<39xsi32, #ttnn_layout1>
        %2 = ttcore.load_cached(@main_const_eval_2, []) : () -> tensor<1x39xsi32, #ttnn_layout2>
        %3 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %4 = "ttnn.mesh_shard"(%arg0, %3) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout3>
        %5 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x39xsi32, #ttnn_layout3>) -> tensor<1x39xui32, #ttnn_layout5>
        %6 = "ttnn.from_device"(%5) : (tensor<1x39xui32, #ttnn_layout5>) -> tensor<1x39xui32, #ttnn_layout6>
        %7 = "ttnn.to_layout"(%6) <{layout = #ttnn.layout<row_major>}> : (tensor<1x39xui32, #ttnn_layout6>) -> tensor<1x39xui32, #ttnn_layout7>
        %8 = "ttnn.to_device"(%7, %3) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x39xui32, #ttnn_layout7>, !ttnn.device) -> tensor<1x39xui32, #ttnn_layout8>
        %9 = "ttnn.embedding"(%8, %0) : (tensor<1x39xui32, #ttnn_layout8>, tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<1x39x3584xbf16, #ttnn_layout9>
        %10 = "ttnn.to_layout"(%9) <{layout = #ttnn.layout<row_major>}> : (tensor<1x39x3584xbf16, #ttnn_layout9>) -> tensor<1x39x3584xbf16, #ttnn_layout10>
        %11 = "ttnn.from_device"(%10) : (tensor<1x39x3584xbf16, #ttnn_layout10>) -> tensor<1x39x3584xbf16, #ttnn_layout11>
        %12 = "ttnn.mesh_shard"(%11, %3) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<2x39x3584xbf16, #ttnn_layout4>
        return %12, %1, %2 : tensor<2x39x3584xbf16, #ttnn_layout4>, tensor<39xsi32, #ttnn_layout1>, tensor<1x39xsi32, #ttnn_layout2>
      }
    }
  }
}


// -----// IR Dump After TTNNDeallocate (ttnn-deallocate) ('builtin.module' operation: @SyncTensorsGraph.16) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4752x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<78x3584xbf16, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #system_memory>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xui32, #system_memory>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xui32, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout10 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #dram>, <interleaved>>
#ttnn_layout11 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #system_memory>>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0(%arg0: tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<152064x3584xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16, #ttnn_layout>, !ttnn.device) -> tensor<152064x3584xbf16, #ttnn_layout>
        return %1 : tensor<152064x3584xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<39xsi32, #ttnn_layout1> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32, #ttnn_layout1>
        %2 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32, #ttnn_layout1>, !ttnn.device) -> tensor<39xsi32, #ttnn_layout1>
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<39xsi32, #ttnn_layout1>) -> ()
        return %2 : tensor<39xsi32, #ttnn_layout1>
      }
      func.func @main_const_eval_2() -> tensor<1x39xsi32, #ttnn_layout2> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32, #ttnn_layout2>
        %2 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32, #ttnn_layout2>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout2>
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x39xsi32, #ttnn_layout2>) -> ()
        return %2 : tensor<1x39xsi32, #ttnn_layout2>
      }
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg1: tensor<152064x3584xbf16, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"}) -> (tensor<2x39x3584xbf16, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, [%arg1]) : (tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<152064x3584xbf16, #ttnn_layout>
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<152064x3584xbf16, #ttnn_layout>) -> ()
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<39xsi32, #ttnn_layout1>
        %2 = ttcore.load_cached(@main_const_eval_2, []) : () -> tensor<1x39xsi32, #ttnn_layout2>
        %3 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %4 = "ttnn.mesh_shard"(%arg0, %3) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout3>
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<2x39xsi32, #ttnn_layout3>) -> ()
        %5 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x39xsi32, #ttnn_layout3>) -> tensor<1x39xui32, #ttnn_layout5>
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1x39xsi32, #ttnn_layout3>) -> ()
        %6 = "ttnn.from_device"(%5) : (tensor<1x39xui32, #ttnn_layout5>) -> tensor<1x39xui32, #ttnn_layout6>
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1x39xui32, #ttnn_layout5>) -> ()
        %7 = "ttnn.to_layout"(%6) <{layout = #ttnn.layout<row_major>}> : (tensor<1x39xui32, #ttnn_layout6>) -> tensor<1x39xui32, #ttnn_layout7>
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1x39xui32, #ttnn_layout6>) -> ()
        %8 = "ttnn.to_device"(%7, %3) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x39xui32, #ttnn_layout7>, !ttnn.device) -> tensor<1x39xui32, #ttnn_layout8>
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x39xui32, #ttnn_layout7>) -> ()
        %9 = "ttnn.embedding"(%8, %0) : (tensor<1x39xui32, #ttnn_layout8>, tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<1x39x3584xbf16, #ttnn_layout9>
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x39xui32, #ttnn_layout8>) -> ()
        "ttnn.deallocate"(%0) <{force = false}> : (tensor<152064x3584xbf16, #ttnn_layout>) -> ()
        %10 = "ttnn.to_layout"(%9) <{layout = #ttnn.layout<row_major>}> : (tensor<1x39x3584xbf16, #ttnn_layout9>) -> tensor<1x39x3584xbf16, #ttnn_layout10>
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x39x3584xbf16, #ttnn_layout9>) -> ()
        %11 = "ttnn.from_device"(%10) : (tensor<1x39x3584xbf16, #ttnn_layout10>) -> tensor<1x39x3584xbf16, #ttnn_layout11>
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x39x3584xbf16, #ttnn_layout10>) -> ()
        %12 = "ttnn.mesh_shard"(%11, %3) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<2x39x3584xbf16, #ttnn_layout4>
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x39x3584xbf16, #ttnn_layout11>) -> ()
        return %12, %1, %2 : tensor<2x39x3584xbf16, #ttnn_layout4>, tensor<39xsi32, #ttnn_layout1>, tensor<1x39xsi32, #ttnn_layout2>
      }
    }
  }
}


#dram = #ttnn.buffer_type<dram>
#loc = loc(unknown)
#loc1 = loc("xla__device_data")
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4752x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<78x3584xbf16, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, u32>, #system_memory>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xui32, #system_memory>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x39xui32, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout10 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #dram>, <interleaved>>
#ttnn_layout11 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 39 + d1, d2), <1x1>, memref<39x3584xbf16, #system_memory>>
module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.16 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]> loc(#loc)
      func.func @main_const_eval_0(%arg0: tensor<152064x3584xbf16, #ttnn_layout> loc(unknown)) -> tensor<152064x3584xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<152064x3584xbf16, #ttnn_layout>, !ttnn.device) -> tensor<152064x3584xbf16, #ttnn_layout> loc(#loc)
        return %1 : tensor<152064x3584xbf16, #ttnn_layout> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_1() -> tensor<39xsi32, #ttnn_layout1> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32, #ttnn_layout1> loc(#loc)
        %2 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<39xsi32, #ttnn_layout1>, !ttnn.device) -> tensor<39xsi32, #ttnn_layout1> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<39xsi32, #ttnn_layout1>) -> () loc(#loc)
        return %2 : tensor<39xsi32, #ttnn_layout1> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_2() -> tensor<1x39xsi32, #ttnn_layout2> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]]> : tensor<1x39xsi32>}> : () -> tensor<1x39xsi32, #ttnn_layout2> loc(#loc)
        %2 = "ttnn.mesh_shard"(%1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x39xsi32, #ttnn_layout2>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x39xsi32, #ttnn_layout2>) -> () loc(#loc)
        return %2 : tensor<1x39xsi32, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("xla__device_data"), %arg1: tensor<152064x3584xbf16, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___embed_tokens_weight"} loc("xla__device_data")) -> (tensor<2x39x3584xbf16, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39xsi32, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x39xsi32, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, [%arg1]) : (tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<152064x3584xbf16, #ttnn_layout> loc(#loc)
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<152064x3584xbf16, #ttnn_layout>) -> () loc(#loc)
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<39xsi32, #ttnn_layout1> loc(#loc)
        %2 = ttcore.load_cached(@main_const_eval_2, []) : () -> tensor<1x39xsi32, #ttnn_layout2> loc(#loc)
        %3 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device loc(#loc)
        %4 = "ttnn.mesh_shard"(%arg0, %3) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout3> loc(#loc)
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<2x39xsi32, #ttnn_layout3>) -> () loc(#loc)
        %5 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x39xsi32, #ttnn_layout3>) -> tensor<1x39xui32, #ttnn_layout5> loc(#loc2)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1x39xsi32, #ttnn_layout3>) -> () loc(#loc2)
        %6 = "ttnn.from_device"(%5) : (tensor<1x39xui32, #ttnn_layout5>) -> tensor<1x39xui32, #ttnn_layout6> loc(#loc3)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1x39xui32, #ttnn_layout5>) -> () loc(#loc3)
        %7 = "ttnn.to_layout"(%6) <{layout = #ttnn.layout<row_major>}> : (tensor<1x39xui32, #ttnn_layout6>) -> tensor<1x39xui32, #ttnn_layout7> loc(#loc3)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1x39xui32, #ttnn_layout6>) -> () loc(#loc3)
        %8 = "ttnn.to_device"(%7, %3) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x39xui32, #ttnn_layout7>, !ttnn.device) -> tensor<1x39xui32, #ttnn_layout8> loc(#loc3)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x39xui32, #ttnn_layout7>) -> () loc(#loc3)
        %9 = "ttnn.embedding"(%8, %0) : (tensor<1x39xui32, #ttnn_layout8>, tensor<152064x3584xbf16, #ttnn_layout>) -> tensor<1x39x3584xbf16, #ttnn_layout9> loc(#loc2)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x39xui32, #ttnn_layout8>) -> () loc(#loc2)
        "ttnn.deallocate"(%0) <{force = false}> : (tensor<152064x3584xbf16, #ttnn_layout>) -> () loc(#loc2)
        %10 = "ttnn.to_layout"(%9) <{layout = #ttnn.layout<row_major>}> : (tensor<1x39x3584xbf16, #ttnn_layout9>) -> tensor<1x39x3584xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x39x3584xbf16, #ttnn_layout9>) -> () loc(#loc)
        %11 = "ttnn.from_device"(%10) : (tensor<1x39x3584xbf16, #ttnn_layout10>) -> tensor<1x39x3584xbf16, #ttnn_layout11> loc(#loc)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x39x3584xbf16, #ttnn_layout10>) -> () loc(#loc)
        %12 = "ttnn.mesh_shard"(%11, %3) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x39x3584xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<2x39x3584xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x39x3584xbf16, #ttnn_layout11>) -> () loc(#loc)
        return %12, %1, %2 : tensor<2x39x3584xbf16, #ttnn_layout4>, tensor<39xsi32, #ttnn_layout1>, tensor<1x39xsi32, #ttnn_layout2> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("aten__index_select")
#loc3 = loc("aten__index_select_workaround"(#loc2))
#loc1 = loc("xla__device_data")
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<39x!vhlo.i64_v1> loc("xla__device_data")) -> (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<39x39x!vhlo.bool_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>>}> : () -> !vhlo.tensor_v1<39x!vhlo.i64_v1> loc(#loc)
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<-3.389530e+38> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1> loc(#loc2)
    %2 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.bf16_v1> loc(#loc2)
    %3 = "vhlo.broadcast_in_dim_v1"(%0) <{broadcast_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>}> : (!vhlo.tensor_v1<39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.i64_v1> loc(#loc3)
    %4 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x39x!vhlo.i64_v1> loc(#loc4)
    %5 = "vhlo.custom_call_v1"(%4) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x39x!vhlo.i64_v1> loc(#loc5)
    %6 = "vhlo.reshape_v1"(%5) : (!vhlo.tensor_v1<1x1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<39x!vhlo.i64_v1> loc(#loc4)
    %7 = "vhlo.broadcast_in_dim_v1"(%6) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.i64_v1> loc(#loc3)
    %8 = "vhlo.compare_v1"(%3, %7) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GT>}> : (!vhlo.tensor_v1<39x39x!vhlo.i64_v1>, !vhlo.tensor_v1<39x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.bool_v1> loc(#loc3)
    "vhlo.return_v1"(%2, %8) : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<39x39x!vhlo.bool_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("aten__expand")
#loc3 = loc("aten__gt")
#loc4 = loc("aten__view")
#loc5 = loc("xla__custom_call")
// -----// IR Dump Before VhloToVersionPass (vhlo-to-version) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<39x!vhlo.i64_v1>) -> (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<39x39x!vhlo.bool_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>>}> : () -> !vhlo.tensor_v1<39x!vhlo.i64_v1>
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<-3.389530e+38> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1>
    %2 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.bf16_v1>
    %3 = "vhlo.broadcast_in_dim_v1"(%0) <{broadcast_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>}> : (!vhlo.tensor_v1<39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.i64_v1>
    %4 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x39x!vhlo.i64_v1>
    %5 = "vhlo.custom_call_v1"(%4) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x39x!vhlo.i64_v1>
    %6 = "vhlo.reshape_v1"(%5) : (!vhlo.tensor_v1<1x1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<39x!vhlo.i64_v1>
    %7 = "vhlo.broadcast_in_dim_v1"(%6) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.i64_v1>
    %8 = "vhlo.compare_v1"(%3, %7) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GT>}> : (!vhlo.tensor_v1<39x39x!vhlo.i64_v1>, !vhlo.tensor_v1<39x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.bool_v1>
    "vhlo.return_v1"(%2, %8) : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<39x39x!vhlo.bool_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}


// -----// IR Dump Before VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<39x!vhlo.i64_v1>) -> (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<39x39x!vhlo.bool_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>>}> : () -> !vhlo.tensor_v1<39x!vhlo.i64_v1>
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<-3.389530e+38> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1>
    %2 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.bf16_v1>
    %3 = "vhlo.broadcast_in_dim_v1"(%0) <{broadcast_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>}> : (!vhlo.tensor_v1<39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.i64_v1>
    %4 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x39x!vhlo.i64_v1>
    %5 = "vhlo.custom_call_v1"(%4) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x39x!vhlo.i64_v1>
    %6 = "vhlo.reshape_v1"(%5) : (!vhlo.tensor_v1<1x1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<39x!vhlo.i64_v1>
    %7 = "vhlo.broadcast_in_dim_v1"(%6) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.i64_v1>
    %8 = "vhlo.compare_v1"(%3, %7) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GT>}> : (!vhlo.tensor_v1<39x39x!vhlo.i64_v1>, !vhlo.tensor_v1<39x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.bool_v1>
    "vhlo.return_v1"(%2, %8) : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<39x39x!vhlo.bool_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}


// -----// IR Dump After VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}"}) -> (tensor<39x39xbf16>, tensor<39x39xi1>) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.custom_call @tt.mark_argument(%2) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<1x1x39xi64>) -> tensor<1x1x39xi64>
    %4 = stablehlo.reshape %3 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %5 = stablehlo.broadcast_in_dim %4, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %6 = stablehlo.compare  GT, %1, %5 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %6 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


#loc1 = loc("xla__device_data")
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}"} loc("xla__device_data")) -> (tensor<39x39xbf16>, tensor<39x39xi1>) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64> loc(#loc)
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16> loc(#loc2)
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16> loc(#loc2)
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64> loc(#loc3)
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64> loc(#loc4)
    %3 = stablehlo.custom_call @tt.mark_argument(%2) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<1x1x39xi64>) -> tensor<1x1x39xi64> loc(#loc5)
    %4 = stablehlo.reshape %3 : (tensor<1x1x39xi64>) -> tensor<39xi64> loc(#loc4)
    %5 = stablehlo.broadcast_in_dim %4, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64> loc(#loc3)
    %6 = stablehlo.compare  GT, %1, %5 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1> loc(#loc3)
    return %0, %6 : tensor<39x39xbf16>, tensor<39x39xi1> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("aten__expand")
#loc3 = loc("aten__gt")
#loc4 = loc("aten__view")
#loc5 = loc("xla__custom_call")
#loc1 = loc("xla__device_data")
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"} loc("xla__device_data")) -> (tensor<39x39xbf16>, tensor<39x39xi1>) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64> loc(#loc)
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16> loc(#loc2)
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16> loc(#loc2)
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64> loc(#loc3)
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64> loc(#loc4)
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64> loc(#loc4)
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64> loc(#loc3)
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1> loc(#loc3)
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("aten__expand")
#loc3 = loc("aten__gt")
#loc4 = loc("aten__view")
// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}) -> (tensor<39x39xbf16>, tensor<39x39xi1>) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}) -> (tensor<39x39xbf16>, tensor<39x39xi1>) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump Before TTPopulateArgumentTypes (tt-populate-argument-types) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}) -> (tensor<39x39xbf16>, tensor<39x39xi1>) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump Before ApplyArgumentShardStatusPass (apply-argument-shard-status) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}) -> (tensor<39x39xbf16>, tensor<39x39xi1>) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump After ApplyArgumentShardStatusPass (apply-argument-shard-status) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump Before ConvertXlaSdyToSdyPass (convert-xla-sdy-to-sdy) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump Before AnalyzeMeshPass (analyze-mesh) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump After AnalyzeMeshPass (analyze-mesh) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=1]>
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump Before ApplyShardingConstraintsPass (sdy-apply-sharding-constraints) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=1]>
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump Before AggressivePropagationPass (sdy-aggressive-propagate) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=1]>
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump Before ShardingConstraintToReshardPass (sdy-sharding-constraint-to-reshard) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=1]>
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump Before InsertExplicitReshardsPass (sdy-insert-explicit-reshards) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=1]>
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump Before WrapUnderManualComputationPass (wrap-under-manual-computation) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=1]>
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump Before ReshardToCollectivesPass (sdy-reshard-to-collectives) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=1]>
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump Before UpdateGlobalToLocalShapesPass (update-global-to-local-shapes) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=1]>
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump Before CloseShardingsPass (sdy-close-shardings) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=1]>
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=1]>
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


#loc1 = loc("xla__device_data")
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=1]> loc(#loc)
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("xla__device_data")) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64> loc(#loc)
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16> loc(#loc2)
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16> loc(#loc2)
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64> loc(#loc3)
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64> loc(#loc4)
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64> loc(#loc4)
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64> loc(#loc3)
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1> loc(#loc3)
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("aten__expand")
#loc3 = loc("aten__gt")
#loc4 = loc("aten__view")
// -----// IR Dump Before ConvertArithToStableHLO (convert-arith-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=8]>
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump Before LegalizeStableHLOCompositeToTTIR (legalize-stablehlo-composite-to-ttir) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=8]>
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump Before StablehloLegalizeCompositeToCallPass (stablehlo-legalize-composite-to-call) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=8]>
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=8]>
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=8]>
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump Before ConvertStableHLOToTTIR (convert-stablehlo-to-ttir) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=8]>
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>
    %cst = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<39xi64>) -> tensor<39x39xi64>
    %2 = stablehlo.reshape %arg0 : (tensor<39xi64>) -> tensor<1x1x39xi64>
    %3 = stablehlo.reshape %2 : (tensor<1x1x39xi64>) -> tensor<39xi64>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<39xi64>) -> tensor<39x39xi64>
    %5 = stablehlo.compare  GT, %1, %4 : (tensor<39x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi1>
    return %0, %5 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump After ConvertStableHLOToTTIR (convert-stablehlo-to-ttir) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>}> : () -> tensor<39xi64>
    %1 = "ttir.constant"() <{value = dense<-3.389530e+38> : tensor<bf16>}> : () -> tensor<bf16>
    %2 = ttir.empty() : tensor<1x1xbf16>
    %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
    %4 = ttir.empty() : tensor<39x39xbf16>
    %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %6 = ttir.empty() : tensor<1x39xi64>
    %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xi64>, tensor<1x39xi64>) -> tensor<1x39xi64>
    %8 = ttir.empty() : tensor<39x39xi64>
    %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi64>
    %10 = ttir.empty() : tensor<1x1x39xi64>
    %11 = "ttir.reshape"(%arg0, %10) <{shape = [1 : i32, 1 : i32, 39 : i32]}> : (tensor<39xi64>, tensor<1x1x39xi64>) -> tensor<1x1x39xi64>
    %12 = ttir.empty() : tensor<39xi64>
    %13 = "ttir.reshape"(%11, %12) <{shape = [39 : i32]}> : (tensor<1x1x39xi64>, tensor<39xi64>) -> tensor<39xi64>
    %14 = ttir.empty() : tensor<39x1xi64>
    %15 = "ttir.reshape"(%13, %14) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xi64>, tensor<39x1xi64>) -> tensor<39x1xi64>
    %16 = ttir.empty() : tensor<39x39xi64>
    %17 = "ttir.broadcast"(%15, %16) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xi64>, tensor<39x39xi64>) -> tensor<39x39xi64>
    %18 = ttir.empty() : tensor<39x39xi1>
    %19 = "ttir.gt"(%9, %17, %18) : (tensor<39x39xi64>, tensor<39x39xi64>, tensor<39x39xi1>) -> tensor<39x39xi1>
    return %5, %19 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


#loc1 = loc("xla__device_data")
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("xla__device_data")) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>}> : () -> tensor<39xi64> loc(#loc)
    %1 = "ttir.constant"() <{value = dense<-3.389530e+38> : tensor<bf16>}> : () -> tensor<bf16> loc(#loc2)
    %2 = ttir.empty() : tensor<1x1xbf16> loc(#loc2)
    %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16> loc(#loc2)
    %4 = ttir.empty() : tensor<39x39xbf16> loc(#loc2)
    %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16> loc(#loc2)
    %6 = ttir.empty() : tensor<1x39xi64> loc(#loc3)
    %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xi64>, tensor<1x39xi64>) -> tensor<1x39xi64> loc(#loc3)
    %8 = ttir.empty() : tensor<39x39xi64> loc(#loc3)
    %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi64> loc(#loc3)
    %10 = ttir.empty() : tensor<1x1x39xi64> loc(#loc4)
    %11 = "ttir.reshape"(%arg0, %10) <{shape = [1 : i32, 1 : i32, 39 : i32]}> : (tensor<39xi64>, tensor<1x1x39xi64>) -> tensor<1x1x39xi64> loc(#loc4)
    %12 = ttir.empty() : tensor<39xi64> loc(#loc4)
    %13 = "ttir.reshape"(%11, %12) <{shape = [39 : i32]}> : (tensor<1x1x39xi64>, tensor<39xi64>) -> tensor<39xi64> loc(#loc4)
    %14 = ttir.empty() : tensor<39x1xi64> loc(#loc3)
    %15 = "ttir.reshape"(%13, %14) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xi64>, tensor<39x1xi64>) -> tensor<39x1xi64> loc(#loc3)
    %16 = ttir.empty() : tensor<39x39xi64> loc(#loc3)
    %17 = "ttir.broadcast"(%15, %16) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xi64>, tensor<39x39xi64>) -> tensor<39x39xi64> loc(#loc3)
    %18 = ttir.empty() : tensor<39x39xi1> loc(#loc3)
    %19 = "ttir.gt"(%9, %17, %18) : (tensor<39x39xi64>, tensor<39x39xi64>, tensor<39x39xi1>) -> tensor<39x39xi1> loc(#loc3)
    return %5, %19 : tensor<39x39xbf16>, tensor<39x39xi1> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("aten__expand")
#loc3 = loc("aten__gt")
#loc4 = loc("aten__view")
// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>}> : () -> tensor<39xi64>
    %1 = "ttir.constant"() <{value = dense<-3.389530e+38> : tensor<bf16>}> : () -> tensor<bf16>
    %2 = ttir.empty() : tensor<1x1xbf16>
    %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
    %4 = ttir.empty() : tensor<39x39xbf16>
    %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %6 = ttir.empty() : tensor<1x39xi64>
    %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xi64>, tensor<1x39xi64>) -> tensor<1x39xi64>
    %8 = ttir.empty() : tensor<39x39xi64>
    %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi64>
    %10 = ttir.empty() : tensor<1x1x39xi64>
    %11 = "ttir.reshape"(%arg0, %10) <{shape = [1 : i32, 1 : i32, 39 : i32]}> : (tensor<39xi64>, tensor<1x1x39xi64>) -> tensor<1x1x39xi64>
    %12 = ttir.empty() : tensor<39xi64>
    %13 = "ttir.reshape"(%11, %12) <{shape = [39 : i32]}> : (tensor<1x1x39xi64>, tensor<39xi64>) -> tensor<39xi64>
    %14 = ttir.empty() : tensor<39x1xi64>
    %15 = "ttir.reshape"(%13, %14) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xi64>, tensor<39x1xi64>) -> tensor<39x1xi64>
    %16 = ttir.empty() : tensor<39x39xi64>
    %17 = "ttir.broadcast"(%15, %16) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xi64>, tensor<39x39xi64>) -> tensor<39x39xi64>
    %18 = ttir.empty() : tensor<39x39xi1>
    %19 = "ttir.gt"(%9, %17, %18) : (tensor<39x39xi64>, tensor<39x39xi64>, tensor<39x39xi1>) -> tensor<39x39xi1>
    return %5, %19 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>}> : () -> tensor<39xi64>
    %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
    %2 = ttir.empty() : tensor<1x1xbf16>
    %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
    %4 = ttir.empty() : tensor<39x39xbf16>
    %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %6 = ttir.empty() : tensor<1x39xi64>
    %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xi64>, tensor<1x39xi64>) -> tensor<1x39xi64>
    %8 = ttir.empty() : tensor<39x39xi64>
    %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi64>
    %10 = ttir.empty() : tensor<39x1xi64>
    %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xi64>, tensor<39x1xi64>) -> tensor<39x1xi64>
    %12 = ttir.empty() : tensor<39x39xi64>
    %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xi64>, tensor<39x39xi64>) -> tensor<39x39xi64>
    %14 = ttir.empty() : tensor<39x39xi1>
    %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xi64>, tensor<39x39xi64>, tensor<39x39xi1>) -> tensor<39x39xi1>
    return %5, %15 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump Before ElementTypeNormalization (ttir-element-type-normalization) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  func.func @main(%arg0: tensor<39xi64> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xi1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xi64>}> : () -> tensor<39xi64>
    %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
    %2 = ttir.empty() : tensor<1x1xbf16>
    %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
    %4 = ttir.empty() : tensor<39x39xbf16>
    %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %6 = ttir.empty() : tensor<1x39xi64>
    %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xi64>, tensor<1x39xi64>) -> tensor<1x39xi64>
    %8 = ttir.empty() : tensor<39x39xi64>
    %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xi64>, tensor<39x39xi64>) -> tensor<39x39xi64>
    %10 = ttir.empty() : tensor<39x1xi64>
    %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xi64>, tensor<39x1xi64>) -> tensor<39x1xi64>
    %12 = ttir.empty() : tensor<39x39xi64>
    %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xi64>, tensor<39x39xi64>) -> tensor<39x39xi64>
    %14 = ttir.empty() : tensor<39x39xi1>
    %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xi64>, tensor<39x39xi64>, tensor<39x39xi1>) -> tensor<39x39xi1>
    return %5, %15 : tensor<39x39xbf16>, tensor<39x39xi1>
  }
}


// -----// IR Dump After ElementTypeNormalization (ttir-element-type-normalization) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
    %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
    %2 = ttir.empty() : tensor<1x1xbf16>
    %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
    %4 = ttir.empty() : tensor<39x39xbf16>
    %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %6 = ttir.empty() : tensor<1x39xsi32>
    %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
    %8 = ttir.empty() : tensor<39x39xsi32>
    %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
    %10 = ttir.empty() : tensor<39x1xsi32>
    %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
    %12 = ttir.empty() : tensor<39x39xsi32>
    %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
    %14 = ttir.empty() : tensor<39x39xbf16>
    %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xsi32>, tensor<39x39xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
    return %5, %15 : tensor<39x39xbf16>, tensor<39x39xbf16>
  }
}


// -----// IR Dump Before TTCoreWrapDeviceModulePass (ttcore-wrap-device-module) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
    %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
    %2 = ttir.empty() : tensor<1x1xbf16>
    %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
    %4 = ttir.empty() : tensor<39x39xbf16>
    %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %6 = ttir.empty() : tensor<1x39xsi32>
    %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
    %8 = ttir.empty() : tensor<39x39xsi32>
    %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
    %10 = ttir.empty() : tensor<39x1xsi32>
    %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
    %12 = ttir.empty() : tensor<39x39xsi32>
    %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
    %14 = ttir.empty() : tensor<39x39xbf16>
    %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xsi32>, tensor<39x39xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
    return %5, %15 : tensor<39x39xbf16>, tensor<39x39xbf16>
  }
}


// -----// IR Dump After TTCoreWrapDeviceModulePass (ttcore-wrap-device-module) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x39xsi32>
        %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %10 = ttir.empty() : tensor<39x1xsi32>
        %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %12 = ttir.empty() : tensor<39x39xsi32>
        %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %14 = ttir.empty() : tensor<39x39xbf16>
        %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xsi32>, tensor<39x39xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %15 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIRHoistTransform (ttir-cpu-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x39xsi32>
        %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %10 = ttir.empty() : tensor<39x1xsi32>
        %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %12 = ttir.empty() : tensor<39x39xsi32>
        %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %14 = ttir.empty() : tensor<39x39xbf16>
        %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xsi32>, tensor<39x39xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %15 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTCoreRegisterDevicePass (ttcore-register-device) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x39xsi32>
        %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %10 = ttir.empty() : tensor<39x1xsi32>
        %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %12 = ttir.empty() : tensor<39x39xsi32>
        %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %14 = ttir.empty() : tensor<39x39xbf16>
        %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xsi32>, tensor<39x39xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %15 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump After TTCoreRegisterDevicePass (ttcore-register-device) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x39xsi32>
        %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %10 = ttir.empty() : tensor<39x1xsi32>
        %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %12 = ttir.empty() : tensor<39x39xsi32>
        %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %14 = ttir.empty() : tensor<39x39xbf16>
        %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xsi32>, tensor<39x39xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %15 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTPopulateArgumentTypes (tt-populate-argument-types) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x39xsi32>
        %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %10 = ttir.empty() : tensor<39x1xsi32>
        %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %12 = ttir.empty() : tensor<39x39xsi32>
        %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %14 = ttir.empty() : tensor<39x39xbf16>
        %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xsi32>, tensor<39x39xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %15 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x39xsi32>
        %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %10 = ttir.empty() : tensor<39x1xsi32>
        %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %12 = ttir.empty() : tensor<39x39xsi32>
        %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %14 = ttir.empty() : tensor<39x39xbf16>
        %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xsi32>, tensor<39x39xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %15 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIRFusing (ttir-fusing) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x39xsi32>
        %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %10 = ttir.empty() : tensor<39x1xsi32>
        %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %12 = ttir.empty() : tensor<39x39xsi32>
        %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %14 = ttir.empty() : tensor<39x39xbf16>
        %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xsi32>, tensor<39x39xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %15 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIRQuantDequantConversion (ttir-quant-dequant-conversion) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x39xsi32>
        %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %10 = ttir.empty() : tensor<39x1xsi32>
        %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %12 = ttir.empty() : tensor<39x39xsi32>
        %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %14 = ttir.empty() : tensor<39x39xbf16>
        %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xsi32>, tensor<39x39xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %15 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIRToTTIRDecomposition (ttir-to-ttir-decomposition) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x39xsi32>
        %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %10 = ttir.empty() : tensor<39x1xsi32>
        %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %12 = ttir.empty() : tensor<39x39xsi32>
        %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %14 = ttir.empty() : tensor<39x39xbf16>
        %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xsi32>, tensor<39x39xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %15 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIRFusing (ttir-fusing) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x39xsi32>
        %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %10 = ttir.empty() : tensor<39x1xsi32>
        %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %12 = ttir.empty() : tensor<39x39xsi32>
        %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %14 = ttir.empty() : tensor<39x39xbf16>
        %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xsi32>, tensor<39x39xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %15 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x39xsi32>
        %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %10 = ttir.empty() : tensor<39x1xsi32>
        %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %12 = ttir.empty() : tensor<39x39xsi32>
        %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %14 = ttir.empty() : tensor<39x39xbf16>
        %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xsi32>, tensor<39x39xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %15 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x39xsi32>
        %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %10 = ttir.empty() : tensor<39x1xsi32>
        %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %12 = ttir.empty() : tensor<39x39xsi32>
        %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %14 = ttir.empty() : tensor<39x39xbf16>
        %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xsi32>, tensor<39x39xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %15 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x39xsi32>
        %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %10 = ttir.empty() : tensor<39x1xsi32>
        %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %12 = ttir.empty() : tensor<39x39xsi32>
        %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %14 = ttir.empty() : tensor<39x39xbf16>
        %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xsi32>, tensor<39x39xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %15 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIRFlattenSlidingWindow (ttir-flatten-sliding-window) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x39xsi32>
        %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %10 = ttir.empty() : tensor<39x1xsi32>
        %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %12 = ttir.empty() : tensor<39x39xsi32>
        %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %14 = ttir.empty() : tensor<39x39xbf16>
        %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xsi32>, tensor<39x39xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %15 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIRExplicateTMs (ttir-explicate-tms) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x39xsi32>
        %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %10 = ttir.empty() : tensor<39x1xsi32>
        %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %12 = ttir.empty() : tensor<39x39xsi32>
        %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %14 = ttir.empty() : tensor<39x39xbf16>
        %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xsi32>, tensor<39x39xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %15 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIREraseInverseOps (ttir-erase-inverse-ops) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x39xsi32>
        %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %10 = ttir.empty() : tensor<39x1xsi32>
        %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %12 = ttir.empty() : tensor<39x39xsi32>
        %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %14 = ttir.empty() : tensor<39x39xbf16>
        %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xsi32>, tensor<39x39xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %15 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIRFusing (ttir-fusing) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x39xsi32>
        %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %10 = ttir.empty() : tensor<39x1xsi32>
        %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %12 = ttir.empty() : tensor<39x39xsi32>
        %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %14 = ttir.empty() : tensor<39x39xbf16>
        %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xsi32>, tensor<39x39xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %15 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIRImplicitBroadcastFold (ttir-implicit-broadcast-fold) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x39xsi32>
        %9 = "ttir.broadcast"(%7, %8) <{broadcast_dimensions = array<i64: 39, 1>}> : (tensor<1x39xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %10 = ttir.empty() : tensor<39x1xsi32>
        %11 = "ttir.reshape"(%arg0, %10) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %12 = ttir.empty() : tensor<39x39xsi32>
        %13 = "ttir.broadcast"(%11, %12) <{broadcast_dimensions = array<i64: 1, 39>}> : (tensor<39x1xsi32>, tensor<39x39xsi32>) -> tensor<39x39xsi32>
        %14 = ttir.empty() : tensor<39x39xbf16>
        %15 = "ttir.gt"(%9, %13, %14) : (tensor<39x39xsi32>, tensor<39x39xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %15 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump After TTIRImplicitBroadcastFold (ttir-implicit-broadcast-fold) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x1xsi32>
        %9 = "ttir.reshape"(%arg0, %8) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %10 = ttir.empty() : tensor<39x39xbf16>
        %11 = "ttir.gt"(%7, %9, %10) : (tensor<1x39xsi32>, tensor<39x1xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %11 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIRQuantDataTypeConversionPass (ttir-quant-data-type-conversion) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x1xsi32>
        %9 = "ttir.reshape"(%arg0, %8) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %10 = ttir.empty() : tensor<39x39xbf16>
        %11 = "ttir.gt"(%7, %9, %10) : (tensor<1x39xsi32>, tensor<39x1xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %11 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTNNLayout (ttnn-layout) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = ttir.empty() : tensor<1x1xbf16>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
        %4 = ttir.empty() : tensor<39x39xbf16>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %6 = ttir.empty() : tensor<1x39xsi32>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32>, tensor<1x39xsi32>) -> tensor<1x39xsi32>
        %8 = ttir.empty() : tensor<39x1xsi32>
        %9 = "ttir.reshape"(%arg0, %8) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32>, tensor<39x1xsi32>) -> tensor<39x1xsi32>
        %10 = ttir.empty() : tensor<39x39xbf16>
        %11 = "ttir.gt"(%7, %9, %10) : (tensor<1x39xsi32>, tensor<39x1xsi32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        return %5, %11 : tensor<39x39xbf16>, tensor<39x39xbf16>
      }
    }
  }
}


// -----// IR Dump After TTNNLayout (ttnn-layout) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32, #ttnn_layout> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32, #ttnn_layout>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16, #ttnn_layout2>
        %2 = ttir.empty() : tensor<1x1xbf16, #ttnn_layout3>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout2>, tensor<1x1xbf16, #ttnn_layout3>) -> tensor<1x1xbf16, #ttnn_layout3>
        %4 = ttir.empty() : tensor<39x39xbf16, #ttnn_layout1>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16, #ttnn_layout3>, tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xbf16, #ttnn_layout1>
        %6 = ttir.empty() : tensor<1x39xsi32, #ttnn_layout4>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32, #ttnn_layout>, tensor<1x39xsi32, #ttnn_layout4>) -> tensor<1x39xsi32, #ttnn_layout4>
        %8 = ttir.empty() : tensor<39x1xsi32, #ttnn_layout5>
        %9 = "ttir.reshape"(%arg0, %8) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32, #ttnn_layout>, tensor<39x1xsi32, #ttnn_layout5>) -> tensor<39x1xsi32, #ttnn_layout5>
        %10 = ttir.empty() : tensor<39x39xbf16, #ttnn_layout1>
        %11 = "ttir.gt"(%7, %9, %10) : (tensor<1x39xsi32, #ttnn_layout4>, tensor<39x1xsi32, #ttnn_layout5>, tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xbf16, #ttnn_layout1>
        return %5, %11 : tensor<39x39xbf16, #ttnn_layout1>, tensor<39x39xbf16, #ttnn_layout1>
      }
    }
  }
}


// -----// IR Dump Before ConvertTTIRToTTNN (convert-ttir-to-ttnn) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32, #ttnn_layout> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32, #ttnn_layout>
        %1 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16, #ttnn_layout2>
        %2 = ttir.empty() : tensor<1x1xbf16, #ttnn_layout3>
        %3 = "ttir.reshape"(%1, %2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout2>, tensor<1x1xbf16, #ttnn_layout3>) -> tensor<1x1xbf16, #ttnn_layout3>
        %4 = ttir.empty() : tensor<39x39xbf16, #ttnn_layout1>
        %5 = "ttir.broadcast"(%3, %4) <{broadcast_dimensions = array<i64: 39, 39>}> : (tensor<1x1xbf16, #ttnn_layout3>, tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xbf16, #ttnn_layout1>
        %6 = ttir.empty() : tensor<1x39xsi32, #ttnn_layout4>
        %7 = "ttir.reshape"(%0, %6) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32, #ttnn_layout>, tensor<1x39xsi32, #ttnn_layout4>) -> tensor<1x39xsi32, #ttnn_layout4>
        %8 = ttir.empty() : tensor<39x1xsi32, #ttnn_layout5>
        %9 = "ttir.reshape"(%arg0, %8) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32, #ttnn_layout>, tensor<39x1xsi32, #ttnn_layout5>) -> tensor<39x1xsi32, #ttnn_layout5>
        %10 = ttir.empty() : tensor<39x39xbf16, #ttnn_layout1>
        %11 = "ttir.gt"(%7, %9, %10) : (tensor<1x39xsi32, #ttnn_layout4>, tensor<39x1xsi32, #ttnn_layout5>, tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xbf16, #ttnn_layout1>
        return %5, %11 : tensor<39x39xbf16, #ttnn_layout1>, tensor<39x39xbf16, #ttnn_layout1>
      }
    }
  }
}


// -----// IR Dump After ConvertTTIRToTTNN (convert-ttir-to-ttnn) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32, #ttnn_layout> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : (!ttnn.device) -> tensor<39xsi32, #ttnn_layout>
        %2 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout2>
        %3 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x1>}> : (!ttnn.device) -> tensor<1x1xbf16, #ttnn_layout3>
        %4 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout2>) -> tensor<1x1xbf16, #ttnn_layout3>
        %5 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<39x39>}> : (!ttnn.device) -> tensor<39x39xbf16, #ttnn_layout1>
        %6 = "ttnn.repeat"(%4) <{repeat_dims = #ttnn.shape<39x39>}> : (tensor<1x1xbf16, #ttnn_layout3>) -> tensor<39x39xbf16, #ttnn_layout1>
        %7 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x39>}> : (!ttnn.device) -> tensor<1x39xsi32, #ttnn_layout4>
        %8 = "ttnn.reshape"(%1) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32, #ttnn_layout>) -> tensor<1x39xsi32, #ttnn_layout4>
        %9 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<39x1>}> : (!ttnn.device) -> tensor<39x1xsi32, #ttnn_layout5>
        %10 = "ttnn.reshape"(%arg0) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32, #ttnn_layout>) -> tensor<39x1xsi32, #ttnn_layout5>
        %11 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<39x39>}> : (!ttnn.device) -> tensor<39x39xbf16, #ttnn_layout1>
        %12 = "ttnn.gt"(%8, %10) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x39xsi32, #ttnn_layout4>, tensor<39x1xsi32, #ttnn_layout5>) -> tensor<39x39xbf16, #ttnn_layout1>
        return %6, %12 : tensor<39x39xbf16, #ttnn_layout1>, tensor<39x39xbf16, #ttnn_layout1>
      }
    }
  }
}


// -----// IR Dump Before TTNNFusing (ttnn-fusing) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32, #ttnn_layout> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : (!ttnn.device) -> tensor<39xsi32, #ttnn_layout>
        %2 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout2>
        %3 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x1>}> : (!ttnn.device) -> tensor<1x1xbf16, #ttnn_layout3>
        %4 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout2>) -> tensor<1x1xbf16, #ttnn_layout3>
        %5 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<39x39>}> : (!ttnn.device) -> tensor<39x39xbf16, #ttnn_layout1>
        %6 = "ttnn.repeat"(%4) <{repeat_dims = #ttnn.shape<39x39>}> : (tensor<1x1xbf16, #ttnn_layout3>) -> tensor<39x39xbf16, #ttnn_layout1>
        %7 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x39>}> : (!ttnn.device) -> tensor<1x39xsi32, #ttnn_layout4>
        %8 = "ttnn.reshape"(%1) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32, #ttnn_layout>) -> tensor<1x39xsi32, #ttnn_layout4>
        %9 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<39x1>}> : (!ttnn.device) -> tensor<39x1xsi32, #ttnn_layout5>
        %10 = "ttnn.reshape"(%arg0) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32, #ttnn_layout>) -> tensor<39x1xsi32, #ttnn_layout5>
        %11 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<39x39>}> : (!ttnn.device) -> tensor<39x39xbf16, #ttnn_layout1>
        %12 = "ttnn.gt"(%8, %10) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x39xsi32, #ttnn_layout4>, tensor<39x1xsi32, #ttnn_layout5>) -> tensor<39x39xbf16, #ttnn_layout1>
        return %6, %12 : tensor<39x39xbf16, #ttnn_layout1>, tensor<39x39xbf16, #ttnn_layout1>
      }
    }
  }
}


// -----// IR Dump After TTNNFusing (ttnn-fusing) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32, #ttnn_layout> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : (!ttnn.device) -> tensor<39xsi32, #ttnn_layout>
        %2 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout2>
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout2>) -> tensor<1x1xbf16, #ttnn_layout3>
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<39x39>}> : (tensor<1x1xbf16, #ttnn_layout3>) -> tensor<39x39xbf16, #ttnn_layout1>
        %5 = "ttnn.reshape"(%1) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32, #ttnn_layout>) -> tensor<1x39xsi32, #ttnn_layout4>
        %6 = "ttnn.reshape"(%arg0) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32, #ttnn_layout>) -> tensor<39x1xsi32, #ttnn_layout5>
        %7 = "ttnn.gt"(%5, %6) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x39xsi32, #ttnn_layout4>, tensor<39x1xsi32, #ttnn_layout5>) -> tensor<39x39xbf16, #ttnn_layout1>
        return %4, %7 : tensor<39x39xbf16, #ttnn_layout1>, tensor<39x39xbf16, #ttnn_layout1>
      }
    }
  }
}


// -----// IR Dump Before TTNNWorkarounds (ttnn-workaround) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32, #ttnn_layout> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : (!ttnn.device) -> tensor<39xsi32, #ttnn_layout>
        %2 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout2>
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout2>) -> tensor<1x1xbf16, #ttnn_layout3>
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<39x39>}> : (tensor<1x1xbf16, #ttnn_layout3>) -> tensor<39x39xbf16, #ttnn_layout1>
        %5 = "ttnn.reshape"(%1) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32, #ttnn_layout>) -> tensor<1x39xsi32, #ttnn_layout4>
        %6 = "ttnn.reshape"(%arg0) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32, #ttnn_layout>) -> tensor<39x1xsi32, #ttnn_layout5>
        %7 = "ttnn.gt"(%5, %6) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x39xsi32, #ttnn_layout4>, tensor<39x1xsi32, #ttnn_layout5>) -> tensor<39x39xbf16, #ttnn_layout1>
        return %4, %7 : tensor<39x39xbf16, #ttnn_layout1>, tensor<39x39xbf16, #ttnn_layout1>
      }
    }
  }
}


// -----// IR Dump After TTNNWorkarounds (ttnn-workaround) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32, #ttnn_layout> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32, #ttnn_layout2>
        %2 = "ttnn.to_layout"(%1) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<39xsi32, #ttnn_layout2>) -> tensor<39xsi32, #ttnn_layout>
        %3 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout3>
        %4 = "ttnn.reshape"(%3) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout3>) -> tensor<1x1xbf16, #ttnn_layout4>
        %5 = "ttnn.repeat"(%4) <{repeat_dims = #ttnn.shape<39x39>}> : (tensor<1x1xbf16, #ttnn_layout4>) -> tensor<39x39xbf16, #ttnn_layout1>
        %6 = "ttnn.reshape"(%2) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32, #ttnn_layout>) -> tensor<1x39xsi32, #ttnn_layout5>
        %7 = "ttnn.reshape"(%arg0) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32, #ttnn_layout>) -> tensor<39x1xsi32, #ttnn_layout6>
        %8 = "ttnn.to_layout"(%6) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x39xsi32, #ttnn_layout5>) -> tensor<1x39xf32, #ttnn_layout7>
        %9 = "ttnn.to_layout"(%7) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<39x1xsi32, #ttnn_layout6>) -> tensor<39x1xf32, #ttnn_layout8>
        %10 = "ttnn.gt"(%8, %9) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x39xf32, #ttnn_layout7>, tensor<39x1xf32, #ttnn_layout8>) -> tensor<39x39xf32, #ttnn_layout9>
        %11 = "ttnn.to_layout"(%10) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<39x39xf32, #ttnn_layout9>) -> tensor<39x39xbf16, #ttnn_layout1>
        return %5, %11 : tensor<39x39xbf16, #ttnn_layout1>, tensor<39x39xbf16, #ttnn_layout1>
      }
    }
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x39xsi32, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32, #ttnn_layout> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : () -> tensor<39xsi32, #ttnn_layout2>
        %2 = "ttnn.to_layout"(%1) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<39xsi32, #ttnn_layout2>) -> tensor<39xsi32, #ttnn_layout>
        %3 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout3>
        %4 = "ttnn.reshape"(%3) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout3>) -> tensor<1x1xbf16, #ttnn_layout4>
        %5 = "ttnn.repeat"(%4) <{repeat_dims = #ttnn.shape<39x39>}> : (tensor<1x1xbf16, #ttnn_layout4>) -> tensor<39x39xbf16, #ttnn_layout1>
        %6 = "ttnn.reshape"(%2) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32, #ttnn_layout>) -> tensor<1x39xsi32, #ttnn_layout5>
        %7 = "ttnn.reshape"(%arg0) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32, #ttnn_layout>) -> tensor<39x1xsi32, #ttnn_layout6>
        %8 = "ttnn.to_layout"(%6) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x39xsi32, #ttnn_layout5>) -> tensor<1x39xf32, #ttnn_layout7>
        %9 = "ttnn.to_layout"(%7) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<39x1xsi32, #ttnn_layout6>) -> tensor<39x1xf32, #ttnn_layout8>
        %10 = "ttnn.gt"(%8, %9) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x39xf32, #ttnn_layout7>, tensor<39x1xf32, #ttnn_layout8>) -> tensor<39x39xf32, #ttnn_layout9>
        %11 = "ttnn.to_layout"(%10) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<39x39xf32, #ttnn_layout9>) -> tensor<39x39xbf16, #ttnn_layout1>
        return %5, %11 : tensor<39x39xbf16, #ttnn_layout1>, tensor<39x39xbf16, #ttnn_layout1>
      }
    }
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32, #ttnn_layout> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : (!ttnn.device) -> tensor<39xsi32, #ttnn_layout>
        %2 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout2>
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout2>) -> tensor<1x1xbf16, #ttnn_layout3>
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<39x39>}> : (tensor<1x1xbf16, #ttnn_layout3>) -> tensor<39x39xbf16, #ttnn_layout1>
        %5 = "ttnn.reshape"(%1) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32, #ttnn_layout>) -> tensor<1x39xsi32, #ttnn_layout4>
        %6 = "ttnn.reshape"(%arg0) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32, #ttnn_layout>) -> tensor<39x1xsi32, #ttnn_layout5>
        %7 = "ttnn.to_layout"(%5) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x39xsi32, #ttnn_layout4>) -> tensor<1x39xf32, #ttnn_layout6>
        %8 = "ttnn.to_layout"(%6) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<39x1xsi32, #ttnn_layout5>) -> tensor<39x1xf32, #ttnn_layout7>
        %9 = "ttnn.gt"(%7, %8) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x39xf32, #ttnn_layout6>, tensor<39x1xf32, #ttnn_layout7>) -> tensor<39x39xf32, #ttnn_layout8>
        %10 = "ttnn.to_layout"(%9) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<39x39xf32, #ttnn_layout8>) -> tensor<39x39xbf16, #ttnn_layout1>
        return %4, %10 : tensor<39x39xbf16, #ttnn_layout1>, tensor<39x39xbf16, #ttnn_layout1>
      }
    }
  }
}


// -----// IR Dump Before ConstEvalHoistTransform (const-eval-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<39xsi32, #ttnn_layout> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16, #ttnn_layout1> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : (!ttnn.device) -> tensor<39xsi32, #ttnn_layout>
        %2 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout2>
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout2>) -> tensor<1x1xbf16, #ttnn_layout3>
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<39x39>}> : (tensor<1x1xbf16, #ttnn_layout3>) -> tensor<39x39xbf16, #ttnn_layout1>
        %5 = "ttnn.reshape"(%1) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32, #ttnn_layout>) -> tensor<1x39xsi32, #ttnn_layout4>
        %6 = "ttnn.reshape"(%arg0) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32, #ttnn_layout>) -> tensor<39x1xsi32, #ttnn_layout5>
        %7 = "ttnn.to_layout"(%5) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x39xsi32, #ttnn_layout4>) -> tensor<1x39xf32, #ttnn_layout6>
        %8 = "ttnn.to_layout"(%6) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<39x1xsi32, #ttnn_layout5>) -> tensor<39x1xf32, #ttnn_layout7>
        %9 = "ttnn.gt"(%7, %8) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x39xf32, #ttnn_layout6>, tensor<39x1xf32, #ttnn_layout7>) -> tensor<39x39xf32, #ttnn_layout8>
        %10 = "ttnn.to_layout"(%9) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<39x39xf32, #ttnn_layout8>) -> tensor<39x39xbf16, #ttnn_layout1>
        return %4, %10 : tensor<39x39xbf16, #ttnn_layout1>, tensor<39x39xbf16, #ttnn_layout1>
      }
    }
  }
}


// -----// IR Dump After ConstEvalHoistTransform (const-eval-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0() -> tensor<39x39xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1xbf16, #ttnn_layout2>
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<39x39>}> : (tensor<1x1xbf16, #ttnn_layout2>) -> tensor<39x39xbf16, #ttnn_layout>
        return %3 : tensor<39x39xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<1x39xf32, #ttnn_layout3> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : (!ttnn.device) -> tensor<39xsi32, #ttnn_layout4>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32, #ttnn_layout4>) -> tensor<1x39xsi32, #ttnn_layout5>
        %3 = "ttnn.to_layout"(%2) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x39xsi32, #ttnn_layout5>) -> tensor<1x39xf32, #ttnn_layout3>
        return %3 : tensor<1x39xf32, #ttnn_layout3>
      }
      func.func @main(%arg0: tensor<39xsi32, #ttnn_layout4> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<39x39xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x39xf32, #ttnn_layout3>
        %2 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %3 = "ttnn.reshape"(%arg0) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32, #ttnn_layout4>) -> tensor<39x1xsi32, #ttnn_layout6>
        %4 = "ttnn.to_layout"(%3) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<39x1xsi32, #ttnn_layout6>) -> tensor<39x1xf32, #ttnn_layout7>
        %5 = "ttnn.gt"(%1, %4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x39xf32, #ttnn_layout3>, tensor<39x1xf32, #ttnn_layout7>) -> tensor<39x39xf32, #ttnn_layout8>
        %6 = "ttnn.to_layout"(%5) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<39x39xf32, #ttnn_layout8>) -> tensor<39x39xbf16, #ttnn_layout>
        return %0, %6 : tensor<39x39xbf16, #ttnn_layout>, tensor<39x39xbf16, #ttnn_layout>
      }
    }
  }
}


// -----// IR Dump Before ConstEvalHoistTransform (const-eval-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0() -> tensor<39x39xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1xbf16, #ttnn_layout2>
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<39x39>}> : (tensor<1x1xbf16, #ttnn_layout2>) -> tensor<39x39xbf16, #ttnn_layout>
        return %3 : tensor<39x39xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<1x39xf32, #ttnn_layout3> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : (!ttnn.device) -> tensor<39xsi32, #ttnn_layout4>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32, #ttnn_layout4>) -> tensor<1x39xsi32, #ttnn_layout5>
        %3 = "ttnn.to_layout"(%2) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x39xsi32, #ttnn_layout5>) -> tensor<1x39xf32, #ttnn_layout3>
        return %3 : tensor<1x39xf32, #ttnn_layout3>
      }
      func.func @main(%arg0: tensor<39xsi32, #ttnn_layout4> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<39x39xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x39xf32, #ttnn_layout3>
        %2 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %3 = "ttnn.reshape"(%arg0) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32, #ttnn_layout4>) -> tensor<39x1xsi32, #ttnn_layout6>
        %4 = "ttnn.to_layout"(%3) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<39x1xsi32, #ttnn_layout6>) -> tensor<39x1xf32, #ttnn_layout7>
        %5 = "ttnn.gt"(%1, %4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x39xf32, #ttnn_layout3>, tensor<39x1xf32, #ttnn_layout7>) -> tensor<39x39xf32, #ttnn_layout8>
        %6 = "ttnn.to_layout"(%5) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<39x39xf32, #ttnn_layout8>) -> tensor<39x39xbf16, #ttnn_layout>
        return %0, %6 : tensor<39x39xbf16, #ttnn_layout>, tensor<39x39xbf16, #ttnn_layout>
      }
    }
  }
}


// -----// IR Dump After ConstEvalHoistTransform (const-eval-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0() -> tensor<39x39xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1xbf16, #ttnn_layout2>
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<39x39>}> : (tensor<1x1xbf16, #ttnn_layout2>) -> tensor<39x39xbf16, #ttnn_layout>
        return %3 : tensor<39x39xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<1x39xf32, #ttnn_layout3> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : (!ttnn.device) -> tensor<39xsi32, #ttnn_layout4>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32, #ttnn_layout4>) -> tensor<1x39xsi32, #ttnn_layout5>
        %3 = "ttnn.to_layout"(%2) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x39xsi32, #ttnn_layout5>) -> tensor<1x39xf32, #ttnn_layout3>
        return %3 : tensor<1x39xf32, #ttnn_layout3>
      }
      func.func @main(%arg0: tensor<39xsi32, #ttnn_layout4> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<39x39xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x39xf32, #ttnn_layout3>
        %2 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %3 = "ttnn.reshape"(%arg0) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32, #ttnn_layout4>) -> tensor<39x1xsi32, #ttnn_layout6>
        %4 = "ttnn.to_layout"(%3) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<39x1xsi32, #ttnn_layout6>) -> tensor<39x1xf32, #ttnn_layout7>
        %5 = "ttnn.gt"(%1, %4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x39xf32, #ttnn_layout3>, tensor<39x1xf32, #ttnn_layout7>) -> tensor<39x39xf32, #ttnn_layout8>
        %6 = "ttnn.to_layout"(%5) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<39x39xf32, #ttnn_layout8>) -> tensor<39x39xbf16, #ttnn_layout>
        return %0, %6 : tensor<39x39xbf16, #ttnn_layout>, tensor<39x39xbf16, #ttnn_layout>
      }
    }
  }
}


// -----// IR Dump Before TTNNDecomposeLayouts (ttnn-decompose-layouts) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0() -> tensor<39x39xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1xbf16, #ttnn_layout2>
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<39x39>}> : (tensor<1x1xbf16, #ttnn_layout2>) -> tensor<39x39xbf16, #ttnn_layout>
        return %3 : tensor<39x39xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<1x39xf32, #ttnn_layout3> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : (!ttnn.device) -> tensor<39xsi32, #ttnn_layout4>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32, #ttnn_layout4>) -> tensor<1x39xsi32, #ttnn_layout5>
        %3 = "ttnn.to_layout"(%2) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x39xsi32, #ttnn_layout5>) -> tensor<1x39xf32, #ttnn_layout3>
        return %3 : tensor<1x39xf32, #ttnn_layout3>
      }
      func.func @main(%arg0: tensor<39xsi32, #ttnn_layout4> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<39x39xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x39xf32, #ttnn_layout3>
        %2 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %3 = "ttnn.reshape"(%arg0) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32, #ttnn_layout4>) -> tensor<39x1xsi32, #ttnn_layout6>
        %4 = "ttnn.to_layout"(%3) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<39x1xsi32, #ttnn_layout6>) -> tensor<39x1xf32, #ttnn_layout7>
        %5 = "ttnn.gt"(%1, %4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x39xf32, #ttnn_layout3>, tensor<39x1xf32, #ttnn_layout7>) -> tensor<39x39xf32, #ttnn_layout8>
        %6 = "ttnn.to_layout"(%5) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<39x39xf32, #ttnn_layout8>) -> tensor<39x39xbf16, #ttnn_layout>
        return %0, %6 : tensor<39x39xbf16, #ttnn_layout>, tensor<39x39xbf16, #ttnn_layout>
      }
    }
  }
}


// -----// IR Dump After TTNNDecomposeLayouts (ttnn-decompose-layouts) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0() -> tensor<39x39xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1xbf16, #ttnn_layout2>
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<39x39>}> : (tensor<1x1xbf16, #ttnn_layout2>) -> tensor<39x39xbf16, #ttnn_layout>
        return %3 : tensor<39x39xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<1x39xf32, #ttnn_layout3> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : (!ttnn.device) -> tensor<39xsi32, #ttnn_layout4>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32, #ttnn_layout4>) -> tensor<1x39xsi32, #ttnn_layout5>
        %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x39xsi32, #ttnn_layout5>) -> tensor<1x39xf32, #ttnn_layout3>
        return %3 : tensor<1x39xf32, #ttnn_layout3>
      }
      func.func @main(%arg0: tensor<39xsi32, #ttnn_layout4> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<39x39xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x39xf32, #ttnn_layout3>
        %2 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %3 = "ttnn.reshape"(%arg0) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32, #ttnn_layout4>) -> tensor<39x1xsi32, #ttnn_layout6>
        %4 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x1xsi32, #ttnn_layout6>) -> tensor<39x1xf32, #ttnn_layout7>
        %5 = "ttnn.gt"(%1, %4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x39xf32, #ttnn_layout3>, tensor<39x1xf32, #ttnn_layout7>) -> tensor<39x39xf32, #ttnn_layout8>
        %6 = "ttnn.typecast"(%5) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout8>) -> tensor<39x39xbf16, #ttnn_layout>
        return %0, %6 : tensor<39x39xbf16, #ttnn_layout>, tensor<39x39xbf16, #ttnn_layout>
      }
    }
  }
}


// -----// IR Dump Before TTCoreOptimizationBarrierFold (ttcore-optimization-barrier-fold) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0() -> tensor<39x39xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1xbf16, #ttnn_layout2>
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<39x39>}> : (tensor<1x1xbf16, #ttnn_layout2>) -> tensor<39x39xbf16, #ttnn_layout>
        return %3 : tensor<39x39xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<1x39xf32, #ttnn_layout3> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : (!ttnn.device) -> tensor<39xsi32, #ttnn_layout4>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32, #ttnn_layout4>) -> tensor<1x39xsi32, #ttnn_layout5>
        %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x39xsi32, #ttnn_layout5>) -> tensor<1x39xf32, #ttnn_layout3>
        return %3 : tensor<1x39xf32, #ttnn_layout3>
      }
      func.func @main(%arg0: tensor<39xsi32, #ttnn_layout4> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<39x39xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x39xf32, #ttnn_layout3>
        %2 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %3 = "ttnn.reshape"(%arg0) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32, #ttnn_layout4>) -> tensor<39x1xsi32, #ttnn_layout6>
        %4 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x1xsi32, #ttnn_layout6>) -> tensor<39x1xf32, #ttnn_layout7>
        %5 = "ttnn.gt"(%1, %4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x39xf32, #ttnn_layout3>, tensor<39x1xf32, #ttnn_layout7>) -> tensor<39x39xf32, #ttnn_layout8>
        %6 = "ttnn.typecast"(%5) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout8>) -> tensor<39x39xbf16, #ttnn_layout>
        return %0, %6 : tensor<39x39xbf16, #ttnn_layout>, tensor<39x39xbf16, #ttnn_layout>
      }
    }
  }
}


// -----// IR Dump After TTCoreOptimizationBarrierFold (ttcore-optimization-barrier-fold) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0() -> tensor<39x39xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1xbf16, #ttnn_layout2>
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<39x39>}> : (tensor<1x1xbf16, #ttnn_layout2>) -> tensor<39x39xbf16, #ttnn_layout>
        return %3 : tensor<39x39xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<1x39xf32, #ttnn_layout3> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : (!ttnn.device) -> tensor<39xsi32, #ttnn_layout4>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32, #ttnn_layout4>) -> tensor<1x39xsi32, #ttnn_layout5>
        %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x39xsi32, #ttnn_layout5>) -> tensor<1x39xf32, #ttnn_layout3>
        return %3 : tensor<1x39xf32, #ttnn_layout3>
      }
      func.func @main(%arg0: tensor<39xsi32, #ttnn_layout4> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<39x39xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x39xf32, #ttnn_layout3>
        %2 = "ttnn.reshape"(%arg0) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32, #ttnn_layout4>) -> tensor<39x1xsi32, #ttnn_layout6>
        %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x1xsi32, #ttnn_layout6>) -> tensor<39x1xf32, #ttnn_layout7>
        %4 = "ttnn.gt"(%1, %3) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x39xf32, #ttnn_layout3>, tensor<39x1xf32, #ttnn_layout7>) -> tensor<39x39xf32, #ttnn_layout8>
        %5 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout8>) -> tensor<39x39xbf16, #ttnn_layout>
        return %0, %5 : tensor<39x39xbf16, #ttnn_layout>, tensor<39x39xbf16, #ttnn_layout>
      }
    }
  }
}


// -----// IR Dump Before TTNNDeallocate (ttnn-deallocate) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0() -> tensor<39x39xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1xbf16, #ttnn_layout2>
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<39x39>}> : (tensor<1x1xbf16, #ttnn_layout2>) -> tensor<39x39xbf16, #ttnn_layout>
        return %3 : tensor<39x39xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<1x39xf32, #ttnn_layout3> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : (!ttnn.device) -> tensor<39xsi32, #ttnn_layout4>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32, #ttnn_layout4>) -> tensor<1x39xsi32, #ttnn_layout5>
        %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x39xsi32, #ttnn_layout5>) -> tensor<1x39xf32, #ttnn_layout3>
        return %3 : tensor<1x39xf32, #ttnn_layout3>
      }
      func.func @main(%arg0: tensor<39xsi32, #ttnn_layout4> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<39x39xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x39xf32, #ttnn_layout3>
        %2 = "ttnn.reshape"(%arg0) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32, #ttnn_layout4>) -> tensor<39x1xsi32, #ttnn_layout6>
        %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x1xsi32, #ttnn_layout6>) -> tensor<39x1xf32, #ttnn_layout7>
        %4 = "ttnn.gt"(%1, %3) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x39xf32, #ttnn_layout3>, tensor<39x1xf32, #ttnn_layout7>) -> tensor<39x39xf32, #ttnn_layout8>
        %5 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout8>) -> tensor<39x39xbf16, #ttnn_layout>
        return %0, %5 : tensor<39x39xbf16, #ttnn_layout>, tensor<39x39xbf16, #ttnn_layout>
      }
    }
  }
}


// -----// IR Dump After TTNNDeallocate (ttnn-deallocate) ('builtin.module' operation: @SyncTensorsGraph.17) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0() -> tensor<39x39xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1xbf16, #ttnn_layout2>
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<bf16, #ttnn_layout1>) -> ()
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<39x39>}> : (tensor<1x1xbf16, #ttnn_layout2>) -> tensor<39x39xbf16, #ttnn_layout>
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x1xbf16, #ttnn_layout2>) -> ()
        return %3 : tensor<39x39xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<1x39xf32, #ttnn_layout3> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : (!ttnn.device) -> tensor<39xsi32, #ttnn_layout4>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32, #ttnn_layout4>) -> tensor<1x39xsi32, #ttnn_layout5>
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<39xsi32, #ttnn_layout4>) -> ()
        %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x39xsi32, #ttnn_layout5>) -> tensor<1x39xf32, #ttnn_layout3>
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x39xsi32, #ttnn_layout5>) -> ()
        return %3 : tensor<1x39xf32, #ttnn_layout3>
      }
      func.func @main(%arg0: tensor<39xsi32, #ttnn_layout4> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<39x39xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<39x39xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x39xf32, #ttnn_layout3>
        %2 = "ttnn.reshape"(%arg0) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32, #ttnn_layout4>) -> tensor<39x1xsi32, #ttnn_layout6>
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<39xsi32, #ttnn_layout4>) -> ()
        %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x1xsi32, #ttnn_layout6>) -> tensor<39x1xf32, #ttnn_layout7>
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<39x1xsi32, #ttnn_layout6>) -> ()
        %4 = "ttnn.gt"(%1, %3) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x39xf32, #ttnn_layout3>, tensor<39x1xf32, #ttnn_layout7>) -> tensor<39x39xf32, #ttnn_layout8>
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<39x1xf32, #ttnn_layout7>) -> ()
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x39xf32, #ttnn_layout3>) -> ()
        %5 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout8>) -> tensor<39x39xbf16, #ttnn_layout>
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<39x39xf32, #ttnn_layout8>) -> ()
        return %0, %5 : tensor<39x39xbf16, #ttnn_layout>, tensor<39x39xbf16, #ttnn_layout>
      }
    }
  }
}


#dram = #ttnn.buffer_type<dram>
#loc3 = loc("xla__device_data")
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.17 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x8>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x8, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]> loc(#loc)
      func.func @main_const_eval_0() -> tensor<39x39xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1> loc(#loc1)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1xbf16, #ttnn_layout2> loc(#loc1)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<bf16, #ttnn_layout1>) -> () loc(#loc1)
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<39x39>}> : (tensor<1x1xbf16, #ttnn_layout2>) -> tensor<39x39xbf16, #ttnn_layout> loc(#loc1)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x1xbf16, #ttnn_layout2>) -> () loc(#loc1)
        return %3 : tensor<39x39xbf16, #ttnn_layout> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_1() -> tensor<1x39xf32, #ttnn_layout3> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x8>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]> : tensor<39xsi32>}> : (!ttnn.device) -> tensor<39xsi32, #ttnn_layout4> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 39 : i32]}> : (tensor<39xsi32, #ttnn_layout4>) -> tensor<1x39xsi32, #ttnn_layout5> loc(#loc2)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<39xsi32, #ttnn_layout4>) -> () loc(#loc2)
        %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x39xsi32, #ttnn_layout5>) -> tensor<1x39xf32, #ttnn_layout3> loc(#loc4)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x39xsi32, #ttnn_layout5>) -> () loc(#loc4)
        return %3 : tensor<1x39xf32, #ttnn_layout3> loc(#loc)
      } loc(#loc)
      func.func @main(%arg0: tensor<39xsi32, #ttnn_layout4> {mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("xla__device_data")) -> (tensor<39x39xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<39x39xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<39x39xbf16, #ttnn_layout> loc(#loc)
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x39xf32, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.reshape"(%arg0) <{shape = [39 : i32, 1 : i32]}> : (tensor<39xsi32, #ttnn_layout4>) -> tensor<39x1xsi32, #ttnn_layout6> loc(#loc2)
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<39xsi32, #ttnn_layout4>) -> () loc(#loc2)
        %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x1xsi32, #ttnn_layout6>) -> tensor<39x1xf32, #ttnn_layout7> loc(#loc4)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<39x1xsi32, #ttnn_layout6>) -> () loc(#loc4)
        %4 = "ttnn.gt"(%1, %3) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x39xf32, #ttnn_layout3>, tensor<39x1xf32, #ttnn_layout7>) -> tensor<39x39xf32, #ttnn_layout8> loc(#loc2)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<39x1xf32, #ttnn_layout7>) -> () loc(#loc2)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x39xf32, #ttnn_layout3>) -> () loc(#loc2)
        %5 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout8>) -> tensor<39x39xbf16, #ttnn_layout> loc(#loc4)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<39x39xf32, #ttnn_layout8>) -> () loc(#loc4)
        return %0, %5 : tensor<39x39xbf16, #ttnn_layout>, tensor<39x39xbf16, #ttnn_layout> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc1 = loc("aten__expand")
#loc2 = loc("aten__gt")
#loc4 = loc("aten__gt_workaround"(#loc2))
#loc1 = loc("xla__device_data")
#loc9 = loc("aten__mean")
#loc23 = loc("aten__softmax")
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<1x39x!vhlo.i64_v1> loc("xla__device_data"), %arg1: !vhlo.tensor_v1<64x!vhlo.f32_v1> loc("xla__device_data"), %arg2: !vhlo.tensor_v1<512x!vhlo.bf16_v1> loc("xla__device_data"), %arg3: !vhlo.tensor_v1<512x3584x!vhlo.bf16_v1> loc("xla__device_data"), %arg4: !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1> loc("xla__device_data"), %arg5: !vhlo.tensor_v1<3584x!vhlo.bf16_v1> loc("xla__device_data"), %arg6: !vhlo.tensor_v1<512x!vhlo.bf16_v1> loc("xla__device_data"), %arg7: !vhlo.tensor_v1<512x3584x!vhlo.bf16_v1> loc("xla__device_data"), %arg8: !vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1> loc("xla__device_data"), %arg9: !vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1> loc("xla__device_data"), %arg10: !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1> loc("xla__device_data"), %arg11: !vhlo.tensor_v1<2x39x!vhlo.i64_v1> loc("xla__device_data"), %arg12: !vhlo.tensor_v1<39x39x!vhlo.bool_v1> loc("xla__device_data"), %arg13: !vhlo.tensor_v1<39x39x!vhlo.bf16_v1> loc("xla__device_data"), %arg14: !vhlo.tensor_v1<3584x!vhlo.bf16_v1> loc("xla__device_data"), %arg15: !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1> loc("xla__device_data"), %arg16: !vhlo.tensor_v1<3584x!vhlo.bf16_v1> loc("xla__device_data"), %arg17: !vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1> loc("xla__device_data"), %arg18: !vhlo.tensor_v1<3584x!vhlo.bf16_v1> loc("xla__device_data")) -> (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.7901787E-4> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %4 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<9.99999997E-7> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %5 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.0883883461> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %6 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1> loc(#loc)
    %7 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<-3.389530e+38> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1> loc(#loc)
    %8 = "vhlo.broadcast_in_dim_v1"(%7) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1> loc(#loc)
    %9 = "vhlo.broadcast_in_dim_v1"(%6) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1> loc(#loc)
    %10 = "vhlo.broadcast_in_dim_v1"(%5) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1> loc(#loc)
    %11 = "vhlo.broadcast_in_dim_v1"(%4) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1> loc(#loc)
    %12 = "vhlo.broadcast_in_dim_v1"(%3) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1> loc(#loc)
    %13 = "vhlo.broadcast_in_dim_v1"(%2) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc)
    %14 = "vhlo.convert_v1"(%arg13) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.f32_v1> loc(#loc2)
    %15 = "vhlo.convert_v1"(%arg12) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<39x39x!vhlo.bool_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.f32_v1> loc(#loc2)
    %16 = "vhlo.multiply_v1"(%14, %15) : (!vhlo.tensor_v1<39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.f32_v1> loc(#loc3)
    %17 = "vhlo.convert_v1"(%16) : (!vhlo.tensor_v1<39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.bf16_v1> loc(#loc2)
    %18 = "vhlo.custom_call_v1"(%17) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.bf16_v1> loc(#loc4)
    %19 = "vhlo.reshape_v1"(%18) : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x39x39x!vhlo.bf16_v1> loc(#loc5)
    %20 = "vhlo.broadcast_in_dim_v1"(%19) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[1, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1> loc(#loc6)
    %21 = "vhlo.reshape_v1"(%arg5) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1> loc(#loc5)
    %22 = "vhlo.custom_call_v1"(%21) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___input_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1> loc(#loc7)
    %23 = "vhlo.reshape_v1"(%22) : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.bf16_v1> loc(#loc5)
    %24 = "vhlo.convert_v1"(%23) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.f32_v1> loc(#loc2)
    %25 = "vhlo.broadcast_in_dim_v1"(%24) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc3)
    %26 = "vhlo.custom_call_v1"(%arg4) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_1">}>} : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1> loc(#loc7)
    %27 = "vhlo.convert_v1"(%26) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc2)
    %28 = "vhlo.power_v1"(%27, %13) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc8)
    %29 = "vhlo.reduce_v1"(%28, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1> loc("aten__mean"), %arg20: !vhlo.tensor_v1<!vhlo.f32_v1> loc("aten__mean")):
      %238 = "vhlo.add_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc10)
      "vhlo.return_v1"(%238) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1> loc(#loc9)
    %30 = "vhlo.multiply_v1"(%29, %12) : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1> loc(#loc9)
    %31 = "vhlo.reshape_v1"(%30) : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1> loc(#loc9)
    %32 = "vhlo.add_v1"(%31, %11) : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1> loc(#loc11)
    %33 = "vhlo.rsqrt_v2"(%32) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1> loc(#loc12)
    %34 = "vhlo.reshape_v1"(%33) : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1> loc(#loc3)
    %35 = "vhlo.broadcast_in_dim_v1"(%34) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc3)
    %36 = "vhlo.multiply_v1"(%27, %35) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc3)
    %37 = "vhlo.convert_v1"(%36) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1> loc(#loc2)
    %38 = "vhlo.convert_v1"(%37) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc2)
    %39 = "vhlo.multiply_v1"(%25, %38) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc3)
    %40 = "vhlo.convert_v1"(%39) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1> loc(#loc2)
    %41 = "vhlo.reshape_v1"(%40) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1> loc(#loc5)
    %42 = "vhlo.reshape_v1"(%arg3) : (!vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1> loc(#loc5)
    %43 = "vhlo.custom_call_v1"(%42) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_k_proj_weight">}>} : (!vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1> loc(#loc7)
    %44 = "vhlo.reshape_v1"(%43) : (!vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<512x3584x!vhlo.bf16_v1> loc(#loc5)
    %45 = "vhlo.transpose_v1"(%44) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,512]{0,1}">} : (!vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x512x!vhlo.bf16_v1> loc(#loc13)
    %46 = "vhlo.dot_general_v2"(%41, %45) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x512x!vhlo.bf16_v1> loc(#loc14)
    %47 = "vhlo.reshape_v1"(%46) : (!vhlo.tensor_v1<78x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1> loc(#loc5)
    %48 = "vhlo.reshape_v1"(%arg2) : (!vhlo.tensor_v1<512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1> loc(#loc5)
    %49 = "vhlo.custom_call_v1"(%48) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_k_proj_bias">}>} : (!vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1> loc(#loc7)
    %50 = "vhlo.reshape_v1"(%49) : (!vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<512x!vhlo.bf16_v1> loc(#loc5)
    %51 = "vhlo.broadcast_in_dim_v1"(%50) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1> loc(#loc11)
    %52 = "vhlo.add_v1"(%47, %51) : (!vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1> loc(#loc11)
    %53 = "vhlo.reshape_v1"(%52) : (!vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x4x128x!vhlo.bf16_v1> loc(#loc5)
    %54 = "vhlo.transpose_v1"(%53) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[2,4,39,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x39x4x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1> loc(#loc13)
    %55 = "vhlo.convert_v1"(%54) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[2,4,39,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1> loc(#loc2)
    %56 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1> loc(#loc5)
    %57 = "vhlo.custom_call_v1"(%56) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"constant">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___rotary_emb_inv_freq">}>} : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1> loc(#loc7)
    %58 = "vhlo.reshape_v1"(%57) : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1> loc(#loc5)
    %59 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x39x!vhlo.i64_v1> loc(#loc5)
    %60 = "vhlo.custom_call_v1"(%59) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_2">}>} : (!vhlo.tensor_v1<1x1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x39x!vhlo.i64_v1> loc(#loc7)
    %61 = "vhlo.convert_v1"(%60) : (!vhlo.tensor_v1<1x1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x39x!vhlo.f32_v1> loc(#loc2)
    %62 = "vhlo.dot_general_v2"(%58, %61) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x39x!vhlo.f32_v1> loc(#loc15)
    %63 = "vhlo.transpose_v1"(%62) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1]> : tensor<3xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[1, 2, 0]> : tensor<3xindex>>, xla_shape = #vhlo.string_v1<"f32[1,39,64]{1,2,0}">} : (!vhlo.tensor_v1<1x64x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x39x64x!vhlo.f32_v1> loc(#loc13)
    %64 = "vhlo.concatenate_v1"(%63, %63) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<1x39x64x!vhlo.f32_v1>, !vhlo.tensor_v1<1x39x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x39x128x!vhlo.f32_v1> loc(#loc16)
    %65 = "vhlo.cosine_v2"(%64) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x39x128x!vhlo.f32_v1> loc(#loc17)
    %66 = "vhlo.convert_v1"(%65) : (!vhlo.tensor_v1<1x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x39x128x!vhlo.bf16_v1> loc(#loc2)
    %67 = "vhlo.reshape_v1"(%66) : (!vhlo.tensor_v1<1x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x39x128x!vhlo.bf16_v1> loc(#loc5)
    %68 = "vhlo.convert_v1"(%67) : (!vhlo.tensor_v1<1x1x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x39x128x!vhlo.f32_v1> loc(#loc2)
    %69 = "vhlo.reshape_v1"(%68) : (!vhlo.tensor_v1<1x1x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<39x128x!vhlo.f32_v1> loc(#loc3)
    %70 = "vhlo.broadcast_in_dim_v1"(%69) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1> loc(#loc3)
    %71 = "vhlo.multiply_v1"(%55, %70) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>, !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1> loc(#loc3)
    %72 = "vhlo.convert_v1"(%71) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1> loc(#loc2)
    %73 = "vhlo.slice_v1"(%54) <{limit_indices = #vhlo.tensor_v1<dense<[2, 4, 39, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x64x!vhlo.bf16_v1> loc(#loc18)
    %74 = "vhlo.negate_v1"(%73) : (!vhlo.tensor_v1<2x4x39x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x64x!vhlo.bf16_v1> loc(#loc19)
    %75 = "vhlo.slice_v1"(%54) <{limit_indices = #vhlo.tensor_v1<dense<[2, 4, 39, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x64x!vhlo.bf16_v1> loc(#loc18)
    %76 = "vhlo.concatenate_v1"(%74, %75) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<2x4x39x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x4x39x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1> loc(#loc16)
    %77 = "vhlo.convert_v1"(%76) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1> loc(#loc2)
    %78 = "vhlo.sine_v2"(%64) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x39x128x!vhlo.f32_v1> loc(#loc20)
    %79 = "vhlo.convert_v1"(%78) : (!vhlo.tensor_v1<1x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x39x128x!vhlo.bf16_v1> loc(#loc2)
    %80 = "vhlo.reshape_v1"(%79) : (!vhlo.tensor_v1<1x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x39x128x!vhlo.bf16_v1> loc(#loc5)
    %81 = "vhlo.convert_v1"(%80) : (!vhlo.tensor_v1<1x1x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x39x128x!vhlo.f32_v1> loc(#loc2)
    %82 = "vhlo.reshape_v1"(%81) : (!vhlo.tensor_v1<1x1x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<39x128x!vhlo.f32_v1> loc(#loc3)
    %83 = "vhlo.broadcast_in_dim_v1"(%82) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1> loc(#loc3)
    %84 = "vhlo.multiply_v1"(%77, %83) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>, !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1> loc(#loc3)
    %85 = "vhlo.convert_v1"(%84) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1> loc(#loc2)
    %86 = "vhlo.add_v1"(%72, %85) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1> loc(#loc11)
    %87 = "vhlo.reshape_v1"(%arg7) : (!vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1> loc(#loc5)
    %88 = "vhlo.custom_call_v1"(%87) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_v_proj_weight">}>} : (!vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1> loc(#loc7)
    %89 = "vhlo.reshape_v1"(%88) : (!vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<512x3584x!vhlo.bf16_v1> loc(#loc5)
    %90 = "vhlo.transpose_v1"(%89) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,512]{0,1}">} : (!vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x512x!vhlo.bf16_v1> loc(#loc13)
    %91 = "vhlo.dot_general_v2"(%41, %90) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x512x!vhlo.bf16_v1> loc(#loc14)
    %92 = "vhlo.reshape_v1"(%91) : (!vhlo.tensor_v1<78x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1> loc(#loc5)
    %93 = "vhlo.reshape_v1"(%arg6) : (!vhlo.tensor_v1<512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1> loc(#loc5)
    %94 = "vhlo.custom_call_v1"(%93) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_v_proj_bias">}>} : (!vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1> loc(#loc7)
    %95 = "vhlo.reshape_v1"(%94) : (!vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<512x!vhlo.bf16_v1> loc(#loc5)
    %96 = "vhlo.broadcast_in_dim_v1"(%95) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1> loc(#loc11)
    %97 = "vhlo.add_v1"(%92, %96) : (!vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1> loc(#loc11)
    %98 = "vhlo.reshape_v1"(%97) : (!vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x4x128x!vhlo.bf16_v1> loc(#loc5)
    %99 = "vhlo.transpose_v1"(%98) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[2,4,39,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x39x4x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1> loc(#loc13)
    %100 = "vhlo.reshape_v1"(%arg18) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1> loc(#loc5)
    %101 = "vhlo.custom_call_v1"(%100) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___norm_weight">}>} : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1> loc(#loc7)
    %102 = "vhlo.reshape_v1"(%101) : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.bf16_v1> loc(#loc5)
    %103 = "vhlo.convert_v1"(%102) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.f32_v1> loc(#loc2)
    %104 = "vhlo.broadcast_in_dim_v1"(%103) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc3)
    %105 = "vhlo.reshape_v1"(%arg15) : (!vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1> loc(#loc5)
    %106 = "vhlo.custom_call_v1"(%105) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_q_proj_weight">}>} : (!vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1> loc(#loc7)
    %107 = "vhlo.reshape_v1"(%106) : (!vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1> loc(#loc5)
    %108 = "vhlo.transpose_v1"(%107) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,3584]{0,1}">} : (!vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1> loc(#loc13)
    %109 = "vhlo.dot_general_v2"(%41, %108) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1> loc(#loc14)
    %110 = "vhlo.reshape_v1"(%109) : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1> loc(#loc5)
    %111 = "vhlo.reshape_v1"(%arg14) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1> loc(#loc5)
    %112 = "vhlo.custom_call_v1"(%111) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_q_proj_bias">}>} : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1> loc(#loc7)
    %113 = "vhlo.reshape_v1"(%112) : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.bf16_v1> loc(#loc5)
    %114 = "vhlo.broadcast_in_dim_v1"(%113) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1> loc(#loc11)
    %115 = "vhlo.add_v1"(%110, %114) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1> loc(#loc11)
    %116 = "vhlo.reshape_v1"(%115) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x28x128x!vhlo.bf16_v1> loc(#loc5)
    %117 = "vhlo.transpose_v1"(%116) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[2,28,39,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x39x28x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1> loc(#loc13)
    %118 = "vhlo.convert_v1"(%117) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[2,28,39,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1> loc(#loc2)
    %119 = "vhlo.broadcast_in_dim_v1"(%69) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1> loc(#loc3)
    %120 = "vhlo.multiply_v1"(%118, %119) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>, !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1> loc(#loc3)
    %121 = "vhlo.convert_v1"(%120) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1> loc(#loc2)
    %122 = "vhlo.slice_v1"(%117) <{limit_indices = #vhlo.tensor_v1<dense<[2, 28, 39, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x64x!vhlo.bf16_v1> loc(#loc18)
    %123 = "vhlo.negate_v1"(%122) : (!vhlo.tensor_v1<2x28x39x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x64x!vhlo.bf16_v1> loc(#loc19)
    %124 = "vhlo.slice_v1"(%117) <{limit_indices = #vhlo.tensor_v1<dense<[2, 28, 39, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x64x!vhlo.bf16_v1> loc(#loc18)
    %125 = "vhlo.concatenate_v1"(%123, %124) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<2x28x39x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x28x39x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1> loc(#loc16)
    %126 = "vhlo.convert_v1"(%125) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1> loc(#loc2)
    %127 = "vhlo.broadcast_in_dim_v1"(%82) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1> loc(#loc3)
    %128 = "vhlo.multiply_v1"(%126, %127) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>, !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1> loc(#loc3)
    %129 = "vhlo.convert_v1"(%128) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1> loc(#loc2)
    %130 = "vhlo.add_v1"(%121, %129) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1> loc(#loc11)
    %131 = "vhlo.reshape_v1"(%130) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<56x39x128x!vhlo.bf16_v1> loc(#loc5)
    %132 = "vhlo.broadcast_in_dim_v1"(%86) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x7x39x128x!vhlo.bf16_v1> loc(#loc6)
    %133 = "vhlo.reshape_v1"(%132) : (!vhlo.tensor_v1<2x4x7x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1> loc(#loc5)
    %134 = "vhlo.transpose_v1"(%133) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[2,28,128,39]{2,3,1,0}">} : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x128x39x!vhlo.bf16_v1> loc(#loc13)
    %135 = "vhlo.reshape_v1"(%134) : (!vhlo.tensor_v1<2x28x128x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<56x128x39x!vhlo.bf16_v1> loc(#loc5)
    %136 = "vhlo.dot_general_v2"(%131, %135) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<56x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<56x128x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<56x39x39x!vhlo.bf16_v1> loc(#loc15)
    %137 = "vhlo.reshape_v1"(%136) : (!vhlo.tensor_v1<56x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1> loc(#loc5)
    %138 = "vhlo.convert_v1"(%137) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1> loc(#loc2)
    %139 = "vhlo.multiply_v1"(%138, %10) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1> loc(#loc3)
    %140 = "vhlo.convert_v1"(%139) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1> loc(#loc2)
    %141 = "vhlo.reshape_v1"(%arg11) : (!vhlo.tensor_v1<2x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<2x1x1x39x!vhlo.i64_v1> loc(#loc5)
    %142 = "vhlo.convert_v1"(%141) : (!vhlo.tensor_v1<2x1x1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<2x1x1x39x!vhlo.bf16_v1> loc(#loc11)
    %143 = "vhlo.reshape_v1"(%142) : (!vhlo.tensor_v1<2x1x1x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x!vhlo.bf16_v1> loc(#loc11)
    %144 = "vhlo.broadcast_in_dim_v1"(%143) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x1x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1> loc(#loc11)
    %145 = "vhlo.add_v1"(%20, %144) : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1> loc(#loc11)
    %146 = "vhlo.compare_v1"(%145, %9) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 EQ>}> : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bool_v1> loc(#loc21)
    %147 = "vhlo.select_v1"(%146, %8, %20) : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bool_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1> loc(#loc22)
    %148 = "vhlo.custom_call_v1"(%147) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1> loc(#loc7)
    %149 = "vhlo.reshape_v1"(%148) : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x39x!vhlo.bf16_v1> loc(#loc11)
    %150 = "vhlo.broadcast_in_dim_v1"(%149) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1> loc(#loc11)
    %151 = "vhlo.add_v1"(%140, %150) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1> loc(#loc11)
    %152 = "vhlo.convert_v1"(%151) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1> loc(#loc2)
    %153 = "vhlo.reduce_v1"(%152, %1) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1> loc("aten__softmax"), %arg20: !vhlo.tensor_v1<!vhlo.f32_v1> loc("aten__softmax")):
      %238 = "vhlo.maximum_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc24)
      "vhlo.return_v1"(%238) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x!vhlo.f32_v1> loc(#loc23)
    %154 = "vhlo.broadcast_in_dim_v1"(%153) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x28x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1> loc(#loc23)
    %155 = "vhlo.subtract_v1"(%152, %154) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1> loc(#loc23)
    %156 = "vhlo.exponential_v2"(%155) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1> loc(#loc23)
    %157 = "vhlo.reduce_v1"(%156, %0) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1> loc("aten__softmax"), %arg20: !vhlo.tensor_v1<!vhlo.f32_v1> loc("aten__softmax")):
      %238 = "vhlo.add_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc25)
      "vhlo.return_v1"(%238) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x!vhlo.f32_v1> loc(#loc23)
    %158 = "vhlo.broadcast_in_dim_v1"(%157) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x28x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1> loc(#loc23)
    %159 = "vhlo.divide_v1"(%156, %158) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1> loc(#loc23)
    %160 = "vhlo.convert_v1"(%159) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1> loc(#loc2)
    %161 = "vhlo.reshape_v1"(%160) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<56x39x39x!vhlo.bf16_v1> loc(#loc5)
    %162 = "vhlo.broadcast_in_dim_v1"(%99) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x7x39x128x!vhlo.bf16_v1> loc(#loc6)
    %163 = "vhlo.reshape_v1"(%162) : (!vhlo.tensor_v1<2x4x7x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<56x39x128x!vhlo.bf16_v1> loc(#loc5)
    %164 = "vhlo.dot_general_v2"(%161, %163) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<56x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<56x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<56x39x128x!vhlo.bf16_v1> loc(#loc15)
    %165 = "vhlo.reshape_v1"(%164) : (!vhlo.tensor_v1<56x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1> loc(#loc5)
    %166 = "vhlo.transpose_v1"(%165) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[2,39,28,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x28x128x!vhlo.bf16_v1> loc(#loc13)
    %167 = "vhlo.reshape_v1"(%166) : (!vhlo.tensor_v1<2x39x28x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1> loc(#loc5)
    %168 = "vhlo.reshape_v1"(%arg10) : (!vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1> loc(#loc5)
    %169 = "vhlo.custom_call_v1"(%168) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_o_proj_weight">}>} : (!vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1> loc(#loc7)
    %170 = "vhlo.reshape_v1"(%169) : (!vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1> loc(#loc5)
    %171 = "vhlo.transpose_v1"(%170) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,3584]{0,1}">} : (!vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1> loc(#loc13)
    %172 = "vhlo.dot_general_v2"(%167, %171) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1> loc(#loc14)
    %173 = "vhlo.reshape_v1"(%172) : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1> loc(#loc5)
    %174 = "vhlo.add_v1"(%26, %173) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1> loc(#loc11)
    %175 = "vhlo.reshape_v1"(%arg16) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1> loc(#loc5)
    %176 = "vhlo.custom_call_v1"(%175) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___post_attention_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1> loc(#loc7)
    %177 = "vhlo.reshape_v1"(%176) : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.bf16_v1> loc(#loc5)
    %178 = "vhlo.convert_v1"(%177) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.f32_v1> loc(#loc2)
    %179 = "vhlo.broadcast_in_dim_v1"(%178) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc3)
    %180 = "vhlo.convert_v1"(%174) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc2)
    %181 = "vhlo.power_v1"(%180, %13) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc8)
    %182 = "vhlo.reduce_v1"(%181, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1> loc("aten__mean"), %arg20: !vhlo.tensor_v1<!vhlo.f32_v1> loc("aten__mean")):
      %238 = "vhlo.add_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc26)
      "vhlo.return_v1"(%238) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1> loc(#loc9)
    %183 = "vhlo.multiply_v1"(%182, %12) : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1> loc(#loc9)
    %184 = "vhlo.reshape_v1"(%183) : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1> loc(#loc9)
    %185 = "vhlo.add_v1"(%184, %11) : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1> loc(#loc11)
    %186 = "vhlo.rsqrt_v2"(%185) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1> loc(#loc12)
    %187 = "vhlo.reshape_v1"(%186) : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1> loc(#loc3)
    %188 = "vhlo.broadcast_in_dim_v1"(%187) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc3)
    %189 = "vhlo.multiply_v1"(%180, %188) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc3)
    %190 = "vhlo.convert_v1"(%189) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1> loc(#loc2)
    %191 = "vhlo.convert_v1"(%190) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc2)
    %192 = "vhlo.multiply_v1"(%179, %191) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc3)
    %193 = "vhlo.convert_v1"(%192) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1> loc(#loc2)
    %194 = "vhlo.reshape_v1"(%193) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1> loc(#loc5)
    %195 = "vhlo.reshape_v1"(%arg17) : (!vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1> loc(#loc5)
    %196 = "vhlo.custom_call_v1"(%195) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___mlp_gate_proj_weight">}>} : (!vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1> loc(#loc7)
    %197 = "vhlo.reshape_v1"(%196) : (!vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1> loc(#loc5)
    %198 = "vhlo.transpose_v1"(%197) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,18944]{0,1}">} : (!vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1> loc(#loc13)
    %199 = "vhlo.dot_general_v2"(%194, %198) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x18944x!vhlo.bf16_v1> loc(#loc14)
    %200 = "vhlo.reshape_v1"(%199) : (!vhlo.tensor_v1<78x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1> loc(#loc5)
    %201 = "vhlo.convert_v1"(%200) : (!vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1> loc(#loc2)
    %202 = "vhlo.logistic_v2"(%200) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1> loc(#loc27)
    %203 = "vhlo.convert_v1"(%202) : (!vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1> loc(#loc2)
    %204 = "vhlo.multiply_v1"(%201, %203) : (!vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1> loc(#loc3)
    %205 = "vhlo.convert_v1"(%204) : (!vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1> loc(#loc2)
    %206 = "vhlo.convert_v1"(%205) : (!vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1> loc(#loc2)
    %207 = "vhlo.reshape_v1"(%arg9) : (!vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1> loc(#loc5)
    %208 = "vhlo.custom_call_v1"(%207) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___mlp_up_proj_weight">}>} : (!vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1> loc(#loc7)
    %209 = "vhlo.reshape_v1"(%208) : (!vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1> loc(#loc5)
    %210 = "vhlo.transpose_v1"(%209) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,18944]{0,1}">} : (!vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1> loc(#loc13)
    %211 = "vhlo.dot_general_v2"(%194, %210) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x18944x!vhlo.bf16_v1> loc(#loc14)
    %212 = "vhlo.reshape_v1"(%211) : (!vhlo.tensor_v1<78x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1> loc(#loc5)
    %213 = "vhlo.convert_v1"(%212) : (!vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1> loc(#loc2)
    %214 = "vhlo.multiply_v1"(%206, %213) : (!vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1> loc(#loc3)
    %215 = "vhlo.convert_v1"(%214) : (!vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1> loc(#loc2)
    %216 = "vhlo.reshape_v1"(%215) : (!vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x18944x!vhlo.bf16_v1> loc(#loc5)
    %217 = "vhlo.reshape_v1"(%arg8) : (!vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x18944x!vhlo.bf16_v1> loc(#loc5)
    %218 = "vhlo.custom_call_v1"(%217) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___mlp_down_proj_weight">}>} : (!vhlo.tensor_v1<1x3584x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x18944x!vhlo.bf16_v1> loc(#loc7)
    %219 = "vhlo.reshape_v1"(%218) : (!vhlo.tensor_v1<1x3584x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1> loc(#loc5)
    %220 = "vhlo.transpose_v1"(%219) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[18944,3584]{0,1}">} : (!vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1> loc(#loc13)
    %221 = "vhlo.dot_general_v2"(%216, %220) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x18944x!vhlo.bf16_v1>, !vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1> loc(#loc14)
    %222 = "vhlo.reshape_v1"(%221) : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1> loc(#loc5)
    %223 = "vhlo.add_v1"(%174, %222) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1> loc(#loc11)
    %224 = "vhlo.convert_v1"(%223) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc2)
    %225 = "vhlo.power_v1"(%224, %13) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc8)
    %226 = "vhlo.reduce_v1"(%225, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1> loc("aten__mean"), %arg20: !vhlo.tensor_v1<!vhlo.f32_v1> loc("aten__mean")):
      %238 = "vhlo.add_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc28)
      "vhlo.return_v1"(%238) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1> loc(#loc9)
    %227 = "vhlo.multiply_v1"(%226, %12) : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1> loc(#loc9)
    %228 = "vhlo.reshape_v1"(%227) : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1> loc(#loc9)
    %229 = "vhlo.add_v1"(%228, %11) : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1> loc(#loc11)
    %230 = "vhlo.rsqrt_v2"(%229) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1> loc(#loc12)
    %231 = "vhlo.reshape_v1"(%230) : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1> loc(#loc3)
    %232 = "vhlo.broadcast_in_dim_v1"(%231) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc3)
    %233 = "vhlo.multiply_v1"(%224, %232) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc3)
    %234 = "vhlo.convert_v1"(%233) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1> loc(#loc2)
    %235 = "vhlo.convert_v1"(%234) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc2)
    %236 = "vhlo.multiply_v1"(%104, %235) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1> loc(#loc3)
    %237 = "vhlo.convert_v1"(%236) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1> loc(#loc2)
    "vhlo.return_v1"(%86, %99, %237) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,2]<=[2,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,2]<=[2,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,4]<=[8]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,2]<=[2,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,4]<=[8]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1,4]<=[8] last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,2]<=[2,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,2]<=[2,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("xla__cast")
#loc3 = loc("aten__mul")
#loc4 = loc("xla__custom_sharding")
#loc5 = loc("aten__view")
#loc6 = loc("aten__expand")
#loc7 = loc("xla__custom_call")
#loc8 = loc("aten__pow")
#loc10 = loc("add.53")
#loc11 = loc("aten__add")
#loc12 = loc("aten__rsqrt")
#loc13 = loc("aten__permute")
#loc14 = loc("aten__mm")
#loc15 = loc("aten__matmul")
#loc16 = loc("aten__cat")
#loc17 = loc("aten__cos")
#loc18 = loc("xla__select")
#loc19 = loc("aten__neg")
#loc20 = loc("aten__sin")
#loc21 = loc("aten__eq")
#loc22 = loc("aten__masked_fill")
#loc24 = loc("maximum.291")
#loc25 = loc("add.300")
#loc26 = loc("add.325")
#loc27 = loc("aten__sigmoid")
#loc28 = loc("add.389")
// -----// IR Dump Before VhloToVersionPass (vhlo-to-version) ('builtin.module' operation: @SyncTensorsGraph.420) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<1x39x!vhlo.i64_v1>, %arg1: !vhlo.tensor_v1<64x!vhlo.f32_v1>, %arg2: !vhlo.tensor_v1<512x!vhlo.bf16_v1>, %arg3: !vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>, %arg4: !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>, %arg5: !vhlo.tensor_v1<3584x!vhlo.bf16_v1>, %arg6: !vhlo.tensor_v1<512x!vhlo.bf16_v1>, %arg7: !vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>, %arg8: !vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1>, %arg9: !vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>, %arg10: !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>, %arg11: !vhlo.tensor_v1<2x39x!vhlo.i64_v1>, %arg12: !vhlo.tensor_v1<39x39x!vhlo.bool_v1>, %arg13: !vhlo.tensor_v1<39x39x!vhlo.bf16_v1>, %arg14: !vhlo.tensor_v1<3584x!vhlo.bf16_v1>, %arg15: !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>, %arg16: !vhlo.tensor_v1<3584x!vhlo.bf16_v1>, %arg17: !vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>, %arg18: !vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.7901787E-4> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %4 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<9.99999997E-7> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %5 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.0883883461> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %6 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1>
    %7 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<-3.389530e+38> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1>
    %8 = "vhlo.broadcast_in_dim_v1"(%7) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %9 = "vhlo.broadcast_in_dim_v1"(%6) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %10 = "vhlo.broadcast_in_dim_v1"(%5) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>
    %11 = "vhlo.broadcast_in_dim_v1"(%4) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>
    %12 = "vhlo.broadcast_in_dim_v1"(%3) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1>
    %13 = "vhlo.broadcast_in_dim_v1"(%2) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %14 = "vhlo.convert_v1"(%arg13) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.f32_v1>
    %15 = "vhlo.convert_v1"(%arg12) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<39x39x!vhlo.bool_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.f32_v1>
    %16 = "vhlo.multiply_v1"(%14, %15) : (!vhlo.tensor_v1<39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.f32_v1>
    %17 = "vhlo.convert_v1"(%16) : (!vhlo.tensor_v1<39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.bf16_v1>
    %18 = "vhlo.custom_call_v1"(%17) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.bf16_v1>
    %19 = "vhlo.reshape_v1"(%18) : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x39x39x!vhlo.bf16_v1>
    %20 = "vhlo.broadcast_in_dim_v1"(%19) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[1, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %21 = "vhlo.reshape_v1"(%arg5) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>
    %22 = "vhlo.custom_call_v1"(%21) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___input_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>
    %23 = "vhlo.reshape_v1"(%22) : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.bf16_v1>
    %24 = "vhlo.convert_v1"(%23) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.f32_v1>
    %25 = "vhlo.broadcast_in_dim_v1"(%24) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %26 = "vhlo.custom_call_v1"(%arg4) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_1">}>} : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %27 = "vhlo.convert_v1"(%26) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %28 = "vhlo.power_v1"(%27, %13) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %29 = "vhlo.reduce_v1"(%28, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg20: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %238 = "vhlo.add_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%238) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1>
    %30 = "vhlo.multiply_v1"(%29, %12) : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1>
    %31 = "vhlo.reshape_v1"(%30) : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>
    %32 = "vhlo.add_v1"(%31, %11) : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>
    %33 = "vhlo.rsqrt_v2"(%32) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>
    %34 = "vhlo.reshape_v1"(%33) : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1>
    %35 = "vhlo.broadcast_in_dim_v1"(%34) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %36 = "vhlo.multiply_v1"(%27, %35) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %37 = "vhlo.convert_v1"(%36) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %38 = "vhlo.convert_v1"(%37) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %39 = "vhlo.multiply_v1"(%25, %38) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %40 = "vhlo.convert_v1"(%39) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %41 = "vhlo.reshape_v1"(%40) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>
    %42 = "vhlo.reshape_v1"(%arg3) : (!vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>
    %43 = "vhlo.custom_call_v1"(%42) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_k_proj_weight">}>} : (!vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>
    %44 = "vhlo.reshape_v1"(%43) : (!vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>
    %45 = "vhlo.transpose_v1"(%44) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,512]{0,1}">} : (!vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x512x!vhlo.bf16_v1>
    %46 = "vhlo.dot_general_v2"(%41, %45) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x512x!vhlo.bf16_v1>
    %47 = "vhlo.reshape_v1"(%46) : (!vhlo.tensor_v1<78x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>
    %48 = "vhlo.reshape_v1"(%arg2) : (!vhlo.tensor_v1<512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>
    %49 = "vhlo.custom_call_v1"(%48) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_k_proj_bias">}>} : (!vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>
    %50 = "vhlo.reshape_v1"(%49) : (!vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<512x!vhlo.bf16_v1>
    %51 = "vhlo.broadcast_in_dim_v1"(%50) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>
    %52 = "vhlo.add_v1"(%47, %51) : (!vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>
    %53 = "vhlo.reshape_v1"(%52) : (!vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x4x128x!vhlo.bf16_v1>
    %54 = "vhlo.transpose_v1"(%53) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[2,4,39,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x39x4x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>
    %55 = "vhlo.convert_v1"(%54) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[2,4,39,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>
    %56 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>
    %57 = "vhlo.custom_call_v1"(%56) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"constant">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___rotary_emb_inv_freq">}>} : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>
    %58 = "vhlo.reshape_v1"(%57) : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>
    %59 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x39x!vhlo.i64_v1>
    %60 = "vhlo.custom_call_v1"(%59) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_2">}>} : (!vhlo.tensor_v1<1x1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x39x!vhlo.i64_v1>
    %61 = "vhlo.convert_v1"(%60) : (!vhlo.tensor_v1<1x1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x39x!vhlo.f32_v1>
    %62 = "vhlo.dot_general_v2"(%58, %61) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x39x!vhlo.f32_v1>
    %63 = "vhlo.transpose_v1"(%62) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1]> : tensor<3xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[1, 2, 0]> : tensor<3xindex>>, xla_shape = #vhlo.string_v1<"f32[1,39,64]{1,2,0}">} : (!vhlo.tensor_v1<1x64x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x39x64x!vhlo.f32_v1>
    %64 = "vhlo.concatenate_v1"(%63, %63) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<1x39x64x!vhlo.f32_v1>, !vhlo.tensor_v1<1x39x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x39x128x!vhlo.f32_v1>
    %65 = "vhlo.cosine_v2"(%64) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x39x128x!vhlo.f32_v1>
    %66 = "vhlo.convert_v1"(%65) : (!vhlo.tensor_v1<1x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x39x128x!vhlo.bf16_v1>
    %67 = "vhlo.reshape_v1"(%66) : (!vhlo.tensor_v1<1x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x39x128x!vhlo.bf16_v1>
    %68 = "vhlo.convert_v1"(%67) : (!vhlo.tensor_v1<1x1x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x39x128x!vhlo.f32_v1>
    %69 = "vhlo.reshape_v1"(%68) : (!vhlo.tensor_v1<1x1x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<39x128x!vhlo.f32_v1>
    %70 = "vhlo.broadcast_in_dim_v1"(%69) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>
    %71 = "vhlo.multiply_v1"(%55, %70) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>, !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>
    %72 = "vhlo.convert_v1"(%71) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>
    %73 = "vhlo.slice_v1"(%54) <{limit_indices = #vhlo.tensor_v1<dense<[2, 4, 39, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x64x!vhlo.bf16_v1>
    %74 = "vhlo.negate_v1"(%73) : (!vhlo.tensor_v1<2x4x39x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x64x!vhlo.bf16_v1>
    %75 = "vhlo.slice_v1"(%54) <{limit_indices = #vhlo.tensor_v1<dense<[2, 4, 39, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x64x!vhlo.bf16_v1>
    %76 = "vhlo.concatenate_v1"(%74, %75) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<2x4x39x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x4x39x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>
    %77 = "vhlo.convert_v1"(%76) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>
    %78 = "vhlo.sine_v2"(%64) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x39x128x!vhlo.f32_v1>
    %79 = "vhlo.convert_v1"(%78) : (!vhlo.tensor_v1<1x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x39x128x!vhlo.bf16_v1>
    %80 = "vhlo.reshape_v1"(%79) : (!vhlo.tensor_v1<1x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x39x128x!vhlo.bf16_v1>
    %81 = "vhlo.convert_v1"(%80) : (!vhlo.tensor_v1<1x1x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x39x128x!vhlo.f32_v1>
    %82 = "vhlo.reshape_v1"(%81) : (!vhlo.tensor_v1<1x1x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<39x128x!vhlo.f32_v1>
    %83 = "vhlo.broadcast_in_dim_v1"(%82) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>
    %84 = "vhlo.multiply_v1"(%77, %83) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>, !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>
    %85 = "vhlo.convert_v1"(%84) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>
    %86 = "vhlo.add_v1"(%72, %85) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>
    %87 = "vhlo.reshape_v1"(%arg7) : (!vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>
    %88 = "vhlo.custom_call_v1"(%87) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_v_proj_weight">}>} : (!vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>
    %89 = "vhlo.reshape_v1"(%88) : (!vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>
    %90 = "vhlo.transpose_v1"(%89) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,512]{0,1}">} : (!vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x512x!vhlo.bf16_v1>
    %91 = "vhlo.dot_general_v2"(%41, %90) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x512x!vhlo.bf16_v1>
    %92 = "vhlo.reshape_v1"(%91) : (!vhlo.tensor_v1<78x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>
    %93 = "vhlo.reshape_v1"(%arg6) : (!vhlo.tensor_v1<512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>
    %94 = "vhlo.custom_call_v1"(%93) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_v_proj_bias">}>} : (!vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>
    %95 = "vhlo.reshape_v1"(%94) : (!vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<512x!vhlo.bf16_v1>
    %96 = "vhlo.broadcast_in_dim_v1"(%95) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>
    %97 = "vhlo.add_v1"(%92, %96) : (!vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>
    %98 = "vhlo.reshape_v1"(%97) : (!vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x4x128x!vhlo.bf16_v1>
    %99 = "vhlo.transpose_v1"(%98) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[2,4,39,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x39x4x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>
    %100 = "vhlo.reshape_v1"(%arg18) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>
    %101 = "vhlo.custom_call_v1"(%100) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___norm_weight">}>} : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>
    %102 = "vhlo.reshape_v1"(%101) : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.bf16_v1>
    %103 = "vhlo.convert_v1"(%102) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.f32_v1>
    %104 = "vhlo.broadcast_in_dim_v1"(%103) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %105 = "vhlo.reshape_v1"(%arg15) : (!vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>
    %106 = "vhlo.custom_call_v1"(%105) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_q_proj_weight">}>} : (!vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>
    %107 = "vhlo.reshape_v1"(%106) : (!vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>
    %108 = "vhlo.transpose_v1"(%107) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,3584]{0,1}">} : (!vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>
    %109 = "vhlo.dot_general_v2"(%41, %108) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>
    %110 = "vhlo.reshape_v1"(%109) : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %111 = "vhlo.reshape_v1"(%arg14) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>
    %112 = "vhlo.custom_call_v1"(%111) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_q_proj_bias">}>} : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>
    %113 = "vhlo.reshape_v1"(%112) : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.bf16_v1>
    %114 = "vhlo.broadcast_in_dim_v1"(%113) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %115 = "vhlo.add_v1"(%110, %114) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %116 = "vhlo.reshape_v1"(%115) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x28x128x!vhlo.bf16_v1>
    %117 = "vhlo.transpose_v1"(%116) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[2,28,39,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x39x28x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>
    %118 = "vhlo.convert_v1"(%117) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[2,28,39,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>
    %119 = "vhlo.broadcast_in_dim_v1"(%69) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>
    %120 = "vhlo.multiply_v1"(%118, %119) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>, !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>
    %121 = "vhlo.convert_v1"(%120) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>
    %122 = "vhlo.slice_v1"(%117) <{limit_indices = #vhlo.tensor_v1<dense<[2, 28, 39, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x64x!vhlo.bf16_v1>
    %123 = "vhlo.negate_v1"(%122) : (!vhlo.tensor_v1<2x28x39x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x64x!vhlo.bf16_v1>
    %124 = "vhlo.slice_v1"(%117) <{limit_indices = #vhlo.tensor_v1<dense<[2, 28, 39, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x64x!vhlo.bf16_v1>
    %125 = "vhlo.concatenate_v1"(%123, %124) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<2x28x39x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x28x39x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>
    %126 = "vhlo.convert_v1"(%125) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>
    %127 = "vhlo.broadcast_in_dim_v1"(%82) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>
    %128 = "vhlo.multiply_v1"(%126, %127) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>, !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>
    %129 = "vhlo.convert_v1"(%128) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>
    %130 = "vhlo.add_v1"(%121, %129) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>
    %131 = "vhlo.reshape_v1"(%130) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<56x39x128x!vhlo.bf16_v1>
    %132 = "vhlo.broadcast_in_dim_v1"(%86) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x7x39x128x!vhlo.bf16_v1>
    %133 = "vhlo.reshape_v1"(%132) : (!vhlo.tensor_v1<2x4x7x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>
    %134 = "vhlo.transpose_v1"(%133) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[2,28,128,39]{2,3,1,0}">} : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x128x39x!vhlo.bf16_v1>
    %135 = "vhlo.reshape_v1"(%134) : (!vhlo.tensor_v1<2x28x128x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<56x128x39x!vhlo.bf16_v1>
    %136 = "vhlo.dot_general_v2"(%131, %135) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<56x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<56x128x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<56x39x39x!vhlo.bf16_v1>
    %137 = "vhlo.reshape_v1"(%136) : (!vhlo.tensor_v1<56x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>
    %138 = "vhlo.convert_v1"(%137) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>
    %139 = "vhlo.multiply_v1"(%138, %10) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>
    %140 = "vhlo.convert_v1"(%139) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>
    %141 = "vhlo.reshape_v1"(%arg11) : (!vhlo.tensor_v1<2x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<2x1x1x39x!vhlo.i64_v1>
    %142 = "vhlo.convert_v1"(%141) : (!vhlo.tensor_v1<2x1x1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<2x1x1x39x!vhlo.bf16_v1>
    %143 = "vhlo.reshape_v1"(%142) : (!vhlo.tensor_v1<2x1x1x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x!vhlo.bf16_v1>
    %144 = "vhlo.broadcast_in_dim_v1"(%143) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x1x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %145 = "vhlo.add_v1"(%20, %144) : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %146 = "vhlo.compare_v1"(%145, %9) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 EQ>}> : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bool_v1>
    %147 = "vhlo.select_v1"(%146, %8, %20) : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bool_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %148 = "vhlo.custom_call_v1"(%147) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %149 = "vhlo.reshape_v1"(%148) : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x39x!vhlo.bf16_v1>
    %150 = "vhlo.broadcast_in_dim_v1"(%149) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>
    %151 = "vhlo.add_v1"(%140, %150) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>
    %152 = "vhlo.convert_v1"(%151) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>
    %153 = "vhlo.reduce_v1"(%152, %1) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg20: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %238 = "vhlo.maximum_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%238) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x!vhlo.f32_v1>
    %154 = "vhlo.broadcast_in_dim_v1"(%153) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x28x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>
    %155 = "vhlo.subtract_v1"(%152, %154) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>
    %156 = "vhlo.exponential_v2"(%155) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>
    %157 = "vhlo.reduce_v1"(%156, %0) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg20: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %238 = "vhlo.add_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%238) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x!vhlo.f32_v1>
    %158 = "vhlo.broadcast_in_dim_v1"(%157) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x28x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>
    %159 = "vhlo.divide_v1"(%156, %158) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>
    %160 = "vhlo.convert_v1"(%159) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>
    %161 = "vhlo.reshape_v1"(%160) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<56x39x39x!vhlo.bf16_v1>
    %162 = "vhlo.broadcast_in_dim_v1"(%99) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x7x39x128x!vhlo.bf16_v1>
    %163 = "vhlo.reshape_v1"(%162) : (!vhlo.tensor_v1<2x4x7x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<56x39x128x!vhlo.bf16_v1>
    %164 = "vhlo.dot_general_v2"(%161, %163) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<56x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<56x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<56x39x128x!vhlo.bf16_v1>
    %165 = "vhlo.reshape_v1"(%164) : (!vhlo.tensor_v1<56x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>
    %166 = "vhlo.transpose_v1"(%165) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[2,39,28,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x28x128x!vhlo.bf16_v1>
    %167 = "vhlo.reshape_v1"(%166) : (!vhlo.tensor_v1<2x39x28x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>
    %168 = "vhlo.reshape_v1"(%arg10) : (!vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>
    %169 = "vhlo.custom_call_v1"(%168) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_o_proj_weight">}>} : (!vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>
    %170 = "vhlo.reshape_v1"(%169) : (!vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>
    %171 = "vhlo.transpose_v1"(%170) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,3584]{0,1}">} : (!vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>
    %172 = "vhlo.dot_general_v2"(%167, %171) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>
    %173 = "vhlo.reshape_v1"(%172) : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %174 = "vhlo.add_v1"(%26, %173) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %175 = "vhlo.reshape_v1"(%arg16) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>
    %176 = "vhlo.custom_call_v1"(%175) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___post_attention_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>
    %177 = "vhlo.reshape_v1"(%176) : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.bf16_v1>
    %178 = "vhlo.convert_v1"(%177) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.f32_v1>
    %179 = "vhlo.broadcast_in_dim_v1"(%178) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %180 = "vhlo.convert_v1"(%174) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %181 = "vhlo.power_v1"(%180, %13) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %182 = "vhlo.reduce_v1"(%181, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg20: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %238 = "vhlo.add_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%238) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1>
    %183 = "vhlo.multiply_v1"(%182, %12) : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1>
    %184 = "vhlo.reshape_v1"(%183) : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>
    %185 = "vhlo.add_v1"(%184, %11) : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>
    %186 = "vhlo.rsqrt_v2"(%185) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>
    %187 = "vhlo.reshape_v1"(%186) : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1>
    %188 = "vhlo.broadcast_in_dim_v1"(%187) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %189 = "vhlo.multiply_v1"(%180, %188) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %190 = "vhlo.convert_v1"(%189) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %191 = "vhlo.convert_v1"(%190) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %192 = "vhlo.multiply_v1"(%179, %191) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %193 = "vhlo.convert_v1"(%192) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %194 = "vhlo.reshape_v1"(%193) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>
    %195 = "vhlo.reshape_v1"(%arg17) : (!vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1>
    %196 = "vhlo.custom_call_v1"(%195) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___mlp_gate_proj_weight">}>} : (!vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1>
    %197 = "vhlo.reshape_v1"(%196) : (!vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>
    %198 = "vhlo.transpose_v1"(%197) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,18944]{0,1}">} : (!vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1>
    %199 = "vhlo.dot_general_v2"(%194, %198) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x18944x!vhlo.bf16_v1>
    %200 = "vhlo.reshape_v1"(%199) : (!vhlo.tensor_v1<78x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>
    %201 = "vhlo.convert_v1"(%200) : (!vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>
    %202 = "vhlo.logistic_v2"(%200) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>
    %203 = "vhlo.convert_v1"(%202) : (!vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>
    %204 = "vhlo.multiply_v1"(%201, %203) : (!vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>
    %205 = "vhlo.convert_v1"(%204) : (!vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>
    %206 = "vhlo.convert_v1"(%205) : (!vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>
    %207 = "vhlo.reshape_v1"(%arg9) : (!vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1>
    %208 = "vhlo.custom_call_v1"(%207) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___mlp_up_proj_weight">}>} : (!vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1>
    %209 = "vhlo.reshape_v1"(%208) : (!vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>
    %210 = "vhlo.transpose_v1"(%209) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,18944]{0,1}">} : (!vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1>
    %211 = "vhlo.dot_general_v2"(%194, %210) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x18944x!vhlo.bf16_v1>
    %212 = "vhlo.reshape_v1"(%211) : (!vhlo.tensor_v1<78x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>
    %213 = "vhlo.convert_v1"(%212) : (!vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>
    %214 = "vhlo.multiply_v1"(%206, %213) : (!vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>
    %215 = "vhlo.convert_v1"(%214) : (!vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>
    %216 = "vhlo.reshape_v1"(%215) : (!vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x18944x!vhlo.bf16_v1>
    %217 = "vhlo.reshape_v1"(%arg8) : (!vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x18944x!vhlo.bf16_v1>
    %218 = "vhlo.custom_call_v1"(%217) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___mlp_down_proj_weight">}>} : (!vhlo.tensor_v1<1x3584x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x18944x!vhlo.bf16_v1>
    %219 = "vhlo.reshape_v1"(%218) : (!vhlo.tensor_v1<1x3584x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1>
    %220 = "vhlo.transpose_v1"(%219) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[18944,3584]{0,1}">} : (!vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>
    %221 = "vhlo.dot_general_v2"(%216, %220) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x18944x!vhlo.bf16_v1>, !vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>
    %222 = "vhlo.reshape_v1"(%221) : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %223 = "vhlo.add_v1"(%174, %222) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %224 = "vhlo.convert_v1"(%223) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %225 = "vhlo.power_v1"(%224, %13) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %226 = "vhlo.reduce_v1"(%225, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg20: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %238 = "vhlo.add_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%238) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1>
    %227 = "vhlo.multiply_v1"(%226, %12) : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1>
    %228 = "vhlo.reshape_v1"(%227) : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>
    %229 = "vhlo.add_v1"(%228, %11) : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>
    %230 = "vhlo.rsqrt_v2"(%229) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>
    %231 = "vhlo.reshape_v1"(%230) : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1>
    %232 = "vhlo.broadcast_in_dim_v1"(%231) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %233 = "vhlo.multiply_v1"(%224, %232) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %234 = "vhlo.convert_v1"(%233) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %235 = "vhlo.convert_v1"(%234) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %236 = "vhlo.multiply_v1"(%104, %235) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %237 = "vhlo.convert_v1"(%236) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    "vhlo.return_v1"(%86, %99, %237) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,2]<=[2,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,2]<=[2,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,4]<=[8]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,2]<=[2,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,4]<=[8]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1,4]<=[8] last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,2]<=[2,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,2]<=[2,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}


// -----// IR Dump Before VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.420) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<1x39x!vhlo.i64_v1>, %arg1: !vhlo.tensor_v1<64x!vhlo.f32_v1>, %arg2: !vhlo.tensor_v1<512x!vhlo.bf16_v1>, %arg3: !vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>, %arg4: !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>, %arg5: !vhlo.tensor_v1<3584x!vhlo.bf16_v1>, %arg6: !vhlo.tensor_v1<512x!vhlo.bf16_v1>, %arg7: !vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>, %arg8: !vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1>, %arg9: !vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>, %arg10: !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>, %arg11: !vhlo.tensor_v1<2x39x!vhlo.i64_v1>, %arg12: !vhlo.tensor_v1<39x39x!vhlo.bool_v1>, %arg13: !vhlo.tensor_v1<39x39x!vhlo.bf16_v1>, %arg14: !vhlo.tensor_v1<3584x!vhlo.bf16_v1>, %arg15: !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>, %arg16: !vhlo.tensor_v1<3584x!vhlo.bf16_v1>, %arg17: !vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>, %arg18: !vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.7901787E-4> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %4 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<9.99999997E-7> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %5 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.0883883461> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %6 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1>
    %7 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<-3.389530e+38> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1>
    %8 = "vhlo.broadcast_in_dim_v1"(%7) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %9 = "vhlo.broadcast_in_dim_v1"(%6) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %10 = "vhlo.broadcast_in_dim_v1"(%5) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>
    %11 = "vhlo.broadcast_in_dim_v1"(%4) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>
    %12 = "vhlo.broadcast_in_dim_v1"(%3) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1>
    %13 = "vhlo.broadcast_in_dim_v1"(%2) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %14 = "vhlo.convert_v1"(%arg13) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.f32_v1>
    %15 = "vhlo.convert_v1"(%arg12) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<39x39x!vhlo.bool_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.f32_v1>
    %16 = "vhlo.multiply_v1"(%14, %15) : (!vhlo.tensor_v1<39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.f32_v1>
    %17 = "vhlo.convert_v1"(%16) : (!vhlo.tensor_v1<39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.bf16_v1>
    %18 = "vhlo.custom_call_v1"(%17) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.bf16_v1>
    %19 = "vhlo.reshape_v1"(%18) : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x39x39x!vhlo.bf16_v1>
    %20 = "vhlo.broadcast_in_dim_v1"(%19) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[1, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %21 = "vhlo.reshape_v1"(%arg5) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>
    %22 = "vhlo.custom_call_v1"(%21) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___input_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>
    %23 = "vhlo.reshape_v1"(%22) : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.bf16_v1>
    %24 = "vhlo.convert_v1"(%23) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.f32_v1>
    %25 = "vhlo.broadcast_in_dim_v1"(%24) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %26 = "vhlo.custom_call_v1"(%arg4) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_1">}>} : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %27 = "vhlo.convert_v1"(%26) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %28 = "vhlo.power_v1"(%27, %13) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %29 = "vhlo.reduce_v1"(%28, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg20: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %238 = "vhlo.add_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%238) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1>
    %30 = "vhlo.multiply_v1"(%29, %12) : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1>
    %31 = "vhlo.reshape_v1"(%30) : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>
    %32 = "vhlo.add_v1"(%31, %11) : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>
    %33 = "vhlo.rsqrt_v2"(%32) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>
    %34 = "vhlo.reshape_v1"(%33) : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1>
    %35 = "vhlo.broadcast_in_dim_v1"(%34) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %36 = "vhlo.multiply_v1"(%27, %35) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %37 = "vhlo.convert_v1"(%36) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %38 = "vhlo.convert_v1"(%37) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %39 = "vhlo.multiply_v1"(%25, %38) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %40 = "vhlo.convert_v1"(%39) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %41 = "vhlo.reshape_v1"(%40) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>
    %42 = "vhlo.reshape_v1"(%arg3) : (!vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>
    %43 = "vhlo.custom_call_v1"(%42) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_k_proj_weight">}>} : (!vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>
    %44 = "vhlo.reshape_v1"(%43) : (!vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>
    %45 = "vhlo.transpose_v1"(%44) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,512]{0,1}">} : (!vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x512x!vhlo.bf16_v1>
    %46 = "vhlo.dot_general_v2"(%41, %45) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x512x!vhlo.bf16_v1>
    %47 = "vhlo.reshape_v1"(%46) : (!vhlo.tensor_v1<78x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>
    %48 = "vhlo.reshape_v1"(%arg2) : (!vhlo.tensor_v1<512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>
    %49 = "vhlo.custom_call_v1"(%48) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_k_proj_bias">}>} : (!vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>
    %50 = "vhlo.reshape_v1"(%49) : (!vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<512x!vhlo.bf16_v1>
    %51 = "vhlo.broadcast_in_dim_v1"(%50) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>
    %52 = "vhlo.add_v1"(%47, %51) : (!vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>
    %53 = "vhlo.reshape_v1"(%52) : (!vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x4x128x!vhlo.bf16_v1>
    %54 = "vhlo.transpose_v1"(%53) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[2,4,39,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x39x4x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>
    %55 = "vhlo.convert_v1"(%54) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[2,4,39,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>
    %56 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>
    %57 = "vhlo.custom_call_v1"(%56) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"constant">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___rotary_emb_inv_freq">}>} : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>
    %58 = "vhlo.reshape_v1"(%57) : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>
    %59 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x39x!vhlo.i64_v1>
    %60 = "vhlo.custom_call_v1"(%59) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_2">}>} : (!vhlo.tensor_v1<1x1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x39x!vhlo.i64_v1>
    %61 = "vhlo.convert_v1"(%60) : (!vhlo.tensor_v1<1x1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x39x!vhlo.f32_v1>
    %62 = "vhlo.dot_general_v2"(%58, %61) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x39x!vhlo.f32_v1>
    %63 = "vhlo.transpose_v1"(%62) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1]> : tensor<3xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[1, 2, 0]> : tensor<3xindex>>, xla_shape = #vhlo.string_v1<"f32[1,39,64]{1,2,0}">} : (!vhlo.tensor_v1<1x64x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x39x64x!vhlo.f32_v1>
    %64 = "vhlo.concatenate_v1"(%63, %63) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<1x39x64x!vhlo.f32_v1>, !vhlo.tensor_v1<1x39x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x39x128x!vhlo.f32_v1>
    %65 = "vhlo.cosine_v2"(%64) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x39x128x!vhlo.f32_v1>
    %66 = "vhlo.convert_v1"(%65) : (!vhlo.tensor_v1<1x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x39x128x!vhlo.bf16_v1>
    %67 = "vhlo.reshape_v1"(%66) : (!vhlo.tensor_v1<1x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x39x128x!vhlo.bf16_v1>
    %68 = "vhlo.convert_v1"(%67) : (!vhlo.tensor_v1<1x1x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x39x128x!vhlo.f32_v1>
    %69 = "vhlo.reshape_v1"(%68) : (!vhlo.tensor_v1<1x1x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<39x128x!vhlo.f32_v1>
    %70 = "vhlo.broadcast_in_dim_v1"(%69) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>
    %71 = "vhlo.multiply_v1"(%55, %70) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>, !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>
    %72 = "vhlo.convert_v1"(%71) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>
    %73 = "vhlo.slice_v1"(%54) <{limit_indices = #vhlo.tensor_v1<dense<[2, 4, 39, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x64x!vhlo.bf16_v1>
    %74 = "vhlo.negate_v1"(%73) : (!vhlo.tensor_v1<2x4x39x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x64x!vhlo.bf16_v1>
    %75 = "vhlo.slice_v1"(%54) <{limit_indices = #vhlo.tensor_v1<dense<[2, 4, 39, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x64x!vhlo.bf16_v1>
    %76 = "vhlo.concatenate_v1"(%74, %75) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<2x4x39x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x4x39x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>
    %77 = "vhlo.convert_v1"(%76) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>
    %78 = "vhlo.sine_v2"(%64) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x39x128x!vhlo.f32_v1>
    %79 = "vhlo.convert_v1"(%78) : (!vhlo.tensor_v1<1x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x39x128x!vhlo.bf16_v1>
    %80 = "vhlo.reshape_v1"(%79) : (!vhlo.tensor_v1<1x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x39x128x!vhlo.bf16_v1>
    %81 = "vhlo.convert_v1"(%80) : (!vhlo.tensor_v1<1x1x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x39x128x!vhlo.f32_v1>
    %82 = "vhlo.reshape_v1"(%81) : (!vhlo.tensor_v1<1x1x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<39x128x!vhlo.f32_v1>
    %83 = "vhlo.broadcast_in_dim_v1"(%82) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>
    %84 = "vhlo.multiply_v1"(%77, %83) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>, !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>
    %85 = "vhlo.convert_v1"(%84) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>
    %86 = "vhlo.add_v1"(%72, %85) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>
    %87 = "vhlo.reshape_v1"(%arg7) : (!vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>
    %88 = "vhlo.custom_call_v1"(%87) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_v_proj_weight">}>} : (!vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>
    %89 = "vhlo.reshape_v1"(%88) : (!vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>
    %90 = "vhlo.transpose_v1"(%89) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,512]{0,1}">} : (!vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x512x!vhlo.bf16_v1>
    %91 = "vhlo.dot_general_v2"(%41, %90) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x512x!vhlo.bf16_v1>
    %92 = "vhlo.reshape_v1"(%91) : (!vhlo.tensor_v1<78x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>
    %93 = "vhlo.reshape_v1"(%arg6) : (!vhlo.tensor_v1<512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>
    %94 = "vhlo.custom_call_v1"(%93) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_v_proj_bias">}>} : (!vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>
    %95 = "vhlo.reshape_v1"(%94) : (!vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<512x!vhlo.bf16_v1>
    %96 = "vhlo.broadcast_in_dim_v1"(%95) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>
    %97 = "vhlo.add_v1"(%92, %96) : (!vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>
    %98 = "vhlo.reshape_v1"(%97) : (!vhlo.tensor_v1<2x39x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x4x128x!vhlo.bf16_v1>
    %99 = "vhlo.transpose_v1"(%98) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[2,4,39,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x39x4x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>
    %100 = "vhlo.reshape_v1"(%arg18) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>
    %101 = "vhlo.custom_call_v1"(%100) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___norm_weight">}>} : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>
    %102 = "vhlo.reshape_v1"(%101) : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.bf16_v1>
    %103 = "vhlo.convert_v1"(%102) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.f32_v1>
    %104 = "vhlo.broadcast_in_dim_v1"(%103) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %105 = "vhlo.reshape_v1"(%arg15) : (!vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>
    %106 = "vhlo.custom_call_v1"(%105) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_q_proj_weight">}>} : (!vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>
    %107 = "vhlo.reshape_v1"(%106) : (!vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>
    %108 = "vhlo.transpose_v1"(%107) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,3584]{0,1}">} : (!vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>
    %109 = "vhlo.dot_general_v2"(%41, %108) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>
    %110 = "vhlo.reshape_v1"(%109) : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %111 = "vhlo.reshape_v1"(%arg14) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>
    %112 = "vhlo.custom_call_v1"(%111) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_q_proj_bias">}>} : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>
    %113 = "vhlo.reshape_v1"(%112) : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.bf16_v1>
    %114 = "vhlo.broadcast_in_dim_v1"(%113) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %115 = "vhlo.add_v1"(%110, %114) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %116 = "vhlo.reshape_v1"(%115) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x28x128x!vhlo.bf16_v1>
    %117 = "vhlo.transpose_v1"(%116) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[2,28,39,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x39x28x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>
    %118 = "vhlo.convert_v1"(%117) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[2,28,39,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>
    %119 = "vhlo.broadcast_in_dim_v1"(%69) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>
    %120 = "vhlo.multiply_v1"(%118, %119) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>, !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>
    %121 = "vhlo.convert_v1"(%120) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>
    %122 = "vhlo.slice_v1"(%117) <{limit_indices = #vhlo.tensor_v1<dense<[2, 28, 39, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x64x!vhlo.bf16_v1>
    %123 = "vhlo.negate_v1"(%122) : (!vhlo.tensor_v1<2x28x39x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x64x!vhlo.bf16_v1>
    %124 = "vhlo.slice_v1"(%117) <{limit_indices = #vhlo.tensor_v1<dense<[2, 28, 39, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x64x!vhlo.bf16_v1>
    %125 = "vhlo.concatenate_v1"(%123, %124) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<2x28x39x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x28x39x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>
    %126 = "vhlo.convert_v1"(%125) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>
    %127 = "vhlo.broadcast_in_dim_v1"(%82) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>
    %128 = "vhlo.multiply_v1"(%126, %127) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>, !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>
    %129 = "vhlo.convert_v1"(%128) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>
    %130 = "vhlo.add_v1"(%121, %129) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>
    %131 = "vhlo.reshape_v1"(%130) : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<56x39x128x!vhlo.bf16_v1>
    %132 = "vhlo.broadcast_in_dim_v1"(%86) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x7x39x128x!vhlo.bf16_v1>
    %133 = "vhlo.reshape_v1"(%132) : (!vhlo.tensor_v1<2x4x7x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>
    %134 = "vhlo.transpose_v1"(%133) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[2,28,128,39]{2,3,1,0}">} : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x128x39x!vhlo.bf16_v1>
    %135 = "vhlo.reshape_v1"(%134) : (!vhlo.tensor_v1<2x28x128x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<56x128x39x!vhlo.bf16_v1>
    %136 = "vhlo.dot_general_v2"(%131, %135) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<56x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<56x128x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<56x39x39x!vhlo.bf16_v1>
    %137 = "vhlo.reshape_v1"(%136) : (!vhlo.tensor_v1<56x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>
    %138 = "vhlo.convert_v1"(%137) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>
    %139 = "vhlo.multiply_v1"(%138, %10) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>
    %140 = "vhlo.convert_v1"(%139) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>
    %141 = "vhlo.reshape_v1"(%arg11) : (!vhlo.tensor_v1<2x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<2x1x1x39x!vhlo.i64_v1>
    %142 = "vhlo.convert_v1"(%141) : (!vhlo.tensor_v1<2x1x1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<2x1x1x39x!vhlo.bf16_v1>
    %143 = "vhlo.reshape_v1"(%142) : (!vhlo.tensor_v1<2x1x1x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x!vhlo.bf16_v1>
    %144 = "vhlo.broadcast_in_dim_v1"(%143) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x1x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %145 = "vhlo.add_v1"(%20, %144) : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %146 = "vhlo.compare_v1"(%145, %9) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 EQ>}> : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bool_v1>
    %147 = "vhlo.select_v1"(%146, %8, %20) : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bool_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %148 = "vhlo.custom_call_v1"(%147) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %149 = "vhlo.reshape_v1"(%148) : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x39x!vhlo.bf16_v1>
    %150 = "vhlo.broadcast_in_dim_v1"(%149) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>
    %151 = "vhlo.add_v1"(%140, %150) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>
    %152 = "vhlo.convert_v1"(%151) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>
    %153 = "vhlo.reduce_v1"(%152, %1) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg20: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %238 = "vhlo.maximum_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%238) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x!vhlo.f32_v1>
    %154 = "vhlo.broadcast_in_dim_v1"(%153) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x28x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>
    %155 = "vhlo.subtract_v1"(%152, %154) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>
    %156 = "vhlo.exponential_v2"(%155) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>
    %157 = "vhlo.reduce_v1"(%156, %0) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg20: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %238 = "vhlo.add_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%238) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x!vhlo.f32_v1>
    %158 = "vhlo.broadcast_in_dim_v1"(%157) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x28x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>
    %159 = "vhlo.divide_v1"(%156, %158) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>
    %160 = "vhlo.convert_v1"(%159) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>
    %161 = "vhlo.reshape_v1"(%160) : (!vhlo.tensor_v1<2x28x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<56x39x39x!vhlo.bf16_v1>
    %162 = "vhlo.broadcast_in_dim_v1"(%99) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x7x39x128x!vhlo.bf16_v1>
    %163 = "vhlo.reshape_v1"(%162) : (!vhlo.tensor_v1<2x4x7x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<56x39x128x!vhlo.bf16_v1>
    %164 = "vhlo.dot_general_v2"(%161, %163) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<56x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<56x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<56x39x128x!vhlo.bf16_v1>
    %165 = "vhlo.reshape_v1"(%164) : (!vhlo.tensor_v1<56x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>
    %166 = "vhlo.transpose_v1"(%165) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[2,39,28,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x28x39x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x28x128x!vhlo.bf16_v1>
    %167 = "vhlo.reshape_v1"(%166) : (!vhlo.tensor_v1<2x39x28x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>
    %168 = "vhlo.reshape_v1"(%arg10) : (!vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>
    %169 = "vhlo.custom_call_v1"(%168) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___self_attn_o_proj_weight">}>} : (!vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>
    %170 = "vhlo.reshape_v1"(%169) : (!vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>
    %171 = "vhlo.transpose_v1"(%170) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,3584]{0,1}">} : (!vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>
    %172 = "vhlo.dot_general_v2"(%167, %171) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>
    %173 = "vhlo.reshape_v1"(%172) : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %174 = "vhlo.add_v1"(%26, %173) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %175 = "vhlo.reshape_v1"(%arg16) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>
    %176 = "vhlo.custom_call_v1"(%175) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___post_attention_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>
    %177 = "vhlo.reshape_v1"(%176) : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.bf16_v1>
    %178 = "vhlo.convert_v1"(%177) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.f32_v1>
    %179 = "vhlo.broadcast_in_dim_v1"(%178) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %180 = "vhlo.convert_v1"(%174) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %181 = "vhlo.power_v1"(%180, %13) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %182 = "vhlo.reduce_v1"(%181, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg20: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %238 = "vhlo.add_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%238) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1>
    %183 = "vhlo.multiply_v1"(%182, %12) : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1>
    %184 = "vhlo.reshape_v1"(%183) : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>
    %185 = "vhlo.add_v1"(%184, %11) : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>
    %186 = "vhlo.rsqrt_v2"(%185) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>
    %187 = "vhlo.reshape_v1"(%186) : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1>
    %188 = "vhlo.broadcast_in_dim_v1"(%187) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %189 = "vhlo.multiply_v1"(%180, %188) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %190 = "vhlo.convert_v1"(%189) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %191 = "vhlo.convert_v1"(%190) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %192 = "vhlo.multiply_v1"(%179, %191) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %193 = "vhlo.convert_v1"(%192) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %194 = "vhlo.reshape_v1"(%193) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>
    %195 = "vhlo.reshape_v1"(%arg17) : (!vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1>
    %196 = "vhlo.custom_call_v1"(%195) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___mlp_gate_proj_weight">}>} : (!vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1>
    %197 = "vhlo.reshape_v1"(%196) : (!vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>
    %198 = "vhlo.transpose_v1"(%197) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,18944]{0,1}">} : (!vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1>
    %199 = "vhlo.dot_general_v2"(%194, %198) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x18944x!vhlo.bf16_v1>
    %200 = "vhlo.reshape_v1"(%199) : (!vhlo.tensor_v1<78x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>
    %201 = "vhlo.convert_v1"(%200) : (!vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>
    %202 = "vhlo.logistic_v2"(%200) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>
    %203 = "vhlo.convert_v1"(%202) : (!vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>
    %204 = "vhlo.multiply_v1"(%201, %203) : (!vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>
    %205 = "vhlo.convert_v1"(%204) : (!vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>
    %206 = "vhlo.convert_v1"(%205) : (!vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>
    %207 = "vhlo.reshape_v1"(%arg9) : (!vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1>
    %208 = "vhlo.custom_call_v1"(%207) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___mlp_up_proj_weight">}>} : (!vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1>
    %209 = "vhlo.reshape_v1"(%208) : (!vhlo.tensor_v1<1x18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>
    %210 = "vhlo.transpose_v1"(%209) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,18944]{0,1}">} : (!vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1>
    %211 = "vhlo.dot_general_v2"(%194, %210) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x18944x!vhlo.bf16_v1>
    %212 = "vhlo.reshape_v1"(%211) : (!vhlo.tensor_v1<78x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>
    %213 = "vhlo.convert_v1"(%212) : (!vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>
    %214 = "vhlo.multiply_v1"(%206, %213) : (!vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>
    %215 = "vhlo.convert_v1"(%214) : (!vhlo.tensor_v1<2x39x18944x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>
    %216 = "vhlo.reshape_v1"(%215) : (!vhlo.tensor_v1<2x39x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x18944x!vhlo.bf16_v1>
    %217 = "vhlo.reshape_v1"(%arg8) : (!vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x18944x!vhlo.bf16_v1>
    %218 = "vhlo.custom_call_v1"(%217) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___layers__modules__0___mlp_down_proj_weight">}>} : (!vhlo.tensor_v1<1x3584x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x18944x!vhlo.bf16_v1>
    %219 = "vhlo.reshape_v1"(%218) : (!vhlo.tensor_v1<1x3584x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1>
    %220 = "vhlo.transpose_v1"(%219) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[18944,3584]{0,1}">} : (!vhlo.tensor_v1<3584x18944x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>
    %221 = "vhlo.dot_general_v2"(%216, %220) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<78x18944x!vhlo.bf16_v1>, !vhlo.tensor_v1<18944x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>
    %222 = "vhlo.reshape_v1"(%221) : (!vhlo.tensor_v1<78x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %223 = "vhlo.add_v1"(%174, %222) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %224 = "vhlo.convert_v1"(%223) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %225 = "vhlo.power_v1"(%224, %13) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %226 = "vhlo.reduce_v1"(%225, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg20: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %238 = "vhlo.add_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%238) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1>
    %227 = "vhlo.multiply_v1"(%226, %12) : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1>
    %228 = "vhlo.reshape_v1"(%227) : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>
    %229 = "vhlo.add_v1"(%228, %11) : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>
    %230 = "vhlo.rsqrt_v2"(%229) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>
    %231 = "vhlo.reshape_v1"(%230) : (!vhlo.tensor_v1<2x39x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x!vhlo.f32_v1>
    %232 = "vhlo.broadcast_in_dim_v1"(%231) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<2x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %233 = "vhlo.multiply_v1"(%224, %232) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %234 = "vhlo.convert_v1"(%233) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    %235 = "vhlo.convert_v1"(%234) : (!vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %236 = "vhlo.multiply_v1"(%104, %235) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>
    %237 = "vhlo.convert_v1"(%236) : (!vhlo.tensor_v1<2x39x3584x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>
    "vhlo.return_v1"(%86, %99, %237) : (!vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x4x39x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x39x3584x!vhlo.bf16_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,2]<=[2,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,2]<=[2,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,4]<=[8]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,2]<=[2,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,4]<=[8]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1,4]<=[8] last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,2]<=[2,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,2]<=[2,4]T(1,0)}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}


// -----// IR Dump After VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.420) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"}, %arg1: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"}, %arg2: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"}, %arg3: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}"}, %arg4: tensor<2x39x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}, {}]>"}, mhlo.sharding = "{replicated}"}, %arg5: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"}, %arg6: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"}, %arg7: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}"}, %arg8: tensor<3584x18944xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[2,4]<=[8]}"}, %arg9: tensor<18944x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}"}, %arg10: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[2,4]<=[8]}"}, %arg11: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}"}, %arg12: tensor<39x39xi1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"}, %arg13: tensor<39x39xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"}, %arg14: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"}, %arg15: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}"}, %arg16: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"}, %arg17: tensor<18944x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}"}, %arg18: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"}) -> (tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
    %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
    %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f32>) -> tensor<2x28x39x39xf32>
    %3 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
    %4 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
    %5 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<2x39x3584xf32>
    %6 = stablehlo.convert %arg13 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %7 = stablehlo.convert %arg12 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %8 = stablehlo.multiply %6, %7 : tensor<39x39xf32>
    %9 = stablehlo.convert %8 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %10 = stablehlo.custom_call @Sharding(%9) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %11 = stablehlo.reshape %10 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.reshape %arg5 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %14 = stablehlo.custom_call @tt.mark_argument(%13) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}} : (tensor<1x1x3584xbf16>) -> tensor<1x1x3584xbf16>
    %15 = stablehlo.reshape %14 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %16 = stablehlo.convert %15 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %18 = stablehlo.custom_call @tt.mark_argument(%arg4) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_1"}} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xbf16>
    %19 = stablehlo.convert %18 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %20 = stablehlo.power %19, %5 : tensor<2x39x3584xf32>
    %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %22 = stablehlo.multiply %21, %4 : tensor<2x39xf32>
    %23 = stablehlo.reshape %22 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %24 = stablehlo.add %23, %3 : tensor<2x39x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<2x39x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %28 = stablehlo.multiply %19, %27 : tensor<2x39x3584xf32>
    %29 = stablehlo.convert %28 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %30 = stablehlo.convert %29 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %31 = stablehlo.multiply %17, %30 : tensor<2x39x3584xf32>
    %32 = stablehlo.convert %31 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %33 = stablehlo.reshape %32 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %34 = stablehlo.reshape %arg3 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %35 = stablehlo.custom_call @tt.mark_argument(%34) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}} : (tensor<1x512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %36 = stablehlo.reshape %35 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %37 = stablehlo.transpose %36, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %38 = stablehlo.dot_general %33, %37, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %39 = stablehlo.reshape %38 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %40 = stablehlo.reshape %arg2 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %41 = stablehlo.custom_call @tt.mark_argument(%40) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}} : (tensor<1x1x512xbf16>) -> tensor<1x1x512xbf16>
    %42 = stablehlo.reshape %41 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %43 = stablehlo.broadcast_in_dim %42, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %44 = stablehlo.add %39, %43 : tensor<2x39x512xbf16>
    %45 = stablehlo.reshape %44 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %46 = stablehlo.transpose %45, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %47 = stablehlo.convert %46 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %48 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %49 = stablehlo.custom_call @tt.mark_argument(%48) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "constant", ttir.name = "l__self___rotary_emb_inv_freq"}} : (tensor<1x1x64xf32>) -> tensor<1x1x64xf32>
    %50 = stablehlo.reshape %49 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %51 = stablehlo.reshape %arg0 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
    %52 = stablehlo.custom_call @tt.mark_argument(%51) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_2"}} : (tensor<1x1x39xi64>) -> tensor<1x1x39xi64>
    %53 = stablehlo.convert %52 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
    %54 = stablehlo.dot_general %50, %53, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
    %55 = stablehlo.transpose %54, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
    %56 = stablehlo.concatenate %55, %55, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
    %57 = stablehlo.cosine %56 : tensor<1x39x128xf32>
    %58 = stablehlo.convert %57 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %59 = stablehlo.reshape %58 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %60 = stablehlo.convert %59 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %61 = stablehlo.reshape %60 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %62 = stablehlo.broadcast_in_dim %61, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %63 = stablehlo.multiply %47, %62 : tensor<2x4x39x128xf32>
    %64 = stablehlo.convert %63 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %65 = stablehlo.slice %46 [0:2, 0:4, 0:39, 64:128] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %66 = stablehlo.negate %65 : tensor<2x4x39x64xbf16>
    %67 = stablehlo.slice %46 [0:2, 0:4, 0:39, 0:64] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %68 = stablehlo.concatenate %66, %67, dim = 3 : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
    %69 = stablehlo.convert %68 : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %70 = stablehlo.sine %56 : tensor<1x39x128xf32>
    %71 = stablehlo.convert %70 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %72 = stablehlo.reshape %71 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %73 = stablehlo.convert %72 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %74 = stablehlo.reshape %73 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %75 = stablehlo.broadcast_in_dim %74, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %76 = stablehlo.multiply %69, %75 : tensor<2x4x39x128xf32>
    %77 = stablehlo.convert %76 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %78 = stablehlo.add %64, %77 : tensor<2x4x39x128xbf16>
    %79 = stablehlo.reshape %arg7 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %80 = stablehlo.custom_call @tt.mark_argument(%79) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}} : (tensor<1x512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %81 = stablehlo.reshape %80 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %82 = stablehlo.transpose %81, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %83 = stablehlo.dot_general %33, %82, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %84 = stablehlo.reshape %83 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %85 = stablehlo.reshape %arg6 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %86 = stablehlo.custom_call @tt.mark_argument(%85) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}} : (tensor<1x1x512xbf16>) -> tensor<1x1x512xbf16>
    %87 = stablehlo.reshape %86 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %88 = stablehlo.broadcast_in_dim %87, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %89 = stablehlo.add %84, %88 : tensor<2x39x512xbf16>
    %90 = stablehlo.reshape %89 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %91 = stablehlo.transpose %90, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %92 = stablehlo.reshape %arg18 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %93 = stablehlo.custom_call @tt.mark_argument(%92) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___norm_weight"}} : (tensor<1x1x3584xbf16>) -> tensor<1x1x3584xbf16>
    %94 = stablehlo.reshape %93 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %95 = stablehlo.convert %94 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %96 = stablehlo.broadcast_in_dim %95, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %97 = stablehlo.reshape %arg15 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %98 = stablehlo.custom_call @tt.mark_argument(%97) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}} : (tensor<1x3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %99 = stablehlo.reshape %98 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %100 = stablehlo.transpose %99, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %101 = stablehlo.dot_general %33, %100, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %102 = stablehlo.reshape %101 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %103 = stablehlo.reshape %arg14 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %104 = stablehlo.custom_call @tt.mark_argument(%103) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}} : (tensor<1x1x3584xbf16>) -> tensor<1x1x3584xbf16>
    %105 = stablehlo.reshape %104 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %106 = stablehlo.broadcast_in_dim %105, dims = [2] : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
    %107 = stablehlo.add %102, %106 : tensor<2x39x3584xbf16>
    %108 = stablehlo.reshape %107 : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
    %109 = stablehlo.transpose %108, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
    %110 = stablehlo.convert %109 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %111 = stablehlo.broadcast_in_dim %61, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %112 = stablehlo.multiply %110, %111 : tensor<2x28x39x128xf32>
    %113 = stablehlo.convert %112 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %114 = stablehlo.slice %109 [0:2, 0:28, 0:39, 64:128] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %115 = stablehlo.negate %114 : tensor<2x28x39x64xbf16>
    %116 = stablehlo.slice %109 [0:2, 0:28, 0:39, 0:64] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %117 = stablehlo.concatenate %115, %116, dim = 3 : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
    %118 = stablehlo.convert %117 : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %119 = stablehlo.broadcast_in_dim %74, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %120 = stablehlo.multiply %118, %119 : tensor<2x28x39x128xf32>
    %121 = stablehlo.convert %120 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %122 = stablehlo.add %113, %121 : tensor<2x28x39x128xbf16>
    %123 = stablehlo.reshape %122 : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
    %124 = stablehlo.broadcast_in_dim %78, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %125 = stablehlo.reshape %124 : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %126 = stablehlo.transpose %125, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
    %127 = stablehlo.reshape %126 : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
    %128 = stablehlo.dot_general %123, %127, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
    %129 = stablehlo.reshape %128 : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %130 = stablehlo.convert %129 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %131 = stablehlo.multiply %130, %2 : tensor<2x28x39x39xf32>
    %132 = stablehlo.convert %131 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %133 = stablehlo.reshape %arg11 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %134 = stablehlo.convert %133 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %135 = stablehlo.reshape %134 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %136 = stablehlo.broadcast_in_dim %135, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %137 = stablehlo.add %12, %136 : tensor<2x1x39x39xbf16>
    %138 = stablehlo.compare  EQ, %137, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %139 = stablehlo.select %138, %0, %12 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    %140 = stablehlo.custom_call @tt.mark_argument(%139) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %141 = stablehlo.reshape %140 : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
    %142 = stablehlo.broadcast_in_dim %141, dims = [0, 2, 3] : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %143 = stablehlo.add %132, %142 : tensor<2x28x39x39xbf16>
    %144 = stablehlo.convert %143 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %145 = stablehlo.reduce(%144 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %146 = stablehlo.broadcast_in_dim %145, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %147 = stablehlo.subtract %144, %146 : tensor<2x28x39x39xf32>
    %148 = stablehlo.exponential %147 : tensor<2x28x39x39xf32>
    %149 = stablehlo.reduce(%148 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %150 = stablehlo.broadcast_in_dim %149, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %151 = stablehlo.divide %148, %150 : tensor<2x28x39x39xf32>
    %152 = stablehlo.convert %151 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %153 = stablehlo.reshape %152 : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
    %154 = stablehlo.broadcast_in_dim %91, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %155 = stablehlo.reshape %154 : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
    %156 = stablehlo.dot_general %153, %155, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
    %157 = stablehlo.reshape %156 : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %158 = stablehlo.transpose %157, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
    %159 = stablehlo.reshape %158 : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
    %160 = stablehlo.reshape %arg10 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %161 = stablehlo.custom_call @tt.mark_argument(%160) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}} : (tensor<1x3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %162 = stablehlo.reshape %161 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %163 = stablehlo.transpose %162, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %164 = stablehlo.dot_general %159, %163, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %165 = stablehlo.reshape %164 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %166 = stablehlo.add %18, %165 : tensor<2x39x3584xbf16>
    %167 = stablehlo.reshape %arg16 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %168 = stablehlo.custom_call @tt.mark_argument(%167) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}} : (tensor<1x1x3584xbf16>) -> tensor<1x1x3584xbf16>
    %169 = stablehlo.reshape %168 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %170 = stablehlo.convert %169 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %171 = stablehlo.broadcast_in_dim %170, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %172 = stablehlo.convert %166 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %173 = stablehlo.power %172, %5 : tensor<2x39x3584xf32>
    %174 = stablehlo.reduce(%173 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %175 = stablehlo.multiply %174, %4 : tensor<2x39xf32>
    %176 = stablehlo.reshape %175 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %177 = stablehlo.add %176, %3 : tensor<2x39x1xf32>
    %178 = stablehlo.rsqrt %177 : tensor<2x39x1xf32>
    %179 = stablehlo.reshape %178 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %180 = stablehlo.broadcast_in_dim %179, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %181 = stablehlo.multiply %172, %180 : tensor<2x39x3584xf32>
    %182 = stablehlo.convert %181 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %183 = stablehlo.convert %182 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %184 = stablehlo.multiply %171, %183 : tensor<2x39x3584xf32>
    %185 = stablehlo.convert %184 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %186 = stablehlo.reshape %185 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %187 = stablehlo.reshape %arg17 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %188 = stablehlo.custom_call @tt.mark_argument(%187) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}} : (tensor<1x18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %189 = stablehlo.reshape %188 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %190 = stablehlo.transpose %189, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %191 = stablehlo.dot_general %186, %190, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %192 = stablehlo.reshape %191 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %193 = stablehlo.convert %192 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %194 = stablehlo.logistic %192 : tensor<2x39x18944xbf16>
    %195 = stablehlo.convert %194 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %196 = stablehlo.multiply %193, %195 : tensor<2x39x18944xf32>
    %197 = stablehlo.convert %196 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %198 = stablehlo.convert %197 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %199 = stablehlo.reshape %arg9 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %200 = stablehlo.custom_call @tt.mark_argument(%199) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}} : (tensor<1x18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %201 = stablehlo.reshape %200 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %202 = stablehlo.transpose %201, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %203 = stablehlo.dot_general %186, %202, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %204 = stablehlo.reshape %203 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %205 = stablehlo.convert %204 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %206 = stablehlo.multiply %198, %205 : tensor<2x39x18944xf32>
    %207 = stablehlo.convert %206 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %208 = stablehlo.reshape %207 : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
    %209 = stablehlo.reshape %arg8 : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
    %210 = stablehlo.custom_call @tt.mark_argument(%209) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}} : (tensor<1x3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
    %211 = stablehlo.reshape %210 : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
    %212 = stablehlo.transpose %211, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
    %213 = stablehlo.dot_general %208, %212, contracting_dims = [1] x [0] : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
    %214 = stablehlo.reshape %213 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %215 = stablehlo.add %166, %214 : tensor<2x39x3584xbf16>
    %216 = stablehlo.convert %215 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %217 = stablehlo.power %216, %5 : tensor<2x39x3584xf32>
    %218 = stablehlo.reduce(%217 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %219 = stablehlo.multiply %218, %4 : tensor<2x39xf32>
    %220 = stablehlo.reshape %219 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %221 = stablehlo.add %220, %3 : tensor<2x39x1xf32>
    %222 = stablehlo.rsqrt %221 : tensor<2x39x1xf32>
    %223 = stablehlo.reshape %222 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %224 = stablehlo.broadcast_in_dim %223, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %225 = stablehlo.multiply %216, %224 : tensor<2x39x3584xf32>
    %226 = stablehlo.convert %225 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %227 = stablehlo.convert %226 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %228 = stablehlo.multiply %96, %227 : tensor<2x39x3584xf32>
    %229 = stablehlo.convert %228 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    return %78, %91, %229 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


#loc1 = loc("xla__device_data")
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("xla__device_data"), %arg1: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("xla__device_data"), %arg2: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("xla__device_data"), %arg3: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}"} loc("xla__device_data"), %arg4: tensor<2x39x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}, {}]>"}, mhlo.sharding = "{replicated}"} loc("xla__device_data"), %arg5: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("xla__device_data"), %arg6: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("xla__device_data"), %arg7: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}"} loc("xla__device_data"), %arg8: tensor<3584x18944xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[2,4]<=[8]}"} loc("xla__device_data"), %arg9: tensor<18944x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}"} loc("xla__device_data"), %arg10: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[2,4]<=[8]}"} loc("xla__device_data"), %arg11: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}"} loc("xla__device_data"), %arg12: tensor<39x39xi1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("xla__device_data"), %arg13: tensor<39x39xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("xla__device_data"), %arg14: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("xla__device_data"), %arg15: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}"} loc("xla__device_data"), %arg16: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("xla__device_data"), %arg17: tensor<18944x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}"} loc("xla__device_data"), %arg18: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("xla__device_data")) -> (tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32> loc(#loc)
    %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32> loc(#loc)
    %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16> loc(#loc)
    %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f32>) -> tensor<2x28x39x39xf32> loc(#loc)
    %3 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32> loc(#loc)
    %4 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32> loc(#loc)
    %5 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<2x39x3584xf32> loc(#loc)
    %6 = stablehlo.convert %arg13 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32> loc(#loc2)
    %7 = stablehlo.convert %arg12 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32> loc(#loc2)
    %8 = stablehlo.multiply %6, %7 : tensor<39x39xf32> loc(#loc3)
    %9 = stablehlo.convert %8 : (tensor<39x39xf32>) -> tensor<39x39xbf16> loc(#loc2)
    %10 = stablehlo.custom_call @Sharding(%9) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16> loc(#loc4)
    %11 = stablehlo.reshape %10 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16> loc(#loc5)
    %12 = stablehlo.broadcast_in_dim %11, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16> loc(#loc6)
    %13 = stablehlo.reshape %arg5 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16> loc(#loc5)
    %14 = stablehlo.custom_call @tt.mark_argument(%13) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}} : (tensor<1x1x3584xbf16>) -> tensor<1x1x3584xbf16> loc(#loc7)
    %15 = stablehlo.reshape %14 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16> loc(#loc5)
    %16 = stablehlo.convert %15 : (tensor<3584xbf16>) -> tensor<3584xf32> loc(#loc2)
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32> loc(#loc3)
    %18 = stablehlo.custom_call @tt.mark_argument(%arg4) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_1"}} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xbf16> loc(#loc7)
    %19 = stablehlo.convert %18 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32> loc(#loc2)
    %20 = stablehlo.power %19, %5 : tensor<2x39x3584xf32> loc(#loc8)
    %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32> loc(#loc9)
    %22 = stablehlo.multiply %21, %4 : tensor<2x39xf32> loc(#loc9)
    %23 = stablehlo.reshape %22 : (tensor<2x39xf32>) -> tensor<2x39x1xf32> loc(#loc9)
    %24 = stablehlo.add %23, %3 : tensor<2x39x1xf32> loc(#loc10)
    %25 = stablehlo.rsqrt %24 : tensor<2x39x1xf32> loc(#loc11)
    %26 = stablehlo.reshape %25 : (tensor<2x39x1xf32>) -> tensor<2x39xf32> loc(#loc3)
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32> loc(#loc3)
    %28 = stablehlo.multiply %19, %27 : tensor<2x39x3584xf32> loc(#loc3)
    %29 = stablehlo.convert %28 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16> loc(#loc2)
    %30 = stablehlo.convert %29 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32> loc(#loc2)
    %31 = stablehlo.multiply %17, %30 : tensor<2x39x3584xf32> loc(#loc3)
    %32 = stablehlo.convert %31 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16> loc(#loc2)
    %33 = stablehlo.reshape %32 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16> loc(#loc5)
    %34 = stablehlo.reshape %arg3 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16> loc(#loc5)
    %35 = stablehlo.custom_call @tt.mark_argument(%34) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}} : (tensor<1x512x3584xbf16>) -> tensor<1x512x3584xbf16> loc(#loc7)
    %36 = stablehlo.reshape %35 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16> loc(#loc5)
    %37 = stablehlo.transpose %36, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16> loc(#loc12)
    %38 = stablehlo.dot_general %33, %37, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16> loc(#loc13)
    %39 = stablehlo.reshape %38 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16> loc(#loc5)
    %40 = stablehlo.reshape %arg2 : (tensor<512xbf16>) -> tensor<1x1x512xbf16> loc(#loc5)
    %41 = stablehlo.custom_call @tt.mark_argument(%40) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}} : (tensor<1x1x512xbf16>) -> tensor<1x1x512xbf16> loc(#loc7)
    %42 = stablehlo.reshape %41 : (tensor<1x1x512xbf16>) -> tensor<512xbf16> loc(#loc5)
    %43 = stablehlo.broadcast_in_dim %42, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16> loc(#loc10)
    %44 = stablehlo.add %39, %43 : tensor<2x39x512xbf16> loc(#loc10)
    %45 = stablehlo.reshape %44 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16> loc(#loc5)
    %46 = stablehlo.transpose %45, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16> loc(#loc12)
    %47 = stablehlo.convert %46 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32> loc(#loc2)
    %48 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc5)
    %49 = stablehlo.custom_call @tt.mark_argument(%48) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "constant", ttir.name = "l__self___rotary_emb_inv_freq"}} : (tensor<1x1x64xf32>) -> tensor<1x1x64xf32> loc(#loc7)
    %50 = stablehlo.reshape %49 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc5)
    %51 = stablehlo.reshape %arg0 : (tensor<1x39xi64>) -> tensor<1x1x39xi64> loc(#loc5)
    %52 = stablehlo.custom_call @tt.mark_argument(%51) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_2"}} : (tensor<1x1x39xi64>) -> tensor<1x1x39xi64> loc(#loc7)
    %53 = stablehlo.convert %52 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32> loc(#loc2)
    %54 = stablehlo.dot_general %50, %53, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32> loc(#loc14)
    %55 = stablehlo.transpose %54, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32> loc(#loc12)
    %56 = stablehlo.concatenate %55, %55, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32> loc(#loc15)
    %57 = stablehlo.cosine %56 : tensor<1x39x128xf32> loc(#loc16)
    %58 = stablehlo.convert %57 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16> loc(#loc2)
    %59 = stablehlo.reshape %58 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16> loc(#loc5)
    %60 = stablehlo.convert %59 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32> loc(#loc2)
    %61 = stablehlo.reshape %60 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32> loc(#loc3)
    %62 = stablehlo.broadcast_in_dim %61, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32> loc(#loc3)
    %63 = stablehlo.multiply %47, %62 : tensor<2x4x39x128xf32> loc(#loc3)
    %64 = stablehlo.convert %63 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16> loc(#loc2)
    %65 = stablehlo.slice %46 [0:2, 0:4, 0:39, 64:128] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16> loc(#loc17)
    %66 = stablehlo.negate %65 : tensor<2x4x39x64xbf16> loc(#loc18)
    %67 = stablehlo.slice %46 [0:2, 0:4, 0:39, 0:64] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16> loc(#loc17)
    %68 = stablehlo.concatenate %66, %67, dim = 3 : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16> loc(#loc15)
    %69 = stablehlo.convert %68 : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32> loc(#loc2)
    %70 = stablehlo.sine %56 : tensor<1x39x128xf32> loc(#loc19)
    %71 = stablehlo.convert %70 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16> loc(#loc2)
    %72 = stablehlo.reshape %71 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16> loc(#loc5)
    %73 = stablehlo.convert %72 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32> loc(#loc2)
    %74 = stablehlo.reshape %73 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32> loc(#loc3)
    %75 = stablehlo.broadcast_in_dim %74, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32> loc(#loc3)
    %76 = stablehlo.multiply %69, %75 : tensor<2x4x39x128xf32> loc(#loc3)
    %77 = stablehlo.convert %76 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16> loc(#loc2)
    %78 = stablehlo.add %64, %77 : tensor<2x4x39x128xbf16> loc(#loc10)
    %79 = stablehlo.reshape %arg7 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16> loc(#loc5)
    %80 = stablehlo.custom_call @tt.mark_argument(%79) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}} : (tensor<1x512x3584xbf16>) -> tensor<1x512x3584xbf16> loc(#loc7)
    %81 = stablehlo.reshape %80 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16> loc(#loc5)
    %82 = stablehlo.transpose %81, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16> loc(#loc12)
    %83 = stablehlo.dot_general %33, %82, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16> loc(#loc13)
    %84 = stablehlo.reshape %83 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16> loc(#loc5)
    %85 = stablehlo.reshape %arg6 : (tensor<512xbf16>) -> tensor<1x1x512xbf16> loc(#loc5)
    %86 = stablehlo.custom_call @tt.mark_argument(%85) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}} : (tensor<1x1x512xbf16>) -> tensor<1x1x512xbf16> loc(#loc7)
    %87 = stablehlo.reshape %86 : (tensor<1x1x512xbf16>) -> tensor<512xbf16> loc(#loc5)
    %88 = stablehlo.broadcast_in_dim %87, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16> loc(#loc10)
    %89 = stablehlo.add %84, %88 : tensor<2x39x512xbf16> loc(#loc10)
    %90 = stablehlo.reshape %89 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16> loc(#loc5)
    %91 = stablehlo.transpose %90, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16> loc(#loc12)
    %92 = stablehlo.reshape %arg18 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16> loc(#loc5)
    %93 = stablehlo.custom_call @tt.mark_argument(%92) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___norm_weight"}} : (tensor<1x1x3584xbf16>) -> tensor<1x1x3584xbf16> loc(#loc7)
    %94 = stablehlo.reshape %93 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16> loc(#loc5)
    %95 = stablehlo.convert %94 : (tensor<3584xbf16>) -> tensor<3584xf32> loc(#loc2)
    %96 = stablehlo.broadcast_in_dim %95, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32> loc(#loc3)
    %97 = stablehlo.reshape %arg15 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16> loc(#loc5)
    %98 = stablehlo.custom_call @tt.mark_argument(%97) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}} : (tensor<1x3584x3584xbf16>) -> tensor<1x3584x3584xbf16> loc(#loc7)
    %99 = stablehlo.reshape %98 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16> loc(#loc5)
    %100 = stablehlo.transpose %99, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16> loc(#loc12)
    %101 = stablehlo.dot_general %33, %100, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16> loc(#loc13)
    %102 = stablehlo.reshape %101 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16> loc(#loc5)
    %103 = stablehlo.reshape %arg14 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16> loc(#loc5)
    %104 = stablehlo.custom_call @tt.mark_argument(%103) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}} : (tensor<1x1x3584xbf16>) -> tensor<1x1x3584xbf16> loc(#loc7)
    %105 = stablehlo.reshape %104 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16> loc(#loc5)
    %106 = stablehlo.broadcast_in_dim %105, dims = [2] : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16> loc(#loc10)
    %107 = stablehlo.add %102, %106 : tensor<2x39x3584xbf16> loc(#loc10)
    %108 = stablehlo.reshape %107 : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16> loc(#loc5)
    %109 = stablehlo.transpose %108, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16> loc(#loc12)
    %110 = stablehlo.convert %109 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32> loc(#loc2)
    %111 = stablehlo.broadcast_in_dim %61, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32> loc(#loc3)
    %112 = stablehlo.multiply %110, %111 : tensor<2x28x39x128xf32> loc(#loc3)
    %113 = stablehlo.convert %112 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16> loc(#loc2)
    %114 = stablehlo.slice %109 [0:2, 0:28, 0:39, 64:128] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16> loc(#loc17)
    %115 = stablehlo.negate %114 : tensor<2x28x39x64xbf16> loc(#loc18)
    %116 = stablehlo.slice %109 [0:2, 0:28, 0:39, 0:64] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16> loc(#loc17)
    %117 = stablehlo.concatenate %115, %116, dim = 3 : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16> loc(#loc15)
    %118 = stablehlo.convert %117 : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32> loc(#loc2)
    %119 = stablehlo.broadcast_in_dim %74, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32> loc(#loc3)
    %120 = stablehlo.multiply %118, %119 : tensor<2x28x39x128xf32> loc(#loc3)
    %121 = stablehlo.convert %120 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16> loc(#loc2)
    %122 = stablehlo.add %113, %121 : tensor<2x28x39x128xbf16> loc(#loc10)
    %123 = stablehlo.reshape %122 : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16> loc(#loc5)
    %124 = stablehlo.broadcast_in_dim %78, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16> loc(#loc6)
    %125 = stablehlo.reshape %124 : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16> loc(#loc5)
    %126 = stablehlo.transpose %125, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16> loc(#loc12)
    %127 = stablehlo.reshape %126 : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16> loc(#loc5)
    %128 = stablehlo.dot_general %123, %127, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16> loc(#loc14)
    %129 = stablehlo.reshape %128 : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16> loc(#loc5)
    %130 = stablehlo.convert %129 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32> loc(#loc2)
    %131 = stablehlo.multiply %130, %2 : tensor<2x28x39x39xf32> loc(#loc3)
    %132 = stablehlo.convert %131 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16> loc(#loc2)
    %133 = stablehlo.reshape %arg11 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64> loc(#loc5)
    %134 = stablehlo.convert %133 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16> loc(#loc10)
    %135 = stablehlo.reshape %134 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16> loc(#loc10)
    %136 = stablehlo.broadcast_in_dim %135, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16> loc(#loc10)
    %137 = stablehlo.add %12, %136 : tensor<2x1x39x39xbf16> loc(#loc10)
    %138 = stablehlo.compare  EQ, %137, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1> loc(#loc20)
    %139 = stablehlo.select %138, %0, %12 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16> loc(#loc21)
    %140 = stablehlo.custom_call @tt.mark_argument(%139) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xbf16> loc(#loc7)
    %141 = stablehlo.reshape %140 : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16> loc(#loc10)
    %142 = stablehlo.broadcast_in_dim %141, dims = [0, 2, 3] : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16> loc(#loc10)
    %143 = stablehlo.add %132, %142 : tensor<2x28x39x39xbf16> loc(#loc10)
    %144 = stablehlo.convert %143 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32> loc(#loc2)
    %145 = stablehlo.reduce(%144 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32> loc(#loc22)
    %146 = stablehlo.broadcast_in_dim %145, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32> loc(#loc22)
    %147 = stablehlo.subtract %144, %146 : tensor<2x28x39x39xf32> loc(#loc22)
    %148 = stablehlo.exponential %147 : tensor<2x28x39x39xf32> loc(#loc22)
    %149 = stablehlo.reduce(%148 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32> loc(#loc22)
    %150 = stablehlo.broadcast_in_dim %149, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32> loc(#loc22)
    %151 = stablehlo.divide %148, %150 : tensor<2x28x39x39xf32> loc(#loc22)
    %152 = stablehlo.convert %151 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16> loc(#loc2)
    %153 = stablehlo.reshape %152 : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16> loc(#loc5)
    %154 = stablehlo.broadcast_in_dim %91, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16> loc(#loc6)
    %155 = stablehlo.reshape %154 : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16> loc(#loc5)
    %156 = stablehlo.dot_general %153, %155, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16> loc(#loc14)
    %157 = stablehlo.reshape %156 : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16> loc(#loc5)
    %158 = stablehlo.transpose %157, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16> loc(#loc12)
    %159 = stablehlo.reshape %158 : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16> loc(#loc5)
    %160 = stablehlo.reshape %arg10 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16> loc(#loc5)
    %161 = stablehlo.custom_call @tt.mark_argument(%160) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}} : (tensor<1x3584x3584xbf16>) -> tensor<1x3584x3584xbf16> loc(#loc7)
    %162 = stablehlo.reshape %161 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16> loc(#loc5)
    %163 = stablehlo.transpose %162, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16> loc(#loc12)
    %164 = stablehlo.dot_general %159, %163, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16> loc(#loc13)
    %165 = stablehlo.reshape %164 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16> loc(#loc5)
    %166 = stablehlo.add %18, %165 : tensor<2x39x3584xbf16> loc(#loc10)
    %167 = stablehlo.reshape %arg16 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16> loc(#loc5)
    %168 = stablehlo.custom_call @tt.mark_argument(%167) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}} : (tensor<1x1x3584xbf16>) -> tensor<1x1x3584xbf16> loc(#loc7)
    %169 = stablehlo.reshape %168 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16> loc(#loc5)
    %170 = stablehlo.convert %169 : (tensor<3584xbf16>) -> tensor<3584xf32> loc(#loc2)
    %171 = stablehlo.broadcast_in_dim %170, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32> loc(#loc3)
    %172 = stablehlo.convert %166 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32> loc(#loc2)
    %173 = stablehlo.power %172, %5 : tensor<2x39x3584xf32> loc(#loc8)
    %174 = stablehlo.reduce(%173 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32> loc(#loc9)
    %175 = stablehlo.multiply %174, %4 : tensor<2x39xf32> loc(#loc9)
    %176 = stablehlo.reshape %175 : (tensor<2x39xf32>) -> tensor<2x39x1xf32> loc(#loc9)
    %177 = stablehlo.add %176, %3 : tensor<2x39x1xf32> loc(#loc10)
    %178 = stablehlo.rsqrt %177 : tensor<2x39x1xf32> loc(#loc11)
    %179 = stablehlo.reshape %178 : (tensor<2x39x1xf32>) -> tensor<2x39xf32> loc(#loc3)
    %180 = stablehlo.broadcast_in_dim %179, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32> loc(#loc3)
    %181 = stablehlo.multiply %172, %180 : tensor<2x39x3584xf32> loc(#loc3)
    %182 = stablehlo.convert %181 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16> loc(#loc2)
    %183 = stablehlo.convert %182 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32> loc(#loc2)
    %184 = stablehlo.multiply %171, %183 : tensor<2x39x3584xf32> loc(#loc3)
    %185 = stablehlo.convert %184 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16> loc(#loc2)
    %186 = stablehlo.reshape %185 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16> loc(#loc5)
    %187 = stablehlo.reshape %arg17 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16> loc(#loc5)
    %188 = stablehlo.custom_call @tt.mark_argument(%187) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}} : (tensor<1x18944x3584xbf16>) -> tensor<1x18944x3584xbf16> loc(#loc7)
    %189 = stablehlo.reshape %188 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16> loc(#loc5)
    %190 = stablehlo.transpose %189, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16> loc(#loc12)
    %191 = stablehlo.dot_general %186, %190, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16> loc(#loc13)
    %192 = stablehlo.reshape %191 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16> loc(#loc5)
    %193 = stablehlo.convert %192 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32> loc(#loc2)
    %194 = stablehlo.logistic %192 : tensor<2x39x18944xbf16> loc(#loc23)
    %195 = stablehlo.convert %194 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32> loc(#loc2)
    %196 = stablehlo.multiply %193, %195 : tensor<2x39x18944xf32> loc(#loc3)
    %197 = stablehlo.convert %196 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16> loc(#loc2)
    %198 = stablehlo.convert %197 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32> loc(#loc2)
    %199 = stablehlo.reshape %arg9 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16> loc(#loc5)
    %200 = stablehlo.custom_call @tt.mark_argument(%199) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}} : (tensor<1x18944x3584xbf16>) -> tensor<1x18944x3584xbf16> loc(#loc7)
    %201 = stablehlo.reshape %200 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16> loc(#loc5)
    %202 = stablehlo.transpose %201, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16> loc(#loc12)
    %203 = stablehlo.dot_general %186, %202, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16> loc(#loc13)
    %204 = stablehlo.reshape %203 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16> loc(#loc5)
    %205 = stablehlo.convert %204 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32> loc(#loc2)
    %206 = stablehlo.multiply %198, %205 : tensor<2x39x18944xf32> loc(#loc3)
    %207 = stablehlo.convert %206 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16> loc(#loc2)
    %208 = stablehlo.reshape %207 : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16> loc(#loc5)
    %209 = stablehlo.reshape %arg8 : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16> loc(#loc5)
    %210 = stablehlo.custom_call @tt.mark_argument(%209) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}} : (tensor<1x3584x18944xbf16>) -> tensor<1x3584x18944xbf16> loc(#loc7)
    %211 = stablehlo.reshape %210 : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16> loc(#loc5)
    %212 = stablehlo.transpose %211, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16> loc(#loc12)
    %213 = stablehlo.dot_general %208, %212, contracting_dims = [1] x [0] : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16> loc(#loc13)
    %214 = stablehlo.reshape %213 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16> loc(#loc5)
    %215 = stablehlo.add %166, %214 : tensor<2x39x3584xbf16> loc(#loc10)
    %216 = stablehlo.convert %215 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32> loc(#loc2)
    %217 = stablehlo.power %216, %5 : tensor<2x39x3584xf32> loc(#loc8)
    %218 = stablehlo.reduce(%217 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32> loc(#loc9)
    %219 = stablehlo.multiply %218, %4 : tensor<2x39xf32> loc(#loc9)
    %220 = stablehlo.reshape %219 : (tensor<2x39xf32>) -> tensor<2x39x1xf32> loc(#loc9)
    %221 = stablehlo.add %220, %3 : tensor<2x39x1xf32> loc(#loc10)
    %222 = stablehlo.rsqrt %221 : tensor<2x39x1xf32> loc(#loc11)
    %223 = stablehlo.reshape %222 : (tensor<2x39x1xf32>) -> tensor<2x39xf32> loc(#loc3)
    %224 = stablehlo.broadcast_in_dim %223, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32> loc(#loc3)
    %225 = stablehlo.multiply %216, %224 : tensor<2x39x3584xf32> loc(#loc3)
    %226 = stablehlo.convert %225 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16> loc(#loc2)
    %227 = stablehlo.convert %226 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32> loc(#loc2)
    %228 = stablehlo.multiply %96, %227 : tensor<2x39x3584xf32> loc(#loc3)
    %229 = stablehlo.convert %228 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16> loc(#loc2)
    return %78, %91, %229 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("xla__cast")
#loc3 = loc("aten__mul")
#loc4 = loc("xla__custom_sharding")
#loc5 = loc("aten__view")
#loc6 = loc("aten__expand")
#loc7 = loc("xla__custom_call")
#loc8 = loc("aten__pow")
#loc9 = loc("aten__mean")
#loc10 = loc("aten__add")
#loc11 = loc("aten__rsqrt")
#loc12 = loc("aten__permute")
#loc13 = loc("aten__mm")
#loc14 = loc("aten__matmul")
#loc15 = loc("aten__cat")
#loc16 = loc("aten__cos")
#loc17 = loc("xla__select")
#loc18 = loc("aten__neg")
#loc19 = loc("aten__sin")
#loc20 = loc("aten__eq")
#loc21 = loc("aten__masked_fill")
#loc22 = loc("aten__softmax")
#loc23 = loc("aten__sigmoid")
#loc1 = loc("xla__device_data")
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_2"} loc("xla__device_data"), %arg1: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "l__self___rotary_emb_inv_freq"} loc("xla__device_data"), %arg2: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"} loc("xla__device_data"), %arg3: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"} loc("xla__device_data"), %arg4: tensor<2x39x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"} loc("xla__device_data"), %arg5: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"} loc("xla__device_data"), %arg6: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"} loc("xla__device_data"), %arg7: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"} loc("xla__device_data"), %arg8: tensor<3584x18944xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[2,4]<=[8]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"} loc("xla__device_data"), %arg9: tensor<18944x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"} loc("xla__device_data"), %arg10: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[2,4]<=[8]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"} loc("xla__device_data"), %arg11: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"} loc("xla__device_data"), %arg12: tensor<39x39xi1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"} loc("xla__device_data"), %arg13: tensor<39x39xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"} loc("xla__device_data"), %arg14: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"} loc("xla__device_data"), %arg15: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"} loc("xla__device_data"), %arg16: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"} loc("xla__device_data"), %arg17: tensor<18944x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"} loc("xla__device_data"), %arg18: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___norm_weight"} loc("xla__device_data")) -> (tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32> loc(#loc)
    %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32> loc(#loc)
    %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16> loc(#loc)
    %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f32>) -> tensor<2x28x39x39xf32> loc(#loc)
    %3 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32> loc(#loc)
    %4 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32> loc(#loc)
    %5 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<2x39x3584xf32> loc(#loc)
    %6 = stablehlo.convert %arg13 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32> loc(#loc2)
    %7 = stablehlo.convert %arg12 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32> loc(#loc2)
    %8 = stablehlo.multiply %6, %7 : tensor<39x39xf32> loc(#loc3)
    %9 = stablehlo.convert %8 : (tensor<39x39xf32>) -> tensor<39x39xbf16> loc(#loc2)
    %10 = stablehlo.custom_call @Sharding(%9) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16> loc(#loc4)
    %11 = stablehlo.reshape %10 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16> loc(#loc5)
    %12 = stablehlo.broadcast_in_dim %11, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16> loc(#loc6)
    %13 = stablehlo.reshape %arg5 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16> loc(#loc5)
    %14 = stablehlo.reshape %13 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16> loc(#loc5)
    %15 = stablehlo.convert %14 : (tensor<3584xbf16>) -> tensor<3584xf32> loc(#loc2)
    %16 = stablehlo.broadcast_in_dim %15, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32> loc(#loc3)
    %17 = stablehlo.convert %arg4 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32> loc(#loc2)
    %18 = stablehlo.power %17, %5 : tensor<2x39x3584xf32> loc(#loc7)
    %19 = stablehlo.reduce(%18 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32> loc(#loc8)
    %20 = stablehlo.multiply %19, %4 : tensor<2x39xf32> loc(#loc8)
    %21 = stablehlo.reshape %20 : (tensor<2x39xf32>) -> tensor<2x39x1xf32> loc(#loc8)
    %22 = stablehlo.add %21, %3 : tensor<2x39x1xf32> loc(#loc9)
    %23 = stablehlo.rsqrt %22 : tensor<2x39x1xf32> loc(#loc10)
    %24 = stablehlo.reshape %23 : (tensor<2x39x1xf32>) -> tensor<2x39xf32> loc(#loc3)
    %25 = stablehlo.broadcast_in_dim %24, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32> loc(#loc3)
    %26 = stablehlo.multiply %17, %25 : tensor<2x39x3584xf32> loc(#loc3)
    %27 = stablehlo.convert %26 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16> loc(#loc2)
    %28 = stablehlo.convert %27 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32> loc(#loc2)
    %29 = stablehlo.multiply %16, %28 : tensor<2x39x3584xf32> loc(#loc3)
    %30 = stablehlo.convert %29 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16> loc(#loc2)
    %31 = stablehlo.reshape %30 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16> loc(#loc5)
    %32 = stablehlo.reshape %arg3 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16> loc(#loc5)
    %33 = stablehlo.reshape %32 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16> loc(#loc5)
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16> loc(#loc11)
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16> loc(#loc12)
    %36 = stablehlo.reshape %35 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16> loc(#loc5)
    %37 = stablehlo.reshape %arg2 : (tensor<512xbf16>) -> tensor<1x1x512xbf16> loc(#loc5)
    %38 = stablehlo.reshape %37 : (tensor<1x1x512xbf16>) -> tensor<512xbf16> loc(#loc5)
    %39 = stablehlo.broadcast_in_dim %38, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16> loc(#loc9)
    %40 = stablehlo.add %36, %39 : tensor<2x39x512xbf16> loc(#loc9)
    %41 = stablehlo.reshape %40 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16> loc(#loc5)
    %42 = stablehlo.transpose %41, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16> loc(#loc11)
    %43 = stablehlo.convert %42 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32> loc(#loc2)
    %44 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc5)
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc5)
    %46 = stablehlo.reshape %arg0 : (tensor<1x39xi64>) -> tensor<1x1x39xi64> loc(#loc5)
    %47 = stablehlo.convert %46 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32> loc(#loc2)
    %48 = stablehlo.dot_general %45, %47, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32> loc(#loc13)
    %49 = stablehlo.transpose %48, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32> loc(#loc11)
    %50 = stablehlo.concatenate %49, %49, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32> loc(#loc14)
    %51 = stablehlo.cosine %50 : tensor<1x39x128xf32> loc(#loc15)
    %52 = stablehlo.convert %51 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16> loc(#loc2)
    %53 = stablehlo.reshape %52 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16> loc(#loc5)
    %54 = stablehlo.convert %53 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32> loc(#loc2)
    %55 = stablehlo.reshape %54 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32> loc(#loc3)
    %56 = stablehlo.broadcast_in_dim %55, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32> loc(#loc3)
    %57 = stablehlo.multiply %43, %56 : tensor<2x4x39x128xf32> loc(#loc3)
    %58 = stablehlo.convert %57 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16> loc(#loc2)
    %59 = stablehlo.slice %42 [0:2, 0:4, 0:39, 64:128] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16> loc(#loc16)
    %60 = stablehlo.negate %59 : tensor<2x4x39x64xbf16> loc(#loc17)
    %61 = stablehlo.slice %42 [0:2, 0:4, 0:39, 0:64] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16> loc(#loc16)
    %62 = stablehlo.concatenate %60, %61, dim = 3 : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16> loc(#loc14)
    %63 = stablehlo.convert %62 : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32> loc(#loc2)
    %64 = stablehlo.sine %50 : tensor<1x39x128xf32> loc(#loc18)
    %65 = stablehlo.convert %64 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16> loc(#loc2)
    %66 = stablehlo.reshape %65 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16> loc(#loc5)
    %67 = stablehlo.convert %66 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32> loc(#loc2)
    %68 = stablehlo.reshape %67 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32> loc(#loc3)
    %69 = stablehlo.broadcast_in_dim %68, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32> loc(#loc3)
    %70 = stablehlo.multiply %63, %69 : tensor<2x4x39x128xf32> loc(#loc3)
    %71 = stablehlo.convert %70 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16> loc(#loc2)
    %72 = stablehlo.add %58, %71 : tensor<2x4x39x128xbf16> loc(#loc9)
    %73 = stablehlo.reshape %arg7 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16> loc(#loc5)
    %74 = stablehlo.reshape %73 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16> loc(#loc5)
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16> loc(#loc11)
    %76 = stablehlo.dot_general %31, %75, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16> loc(#loc12)
    %77 = stablehlo.reshape %76 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16> loc(#loc5)
    %78 = stablehlo.reshape %arg6 : (tensor<512xbf16>) -> tensor<1x1x512xbf16> loc(#loc5)
    %79 = stablehlo.reshape %78 : (tensor<1x1x512xbf16>) -> tensor<512xbf16> loc(#loc5)
    %80 = stablehlo.broadcast_in_dim %79, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16> loc(#loc9)
    %81 = stablehlo.add %77, %80 : tensor<2x39x512xbf16> loc(#loc9)
    %82 = stablehlo.reshape %81 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16> loc(#loc5)
    %83 = stablehlo.transpose %82, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16> loc(#loc11)
    %84 = stablehlo.reshape %arg18 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16> loc(#loc5)
    %85 = stablehlo.reshape %84 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16> loc(#loc5)
    %86 = stablehlo.convert %85 : (tensor<3584xbf16>) -> tensor<3584xf32> loc(#loc2)
    %87 = stablehlo.broadcast_in_dim %86, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32> loc(#loc3)
    %88 = stablehlo.reshape %arg15 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16> loc(#loc5)
    %89 = stablehlo.reshape %88 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16> loc(#loc5)
    %90 = stablehlo.transpose %89, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16> loc(#loc11)
    %91 = stablehlo.dot_general %31, %90, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16> loc(#loc12)
    %92 = stablehlo.reshape %91 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16> loc(#loc5)
    %93 = stablehlo.reshape %arg14 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16> loc(#loc5)
    %94 = stablehlo.reshape %93 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16> loc(#loc5)
    %95 = stablehlo.broadcast_in_dim %94, dims = [2] : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16> loc(#loc9)
    %96 = stablehlo.add %92, %95 : tensor<2x39x3584xbf16> loc(#loc9)
    %97 = stablehlo.reshape %96 : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16> loc(#loc5)
    %98 = stablehlo.transpose %97, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16> loc(#loc11)
    %99 = stablehlo.convert %98 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32> loc(#loc2)
    %100 = stablehlo.broadcast_in_dim %55, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32> loc(#loc3)
    %101 = stablehlo.multiply %99, %100 : tensor<2x28x39x128xf32> loc(#loc3)
    %102 = stablehlo.convert %101 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16> loc(#loc2)
    %103 = stablehlo.slice %98 [0:2, 0:28, 0:39, 64:128] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16> loc(#loc16)
    %104 = stablehlo.negate %103 : tensor<2x28x39x64xbf16> loc(#loc17)
    %105 = stablehlo.slice %98 [0:2, 0:28, 0:39, 0:64] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16> loc(#loc16)
    %106 = stablehlo.concatenate %104, %105, dim = 3 : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16> loc(#loc14)
    %107 = stablehlo.convert %106 : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32> loc(#loc2)
    %108 = stablehlo.broadcast_in_dim %68, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32> loc(#loc3)
    %109 = stablehlo.multiply %107, %108 : tensor<2x28x39x128xf32> loc(#loc3)
    %110 = stablehlo.convert %109 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16> loc(#loc2)
    %111 = stablehlo.add %102, %110 : tensor<2x28x39x128xbf16> loc(#loc9)
    %112 = stablehlo.reshape %111 : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16> loc(#loc5)
    %113 = stablehlo.broadcast_in_dim %72, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16> loc(#loc6)
    %114 = stablehlo.reshape %113 : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16> loc(#loc5)
    %115 = stablehlo.transpose %114, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16> loc(#loc11)
    %116 = stablehlo.reshape %115 : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16> loc(#loc5)
    %117 = stablehlo.dot_general %112, %116, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16> loc(#loc13)
    %118 = stablehlo.reshape %117 : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16> loc(#loc5)
    %119 = stablehlo.convert %118 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32> loc(#loc2)
    %120 = stablehlo.multiply %119, %2 : tensor<2x28x39x39xf32> loc(#loc3)
    %121 = stablehlo.convert %120 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16> loc(#loc2)
    %122 = stablehlo.reshape %arg11 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64> loc(#loc5)
    %123 = stablehlo.convert %122 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16> loc(#loc9)
    %124 = stablehlo.reshape %123 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16> loc(#loc9)
    %125 = stablehlo.broadcast_in_dim %124, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16> loc(#loc9)
    %126 = stablehlo.add %12, %125 : tensor<2x1x39x39xbf16> loc(#loc9)
    %127 = stablehlo.compare  EQ, %126, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1> loc(#loc19)
    %128 = stablehlo.select %127, %0, %12 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16> loc(#loc20)
    %129 = stablehlo.reshape %128 : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16> loc(#loc9)
    %130 = stablehlo.broadcast_in_dim %129, dims = [0, 2, 3] : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16> loc(#loc9)
    %131 = stablehlo.add %121, %130 : tensor<2x28x39x39xbf16> loc(#loc9)
    %132 = stablehlo.convert %131 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32> loc(#loc2)
    %133 = stablehlo.reduce(%132 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32> loc(#loc21)
    %134 = stablehlo.broadcast_in_dim %133, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32> loc(#loc21)
    %135 = stablehlo.subtract %132, %134 : tensor<2x28x39x39xf32> loc(#loc21)
    %136 = stablehlo.exponential %135 : tensor<2x28x39x39xf32> loc(#loc21)
    %137 = stablehlo.reduce(%136 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32> loc(#loc21)
    %138 = stablehlo.broadcast_in_dim %137, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32> loc(#loc21)
    %139 = stablehlo.divide %136, %138 : tensor<2x28x39x39xf32> loc(#loc21)
    %140 = stablehlo.convert %139 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16> loc(#loc2)
    %141 = stablehlo.reshape %140 : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16> loc(#loc5)
    %142 = stablehlo.broadcast_in_dim %83, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16> loc(#loc6)
    %143 = stablehlo.reshape %142 : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16> loc(#loc5)
    %144 = stablehlo.dot_general %141, %143, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16> loc(#loc13)
    %145 = stablehlo.reshape %144 : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16> loc(#loc5)
    %146 = stablehlo.transpose %145, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16> loc(#loc11)
    %147 = stablehlo.reshape %146 : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16> loc(#loc5)
    %148 = stablehlo.reshape %arg10 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16> loc(#loc5)
    %149 = stablehlo.reshape %148 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16> loc(#loc5)
    %150 = stablehlo.transpose %149, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16> loc(#loc11)
    %151 = stablehlo.dot_general %147, %150, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16> loc(#loc12)
    %152 = stablehlo.reshape %151 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16> loc(#loc5)
    %153 = stablehlo.add %arg4, %152 : tensor<2x39x3584xbf16> loc(#loc9)
    %154 = stablehlo.reshape %arg16 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16> loc(#loc5)
    %155 = stablehlo.reshape %154 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16> loc(#loc5)
    %156 = stablehlo.convert %155 : (tensor<3584xbf16>) -> tensor<3584xf32> loc(#loc2)
    %157 = stablehlo.broadcast_in_dim %156, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32> loc(#loc3)
    %158 = stablehlo.convert %153 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32> loc(#loc2)
    %159 = stablehlo.power %158, %5 : tensor<2x39x3584xf32> loc(#loc7)
    %160 = stablehlo.reduce(%159 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32> loc(#loc8)
    %161 = stablehlo.multiply %160, %4 : tensor<2x39xf32> loc(#loc8)
    %162 = stablehlo.reshape %161 : (tensor<2x39xf32>) -> tensor<2x39x1xf32> loc(#loc8)
    %163 = stablehlo.add %162, %3 : tensor<2x39x1xf32> loc(#loc9)
    %164 = stablehlo.rsqrt %163 : tensor<2x39x1xf32> loc(#loc10)
    %165 = stablehlo.reshape %164 : (tensor<2x39x1xf32>) -> tensor<2x39xf32> loc(#loc3)
    %166 = stablehlo.broadcast_in_dim %165, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32> loc(#loc3)
    %167 = stablehlo.multiply %158, %166 : tensor<2x39x3584xf32> loc(#loc3)
    %168 = stablehlo.convert %167 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16> loc(#loc2)
    %169 = stablehlo.convert %168 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32> loc(#loc2)
    %170 = stablehlo.multiply %157, %169 : tensor<2x39x3584xf32> loc(#loc3)
    %171 = stablehlo.convert %170 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16> loc(#loc2)
    %172 = stablehlo.reshape %171 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16> loc(#loc5)
    %173 = stablehlo.reshape %arg17 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16> loc(#loc5)
    %174 = stablehlo.reshape %173 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16> loc(#loc5)
    %175 = stablehlo.transpose %174, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16> loc(#loc11)
    %176 = stablehlo.dot_general %172, %175, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16> loc(#loc12)
    %177 = stablehlo.reshape %176 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16> loc(#loc5)
    %178 = stablehlo.convert %177 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32> loc(#loc2)
    %179 = stablehlo.logistic %177 : tensor<2x39x18944xbf16> loc(#loc22)
    %180 = stablehlo.convert %179 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32> loc(#loc2)
    %181 = stablehlo.multiply %178, %180 : tensor<2x39x18944xf32> loc(#loc3)
    %182 = stablehlo.convert %181 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16> loc(#loc2)
    %183 = stablehlo.convert %182 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32> loc(#loc2)
    %184 = stablehlo.reshape %arg9 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16> loc(#loc5)
    %185 = stablehlo.reshape %184 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16> loc(#loc5)
    %186 = stablehlo.transpose %185, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16> loc(#loc11)
    %187 = stablehlo.dot_general %172, %186, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16> loc(#loc12)
    %188 = stablehlo.reshape %187 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16> loc(#loc5)
    %189 = stablehlo.convert %188 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32> loc(#loc2)
    %190 = stablehlo.multiply %183, %189 : tensor<2x39x18944xf32> loc(#loc3)
    %191 = stablehlo.convert %190 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16> loc(#loc2)
    %192 = stablehlo.reshape %191 : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16> loc(#loc5)
    %193 = stablehlo.reshape %arg8 : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16> loc(#loc5)
    %194 = stablehlo.reshape %193 : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16> loc(#loc5)
    %195 = stablehlo.transpose %194, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16> loc(#loc11)
    %196 = stablehlo.dot_general %192, %195, contracting_dims = [1] x [0] : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16> loc(#loc12)
    %197 = stablehlo.reshape %196 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16> loc(#loc5)
    %198 = stablehlo.add %153, %197 : tensor<2x39x3584xbf16> loc(#loc9)
    %199 = stablehlo.convert %198 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32> loc(#loc2)
    %200 = stablehlo.power %199, %5 : tensor<2x39x3584xf32> loc(#loc7)
    %201 = stablehlo.reduce(%200 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32> loc(#loc8)
    %202 = stablehlo.multiply %201, %4 : tensor<2x39xf32> loc(#loc8)
    %203 = stablehlo.reshape %202 : (tensor<2x39xf32>) -> tensor<2x39x1xf32> loc(#loc8)
    %204 = stablehlo.add %203, %3 : tensor<2x39x1xf32> loc(#loc9)
    %205 = stablehlo.rsqrt %204 : tensor<2x39x1xf32> loc(#loc10)
    %206 = stablehlo.reshape %205 : (tensor<2x39x1xf32>) -> tensor<2x39xf32> loc(#loc3)
    %207 = stablehlo.broadcast_in_dim %206, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32> loc(#loc3)
    %208 = stablehlo.multiply %199, %207 : tensor<2x39x3584xf32> loc(#loc3)
    %209 = stablehlo.convert %208 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16> loc(#loc2)
    %210 = stablehlo.convert %209 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32> loc(#loc2)
    %211 = stablehlo.multiply %87, %210 : tensor<2x39x3584xf32> loc(#loc3)
    %212 = stablehlo.convert %211 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16> loc(#loc2)
    return %72, %83, %212 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("xla__cast")
#loc3 = loc("aten__mul")
#loc4 = loc("xla__custom_sharding")
#loc5 = loc("aten__view")
#loc6 = loc("aten__expand")
#loc7 = loc("aten__pow")
#loc8 = loc("aten__mean")
#loc9 = loc("aten__add")
#loc10 = loc("aten__rsqrt")
#loc11 = loc("aten__permute")
#loc12 = loc("aten__mm")
#loc13 = loc("aten__matmul")
#loc14 = loc("aten__cat")
#loc15 = loc("aten__cos")
#loc16 = loc("xla__select")
#loc17 = loc("aten__neg")
#loc18 = loc("aten__sin")
#loc19 = loc("aten__eq")
#loc20 = loc("aten__masked_fill")
#loc21 = loc("aten__softmax")
#loc22 = loc("aten__sigmoid")
// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @SyncTensorsGraph.420) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_2"}, %arg1: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "l__self___rotary_emb_inv_freq"}, %arg2: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, %arg3: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, %arg4: tensor<2x39x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"}, %arg5: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, %arg6: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, %arg7: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, %arg8: tensor<3584x18944xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[2,4]<=[8]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, %arg9: tensor<18944x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, %arg10: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[2,4]<=[8]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, %arg11: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg12: tensor<39x39xi1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg13: tensor<39x39xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg14: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, %arg15: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, %arg16: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, %arg17: tensor<18944x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, %arg18: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___norm_weight"}) -> (tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
    %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
    %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f32>) -> tensor<2x28x39x39xf32>
    %3 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
    %4 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
    %5 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<2x39x3584xf32>
    %6 = stablehlo.convert %arg13 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %7 = stablehlo.convert %arg12 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %8 = stablehlo.multiply %6, %7 : tensor<39x39xf32>
    %9 = stablehlo.convert %8 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %10 = stablehlo.custom_call @Sharding(%9) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %11 = stablehlo.reshape %10 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.reshape %arg5 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %14 = stablehlo.reshape %13 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %15 = stablehlo.convert %14 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %16 = stablehlo.broadcast_in_dim %15, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %17 = stablehlo.convert %arg4 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %18 = stablehlo.power %17, %5 : tensor<2x39x3584xf32>
    %19 = stablehlo.reduce(%18 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %20 = stablehlo.multiply %19, %4 : tensor<2x39xf32>
    %21 = stablehlo.reshape %20 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %22 = stablehlo.add %21, %3 : tensor<2x39x1xf32>
    %23 = stablehlo.rsqrt %22 : tensor<2x39x1xf32>
    %24 = stablehlo.reshape %23 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %25 = stablehlo.broadcast_in_dim %24, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %26 = stablehlo.multiply %17, %25 : tensor<2x39x3584xf32>
    %27 = stablehlo.convert %26 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %28 = stablehlo.convert %27 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %29 = stablehlo.multiply %16, %28 : tensor<2x39x3584xf32>
    %30 = stablehlo.convert %29 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %31 = stablehlo.reshape %30 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %32 = stablehlo.reshape %arg3 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %36 = stablehlo.reshape %35 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %37 = stablehlo.reshape %arg2 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %38 = stablehlo.reshape %37 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %39 = stablehlo.broadcast_in_dim %38, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %40 = stablehlo.add %36, %39 : tensor<2x39x512xbf16>
    %41 = stablehlo.reshape %40 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %42 = stablehlo.transpose %41, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %43 = stablehlo.convert %42 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %44 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.reshape %arg0 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
    %47 = stablehlo.convert %46 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
    %48 = stablehlo.dot_general %45, %47, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
    %49 = stablehlo.transpose %48, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
    %50 = stablehlo.concatenate %49, %49, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
    %51 = stablehlo.cosine %50 : tensor<1x39x128xf32>
    %52 = stablehlo.convert %51 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %53 = stablehlo.reshape %52 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %54 = stablehlo.convert %53 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %55 = stablehlo.reshape %54 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %56 = stablehlo.broadcast_in_dim %55, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %57 = stablehlo.multiply %43, %56 : tensor<2x4x39x128xf32>
    %58 = stablehlo.convert %57 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %59 = stablehlo.slice %42 [0:2, 0:4, 0:39, 64:128] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %60 = stablehlo.negate %59 : tensor<2x4x39x64xbf16>
    %61 = stablehlo.slice %42 [0:2, 0:4, 0:39, 0:64] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %62 = stablehlo.concatenate %60, %61, dim = 3 : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
    %63 = stablehlo.convert %62 : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %64 = stablehlo.sine %50 : tensor<1x39x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %66 = stablehlo.reshape %65 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %67 = stablehlo.convert %66 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %68 = stablehlo.reshape %67 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %69 = stablehlo.broadcast_in_dim %68, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %70 = stablehlo.multiply %63, %69 : tensor<2x4x39x128xf32>
    %71 = stablehlo.convert %70 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %72 = stablehlo.add %58, %71 : tensor<2x4x39x128xbf16>
    %73 = stablehlo.reshape %arg7 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %74 = stablehlo.reshape %73 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %76 = stablehlo.dot_general %31, %75, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %77 = stablehlo.reshape %76 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %78 = stablehlo.reshape %arg6 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %79 = stablehlo.reshape %78 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %80 = stablehlo.broadcast_in_dim %79, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %81 = stablehlo.add %77, %80 : tensor<2x39x512xbf16>
    %82 = stablehlo.reshape %81 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %83 = stablehlo.transpose %82, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %84 = stablehlo.reshape %arg18 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %85 = stablehlo.reshape %84 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %86 = stablehlo.convert %85 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %87 = stablehlo.broadcast_in_dim %86, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %88 = stablehlo.reshape %arg15 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %89 = stablehlo.reshape %88 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %90 = stablehlo.transpose %89, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %91 = stablehlo.dot_general %31, %90, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %92 = stablehlo.reshape %91 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %93 = stablehlo.reshape %arg14 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %94 = stablehlo.reshape %93 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %95 = stablehlo.broadcast_in_dim %94, dims = [2] : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
    %96 = stablehlo.add %92, %95 : tensor<2x39x3584xbf16>
    %97 = stablehlo.reshape %96 : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
    %98 = stablehlo.transpose %97, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
    %99 = stablehlo.convert %98 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %100 = stablehlo.broadcast_in_dim %55, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %101 = stablehlo.multiply %99, %100 : tensor<2x28x39x128xf32>
    %102 = stablehlo.convert %101 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %103 = stablehlo.slice %98 [0:2, 0:28, 0:39, 64:128] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %104 = stablehlo.negate %103 : tensor<2x28x39x64xbf16>
    %105 = stablehlo.slice %98 [0:2, 0:28, 0:39, 0:64] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %106 = stablehlo.concatenate %104, %105, dim = 3 : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
    %107 = stablehlo.convert %106 : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %108 = stablehlo.broadcast_in_dim %68, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %109 = stablehlo.multiply %107, %108 : tensor<2x28x39x128xf32>
    %110 = stablehlo.convert %109 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %111 = stablehlo.add %102, %110 : tensor<2x28x39x128xbf16>
    %112 = stablehlo.reshape %111 : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
    %113 = stablehlo.broadcast_in_dim %72, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %114 = stablehlo.reshape %113 : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %115 = stablehlo.transpose %114, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
    %116 = stablehlo.reshape %115 : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
    %117 = stablehlo.dot_general %112, %116, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
    %118 = stablehlo.reshape %117 : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %119 = stablehlo.convert %118 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %120 = stablehlo.multiply %119, %2 : tensor<2x28x39x39xf32>
    %121 = stablehlo.convert %120 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %122 = stablehlo.reshape %arg11 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %123 = stablehlo.convert %122 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %124 = stablehlo.reshape %123 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %125 = stablehlo.broadcast_in_dim %124, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %126 = stablehlo.add %12, %125 : tensor<2x1x39x39xbf16>
    %127 = stablehlo.compare  EQ, %126, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %128 = stablehlo.select %127, %0, %12 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    %129 = stablehlo.reshape %128 : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
    %130 = stablehlo.broadcast_in_dim %129, dims = [0, 2, 3] : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %131 = stablehlo.add %121, %130 : tensor<2x28x39x39xbf16>
    %132 = stablehlo.convert %131 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %133 = stablehlo.reduce(%132 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %134 = stablehlo.broadcast_in_dim %133, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %135 = stablehlo.subtract %132, %134 : tensor<2x28x39x39xf32>
    %136 = stablehlo.exponential %135 : tensor<2x28x39x39xf32>
    %137 = stablehlo.reduce(%136 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %138 = stablehlo.broadcast_in_dim %137, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %139 = stablehlo.divide %136, %138 : tensor<2x28x39x39xf32>
    %140 = stablehlo.convert %139 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %141 = stablehlo.reshape %140 : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
    %142 = stablehlo.broadcast_in_dim %83, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %143 = stablehlo.reshape %142 : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
    %144 = stablehlo.dot_general %141, %143, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
    %145 = stablehlo.reshape %144 : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %146 = stablehlo.transpose %145, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
    %147 = stablehlo.reshape %146 : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
    %148 = stablehlo.reshape %arg10 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %149 = stablehlo.reshape %148 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %150 = stablehlo.transpose %149, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %151 = stablehlo.dot_general %147, %150, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %152 = stablehlo.reshape %151 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %153 = stablehlo.add %arg4, %152 : tensor<2x39x3584xbf16>
    %154 = stablehlo.reshape %arg16 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %155 = stablehlo.reshape %154 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %156 = stablehlo.convert %155 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %157 = stablehlo.broadcast_in_dim %156, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %158 = stablehlo.convert %153 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %159 = stablehlo.power %158, %5 : tensor<2x39x3584xf32>
    %160 = stablehlo.reduce(%159 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %161 = stablehlo.multiply %160, %4 : tensor<2x39xf32>
    %162 = stablehlo.reshape %161 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %163 = stablehlo.add %162, %3 : tensor<2x39x1xf32>
    %164 = stablehlo.rsqrt %163 : tensor<2x39x1xf32>
    %165 = stablehlo.reshape %164 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %166 = stablehlo.broadcast_in_dim %165, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %167 = stablehlo.multiply %158, %166 : tensor<2x39x3584xf32>
    %168 = stablehlo.convert %167 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %169 = stablehlo.convert %168 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %170 = stablehlo.multiply %157, %169 : tensor<2x39x3584xf32>
    %171 = stablehlo.convert %170 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %172 = stablehlo.reshape %171 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %173 = stablehlo.reshape %arg17 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %174 = stablehlo.reshape %173 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %175 = stablehlo.transpose %174, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %176 = stablehlo.dot_general %172, %175, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %177 = stablehlo.reshape %176 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %178 = stablehlo.convert %177 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %179 = stablehlo.logistic %177 : tensor<2x39x18944xbf16>
    %180 = stablehlo.convert %179 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %181 = stablehlo.multiply %178, %180 : tensor<2x39x18944xf32>
    %182 = stablehlo.convert %181 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %183 = stablehlo.convert %182 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %184 = stablehlo.reshape %arg9 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %185 = stablehlo.reshape %184 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %186 = stablehlo.transpose %185, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %187 = stablehlo.dot_general %172, %186, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %188 = stablehlo.reshape %187 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %189 = stablehlo.convert %188 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %190 = stablehlo.multiply %183, %189 : tensor<2x39x18944xf32>
    %191 = stablehlo.convert %190 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %192 = stablehlo.reshape %191 : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
    %193 = stablehlo.reshape %arg8 : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
    %194 = stablehlo.reshape %193 : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
    %195 = stablehlo.transpose %194, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
    %196 = stablehlo.dot_general %192, %195, contracting_dims = [1] x [0] : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
    %197 = stablehlo.reshape %196 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %198 = stablehlo.add %153, %197 : tensor<2x39x3584xbf16>
    %199 = stablehlo.convert %198 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %200 = stablehlo.power %199, %5 : tensor<2x39x3584xf32>
    %201 = stablehlo.reduce(%200 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %202 = stablehlo.multiply %201, %4 : tensor<2x39xf32>
    %203 = stablehlo.reshape %202 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %204 = stablehlo.add %203, %3 : tensor<2x39x1xf32>
    %205 = stablehlo.rsqrt %204 : tensor<2x39x1xf32>
    %206 = stablehlo.reshape %205 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %207 = stablehlo.broadcast_in_dim %206, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %208 = stablehlo.multiply %199, %207 : tensor<2x39x3584xf32>
    %209 = stablehlo.convert %208 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %210 = stablehlo.convert %209 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %211 = stablehlo.multiply %87, %210 : tensor<2x39x3584xf32>
    %212 = stablehlo.convert %211 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    return %72, %83, %212 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_2"}, %arg1: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "l__self___rotary_emb_inv_freq"}, %arg2: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, %arg3: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, %arg4: tensor<2x39x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"}, %arg5: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, %arg6: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, %arg7: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, %arg8: tensor<3584x18944xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[2,4]<=[8]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, %arg9: tensor<18944x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, %arg10: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[2,4]<=[8]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, %arg11: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg12: tensor<39x39xi1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg13: tensor<39x39xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg14: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, %arg15: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, %arg16: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, %arg17: tensor<18944x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, %arg18: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___norm_weight"}) -> (tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
    %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
    %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f32>) -> tensor<2x28x39x39xf32>
    %3 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
    %4 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
    %5 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<2x39x3584xf32>
    %6 = stablehlo.convert %arg13 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %7 = stablehlo.convert %arg12 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %8 = stablehlo.multiply %6, %7 : tensor<39x39xf32>
    %9 = stablehlo.convert %8 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %10 = stablehlo.custom_call @Sharding(%9) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %11 = stablehlo.reshape %10 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.reshape %arg5 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %14 = stablehlo.reshape %13 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %15 = stablehlo.convert %14 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %16 = stablehlo.broadcast_in_dim %15, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %17 = stablehlo.convert %arg4 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %18 = stablehlo.power %17, %5 : tensor<2x39x3584xf32>
    %19 = stablehlo.reduce(%18 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %20 = stablehlo.multiply %19, %4 : tensor<2x39xf32>
    %21 = stablehlo.reshape %20 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %22 = stablehlo.add %21, %3 : tensor<2x39x1xf32>
    %23 = stablehlo.rsqrt %22 : tensor<2x39x1xf32>
    %24 = stablehlo.reshape %23 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %25 = stablehlo.broadcast_in_dim %24, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %26 = stablehlo.multiply %17, %25 : tensor<2x39x3584xf32>
    %27 = stablehlo.convert %26 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %28 = stablehlo.convert %27 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %29 = stablehlo.multiply %16, %28 : tensor<2x39x3584xf32>
    %30 = stablehlo.convert %29 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %31 = stablehlo.reshape %30 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %32 = stablehlo.reshape %arg3 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %36 = stablehlo.reshape %35 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %37 = stablehlo.reshape %arg2 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %38 = stablehlo.reshape %37 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %39 = stablehlo.broadcast_in_dim %38, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %40 = stablehlo.add %36, %39 : tensor<2x39x512xbf16>
    %41 = stablehlo.reshape %40 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %42 = stablehlo.transpose %41, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %43 = stablehlo.convert %42 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %44 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.reshape %arg0 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
    %47 = stablehlo.convert %46 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
    %48 = stablehlo.dot_general %45, %47, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
    %49 = stablehlo.transpose %48, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
    %50 = stablehlo.concatenate %49, %49, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
    %51 = stablehlo.cosine %50 : tensor<1x39x128xf32>
    %52 = stablehlo.convert %51 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %53 = stablehlo.reshape %52 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %54 = stablehlo.convert %53 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %55 = stablehlo.reshape %54 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %56 = stablehlo.broadcast_in_dim %55, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %57 = stablehlo.multiply %43, %56 : tensor<2x4x39x128xf32>
    %58 = stablehlo.convert %57 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %59 = stablehlo.slice %42 [0:2, 0:4, 0:39, 64:128] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %60 = stablehlo.negate %59 : tensor<2x4x39x64xbf16>
    %61 = stablehlo.slice %42 [0:2, 0:4, 0:39, 0:64] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %62 = stablehlo.concatenate %60, %61, dim = 3 : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
    %63 = stablehlo.convert %62 : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %64 = stablehlo.sine %50 : tensor<1x39x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %66 = stablehlo.reshape %65 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %67 = stablehlo.convert %66 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %68 = stablehlo.reshape %67 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %69 = stablehlo.broadcast_in_dim %68, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %70 = stablehlo.multiply %63, %69 : tensor<2x4x39x128xf32>
    %71 = stablehlo.convert %70 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %72 = stablehlo.add %58, %71 : tensor<2x4x39x128xbf16>
    %73 = stablehlo.reshape %arg7 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %74 = stablehlo.reshape %73 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %76 = stablehlo.dot_general %31, %75, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %77 = stablehlo.reshape %76 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %78 = stablehlo.reshape %arg6 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %79 = stablehlo.reshape %78 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %80 = stablehlo.broadcast_in_dim %79, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %81 = stablehlo.add %77, %80 : tensor<2x39x512xbf16>
    %82 = stablehlo.reshape %81 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %83 = stablehlo.transpose %82, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %84 = stablehlo.reshape %arg18 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %85 = stablehlo.reshape %84 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %86 = stablehlo.convert %85 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %87 = stablehlo.broadcast_in_dim %86, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %88 = stablehlo.reshape %arg15 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %89 = stablehlo.reshape %88 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %90 = stablehlo.transpose %89, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %91 = stablehlo.dot_general %31, %90, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %92 = stablehlo.reshape %91 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %93 = stablehlo.reshape %arg14 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %94 = stablehlo.reshape %93 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %95 = stablehlo.broadcast_in_dim %94, dims = [2] : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
    %96 = stablehlo.add %92, %95 : tensor<2x39x3584xbf16>
    %97 = stablehlo.reshape %96 : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
    %98 = stablehlo.transpose %97, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
    %99 = stablehlo.convert %98 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %100 = stablehlo.broadcast_in_dim %55, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %101 = stablehlo.multiply %99, %100 : tensor<2x28x39x128xf32>
    %102 = stablehlo.convert %101 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %103 = stablehlo.slice %98 [0:2, 0:28, 0:39, 64:128] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %104 = stablehlo.negate %103 : tensor<2x28x39x64xbf16>
    %105 = stablehlo.slice %98 [0:2, 0:28, 0:39, 0:64] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %106 = stablehlo.concatenate %104, %105, dim = 3 : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
    %107 = stablehlo.convert %106 : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %108 = stablehlo.broadcast_in_dim %68, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %109 = stablehlo.multiply %107, %108 : tensor<2x28x39x128xf32>
    %110 = stablehlo.convert %109 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %111 = stablehlo.add %102, %110 : tensor<2x28x39x128xbf16>
    %112 = stablehlo.reshape %111 : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
    %113 = stablehlo.broadcast_in_dim %72, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %114 = stablehlo.reshape %113 : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %115 = stablehlo.transpose %114, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
    %116 = stablehlo.reshape %115 : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
    %117 = stablehlo.dot_general %112, %116, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
    %118 = stablehlo.reshape %117 : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %119 = stablehlo.convert %118 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %120 = stablehlo.multiply %119, %2 : tensor<2x28x39x39xf32>
    %121 = stablehlo.convert %120 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %122 = stablehlo.reshape %arg11 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %123 = stablehlo.convert %122 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %124 = stablehlo.reshape %123 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %125 = stablehlo.broadcast_in_dim %124, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %126 = stablehlo.add %12, %125 : tensor<2x1x39x39xbf16>
    %127 = stablehlo.compare  EQ, %126, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %128 = stablehlo.select %127, %0, %12 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    %129 = stablehlo.reshape %128 : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
    %130 = stablehlo.broadcast_in_dim %129, dims = [0, 2, 3] : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %131 = stablehlo.add %121, %130 : tensor<2x28x39x39xbf16>
    %132 = stablehlo.convert %131 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %133 = stablehlo.reduce(%132 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %134 = stablehlo.broadcast_in_dim %133, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %135 = stablehlo.subtract %132, %134 : tensor<2x28x39x39xf32>
    %136 = stablehlo.exponential %135 : tensor<2x28x39x39xf32>
    %137 = stablehlo.reduce(%136 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %138 = stablehlo.broadcast_in_dim %137, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %139 = stablehlo.divide %136, %138 : tensor<2x28x39x39xf32>
    %140 = stablehlo.convert %139 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %141 = stablehlo.reshape %140 : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
    %142 = stablehlo.broadcast_in_dim %83, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %143 = stablehlo.reshape %142 : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
    %144 = stablehlo.dot_general %141, %143, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
    %145 = stablehlo.reshape %144 : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %146 = stablehlo.transpose %145, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
    %147 = stablehlo.reshape %146 : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
    %148 = stablehlo.reshape %arg10 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %149 = stablehlo.reshape %148 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %150 = stablehlo.transpose %149, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %151 = stablehlo.dot_general %147, %150, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %152 = stablehlo.reshape %151 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %153 = stablehlo.add %arg4, %152 : tensor<2x39x3584xbf16>
    %154 = stablehlo.reshape %arg16 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %155 = stablehlo.reshape %154 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %156 = stablehlo.convert %155 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %157 = stablehlo.broadcast_in_dim %156, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %158 = stablehlo.convert %153 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %159 = stablehlo.power %158, %5 : tensor<2x39x3584xf32>
    %160 = stablehlo.reduce(%159 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %161 = stablehlo.multiply %160, %4 : tensor<2x39xf32>
    %162 = stablehlo.reshape %161 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %163 = stablehlo.add %162, %3 : tensor<2x39x1xf32>
    %164 = stablehlo.rsqrt %163 : tensor<2x39x1xf32>
    %165 = stablehlo.reshape %164 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %166 = stablehlo.broadcast_in_dim %165, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %167 = stablehlo.multiply %158, %166 : tensor<2x39x3584xf32>
    %168 = stablehlo.convert %167 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %169 = stablehlo.convert %168 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %170 = stablehlo.multiply %157, %169 : tensor<2x39x3584xf32>
    %171 = stablehlo.convert %170 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %172 = stablehlo.reshape %171 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %173 = stablehlo.reshape %arg17 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %174 = stablehlo.reshape %173 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %175 = stablehlo.transpose %174, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %176 = stablehlo.dot_general %172, %175, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %177 = stablehlo.reshape %176 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %178 = stablehlo.convert %177 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %179 = stablehlo.logistic %177 : tensor<2x39x18944xbf16>
    %180 = stablehlo.convert %179 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %181 = stablehlo.multiply %178, %180 : tensor<2x39x18944xf32>
    %182 = stablehlo.convert %181 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %183 = stablehlo.convert %182 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %184 = stablehlo.reshape %arg9 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %185 = stablehlo.reshape %184 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %186 = stablehlo.transpose %185, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %187 = stablehlo.dot_general %172, %186, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %188 = stablehlo.reshape %187 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %189 = stablehlo.convert %188 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %190 = stablehlo.multiply %183, %189 : tensor<2x39x18944xf32>
    %191 = stablehlo.convert %190 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %192 = stablehlo.reshape %191 : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
    %193 = stablehlo.reshape %arg8 : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
    %194 = stablehlo.reshape %193 : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
    %195 = stablehlo.transpose %194, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
    %196 = stablehlo.dot_general %192, %195, contracting_dims = [1] x [0] : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
    %197 = stablehlo.reshape %196 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %198 = stablehlo.add %153, %197 : tensor<2x39x3584xbf16>
    %199 = stablehlo.convert %198 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %200 = stablehlo.power %199, %5 : tensor<2x39x3584xf32>
    %201 = stablehlo.reduce(%200 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %202 = stablehlo.multiply %201, %4 : tensor<2x39xf32>
    %203 = stablehlo.reshape %202 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %204 = stablehlo.add %203, %3 : tensor<2x39x1xf32>
    %205 = stablehlo.rsqrt %204 : tensor<2x39x1xf32>
    %206 = stablehlo.reshape %205 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %207 = stablehlo.broadcast_in_dim %206, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %208 = stablehlo.multiply %199, %207 : tensor<2x39x3584xf32>
    %209 = stablehlo.convert %208 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %210 = stablehlo.convert %209 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %211 = stablehlo.multiply %87, %210 : tensor<2x39x3584xf32>
    %212 = stablehlo.convert %211 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    return %72, %83, %212 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


// -----// IR Dump Before TTPopulateArgumentTypes (tt-populate-argument-types) ('builtin.module' operation: @SyncTensorsGraph.420) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_2"}, %arg1: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "l__self___rotary_emb_inv_freq"}, %arg2: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, %arg3: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, %arg4: tensor<2x39x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"}, %arg5: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, %arg6: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, %arg7: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, %arg8: tensor<3584x18944xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[2,4]<=[8]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, %arg9: tensor<18944x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, %arg10: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[2,4]<=[8]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, %arg11: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg12: tensor<39x39xi1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg13: tensor<39x39xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg14: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, %arg15: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, %arg16: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, %arg17: tensor<18944x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, %arg18: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___norm_weight"}) -> (tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
    %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
    %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f32>) -> tensor<2x28x39x39xf32>
    %3 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
    %4 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
    %5 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<2x39x3584xf32>
    %6 = stablehlo.convert %arg13 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %7 = stablehlo.convert %arg12 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %8 = stablehlo.multiply %6, %7 : tensor<39x39xf32>
    %9 = stablehlo.convert %8 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %10 = stablehlo.custom_call @Sharding(%9) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %11 = stablehlo.reshape %10 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.reshape %arg5 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %14 = stablehlo.reshape %13 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %15 = stablehlo.convert %14 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %16 = stablehlo.broadcast_in_dim %15, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %17 = stablehlo.convert %arg4 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %18 = stablehlo.power %17, %5 : tensor<2x39x3584xf32>
    %19 = stablehlo.reduce(%18 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %20 = stablehlo.multiply %19, %4 : tensor<2x39xf32>
    %21 = stablehlo.reshape %20 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %22 = stablehlo.add %21, %3 : tensor<2x39x1xf32>
    %23 = stablehlo.rsqrt %22 : tensor<2x39x1xf32>
    %24 = stablehlo.reshape %23 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %25 = stablehlo.broadcast_in_dim %24, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %26 = stablehlo.multiply %17, %25 : tensor<2x39x3584xf32>
    %27 = stablehlo.convert %26 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %28 = stablehlo.convert %27 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %29 = stablehlo.multiply %16, %28 : tensor<2x39x3584xf32>
    %30 = stablehlo.convert %29 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %31 = stablehlo.reshape %30 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %32 = stablehlo.reshape %arg3 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %36 = stablehlo.reshape %35 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %37 = stablehlo.reshape %arg2 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %38 = stablehlo.reshape %37 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %39 = stablehlo.broadcast_in_dim %38, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %40 = stablehlo.add %36, %39 : tensor<2x39x512xbf16>
    %41 = stablehlo.reshape %40 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %42 = stablehlo.transpose %41, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %43 = stablehlo.convert %42 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %44 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.reshape %arg0 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
    %47 = stablehlo.convert %46 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
    %48 = stablehlo.dot_general %45, %47, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
    %49 = stablehlo.transpose %48, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
    %50 = stablehlo.concatenate %49, %49, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
    %51 = stablehlo.cosine %50 : tensor<1x39x128xf32>
    %52 = stablehlo.convert %51 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %53 = stablehlo.reshape %52 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %54 = stablehlo.convert %53 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %55 = stablehlo.reshape %54 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %56 = stablehlo.broadcast_in_dim %55, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %57 = stablehlo.multiply %43, %56 : tensor<2x4x39x128xf32>
    %58 = stablehlo.convert %57 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %59 = stablehlo.slice %42 [0:2, 0:4, 0:39, 64:128] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %60 = stablehlo.negate %59 : tensor<2x4x39x64xbf16>
    %61 = stablehlo.slice %42 [0:2, 0:4, 0:39, 0:64] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %62 = stablehlo.concatenate %60, %61, dim = 3 : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
    %63 = stablehlo.convert %62 : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %64 = stablehlo.sine %50 : tensor<1x39x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %66 = stablehlo.reshape %65 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %67 = stablehlo.convert %66 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %68 = stablehlo.reshape %67 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %69 = stablehlo.broadcast_in_dim %68, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %70 = stablehlo.multiply %63, %69 : tensor<2x4x39x128xf32>
    %71 = stablehlo.convert %70 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %72 = stablehlo.add %58, %71 : tensor<2x4x39x128xbf16>
    %73 = stablehlo.reshape %arg7 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %74 = stablehlo.reshape %73 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %76 = stablehlo.dot_general %31, %75, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %77 = stablehlo.reshape %76 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %78 = stablehlo.reshape %arg6 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %79 = stablehlo.reshape %78 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %80 = stablehlo.broadcast_in_dim %79, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %81 = stablehlo.add %77, %80 : tensor<2x39x512xbf16>
    %82 = stablehlo.reshape %81 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %83 = stablehlo.transpose %82, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %84 = stablehlo.reshape %arg18 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %85 = stablehlo.reshape %84 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %86 = stablehlo.convert %85 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %87 = stablehlo.broadcast_in_dim %86, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %88 = stablehlo.reshape %arg15 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %89 = stablehlo.reshape %88 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %90 = stablehlo.transpose %89, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %91 = stablehlo.dot_general %31, %90, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %92 = stablehlo.reshape %91 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %93 = stablehlo.reshape %arg14 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %94 = stablehlo.reshape %93 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %95 = stablehlo.broadcast_in_dim %94, dims = [2] : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
    %96 = stablehlo.add %92, %95 : tensor<2x39x3584xbf16>
    %97 = stablehlo.reshape %96 : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
    %98 = stablehlo.transpose %97, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
    %99 = stablehlo.convert %98 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %100 = stablehlo.broadcast_in_dim %55, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %101 = stablehlo.multiply %99, %100 : tensor<2x28x39x128xf32>
    %102 = stablehlo.convert %101 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %103 = stablehlo.slice %98 [0:2, 0:28, 0:39, 64:128] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %104 = stablehlo.negate %103 : tensor<2x28x39x64xbf16>
    %105 = stablehlo.slice %98 [0:2, 0:28, 0:39, 0:64] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %106 = stablehlo.concatenate %104, %105, dim = 3 : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
    %107 = stablehlo.convert %106 : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %108 = stablehlo.broadcast_in_dim %68, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %109 = stablehlo.multiply %107, %108 : tensor<2x28x39x128xf32>
    %110 = stablehlo.convert %109 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %111 = stablehlo.add %102, %110 : tensor<2x28x39x128xbf16>
    %112 = stablehlo.reshape %111 : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
    %113 = stablehlo.broadcast_in_dim %72, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %114 = stablehlo.reshape %113 : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %115 = stablehlo.transpose %114, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
    %116 = stablehlo.reshape %115 : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
    %117 = stablehlo.dot_general %112, %116, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
    %118 = stablehlo.reshape %117 : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %119 = stablehlo.convert %118 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %120 = stablehlo.multiply %119, %2 : tensor<2x28x39x39xf32>
    %121 = stablehlo.convert %120 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %122 = stablehlo.reshape %arg11 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %123 = stablehlo.convert %122 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %124 = stablehlo.reshape %123 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %125 = stablehlo.broadcast_in_dim %124, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %126 = stablehlo.add %12, %125 : tensor<2x1x39x39xbf16>
    %127 = stablehlo.compare  EQ, %126, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %128 = stablehlo.select %127, %0, %12 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    %129 = stablehlo.reshape %128 : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
    %130 = stablehlo.broadcast_in_dim %129, dims = [0, 2, 3] : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %131 = stablehlo.add %121, %130 : tensor<2x28x39x39xbf16>
    %132 = stablehlo.convert %131 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %133 = stablehlo.reduce(%132 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %134 = stablehlo.broadcast_in_dim %133, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %135 = stablehlo.subtract %132, %134 : tensor<2x28x39x39xf32>
    %136 = stablehlo.exponential %135 : tensor<2x28x39x39xf32>
    %137 = stablehlo.reduce(%136 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %138 = stablehlo.broadcast_in_dim %137, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %139 = stablehlo.divide %136, %138 : tensor<2x28x39x39xf32>
    %140 = stablehlo.convert %139 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %141 = stablehlo.reshape %140 : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
    %142 = stablehlo.broadcast_in_dim %83, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %143 = stablehlo.reshape %142 : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
    %144 = stablehlo.dot_general %141, %143, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
    %145 = stablehlo.reshape %144 : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %146 = stablehlo.transpose %145, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
    %147 = stablehlo.reshape %146 : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
    %148 = stablehlo.reshape %arg10 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %149 = stablehlo.reshape %148 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %150 = stablehlo.transpose %149, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %151 = stablehlo.dot_general %147, %150, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %152 = stablehlo.reshape %151 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %153 = stablehlo.add %arg4, %152 : tensor<2x39x3584xbf16>
    %154 = stablehlo.reshape %arg16 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %155 = stablehlo.reshape %154 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %156 = stablehlo.convert %155 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %157 = stablehlo.broadcast_in_dim %156, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %158 = stablehlo.convert %153 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %159 = stablehlo.power %158, %5 : tensor<2x39x3584xf32>
    %160 = stablehlo.reduce(%159 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %161 = stablehlo.multiply %160, %4 : tensor<2x39xf32>
    %162 = stablehlo.reshape %161 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %163 = stablehlo.add %162, %3 : tensor<2x39x1xf32>
    %164 = stablehlo.rsqrt %163 : tensor<2x39x1xf32>
    %165 = stablehlo.reshape %164 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %166 = stablehlo.broadcast_in_dim %165, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %167 = stablehlo.multiply %158, %166 : tensor<2x39x3584xf32>
    %168 = stablehlo.convert %167 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %169 = stablehlo.convert %168 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %170 = stablehlo.multiply %157, %169 : tensor<2x39x3584xf32>
    %171 = stablehlo.convert %170 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %172 = stablehlo.reshape %171 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %173 = stablehlo.reshape %arg17 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %174 = stablehlo.reshape %173 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %175 = stablehlo.transpose %174, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %176 = stablehlo.dot_general %172, %175, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %177 = stablehlo.reshape %176 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %178 = stablehlo.convert %177 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %179 = stablehlo.logistic %177 : tensor<2x39x18944xbf16>
    %180 = stablehlo.convert %179 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %181 = stablehlo.multiply %178, %180 : tensor<2x39x18944xf32>
    %182 = stablehlo.convert %181 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %183 = stablehlo.convert %182 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %184 = stablehlo.reshape %arg9 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %185 = stablehlo.reshape %184 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %186 = stablehlo.transpose %185, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %187 = stablehlo.dot_general %172, %186, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %188 = stablehlo.reshape %187 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %189 = stablehlo.convert %188 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %190 = stablehlo.multiply %183, %189 : tensor<2x39x18944xf32>
    %191 = stablehlo.convert %190 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %192 = stablehlo.reshape %191 : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
    %193 = stablehlo.reshape %arg8 : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
    %194 = stablehlo.reshape %193 : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
    %195 = stablehlo.transpose %194, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
    %196 = stablehlo.dot_general %192, %195, contracting_dims = [1] x [0] : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
    %197 = stablehlo.reshape %196 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %198 = stablehlo.add %153, %197 : tensor<2x39x3584xbf16>
    %199 = stablehlo.convert %198 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %200 = stablehlo.power %199, %5 : tensor<2x39x3584xf32>
    %201 = stablehlo.reduce(%200 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %202 = stablehlo.multiply %201, %4 : tensor<2x39xf32>
    %203 = stablehlo.reshape %202 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %204 = stablehlo.add %203, %3 : tensor<2x39x1xf32>
    %205 = stablehlo.rsqrt %204 : tensor<2x39x1xf32>
    %206 = stablehlo.reshape %205 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %207 = stablehlo.broadcast_in_dim %206, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %208 = stablehlo.multiply %199, %207 : tensor<2x39x3584xf32>
    %209 = stablehlo.convert %208 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %210 = stablehlo.convert %209 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %211 = stablehlo.multiply %87, %210 : tensor<2x39x3584xf32>
    %212 = stablehlo.convert %211 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    return %72, %83, %212 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


// -----// IR Dump Before ApplyArgumentShardStatusPass (apply-argument-shard-status) ('builtin.module' operation: @SyncTensorsGraph.420) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_2"}, %arg1: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "l__self___rotary_emb_inv_freq"}, %arg2: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, %arg3: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, %arg4: tensor<2x39x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"}, %arg5: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, %arg6: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, %arg7: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, %arg8: tensor<3584x18944xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[2,4]<=[8]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, %arg9: tensor<18944x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, %arg10: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[2,4]<=[8]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, %arg11: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg12: tensor<39x39xi1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg13: tensor<39x39xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg14: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, %arg15: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, %arg16: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, %arg17: tensor<18944x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, %arg18: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___norm_weight"}) -> (tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
    %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
    %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f32>) -> tensor<2x28x39x39xf32>
    %3 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
    %4 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
    %5 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<2x39x3584xf32>
    %6 = stablehlo.convert %arg13 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %7 = stablehlo.convert %arg12 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %8 = stablehlo.multiply %6, %7 : tensor<39x39xf32>
    %9 = stablehlo.convert %8 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %10 = stablehlo.custom_call @Sharding(%9) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %11 = stablehlo.reshape %10 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.reshape %arg5 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %14 = stablehlo.reshape %13 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %15 = stablehlo.convert %14 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %16 = stablehlo.broadcast_in_dim %15, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %17 = stablehlo.convert %arg4 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %18 = stablehlo.power %17, %5 : tensor<2x39x3584xf32>
    %19 = stablehlo.reduce(%18 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %20 = stablehlo.multiply %19, %4 : tensor<2x39xf32>
    %21 = stablehlo.reshape %20 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %22 = stablehlo.add %21, %3 : tensor<2x39x1xf32>
    %23 = stablehlo.rsqrt %22 : tensor<2x39x1xf32>
    %24 = stablehlo.reshape %23 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %25 = stablehlo.broadcast_in_dim %24, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %26 = stablehlo.multiply %17, %25 : tensor<2x39x3584xf32>
    %27 = stablehlo.convert %26 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %28 = stablehlo.convert %27 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %29 = stablehlo.multiply %16, %28 : tensor<2x39x3584xf32>
    %30 = stablehlo.convert %29 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %31 = stablehlo.reshape %30 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %32 = stablehlo.reshape %arg3 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %36 = stablehlo.reshape %35 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %37 = stablehlo.reshape %arg2 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %38 = stablehlo.reshape %37 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %39 = stablehlo.broadcast_in_dim %38, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %40 = stablehlo.add %36, %39 : tensor<2x39x512xbf16>
    %41 = stablehlo.reshape %40 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %42 = stablehlo.transpose %41, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %43 = stablehlo.convert %42 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %44 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.reshape %arg0 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
    %47 = stablehlo.convert %46 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
    %48 = stablehlo.dot_general %45, %47, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
    %49 = stablehlo.transpose %48, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
    %50 = stablehlo.concatenate %49, %49, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
    %51 = stablehlo.cosine %50 : tensor<1x39x128xf32>
    %52 = stablehlo.convert %51 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %53 = stablehlo.reshape %52 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %54 = stablehlo.convert %53 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %55 = stablehlo.reshape %54 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %56 = stablehlo.broadcast_in_dim %55, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %57 = stablehlo.multiply %43, %56 : tensor<2x4x39x128xf32>
    %58 = stablehlo.convert %57 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %59 = stablehlo.slice %42 [0:2, 0:4, 0:39, 64:128] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %60 = stablehlo.negate %59 : tensor<2x4x39x64xbf16>
    %61 = stablehlo.slice %42 [0:2, 0:4, 0:39, 0:64] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %62 = stablehlo.concatenate %60, %61, dim = 3 : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
    %63 = stablehlo.convert %62 : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %64 = stablehlo.sine %50 : tensor<1x39x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %66 = stablehlo.reshape %65 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %67 = stablehlo.convert %66 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %68 = stablehlo.reshape %67 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %69 = stablehlo.broadcast_in_dim %68, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %70 = stablehlo.multiply %63, %69 : tensor<2x4x39x128xf32>
    %71 = stablehlo.convert %70 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %72 = stablehlo.add %58, %71 : tensor<2x4x39x128xbf16>
    %73 = stablehlo.reshape %arg7 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %74 = stablehlo.reshape %73 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %76 = stablehlo.dot_general %31, %75, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %77 = stablehlo.reshape %76 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %78 = stablehlo.reshape %arg6 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %79 = stablehlo.reshape %78 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %80 = stablehlo.broadcast_in_dim %79, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %81 = stablehlo.add %77, %80 : tensor<2x39x512xbf16>
    %82 = stablehlo.reshape %81 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %83 = stablehlo.transpose %82, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %84 = stablehlo.reshape %arg18 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %85 = stablehlo.reshape %84 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %86 = stablehlo.convert %85 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %87 = stablehlo.broadcast_in_dim %86, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %88 = stablehlo.reshape %arg15 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %89 = stablehlo.reshape %88 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %90 = stablehlo.transpose %89, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %91 = stablehlo.dot_general %31, %90, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %92 = stablehlo.reshape %91 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %93 = stablehlo.reshape %arg14 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %94 = stablehlo.reshape %93 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %95 = stablehlo.broadcast_in_dim %94, dims = [2] : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
    %96 = stablehlo.add %92, %95 : tensor<2x39x3584xbf16>
    %97 = stablehlo.reshape %96 : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
    %98 = stablehlo.transpose %97, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
    %99 = stablehlo.convert %98 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %100 = stablehlo.broadcast_in_dim %55, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %101 = stablehlo.multiply %99, %100 : tensor<2x28x39x128xf32>
    %102 = stablehlo.convert %101 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %103 = stablehlo.slice %98 [0:2, 0:28, 0:39, 64:128] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %104 = stablehlo.negate %103 : tensor<2x28x39x64xbf16>
    %105 = stablehlo.slice %98 [0:2, 0:28, 0:39, 0:64] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %106 = stablehlo.concatenate %104, %105, dim = 3 : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
    %107 = stablehlo.convert %106 : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %108 = stablehlo.broadcast_in_dim %68, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %109 = stablehlo.multiply %107, %108 : tensor<2x28x39x128xf32>
    %110 = stablehlo.convert %109 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %111 = stablehlo.add %102, %110 : tensor<2x28x39x128xbf16>
    %112 = stablehlo.reshape %111 : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
    %113 = stablehlo.broadcast_in_dim %72, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %114 = stablehlo.reshape %113 : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %115 = stablehlo.transpose %114, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
    %116 = stablehlo.reshape %115 : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
    %117 = stablehlo.dot_general %112, %116, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
    %118 = stablehlo.reshape %117 : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %119 = stablehlo.convert %118 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %120 = stablehlo.multiply %119, %2 : tensor<2x28x39x39xf32>
    %121 = stablehlo.convert %120 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %122 = stablehlo.reshape %arg11 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %123 = stablehlo.convert %122 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %124 = stablehlo.reshape %123 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %125 = stablehlo.broadcast_in_dim %124, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %126 = stablehlo.add %12, %125 : tensor<2x1x39x39xbf16>
    %127 = stablehlo.compare  EQ, %126, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %128 = stablehlo.select %127, %0, %12 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    %129 = stablehlo.reshape %128 : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
    %130 = stablehlo.broadcast_in_dim %129, dims = [0, 2, 3] : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %131 = stablehlo.add %121, %130 : tensor<2x28x39x39xbf16>
    %132 = stablehlo.convert %131 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %133 = stablehlo.reduce(%132 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %134 = stablehlo.broadcast_in_dim %133, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %135 = stablehlo.subtract %132, %134 : tensor<2x28x39x39xf32>
    %136 = stablehlo.exponential %135 : tensor<2x28x39x39xf32>
    %137 = stablehlo.reduce(%136 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %138 = stablehlo.broadcast_in_dim %137, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %139 = stablehlo.divide %136, %138 : tensor<2x28x39x39xf32>
    %140 = stablehlo.convert %139 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %141 = stablehlo.reshape %140 : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
    %142 = stablehlo.broadcast_in_dim %83, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %143 = stablehlo.reshape %142 : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
    %144 = stablehlo.dot_general %141, %143, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
    %145 = stablehlo.reshape %144 : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %146 = stablehlo.transpose %145, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
    %147 = stablehlo.reshape %146 : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
    %148 = stablehlo.reshape %arg10 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %149 = stablehlo.reshape %148 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %150 = stablehlo.transpose %149, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %151 = stablehlo.dot_general %147, %150, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %152 = stablehlo.reshape %151 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %153 = stablehlo.add %arg4, %152 : tensor<2x39x3584xbf16>
    %154 = stablehlo.reshape %arg16 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %155 = stablehlo.reshape %154 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %156 = stablehlo.convert %155 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %157 = stablehlo.broadcast_in_dim %156, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %158 = stablehlo.convert %153 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %159 = stablehlo.power %158, %5 : tensor<2x39x3584xf32>
    %160 = stablehlo.reduce(%159 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %161 = stablehlo.multiply %160, %4 : tensor<2x39xf32>
    %162 = stablehlo.reshape %161 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %163 = stablehlo.add %162, %3 : tensor<2x39x1xf32>
    %164 = stablehlo.rsqrt %163 : tensor<2x39x1xf32>
    %165 = stablehlo.reshape %164 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %166 = stablehlo.broadcast_in_dim %165, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %167 = stablehlo.multiply %158, %166 : tensor<2x39x3584xf32>
    %168 = stablehlo.convert %167 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %169 = stablehlo.convert %168 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %170 = stablehlo.multiply %157, %169 : tensor<2x39x3584xf32>
    %171 = stablehlo.convert %170 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %172 = stablehlo.reshape %171 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %173 = stablehlo.reshape %arg17 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %174 = stablehlo.reshape %173 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %175 = stablehlo.transpose %174, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %176 = stablehlo.dot_general %172, %175, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %177 = stablehlo.reshape %176 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %178 = stablehlo.convert %177 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %179 = stablehlo.logistic %177 : tensor<2x39x18944xbf16>
    %180 = stablehlo.convert %179 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %181 = stablehlo.multiply %178, %180 : tensor<2x39x18944xf32>
    %182 = stablehlo.convert %181 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %183 = stablehlo.convert %182 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %184 = stablehlo.reshape %arg9 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %185 = stablehlo.reshape %184 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %186 = stablehlo.transpose %185, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %187 = stablehlo.dot_general %172, %186, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %188 = stablehlo.reshape %187 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %189 = stablehlo.convert %188 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %190 = stablehlo.multiply %183, %189 : tensor<2x39x18944xf32>
    %191 = stablehlo.convert %190 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %192 = stablehlo.reshape %191 : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
    %193 = stablehlo.reshape %arg8 : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
    %194 = stablehlo.reshape %193 : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
    %195 = stablehlo.transpose %194, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
    %196 = stablehlo.dot_general %192, %195, contracting_dims = [1] x [0] : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
    %197 = stablehlo.reshape %196 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %198 = stablehlo.add %153, %197 : tensor<2x39x3584xbf16>
    %199 = stablehlo.convert %198 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %200 = stablehlo.power %199, %5 : tensor<2x39x3584xf32>
    %201 = stablehlo.reduce(%200 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %202 = stablehlo.multiply %201, %4 : tensor<2x39xf32>
    %203 = stablehlo.reshape %202 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %204 = stablehlo.add %203, %3 : tensor<2x39x1xf32>
    %205 = stablehlo.rsqrt %204 : tensor<2x39x1xf32>
    %206 = stablehlo.reshape %205 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %207 = stablehlo.broadcast_in_dim %206, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %208 = stablehlo.multiply %199, %207 : tensor<2x39x3584xf32>
    %209 = stablehlo.convert %208 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %210 = stablehlo.convert %209 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %211 = stablehlo.multiply %87, %210 : tensor<2x39x3584xf32>
    %212 = stablehlo.convert %211 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    return %72, %83, %212 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


// -----// IR Dump After ApplyArgumentShardStatusPass (apply-argument-shard-status) ('builtin.module' operation: @SyncTensorsGraph.420) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg1: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___rotary_emb_inv_freq"}, %arg2: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, %arg3: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, %arg4: tensor<2x39x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg5: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, %arg6: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, %arg7: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, %arg8: tensor<3584x18944xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[2,4]<=[8]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, %arg9: tensor<18944x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, %arg10: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[2,4]<=[8]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, %arg11: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg12: tensor<39x39xi1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg13: tensor<39x39xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg14: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, %arg15: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, %arg16: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, %arg17: tensor<18944x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, %arg18: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___norm_weight"}) -> (tensor<2x4x39x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x4x39x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
    %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
    %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f32>) -> tensor<2x28x39x39xf32>
    %3 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
    %4 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
    %5 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<2x39x3584xf32>
    %6 = stablehlo.convert %arg13 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %7 = stablehlo.convert %arg12 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %8 = stablehlo.multiply %6, %7 : tensor<39x39xf32>
    %9 = stablehlo.convert %8 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %10 = stablehlo.custom_call @Sharding(%9) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %11 = stablehlo.reshape %10 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.reshape %arg5 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %14 = stablehlo.reshape %13 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %15 = stablehlo.convert %14 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %16 = stablehlo.broadcast_in_dim %15, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %17 = stablehlo.convert %arg4 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %18 = stablehlo.power %17, %5 : tensor<2x39x3584xf32>
    %19 = stablehlo.reduce(%18 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %20 = stablehlo.multiply %19, %4 : tensor<2x39xf32>
    %21 = stablehlo.reshape %20 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %22 = stablehlo.add %21, %3 : tensor<2x39x1xf32>
    %23 = stablehlo.rsqrt %22 : tensor<2x39x1xf32>
    %24 = stablehlo.reshape %23 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %25 = stablehlo.broadcast_in_dim %24, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %26 = stablehlo.multiply %17, %25 : tensor<2x39x3584xf32>
    %27 = stablehlo.convert %26 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %28 = stablehlo.convert %27 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %29 = stablehlo.multiply %16, %28 : tensor<2x39x3584xf32>
    %30 = stablehlo.convert %29 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %31 = stablehlo.reshape %30 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %32 = stablehlo.reshape %arg3 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %36 = stablehlo.reshape %35 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %37 = stablehlo.reshape %arg2 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %38 = stablehlo.reshape %37 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %39 = stablehlo.broadcast_in_dim %38, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %40 = stablehlo.add %36, %39 : tensor<2x39x512xbf16>
    %41 = stablehlo.reshape %40 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %42 = stablehlo.transpose %41, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %43 = stablehlo.convert %42 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %44 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.reshape %arg0 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
    %47 = stablehlo.convert %46 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
    %48 = stablehlo.dot_general %45, %47, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
    %49 = stablehlo.transpose %48, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
    %50 = stablehlo.concatenate %49, %49, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
    %51 = stablehlo.cosine %50 : tensor<1x39x128xf32>
    %52 = stablehlo.convert %51 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %53 = stablehlo.reshape %52 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %54 = stablehlo.convert %53 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %55 = stablehlo.reshape %54 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %56 = stablehlo.broadcast_in_dim %55, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %57 = stablehlo.multiply %43, %56 : tensor<2x4x39x128xf32>
    %58 = stablehlo.convert %57 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %59 = stablehlo.slice %42 [0:2, 0:4, 0:39, 64:128] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %60 = stablehlo.negate %59 : tensor<2x4x39x64xbf16>
    %61 = stablehlo.slice %42 [0:2, 0:4, 0:39, 0:64] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %62 = stablehlo.concatenate %60, %61, dim = 3 : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
    %63 = stablehlo.convert %62 : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %64 = stablehlo.sine %50 : tensor<1x39x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %66 = stablehlo.reshape %65 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %67 = stablehlo.convert %66 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %68 = stablehlo.reshape %67 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %69 = stablehlo.broadcast_in_dim %68, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %70 = stablehlo.multiply %63, %69 : tensor<2x4x39x128xf32>
    %71 = stablehlo.convert %70 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %72 = stablehlo.add %58, %71 : tensor<2x4x39x128xbf16>
    %73 = stablehlo.reshape %arg7 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %74 = stablehlo.reshape %73 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %76 = stablehlo.dot_general %31, %75, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %77 = stablehlo.reshape %76 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %78 = stablehlo.reshape %arg6 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %79 = stablehlo.reshape %78 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %80 = stablehlo.broadcast_in_dim %79, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %81 = stablehlo.add %77, %80 : tensor<2x39x512xbf16>
    %82 = stablehlo.reshape %81 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %83 = stablehlo.transpose %82, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %84 = stablehlo.reshape %arg18 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %85 = stablehlo.reshape %84 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %86 = stablehlo.convert %85 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %87 = stablehlo.broadcast_in_dim %86, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %88 = stablehlo.reshape %arg15 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %89 = stablehlo.reshape %88 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %90 = stablehlo.transpose %89, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %91 = stablehlo.dot_general %31, %90, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %92 = stablehlo.reshape %91 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %93 = stablehlo.reshape %arg14 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %94 = stablehlo.reshape %93 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %95 = stablehlo.broadcast_in_dim %94, dims = [2] : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
    %96 = stablehlo.add %92, %95 : tensor<2x39x3584xbf16>
    %97 = stablehlo.reshape %96 : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
    %98 = stablehlo.transpose %97, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
    %99 = stablehlo.convert %98 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %100 = stablehlo.broadcast_in_dim %55, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %101 = stablehlo.multiply %99, %100 : tensor<2x28x39x128xf32>
    %102 = stablehlo.convert %101 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %103 = stablehlo.slice %98 [0:2, 0:28, 0:39, 64:128] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %104 = stablehlo.negate %103 : tensor<2x28x39x64xbf16>
    %105 = stablehlo.slice %98 [0:2, 0:28, 0:39, 0:64] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %106 = stablehlo.concatenate %104, %105, dim = 3 : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
    %107 = stablehlo.convert %106 : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %108 = stablehlo.broadcast_in_dim %68, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %109 = stablehlo.multiply %107, %108 : tensor<2x28x39x128xf32>
    %110 = stablehlo.convert %109 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %111 = stablehlo.add %102, %110 : tensor<2x28x39x128xbf16>
    %112 = stablehlo.reshape %111 : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
    %113 = stablehlo.broadcast_in_dim %72, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %114 = stablehlo.reshape %113 : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %115 = stablehlo.transpose %114, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
    %116 = stablehlo.reshape %115 : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
    %117 = stablehlo.dot_general %112, %116, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
    %118 = stablehlo.reshape %117 : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %119 = stablehlo.convert %118 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %120 = stablehlo.multiply %119, %2 : tensor<2x28x39x39xf32>
    %121 = stablehlo.convert %120 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %122 = stablehlo.reshape %arg11 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %123 = stablehlo.convert %122 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %124 = stablehlo.reshape %123 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %125 = stablehlo.broadcast_in_dim %124, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %126 = stablehlo.add %12, %125 : tensor<2x1x39x39xbf16>
    %127 = stablehlo.compare  EQ, %126, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %128 = stablehlo.select %127, %0, %12 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    %129 = stablehlo.reshape %128 : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
    %130 = stablehlo.broadcast_in_dim %129, dims = [0, 2, 3] : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %131 = stablehlo.add %121, %130 : tensor<2x28x39x39xbf16>
    %132 = stablehlo.convert %131 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %133 = stablehlo.reduce(%132 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %134 = stablehlo.broadcast_in_dim %133, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %135 = stablehlo.subtract %132, %134 : tensor<2x28x39x39xf32>
    %136 = stablehlo.exponential %135 : tensor<2x28x39x39xf32>
    %137 = stablehlo.reduce(%136 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %138 = stablehlo.broadcast_in_dim %137, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %139 = stablehlo.divide %136, %138 : tensor<2x28x39x39xf32>
    %140 = stablehlo.convert %139 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %141 = stablehlo.reshape %140 : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
    %142 = stablehlo.broadcast_in_dim %83, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %143 = stablehlo.reshape %142 : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
    %144 = stablehlo.dot_general %141, %143, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
    %145 = stablehlo.reshape %144 : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %146 = stablehlo.transpose %145, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
    %147 = stablehlo.reshape %146 : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
    %148 = stablehlo.reshape %arg10 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %149 = stablehlo.reshape %148 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %150 = stablehlo.transpose %149, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %151 = stablehlo.dot_general %147, %150, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %152 = stablehlo.reshape %151 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %153 = stablehlo.add %arg4, %152 : tensor<2x39x3584xbf16>
    %154 = stablehlo.reshape %arg16 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %155 = stablehlo.reshape %154 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %156 = stablehlo.convert %155 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %157 = stablehlo.broadcast_in_dim %156, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %158 = stablehlo.convert %153 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %159 = stablehlo.power %158, %5 : tensor<2x39x3584xf32>
    %160 = stablehlo.reduce(%159 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %161 = stablehlo.multiply %160, %4 : tensor<2x39xf32>
    %162 = stablehlo.reshape %161 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %163 = stablehlo.add %162, %3 : tensor<2x39x1xf32>
    %164 = stablehlo.rsqrt %163 : tensor<2x39x1xf32>
    %165 = stablehlo.reshape %164 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %166 = stablehlo.broadcast_in_dim %165, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %167 = stablehlo.multiply %158, %166 : tensor<2x39x3584xf32>
    %168 = stablehlo.convert %167 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %169 = stablehlo.convert %168 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %170 = stablehlo.multiply %157, %169 : tensor<2x39x3584xf32>
    %171 = stablehlo.convert %170 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %172 = stablehlo.reshape %171 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %173 = stablehlo.reshape %arg17 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %174 = stablehlo.reshape %173 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %175 = stablehlo.transpose %174, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %176 = stablehlo.dot_general %172, %175, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %177 = stablehlo.reshape %176 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %178 = stablehlo.convert %177 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %179 = stablehlo.logistic %177 : tensor<2x39x18944xbf16>
    %180 = stablehlo.convert %179 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %181 = stablehlo.multiply %178, %180 : tensor<2x39x18944xf32>
    %182 = stablehlo.convert %181 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %183 = stablehlo.convert %182 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %184 = stablehlo.reshape %arg9 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %185 = stablehlo.reshape %184 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %186 = stablehlo.transpose %185, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %187 = stablehlo.dot_general %172, %186, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %188 = stablehlo.reshape %187 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %189 = stablehlo.convert %188 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %190 = stablehlo.multiply %183, %189 : tensor<2x39x18944xf32>
    %191 = stablehlo.convert %190 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %192 = stablehlo.reshape %191 : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
    %193 = stablehlo.reshape %arg8 : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
    %194 = stablehlo.reshape %193 : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
    %195 = stablehlo.transpose %194, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
    %196 = stablehlo.dot_general %192, %195, contracting_dims = [1] x [0] : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
    %197 = stablehlo.reshape %196 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %198 = stablehlo.add %153, %197 : tensor<2x39x3584xbf16>
    %199 = stablehlo.convert %198 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %200 = stablehlo.power %199, %5 : tensor<2x39x3584xf32>
    %201 = stablehlo.reduce(%200 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %202 = stablehlo.multiply %201, %4 : tensor<2x39xf32>
    %203 = stablehlo.reshape %202 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %204 = stablehlo.add %203, %3 : tensor<2x39x1xf32>
    %205 = stablehlo.rsqrt %204 : tensor<2x39x1xf32>
    %206 = stablehlo.reshape %205 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %207 = stablehlo.broadcast_in_dim %206, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %208 = stablehlo.multiply %199, %207 : tensor<2x39x3584xf32>
    %209 = stablehlo.convert %208 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %210 = stablehlo.convert %209 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %211 = stablehlo.multiply %87, %210 : tensor<2x39x3584xf32>
    %212 = stablehlo.convert %211 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    return %72, %83, %212 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


// -----// IR Dump Before ConvertXlaSdyToSdyPass (convert-xla-sdy-to-sdy) ('builtin.module' operation: @SyncTensorsGraph.420) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg1: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___rotary_emb_inv_freq"}, %arg2: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, %arg3: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, %arg4: tensor<2x39x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg5: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, %arg6: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, %arg7: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, %arg8: tensor<3584x18944xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[2,4]<=[8]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, %arg9: tensor<18944x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, %arg10: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[2,4]<=[8]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, %arg11: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg12: tensor<39x39xi1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg13: tensor<39x39xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg14: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, %arg15: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, %arg16: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, %arg17: tensor<18944x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[4,2]<=[2,4]T(1,0)}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, %arg18: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___norm_weight"}) -> (tensor<2x4x39x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x4x39x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
    %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
    %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f32>) -> tensor<2x28x39x39xf32>
    %3 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
    %4 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
    %5 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<2x39x3584xf32>
    %6 = stablehlo.convert %arg13 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %7 = stablehlo.convert %arg12 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %8 = stablehlo.multiply %6, %7 : tensor<39x39xf32>
    %9 = stablehlo.convert %8 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %10 = stablehlo.custom_call @Sharding(%9) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %11 = stablehlo.reshape %10 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.reshape %arg5 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %14 = stablehlo.reshape %13 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %15 = stablehlo.convert %14 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %16 = stablehlo.broadcast_in_dim %15, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %17 = stablehlo.convert %arg4 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %18 = stablehlo.power %17, %5 : tensor<2x39x3584xf32>
    %19 = stablehlo.reduce(%18 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %20 = stablehlo.multiply %19, %4 : tensor<2x39xf32>
    %21 = stablehlo.reshape %20 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %22 = stablehlo.add %21, %3 : tensor<2x39x1xf32>
    %23 = stablehlo.rsqrt %22 : tensor<2x39x1xf32>
    %24 = stablehlo.reshape %23 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %25 = stablehlo.broadcast_in_dim %24, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %26 = stablehlo.multiply %17, %25 : tensor<2x39x3584xf32>
    %27 = stablehlo.convert %26 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %28 = stablehlo.convert %27 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %29 = stablehlo.multiply %16, %28 : tensor<2x39x3584xf32>
    %30 = stablehlo.convert %29 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %31 = stablehlo.reshape %30 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %32 = stablehlo.reshape %arg3 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %36 = stablehlo.reshape %35 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %37 = stablehlo.reshape %arg2 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %38 = stablehlo.reshape %37 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %39 = stablehlo.broadcast_in_dim %38, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %40 = stablehlo.add %36, %39 : tensor<2x39x512xbf16>
    %41 = stablehlo.reshape %40 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %42 = stablehlo.transpose %41, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %43 = stablehlo.convert %42 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %44 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.reshape %arg0 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
    %47 = stablehlo.convert %46 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
    %48 = stablehlo.dot_general %45, %47, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
    %49 = stablehlo.transpose %48, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
    %50 = stablehlo.concatenate %49, %49, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
    %51 = stablehlo.cosine %50 : tensor<1x39x128xf32>
    %52 = stablehlo.convert %51 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %53 = stablehlo.reshape %52 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %54 = stablehlo.convert %53 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %55 = stablehlo.reshape %54 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %56 = stablehlo.broadcast_in_dim %55, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %57 = stablehlo.multiply %43, %56 : tensor<2x4x39x128xf32>
    %58 = stablehlo.convert %57 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %59 = stablehlo.slice %42 [0:2, 0:4, 0:39, 64:128] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %60 = stablehlo.negate %59 : tensor<2x4x39x64xbf16>
    %61 = stablehlo.slice %42 [0:2, 0:4, 0:39, 0:64] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %62 = stablehlo.concatenate %60, %61, dim = 3 : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
    %63 = stablehlo.convert %62 : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %64 = stablehlo.sine %50 : tensor<1x39x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %66 = stablehlo.reshape %65 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %67 = stablehlo.convert %66 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %68 = stablehlo.reshape %67 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %69 = stablehlo.broadcast_in_dim %68, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %70 = stablehlo.multiply %63, %69 : tensor<2x4x39x128xf32>
    %71 = stablehlo.convert %70 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %72 = stablehlo.add %58, %71 : tensor<2x4x39x128xbf16>
    %73 = stablehlo.reshape %arg7 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %74 = stablehlo.reshape %73 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %76 = stablehlo.dot_general %31, %75, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %77 = stablehlo.reshape %76 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %78 = stablehlo.reshape %arg6 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %79 = stablehlo.reshape %78 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %80 = stablehlo.broadcast_in_dim %79, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %81 = stablehlo.add %77, %80 : tensor<2x39x512xbf16>
    %82 = stablehlo.reshape %81 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %83 = stablehlo.transpose %82, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %84 = stablehlo.reshape %arg18 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %85 = stablehlo.reshape %84 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %86 = stablehlo.convert %85 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %87 = stablehlo.broadcast_in_dim %86, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %88 = stablehlo.reshape %arg15 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %89 = stablehlo.reshape %88 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %90 = stablehlo.transpose %89, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %91 = stablehlo.dot_general %31, %90, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %92 = stablehlo.reshape %91 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %93 = stablehlo.reshape %arg14 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %94 = stablehlo.reshape %93 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %95 = stablehlo.broadcast_in_dim %94, dims = [2] : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
    %96 = stablehlo.add %92, %95 : tensor<2x39x3584xbf16>
    %97 = stablehlo.reshape %96 : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
    %98 = stablehlo.transpose %97, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
    %99 = stablehlo.convert %98 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %100 = stablehlo.broadcast_in_dim %55, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %101 = stablehlo.multiply %99, %100 : tensor<2x28x39x128xf32>
    %102 = stablehlo.convert %101 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %103 = stablehlo.slice %98 [0:2, 0:28, 0:39, 64:128] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %104 = stablehlo.negate %103 : tensor<2x28x39x64xbf16>
    %105 = stablehlo.slice %98 [0:2, 0:28, 0:39, 0:64] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %106 = stablehlo.concatenate %104, %105, dim = 3 : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
    %107 = stablehlo.convert %106 : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %108 = stablehlo.broadcast_in_dim %68, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %109 = stablehlo.multiply %107, %108 : tensor<2x28x39x128xf32>
    %110 = stablehlo.convert %109 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %111 = stablehlo.add %102, %110 : tensor<2x28x39x128xbf16>
    %112 = stablehlo.reshape %111 : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
    %113 = stablehlo.broadcast_in_dim %72, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %114 = stablehlo.reshape %113 : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %115 = stablehlo.transpose %114, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
    %116 = stablehlo.reshape %115 : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
    %117 = stablehlo.dot_general %112, %116, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
    %118 = stablehlo.reshape %117 : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %119 = stablehlo.convert %118 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %120 = stablehlo.multiply %119, %2 : tensor<2x28x39x39xf32>
    %121 = stablehlo.convert %120 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %122 = stablehlo.reshape %arg11 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %123 = stablehlo.convert %122 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %124 = stablehlo.reshape %123 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %125 = stablehlo.broadcast_in_dim %124, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %126 = stablehlo.add %12, %125 : tensor<2x1x39x39xbf16>
    %127 = stablehlo.compare  EQ, %126, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %128 = stablehlo.select %127, %0, %12 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    %129 = stablehlo.reshape %128 : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
    %130 = stablehlo.broadcast_in_dim %129, dims = [0, 2, 3] : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %131 = stablehlo.add %121, %130 : tensor<2x28x39x39xbf16>
    %132 = stablehlo.convert %131 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %133 = stablehlo.reduce(%132 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %134 = stablehlo.broadcast_in_dim %133, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %135 = stablehlo.subtract %132, %134 : tensor<2x28x39x39xf32>
    %136 = stablehlo.exponential %135 : tensor<2x28x39x39xf32>
    %137 = stablehlo.reduce(%136 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %138 = stablehlo.broadcast_in_dim %137, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %139 = stablehlo.divide %136, %138 : tensor<2x28x39x39xf32>
    %140 = stablehlo.convert %139 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %141 = stablehlo.reshape %140 : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
    %142 = stablehlo.broadcast_in_dim %83, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %143 = stablehlo.reshape %142 : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
    %144 = stablehlo.dot_general %141, %143, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
    %145 = stablehlo.reshape %144 : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %146 = stablehlo.transpose %145, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
    %147 = stablehlo.reshape %146 : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
    %148 = stablehlo.reshape %arg10 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %149 = stablehlo.reshape %148 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %150 = stablehlo.transpose %149, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %151 = stablehlo.dot_general %147, %150, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %152 = stablehlo.reshape %151 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %153 = stablehlo.add %arg4, %152 : tensor<2x39x3584xbf16>
    %154 = stablehlo.reshape %arg16 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %155 = stablehlo.reshape %154 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %156 = stablehlo.convert %155 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %157 = stablehlo.broadcast_in_dim %156, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %158 = stablehlo.convert %153 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %159 = stablehlo.power %158, %5 : tensor<2x39x3584xf32>
    %160 = stablehlo.reduce(%159 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %161 = stablehlo.multiply %160, %4 : tensor<2x39xf32>
    %162 = stablehlo.reshape %161 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %163 = stablehlo.add %162, %3 : tensor<2x39x1xf32>
    %164 = stablehlo.rsqrt %163 : tensor<2x39x1xf32>
    %165 = stablehlo.reshape %164 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %166 = stablehlo.broadcast_in_dim %165, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %167 = stablehlo.multiply %158, %166 : tensor<2x39x3584xf32>
    %168 = stablehlo.convert %167 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %169 = stablehlo.convert %168 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %170 = stablehlo.multiply %157, %169 : tensor<2x39x3584xf32>
    %171 = stablehlo.convert %170 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %172 = stablehlo.reshape %171 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %173 = stablehlo.reshape %arg17 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %174 = stablehlo.reshape %173 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %175 = stablehlo.transpose %174, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %176 = stablehlo.dot_general %172, %175, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %177 = stablehlo.reshape %176 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %178 = stablehlo.convert %177 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %179 = stablehlo.logistic %177 : tensor<2x39x18944xbf16>
    %180 = stablehlo.convert %179 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %181 = stablehlo.multiply %178, %180 : tensor<2x39x18944xf32>
    %182 = stablehlo.convert %181 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %183 = stablehlo.convert %182 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %184 = stablehlo.reshape %arg9 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %185 = stablehlo.reshape %184 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %186 = stablehlo.transpose %185, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %187 = stablehlo.dot_general %172, %186, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %188 = stablehlo.reshape %187 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %189 = stablehlo.convert %188 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %190 = stablehlo.multiply %183, %189 : tensor<2x39x18944xf32>
    %191 = stablehlo.convert %190 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %192 = stablehlo.reshape %191 : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
    %193 = stablehlo.reshape %arg8 : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
    %194 = stablehlo.reshape %193 : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
    %195 = stablehlo.transpose %194, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
    %196 = stablehlo.dot_general %192, %195, contracting_dims = [1] x [0] : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
    %197 = stablehlo.reshape %196 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %198 = stablehlo.add %153, %197 : tensor<2x39x3584xbf16>
    %199 = stablehlo.convert %198 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %200 = stablehlo.power %199, %5 : tensor<2x39x3584xf32>
    %201 = stablehlo.reduce(%200 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %202 = stablehlo.multiply %201, %4 : tensor<2x39xf32>
    %203 = stablehlo.reshape %202 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %204 = stablehlo.add %203, %3 : tensor<2x39x1xf32>
    %205 = stablehlo.rsqrt %204 : tensor<2x39x1xf32>
    %206 = stablehlo.reshape %205 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %207 = stablehlo.broadcast_in_dim %206, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %208 = stablehlo.multiply %199, %207 : tensor<2x39x3584xf32>
    %209 = stablehlo.convert %208 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %210 = stablehlo.convert %209 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %211 = stablehlo.multiply %87, %210 : tensor<2x39x3584xf32>
    %212 = stablehlo.convert %211 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    return %72, %83, %212 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


// -----// IR Dump After ConvertXlaSdyToSdyPass (convert-xla-sdy-to-sdy) ('builtin.module' operation: @SyncTensorsGraph.420) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___rotary_emb_inv_freq"}, %arg2: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, %arg3: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, %arg4: tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg5: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, %arg6: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, %arg7: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, %arg8: tensor<3584x18944xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, %arg9: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, %arg10: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, %arg11: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg12: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg13: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg14: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, %arg15: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, %arg16: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, %arg17: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, %arg18: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___norm_weight"}) -> (tensor<2x4x39x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x4x39x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
    %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
    %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f32>) -> tensor<2x28x39x39xf32>
    %3 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
    %4 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
    %5 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<2x39x3584xf32>
    %6 = stablehlo.convert %arg13 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %7 = stablehlo.convert %arg12 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %8 = stablehlo.multiply %6, %7 : tensor<39x39xf32>
    %9 = stablehlo.convert %8 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %10 = stablehlo.custom_call @Sharding(%9) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %11 = sdy.sharding_constraint %9 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
    %12 = stablehlo.reshape %11 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %13 = stablehlo.broadcast_in_dim %12, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %14 = stablehlo.reshape %arg5 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %15 = stablehlo.reshape %14 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %16 = stablehlo.convert %15 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %18 = stablehlo.convert %arg4 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %19 = stablehlo.power %18, %5 : tensor<2x39x3584xf32>
    %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %21 = stablehlo.multiply %20, %4 : tensor<2x39xf32>
    %22 = stablehlo.reshape %21 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %23 = stablehlo.add %22, %3 : tensor<2x39x1xf32>
    %24 = stablehlo.rsqrt %23 : tensor<2x39x1xf32>
    %25 = stablehlo.reshape %24 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %26 = stablehlo.broadcast_in_dim %25, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %27 = stablehlo.multiply %18, %26 : tensor<2x39x3584xf32>
    %28 = stablehlo.convert %27 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %29 = stablehlo.convert %28 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %30 = stablehlo.multiply %17, %29 : tensor<2x39x3584xf32>
    %31 = stablehlo.convert %30 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %32 = stablehlo.reshape %31 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %33 = stablehlo.reshape %arg3 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %34 = stablehlo.reshape %33 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %35 = stablehlo.transpose %34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %36 = stablehlo.dot_general %32, %35, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %37 = stablehlo.reshape %36 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %38 = stablehlo.reshape %arg2 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %39 = stablehlo.reshape %38 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %40 = stablehlo.broadcast_in_dim %39, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %41 = stablehlo.add %37, %40 : tensor<2x39x512xbf16>
    %42 = stablehlo.reshape %41 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %43 = stablehlo.transpose %42, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %44 = stablehlo.convert %43 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %45 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %46 = stablehlo.reshape %45 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %47 = stablehlo.reshape %arg0 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
    %48 = stablehlo.convert %47 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
    %49 = stablehlo.dot_general %46, %48, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
    %50 = stablehlo.transpose %49, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
    %51 = stablehlo.concatenate %50, %50, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
    %52 = stablehlo.cosine %51 : tensor<1x39x128xf32>
    %53 = stablehlo.convert %52 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %54 = stablehlo.reshape %53 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %55 = stablehlo.convert %54 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %56 = stablehlo.reshape %55 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %57 = stablehlo.broadcast_in_dim %56, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %58 = stablehlo.multiply %44, %57 : tensor<2x4x39x128xf32>
    %59 = stablehlo.convert %58 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %60 = stablehlo.slice %43 [0:2, 0:4, 0:39, 64:128] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %61 = stablehlo.negate %60 : tensor<2x4x39x64xbf16>
    %62 = stablehlo.slice %43 [0:2, 0:4, 0:39, 0:64] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %63 = stablehlo.concatenate %61, %62, dim = 3 : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
    %64 = stablehlo.convert %63 : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %65 = stablehlo.sine %51 : tensor<1x39x128xf32>
    %66 = stablehlo.convert %65 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %67 = stablehlo.reshape %66 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %68 = stablehlo.convert %67 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %69 = stablehlo.reshape %68 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %70 = stablehlo.broadcast_in_dim %69, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %71 = stablehlo.multiply %64, %70 : tensor<2x4x39x128xf32>
    %72 = stablehlo.convert %71 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %73 = stablehlo.add %59, %72 : tensor<2x4x39x128xbf16>
    %74 = stablehlo.reshape %arg7 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %75 = stablehlo.reshape %74 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %76 = stablehlo.transpose %75, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %77 = stablehlo.dot_general %32, %76, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %78 = stablehlo.reshape %77 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %79 = stablehlo.reshape %arg6 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %80 = stablehlo.reshape %79 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %81 = stablehlo.broadcast_in_dim %80, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %82 = stablehlo.add %78, %81 : tensor<2x39x512xbf16>
    %83 = stablehlo.reshape %82 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %84 = stablehlo.transpose %83, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %85 = stablehlo.reshape %arg18 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %86 = stablehlo.reshape %85 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %87 = stablehlo.convert %86 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %88 = stablehlo.broadcast_in_dim %87, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %89 = stablehlo.reshape %arg15 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %90 = stablehlo.reshape %89 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %91 = stablehlo.transpose %90, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %92 = stablehlo.dot_general %32, %91, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %93 = stablehlo.reshape %92 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %94 = stablehlo.reshape %arg14 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %95 = stablehlo.reshape %94 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %96 = stablehlo.broadcast_in_dim %95, dims = [2] : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
    %97 = stablehlo.add %93, %96 : tensor<2x39x3584xbf16>
    %98 = stablehlo.reshape %97 : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
    %99 = stablehlo.transpose %98, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
    %100 = stablehlo.convert %99 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %101 = stablehlo.broadcast_in_dim %56, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %102 = stablehlo.multiply %100, %101 : tensor<2x28x39x128xf32>
    %103 = stablehlo.convert %102 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %104 = stablehlo.slice %99 [0:2, 0:28, 0:39, 64:128] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %105 = stablehlo.negate %104 : tensor<2x28x39x64xbf16>
    %106 = stablehlo.slice %99 [0:2, 0:28, 0:39, 0:64] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %107 = stablehlo.concatenate %105, %106, dim = 3 : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
    %108 = stablehlo.convert %107 : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %109 = stablehlo.broadcast_in_dim %69, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %110 = stablehlo.multiply %108, %109 : tensor<2x28x39x128xf32>
    %111 = stablehlo.convert %110 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %112 = stablehlo.add %103, %111 : tensor<2x28x39x128xbf16>
    %113 = stablehlo.reshape %112 : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
    %114 = stablehlo.broadcast_in_dim %73, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %115 = stablehlo.reshape %114 : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %116 = stablehlo.transpose %115, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
    %117 = stablehlo.reshape %116 : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
    %118 = stablehlo.dot_general %113, %117, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
    %119 = stablehlo.reshape %118 : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %120 = stablehlo.convert %119 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %121 = stablehlo.multiply %120, %2 : tensor<2x28x39x39xf32>
    %122 = stablehlo.convert %121 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %123 = stablehlo.reshape %arg11 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %124 = stablehlo.convert %123 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %125 = stablehlo.reshape %124 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %126 = stablehlo.broadcast_in_dim %125, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %127 = stablehlo.add %13, %126 : tensor<2x1x39x39xbf16>
    %128 = stablehlo.compare  EQ, %127, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %129 = stablehlo.select %128, %0, %13 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    %130 = stablehlo.reshape %129 : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
    %131 = stablehlo.broadcast_in_dim %130, dims = [0, 2, 3] : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %132 = stablehlo.add %122, %131 : tensor<2x28x39x39xbf16>
    %133 = stablehlo.convert %132 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %134 = stablehlo.reduce(%133 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %136 = stablehlo.subtract %133, %135 : tensor<2x28x39x39xf32>
    %137 = stablehlo.exponential %136 : tensor<2x28x39x39xf32>
    %138 = stablehlo.reduce(%137 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %139 = stablehlo.broadcast_in_dim %138, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %140 = stablehlo.divide %137, %139 : tensor<2x28x39x39xf32>
    %141 = stablehlo.convert %140 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %142 = stablehlo.reshape %141 : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
    %143 = stablehlo.broadcast_in_dim %84, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %144 = stablehlo.reshape %143 : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
    %145 = stablehlo.dot_general %142, %144, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
    %146 = stablehlo.reshape %145 : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %147 = stablehlo.transpose %146, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
    %148 = stablehlo.reshape %147 : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
    %149 = stablehlo.reshape %arg10 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %150 = stablehlo.reshape %149 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %151 = stablehlo.transpose %150, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %152 = stablehlo.dot_general %148, %151, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %153 = stablehlo.reshape %152 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %154 = stablehlo.add %arg4, %153 : tensor<2x39x3584xbf16>
    %155 = stablehlo.reshape %arg16 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %156 = stablehlo.reshape %155 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %157 = stablehlo.convert %156 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %158 = stablehlo.broadcast_in_dim %157, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %159 = stablehlo.convert %154 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %160 = stablehlo.power %159, %5 : tensor<2x39x3584xf32>
    %161 = stablehlo.reduce(%160 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %162 = stablehlo.multiply %161, %4 : tensor<2x39xf32>
    %163 = stablehlo.reshape %162 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %164 = stablehlo.add %163, %3 : tensor<2x39x1xf32>
    %165 = stablehlo.rsqrt %164 : tensor<2x39x1xf32>
    %166 = stablehlo.reshape %165 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %167 = stablehlo.broadcast_in_dim %166, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %168 = stablehlo.multiply %159, %167 : tensor<2x39x3584xf32>
    %169 = stablehlo.convert %168 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %170 = stablehlo.convert %169 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %171 = stablehlo.multiply %158, %170 : tensor<2x39x3584xf32>
    %172 = stablehlo.convert %171 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %173 = stablehlo.reshape %172 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %174 = stablehlo.reshape %arg17 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %175 = stablehlo.reshape %174 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %176 = stablehlo.transpose %175, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %177 = stablehlo.dot_general %173, %176, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %178 = stablehlo.reshape %177 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %179 = stablehlo.convert %178 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %180 = stablehlo.logistic %178 : tensor<2x39x18944xbf16>
    %181 = stablehlo.convert %180 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %182 = stablehlo.multiply %179, %181 : tensor<2x39x18944xf32>
    %183 = stablehlo.convert %182 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %184 = stablehlo.convert %183 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %185 = stablehlo.reshape %arg9 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %186 = stablehlo.reshape %185 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %187 = stablehlo.transpose %186, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %188 = stablehlo.dot_general %173, %187, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %189 = stablehlo.reshape %188 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %190 = stablehlo.convert %189 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %191 = stablehlo.multiply %184, %190 : tensor<2x39x18944xf32>
    %192 = stablehlo.convert %191 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %193 = stablehlo.reshape %192 : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
    %194 = stablehlo.reshape %arg8 : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
    %195 = stablehlo.reshape %194 : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
    %196 = stablehlo.transpose %195, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
    %197 = stablehlo.dot_general %193, %196, contracting_dims = [1] x [0] : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
    %198 = stablehlo.reshape %197 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %199 = stablehlo.add %154, %198 : tensor<2x39x3584xbf16>
    %200 = stablehlo.convert %199 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %201 = stablehlo.power %200, %5 : tensor<2x39x3584xf32>
    %202 = stablehlo.reduce(%201 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %203 = stablehlo.multiply %202, %4 : tensor<2x39xf32>
    %204 = stablehlo.reshape %203 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %205 = stablehlo.add %204, %3 : tensor<2x39x1xf32>
    %206 = stablehlo.rsqrt %205 : tensor<2x39x1xf32>
    %207 = stablehlo.reshape %206 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %208 = stablehlo.broadcast_in_dim %207, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %209 = stablehlo.multiply %200, %208 : tensor<2x39x3584xf32>
    %210 = stablehlo.convert %209 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %211 = stablehlo.convert %210 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %212 = stablehlo.multiply %88, %211 : tensor<2x39x3584xf32>
    %213 = stablehlo.convert %212 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    return %73, %84, %213 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


// -----// IR Dump Before AnalyzeMeshPass (analyze-mesh) ('builtin.module' operation: @SyncTensorsGraph.420) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___rotary_emb_inv_freq"}, %arg2: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, %arg3: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, %arg4: tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg5: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, %arg6: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, %arg7: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, %arg8: tensor<3584x18944xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, %arg9: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, %arg10: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, %arg11: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg12: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg13: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg14: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, %arg15: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, %arg16: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, %arg17: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, %arg18: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___norm_weight"}) -> (tensor<2x4x39x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x4x39x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
    %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
    %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f32>) -> tensor<2x28x39x39xf32>
    %3 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
    %4 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
    %5 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<2x39x3584xf32>
    %6 = stablehlo.convert %arg13 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %7 = stablehlo.convert %arg12 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %8 = stablehlo.multiply %6, %7 : tensor<39x39xf32>
    %9 = stablehlo.convert %8 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %10 = stablehlo.custom_call @Sharding(%9) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %11 = sdy.sharding_constraint %9 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
    %12 = stablehlo.reshape %11 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %13 = stablehlo.broadcast_in_dim %12, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %14 = stablehlo.reshape %arg5 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %15 = stablehlo.reshape %14 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %16 = stablehlo.convert %15 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %18 = stablehlo.convert %arg4 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %19 = stablehlo.power %18, %5 : tensor<2x39x3584xf32>
    %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %21 = stablehlo.multiply %20, %4 : tensor<2x39xf32>
    %22 = stablehlo.reshape %21 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %23 = stablehlo.add %22, %3 : tensor<2x39x1xf32>
    %24 = stablehlo.rsqrt %23 : tensor<2x39x1xf32>
    %25 = stablehlo.reshape %24 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %26 = stablehlo.broadcast_in_dim %25, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %27 = stablehlo.multiply %18, %26 : tensor<2x39x3584xf32>
    %28 = stablehlo.convert %27 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %29 = stablehlo.convert %28 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %30 = stablehlo.multiply %17, %29 : tensor<2x39x3584xf32>
    %31 = stablehlo.convert %30 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %32 = stablehlo.reshape %31 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %33 = stablehlo.reshape %arg3 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %34 = stablehlo.reshape %33 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %35 = stablehlo.transpose %34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %36 = stablehlo.dot_general %32, %35, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %37 = stablehlo.reshape %36 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %38 = stablehlo.reshape %arg2 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %39 = stablehlo.reshape %38 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %40 = stablehlo.broadcast_in_dim %39, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %41 = stablehlo.add %37, %40 : tensor<2x39x512xbf16>
    %42 = stablehlo.reshape %41 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %43 = stablehlo.transpose %42, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %44 = stablehlo.convert %43 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %45 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %46 = stablehlo.reshape %45 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %47 = stablehlo.reshape %arg0 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
    %48 = stablehlo.convert %47 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
    %49 = stablehlo.dot_general %46, %48, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
    %50 = stablehlo.transpose %49, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
    %51 = stablehlo.concatenate %50, %50, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
    %52 = stablehlo.cosine %51 : tensor<1x39x128xf32>
    %53 = stablehlo.convert %52 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %54 = stablehlo.reshape %53 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %55 = stablehlo.convert %54 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %56 = stablehlo.reshape %55 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %57 = stablehlo.broadcast_in_dim %56, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %58 = stablehlo.multiply %44, %57 : tensor<2x4x39x128xf32>
    %59 = stablehlo.convert %58 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %60 = stablehlo.slice %43 [0:2, 0:4, 0:39, 64:128] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %61 = stablehlo.negate %60 : tensor<2x4x39x64xbf16>
    %62 = stablehlo.slice %43 [0:2, 0:4, 0:39, 0:64] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %63 = stablehlo.concatenate %61, %62, dim = 3 : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
    %64 = stablehlo.convert %63 : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %65 = stablehlo.sine %51 : tensor<1x39x128xf32>
    %66 = stablehlo.convert %65 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %67 = stablehlo.reshape %66 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %68 = stablehlo.convert %67 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %69 = stablehlo.reshape %68 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %70 = stablehlo.broadcast_in_dim %69, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %71 = stablehlo.multiply %64, %70 : tensor<2x4x39x128xf32>
    %72 = stablehlo.convert %71 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %73 = stablehlo.add %59, %72 : tensor<2x4x39x128xbf16>
    %74 = stablehlo.reshape %arg7 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %75 = stablehlo.reshape %74 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %76 = stablehlo.transpose %75, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %77 = stablehlo.dot_general %32, %76, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %78 = stablehlo.reshape %77 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %79 = stablehlo.reshape %arg6 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %80 = stablehlo.reshape %79 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %81 = stablehlo.broadcast_in_dim %80, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %82 = stablehlo.add %78, %81 : tensor<2x39x512xbf16>
    %83 = stablehlo.reshape %82 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %84 = stablehlo.transpose %83, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %85 = stablehlo.reshape %arg18 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %86 = stablehlo.reshape %85 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %87 = stablehlo.convert %86 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %88 = stablehlo.broadcast_in_dim %87, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %89 = stablehlo.reshape %arg15 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %90 = stablehlo.reshape %89 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %91 = stablehlo.transpose %90, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %92 = stablehlo.dot_general %32, %91, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %93 = stablehlo.reshape %92 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %94 = stablehlo.reshape %arg14 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %95 = stablehlo.reshape %94 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %96 = stablehlo.broadcast_in_dim %95, dims = [2] : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
    %97 = stablehlo.add %93, %96 : tensor<2x39x3584xbf16>
    %98 = stablehlo.reshape %97 : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
    %99 = stablehlo.transpose %98, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
    %100 = stablehlo.convert %99 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %101 = stablehlo.broadcast_in_dim %56, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %102 = stablehlo.multiply %100, %101 : tensor<2x28x39x128xf32>
    %103 = stablehlo.convert %102 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %104 = stablehlo.slice %99 [0:2, 0:28, 0:39, 64:128] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %105 = stablehlo.negate %104 : tensor<2x28x39x64xbf16>
    %106 = stablehlo.slice %99 [0:2, 0:28, 0:39, 0:64] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %107 = stablehlo.concatenate %105, %106, dim = 3 : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
    %108 = stablehlo.convert %107 : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %109 = stablehlo.broadcast_in_dim %69, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %110 = stablehlo.multiply %108, %109 : tensor<2x28x39x128xf32>
    %111 = stablehlo.convert %110 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %112 = stablehlo.add %103, %111 : tensor<2x28x39x128xbf16>
    %113 = stablehlo.reshape %112 : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
    %114 = stablehlo.broadcast_in_dim %73, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %115 = stablehlo.reshape %114 : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %116 = stablehlo.transpose %115, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
    %117 = stablehlo.reshape %116 : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
    %118 = stablehlo.dot_general %113, %117, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
    %119 = stablehlo.reshape %118 : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %120 = stablehlo.convert %119 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %121 = stablehlo.multiply %120, %2 : tensor<2x28x39x39xf32>
    %122 = stablehlo.convert %121 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %123 = stablehlo.reshape %arg11 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %124 = stablehlo.convert %123 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %125 = stablehlo.reshape %124 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %126 = stablehlo.broadcast_in_dim %125, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %127 = stablehlo.add %13, %126 : tensor<2x1x39x39xbf16>
    %128 = stablehlo.compare  EQ, %127, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %129 = stablehlo.select %128, %0, %13 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    %130 = stablehlo.reshape %129 : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
    %131 = stablehlo.broadcast_in_dim %130, dims = [0, 2, 3] : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %132 = stablehlo.add %122, %131 : tensor<2x28x39x39xbf16>
    %133 = stablehlo.convert %132 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %134 = stablehlo.reduce(%133 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %136 = stablehlo.subtract %133, %135 : tensor<2x28x39x39xf32>
    %137 = stablehlo.exponential %136 : tensor<2x28x39x39xf32>
    %138 = stablehlo.reduce(%137 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %139 = stablehlo.broadcast_in_dim %138, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %140 = stablehlo.divide %137, %139 : tensor<2x28x39x39xf32>
    %141 = stablehlo.convert %140 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %142 = stablehlo.reshape %141 : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
    %143 = stablehlo.broadcast_in_dim %84, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %144 = stablehlo.reshape %143 : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
    %145 = stablehlo.dot_general %142, %144, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
    %146 = stablehlo.reshape %145 : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %147 = stablehlo.transpose %146, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
    %148 = stablehlo.reshape %147 : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
    %149 = stablehlo.reshape %arg10 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %150 = stablehlo.reshape %149 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %151 = stablehlo.transpose %150, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %152 = stablehlo.dot_general %148, %151, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %153 = stablehlo.reshape %152 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %154 = stablehlo.add %arg4, %153 : tensor<2x39x3584xbf16>
    %155 = stablehlo.reshape %arg16 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %156 = stablehlo.reshape %155 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %157 = stablehlo.convert %156 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %158 = stablehlo.broadcast_in_dim %157, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %159 = stablehlo.convert %154 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %160 = stablehlo.power %159, %5 : tensor<2x39x3584xf32>
    %161 = stablehlo.reduce(%160 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %162 = stablehlo.multiply %161, %4 : tensor<2x39xf32>
    %163 = stablehlo.reshape %162 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %164 = stablehlo.add %163, %3 : tensor<2x39x1xf32>
    %165 = stablehlo.rsqrt %164 : tensor<2x39x1xf32>
    %166 = stablehlo.reshape %165 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %167 = stablehlo.broadcast_in_dim %166, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %168 = stablehlo.multiply %159, %167 : tensor<2x39x3584xf32>
    %169 = stablehlo.convert %168 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %170 = stablehlo.convert %169 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %171 = stablehlo.multiply %158, %170 : tensor<2x39x3584xf32>
    %172 = stablehlo.convert %171 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %173 = stablehlo.reshape %172 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %174 = stablehlo.reshape %arg17 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %175 = stablehlo.reshape %174 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %176 = stablehlo.transpose %175, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %177 = stablehlo.dot_general %173, %176, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %178 = stablehlo.reshape %177 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %179 = stablehlo.convert %178 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %180 = stablehlo.logistic %178 : tensor<2x39x18944xbf16>
    %181 = stablehlo.convert %180 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %182 = stablehlo.multiply %179, %181 : tensor<2x39x18944xf32>
    %183 = stablehlo.convert %182 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %184 = stablehlo.convert %183 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %185 = stablehlo.reshape %arg9 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %186 = stablehlo.reshape %185 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %187 = stablehlo.transpose %186, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %188 = stablehlo.dot_general %173, %187, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %189 = stablehlo.reshape %188 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %190 = stablehlo.convert %189 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %191 = stablehlo.multiply %184, %190 : tensor<2x39x18944xf32>
    %192 = stablehlo.convert %191 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %193 = stablehlo.reshape %192 : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
    %194 = stablehlo.reshape %arg8 : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
    %195 = stablehlo.reshape %194 : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
    %196 = stablehlo.transpose %195, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
    %197 = stablehlo.dot_general %193, %196, contracting_dims = [1] x [0] : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
    %198 = stablehlo.reshape %197 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %199 = stablehlo.add %154, %198 : tensor<2x39x3584xbf16>
    %200 = stablehlo.convert %199 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %201 = stablehlo.power %200, %5 : tensor<2x39x3584xf32>
    %202 = stablehlo.reduce(%201 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %203 = stablehlo.multiply %202, %4 : tensor<2x39xf32>
    %204 = stablehlo.reshape %203 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %205 = stablehlo.add %204, %3 : tensor<2x39x1xf32>
    %206 = stablehlo.rsqrt %205 : tensor<2x39x1xf32>
    %207 = stablehlo.reshape %206 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %208 = stablehlo.broadcast_in_dim %207, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %209 = stablehlo.multiply %200, %208 : tensor<2x39x3584xf32>
    %210 = stablehlo.convert %209 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %211 = stablehlo.convert %210 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %212 = stablehlo.multiply %88, %211 : tensor<2x39x3584xf32>
    %213 = stablehlo.convert %212 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    return %73, %84, %213 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


// -----// IR Dump Before ApplyShardingConstraintsPass (sdy-apply-sharding-constraints) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___rotary_emb_inv_freq"}, %arg2: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, %arg3: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, %arg4: tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg5: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, %arg6: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, %arg7: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, %arg8: tensor<3584x18944xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, %arg9: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, %arg10: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, %arg11: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg12: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg13: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg14: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, %arg15: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, %arg16: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, %arg17: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, %arg18: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___norm_weight"}) -> (tensor<2x4x39x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x4x39x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
    %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
    %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f32>) -> tensor<2x28x39x39xf32>
    %3 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
    %4 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
    %5 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<2x39x3584xf32>
    %6 = stablehlo.convert %arg13 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %7 = stablehlo.convert %arg12 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %8 = stablehlo.multiply %6, %7 : tensor<39x39xf32>
    %9 = stablehlo.convert %8 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %10 = stablehlo.custom_call @Sharding(%9) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %11 = sdy.sharding_constraint %9 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
    %12 = stablehlo.reshape %11 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %13 = stablehlo.broadcast_in_dim %12, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %14 = stablehlo.reshape %arg5 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %15 = stablehlo.reshape %14 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %16 = stablehlo.convert %15 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %18 = stablehlo.convert %arg4 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %19 = stablehlo.power %18, %5 : tensor<2x39x3584xf32>
    %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %21 = stablehlo.multiply %20, %4 : tensor<2x39xf32>
    %22 = stablehlo.reshape %21 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %23 = stablehlo.add %22, %3 : tensor<2x39x1xf32>
    %24 = stablehlo.rsqrt %23 : tensor<2x39x1xf32>
    %25 = stablehlo.reshape %24 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %26 = stablehlo.broadcast_in_dim %25, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %27 = stablehlo.multiply %18, %26 : tensor<2x39x3584xf32>
    %28 = stablehlo.convert %27 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %29 = stablehlo.convert %28 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %30 = stablehlo.multiply %17, %29 : tensor<2x39x3584xf32>
    %31 = stablehlo.convert %30 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %32 = stablehlo.reshape %31 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %33 = stablehlo.reshape %arg3 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %34 = stablehlo.reshape %33 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %35 = stablehlo.transpose %34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %36 = stablehlo.dot_general %32, %35, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %37 = stablehlo.reshape %36 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %38 = stablehlo.reshape %arg2 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %39 = stablehlo.reshape %38 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %40 = stablehlo.broadcast_in_dim %39, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %41 = stablehlo.add %37, %40 : tensor<2x39x512xbf16>
    %42 = stablehlo.reshape %41 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %43 = stablehlo.transpose %42, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %44 = stablehlo.convert %43 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %45 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %46 = stablehlo.reshape %45 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %47 = stablehlo.reshape %arg0 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
    %48 = stablehlo.convert %47 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
    %49 = stablehlo.dot_general %46, %48, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
    %50 = stablehlo.transpose %49, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
    %51 = stablehlo.concatenate %50, %50, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
    %52 = stablehlo.cosine %51 : tensor<1x39x128xf32>
    %53 = stablehlo.convert %52 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %54 = stablehlo.reshape %53 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %55 = stablehlo.convert %54 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %56 = stablehlo.reshape %55 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %57 = stablehlo.broadcast_in_dim %56, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %58 = stablehlo.multiply %44, %57 : tensor<2x4x39x128xf32>
    %59 = stablehlo.convert %58 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %60 = stablehlo.slice %43 [0:2, 0:4, 0:39, 64:128] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %61 = stablehlo.negate %60 : tensor<2x4x39x64xbf16>
    %62 = stablehlo.slice %43 [0:2, 0:4, 0:39, 0:64] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %63 = stablehlo.concatenate %61, %62, dim = 3 : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
    %64 = stablehlo.convert %63 : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %65 = stablehlo.sine %51 : tensor<1x39x128xf32>
    %66 = stablehlo.convert %65 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %67 = stablehlo.reshape %66 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %68 = stablehlo.convert %67 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %69 = stablehlo.reshape %68 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %70 = stablehlo.broadcast_in_dim %69, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %71 = stablehlo.multiply %64, %70 : tensor<2x4x39x128xf32>
    %72 = stablehlo.convert %71 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %73 = stablehlo.add %59, %72 : tensor<2x4x39x128xbf16>
    %74 = stablehlo.reshape %arg7 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %75 = stablehlo.reshape %74 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %76 = stablehlo.transpose %75, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %77 = stablehlo.dot_general %32, %76, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %78 = stablehlo.reshape %77 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %79 = stablehlo.reshape %arg6 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %80 = stablehlo.reshape %79 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %81 = stablehlo.broadcast_in_dim %80, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %82 = stablehlo.add %78, %81 : tensor<2x39x512xbf16>
    %83 = stablehlo.reshape %82 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %84 = stablehlo.transpose %83, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %85 = stablehlo.reshape %arg18 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %86 = stablehlo.reshape %85 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %87 = stablehlo.convert %86 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %88 = stablehlo.broadcast_in_dim %87, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %89 = stablehlo.reshape %arg15 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %90 = stablehlo.reshape %89 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %91 = stablehlo.transpose %90, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %92 = stablehlo.dot_general %32, %91, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %93 = stablehlo.reshape %92 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %94 = stablehlo.reshape %arg14 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %95 = stablehlo.reshape %94 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %96 = stablehlo.broadcast_in_dim %95, dims = [2] : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
    %97 = stablehlo.add %93, %96 : tensor<2x39x3584xbf16>
    %98 = stablehlo.reshape %97 : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
    %99 = stablehlo.transpose %98, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
    %100 = stablehlo.convert %99 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %101 = stablehlo.broadcast_in_dim %56, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %102 = stablehlo.multiply %100, %101 : tensor<2x28x39x128xf32>
    %103 = stablehlo.convert %102 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %104 = stablehlo.slice %99 [0:2, 0:28, 0:39, 64:128] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %105 = stablehlo.negate %104 : tensor<2x28x39x64xbf16>
    %106 = stablehlo.slice %99 [0:2, 0:28, 0:39, 0:64] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %107 = stablehlo.concatenate %105, %106, dim = 3 : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
    %108 = stablehlo.convert %107 : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %109 = stablehlo.broadcast_in_dim %69, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %110 = stablehlo.multiply %108, %109 : tensor<2x28x39x128xf32>
    %111 = stablehlo.convert %110 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %112 = stablehlo.add %103, %111 : tensor<2x28x39x128xbf16>
    %113 = stablehlo.reshape %112 : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
    %114 = stablehlo.broadcast_in_dim %73, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %115 = stablehlo.reshape %114 : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %116 = stablehlo.transpose %115, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
    %117 = stablehlo.reshape %116 : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
    %118 = stablehlo.dot_general %113, %117, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
    %119 = stablehlo.reshape %118 : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %120 = stablehlo.convert %119 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %121 = stablehlo.multiply %120, %2 : tensor<2x28x39x39xf32>
    %122 = stablehlo.convert %121 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %123 = stablehlo.reshape %arg11 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %124 = stablehlo.convert %123 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %125 = stablehlo.reshape %124 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %126 = stablehlo.broadcast_in_dim %125, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %127 = stablehlo.add %13, %126 : tensor<2x1x39x39xbf16>
    %128 = stablehlo.compare  EQ, %127, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %129 = stablehlo.select %128, %0, %13 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    %130 = stablehlo.reshape %129 : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
    %131 = stablehlo.broadcast_in_dim %130, dims = [0, 2, 3] : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %132 = stablehlo.add %122, %131 : tensor<2x28x39x39xbf16>
    %133 = stablehlo.convert %132 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %134 = stablehlo.reduce(%133 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %136 = stablehlo.subtract %133, %135 : tensor<2x28x39x39xf32>
    %137 = stablehlo.exponential %136 : tensor<2x28x39x39xf32>
    %138 = stablehlo.reduce(%137 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %139 = stablehlo.broadcast_in_dim %138, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %140 = stablehlo.divide %137, %139 : tensor<2x28x39x39xf32>
    %141 = stablehlo.convert %140 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %142 = stablehlo.reshape %141 : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
    %143 = stablehlo.broadcast_in_dim %84, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %144 = stablehlo.reshape %143 : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
    %145 = stablehlo.dot_general %142, %144, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
    %146 = stablehlo.reshape %145 : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %147 = stablehlo.transpose %146, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
    %148 = stablehlo.reshape %147 : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
    %149 = stablehlo.reshape %arg10 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %150 = stablehlo.reshape %149 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %151 = stablehlo.transpose %150, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %152 = stablehlo.dot_general %148, %151, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %153 = stablehlo.reshape %152 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %154 = stablehlo.add %arg4, %153 : tensor<2x39x3584xbf16>
    %155 = stablehlo.reshape %arg16 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %156 = stablehlo.reshape %155 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %157 = stablehlo.convert %156 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %158 = stablehlo.broadcast_in_dim %157, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %159 = stablehlo.convert %154 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %160 = stablehlo.power %159, %5 : tensor<2x39x3584xf32>
    %161 = stablehlo.reduce(%160 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %162 = stablehlo.multiply %161, %4 : tensor<2x39xf32>
    %163 = stablehlo.reshape %162 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %164 = stablehlo.add %163, %3 : tensor<2x39x1xf32>
    %165 = stablehlo.rsqrt %164 : tensor<2x39x1xf32>
    %166 = stablehlo.reshape %165 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %167 = stablehlo.broadcast_in_dim %166, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %168 = stablehlo.multiply %159, %167 : tensor<2x39x3584xf32>
    %169 = stablehlo.convert %168 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %170 = stablehlo.convert %169 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %171 = stablehlo.multiply %158, %170 : tensor<2x39x3584xf32>
    %172 = stablehlo.convert %171 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %173 = stablehlo.reshape %172 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %174 = stablehlo.reshape %arg17 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %175 = stablehlo.reshape %174 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %176 = stablehlo.transpose %175, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %177 = stablehlo.dot_general %173, %176, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %178 = stablehlo.reshape %177 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %179 = stablehlo.convert %178 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %180 = stablehlo.logistic %178 : tensor<2x39x18944xbf16>
    %181 = stablehlo.convert %180 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %182 = stablehlo.multiply %179, %181 : tensor<2x39x18944xf32>
    %183 = stablehlo.convert %182 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %184 = stablehlo.convert %183 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %185 = stablehlo.reshape %arg9 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %186 = stablehlo.reshape %185 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %187 = stablehlo.transpose %186, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %188 = stablehlo.dot_general %173, %187, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %189 = stablehlo.reshape %188 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %190 = stablehlo.convert %189 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %191 = stablehlo.multiply %184, %190 : tensor<2x39x18944xf32>
    %192 = stablehlo.convert %191 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %193 = stablehlo.reshape %192 : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
    %194 = stablehlo.reshape %arg8 : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
    %195 = stablehlo.reshape %194 : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
    %196 = stablehlo.transpose %195, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
    %197 = stablehlo.dot_general %193, %196, contracting_dims = [1] x [0] : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
    %198 = stablehlo.reshape %197 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %199 = stablehlo.add %154, %198 : tensor<2x39x3584xbf16>
    %200 = stablehlo.convert %199 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %201 = stablehlo.power %200, %5 : tensor<2x39x3584xf32>
    %202 = stablehlo.reduce(%201 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %203 = stablehlo.multiply %202, %4 : tensor<2x39xf32>
    %204 = stablehlo.reshape %203 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %205 = stablehlo.add %204, %3 : tensor<2x39x1xf32>
    %206 = stablehlo.rsqrt %205 : tensor<2x39x1xf32>
    %207 = stablehlo.reshape %206 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %208 = stablehlo.broadcast_in_dim %207, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %209 = stablehlo.multiply %200, %208 : tensor<2x39x3584xf32>
    %210 = stablehlo.convert %209 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %211 = stablehlo.convert %210 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %212 = stablehlo.multiply %88, %211 : tensor<2x39x3584xf32>
    %213 = stablehlo.convert %212 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    return %73, %84, %213 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


// -----// IR Dump Before AggressivePropagationPass (sdy-aggressive-propagate) ('builtin.module' operation: @SyncTensorsGraph.420) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___rotary_emb_inv_freq"}, %arg2: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, %arg3: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, %arg4: tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg5: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, %arg6: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, %arg7: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, %arg8: tensor<3584x18944xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, %arg9: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, %arg10: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, %arg11: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg12: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg13: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg14: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, %arg15: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, %arg16: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, %arg17: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, %arg18: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___norm_weight"}) -> (tensor<2x4x39x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x4x39x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x39x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
    %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
    %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f32>) -> tensor<2x28x39x39xf32>
    %3 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
    %4 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
    %5 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<2x39x3584xf32>
    %6 = stablehlo.convert %arg13 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %7 = stablehlo.convert %arg12 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %8 = stablehlo.multiply %6, %7 : tensor<39x39xf32>
    %9 = stablehlo.convert %8 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %10 = stablehlo.custom_call @Sharding(%9) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %11 = sdy.sharding_constraint %9 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
    %12 = stablehlo.reshape %11 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %13 = stablehlo.broadcast_in_dim %12, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %14 = stablehlo.reshape %arg5 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %15 = stablehlo.reshape %14 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %16 = stablehlo.convert %15 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %18 = stablehlo.convert %arg4 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %19 = stablehlo.power %18, %5 : tensor<2x39x3584xf32>
    %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %21 = stablehlo.multiply %20, %4 : tensor<2x39xf32>
    %22 = stablehlo.reshape %21 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %23 = stablehlo.add %22, %3 : tensor<2x39x1xf32>
    %24 = stablehlo.rsqrt %23 : tensor<2x39x1xf32>
    %25 = stablehlo.reshape %24 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %26 = stablehlo.broadcast_in_dim %25, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %27 = stablehlo.multiply %18, %26 : tensor<2x39x3584xf32>
    %28 = stablehlo.convert %27 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %29 = stablehlo.convert %28 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %30 = stablehlo.multiply %17, %29 : tensor<2x39x3584xf32>
    %31 = stablehlo.convert %30 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %32 = stablehlo.reshape %31 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %33 = stablehlo.reshape %arg3 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %34 = stablehlo.reshape %33 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %35 = stablehlo.transpose %34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %36 = stablehlo.dot_general %32, %35, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %37 = stablehlo.reshape %36 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %38 = stablehlo.reshape %arg2 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %39 = stablehlo.reshape %38 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %40 = stablehlo.broadcast_in_dim %39, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %41 = stablehlo.add %37, %40 : tensor<2x39x512xbf16>
    %42 = stablehlo.reshape %41 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %43 = stablehlo.transpose %42, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %44 = stablehlo.convert %43 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %45 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %46 = stablehlo.reshape %45 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %47 = stablehlo.reshape %arg0 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
    %48 = stablehlo.convert %47 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
    %49 = stablehlo.dot_general %46, %48, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
    %50 = stablehlo.transpose %49, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
    %51 = stablehlo.concatenate %50, %50, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
    %52 = stablehlo.cosine %51 : tensor<1x39x128xf32>
    %53 = stablehlo.convert %52 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %54 = stablehlo.reshape %53 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %55 = stablehlo.convert %54 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %56 = stablehlo.reshape %55 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %57 = stablehlo.broadcast_in_dim %56, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %58 = stablehlo.multiply %44, %57 : tensor<2x4x39x128xf32>
    %59 = stablehlo.convert %58 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %60 = stablehlo.slice %43 [0:2, 0:4, 0:39, 64:128] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %61 = stablehlo.negate %60 : tensor<2x4x39x64xbf16>
    %62 = stablehlo.slice %43 [0:2, 0:4, 0:39, 0:64] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %63 = stablehlo.concatenate %61, %62, dim = 3 : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
    %64 = stablehlo.convert %63 : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %65 = stablehlo.sine %51 : tensor<1x39x128xf32>
    %66 = stablehlo.convert %65 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %67 = stablehlo.reshape %66 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %68 = stablehlo.convert %67 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %69 = stablehlo.reshape %68 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %70 = stablehlo.broadcast_in_dim %69, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %71 = stablehlo.multiply %64, %70 : tensor<2x4x39x128xf32>
    %72 = stablehlo.convert %71 : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %73 = stablehlo.add %59, %72 : tensor<2x4x39x128xbf16>
    %74 = stablehlo.reshape %arg7 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %75 = stablehlo.reshape %74 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %76 = stablehlo.transpose %75, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %77 = stablehlo.dot_general %32, %76, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %78 = stablehlo.reshape %77 : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %79 = stablehlo.reshape %arg6 : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %80 = stablehlo.reshape %79 : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %81 = stablehlo.broadcast_in_dim %80, dims = [2] : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %82 = stablehlo.add %78, %81 : tensor<2x39x512xbf16>
    %83 = stablehlo.reshape %82 : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %84 = stablehlo.transpose %83, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %85 = stablehlo.reshape %arg18 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %86 = stablehlo.reshape %85 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %87 = stablehlo.convert %86 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %88 = stablehlo.broadcast_in_dim %87, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %89 = stablehlo.reshape %arg15 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %90 = stablehlo.reshape %89 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %91 = stablehlo.transpose %90, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %92 = stablehlo.dot_general %32, %91, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %93 = stablehlo.reshape %92 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %94 = stablehlo.reshape %arg14 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %95 = stablehlo.reshape %94 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %96 = stablehlo.broadcast_in_dim %95, dims = [2] : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
    %97 = stablehlo.add %93, %96 : tensor<2x39x3584xbf16>
    %98 = stablehlo.reshape %97 : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
    %99 = stablehlo.transpose %98, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
    %100 = stablehlo.convert %99 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %101 = stablehlo.broadcast_in_dim %56, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %102 = stablehlo.multiply %100, %101 : tensor<2x28x39x128xf32>
    %103 = stablehlo.convert %102 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %104 = stablehlo.slice %99 [0:2, 0:28, 0:39, 64:128] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %105 = stablehlo.negate %104 : tensor<2x28x39x64xbf16>
    %106 = stablehlo.slice %99 [0:2, 0:28, 0:39, 0:64] : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %107 = stablehlo.concatenate %105, %106, dim = 3 : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
    %108 = stablehlo.convert %107 : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %109 = stablehlo.broadcast_in_dim %69, dims = [2, 3] : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %110 = stablehlo.multiply %108, %109 : tensor<2x28x39x128xf32>
    %111 = stablehlo.convert %110 : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %112 = stablehlo.add %103, %111 : tensor<2x28x39x128xbf16>
    %113 = stablehlo.reshape %112 : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
    %114 = stablehlo.broadcast_in_dim %73, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %115 = stablehlo.reshape %114 : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %116 = stablehlo.transpose %115, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
    %117 = stablehlo.reshape %116 : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
    %118 = stablehlo.dot_general %113, %117, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
    %119 = stablehlo.reshape %118 : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %120 = stablehlo.convert %119 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %121 = stablehlo.multiply %120, %2 : tensor<2x28x39x39xf32>
    %122 = stablehlo.convert %121 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %123 = stablehlo.reshape %arg11 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %124 = stablehlo.convert %123 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %125 = stablehlo.reshape %124 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %126 = stablehlo.broadcast_in_dim %125, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %127 = stablehlo.add %13, %126 : tensor<2x1x39x39xbf16>
    %128 = stablehlo.compare  EQ, %127, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %129 = stablehlo.select %128, %0, %13 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    %130 = stablehlo.reshape %129 : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
    %131 = stablehlo.broadcast_in_dim %130, dims = [0, 2, 3] : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %132 = stablehlo.add %122, %131 : tensor<2x28x39x39xbf16>
    %133 = stablehlo.convert %132 : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %134 = stablehlo.reduce(%133 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %136 = stablehlo.subtract %133, %135 : tensor<2x28x39x39xf32>
    %137 = stablehlo.exponential %136 : tensor<2x28x39x39xf32>
    %138 = stablehlo.reduce(%137 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %139 = stablehlo.broadcast_in_dim %138, dims = [0, 1, 2] : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %140 = stablehlo.divide %137, %139 : tensor<2x28x39x39xf32>
    %141 = stablehlo.convert %140 : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %142 = stablehlo.reshape %141 : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
    %143 = stablehlo.broadcast_in_dim %84, dims = [0, 1, 3, 4] : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %144 = stablehlo.reshape %143 : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
    %145 = stablehlo.dot_general %142, %144, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
    %146 = stablehlo.reshape %145 : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %147 = stablehlo.transpose %146, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
    %148 = stablehlo.reshape %147 : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
    %149 = stablehlo.reshape %arg10 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %150 = stablehlo.reshape %149 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %151 = stablehlo.transpose %150, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %152 = stablehlo.dot_general %148, %151, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %153 = stablehlo.reshape %152 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %154 = stablehlo.add %arg4, %153 : tensor<2x39x3584xbf16>
    %155 = stablehlo.reshape %arg16 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %156 = stablehlo.reshape %155 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %157 = stablehlo.convert %156 : (tensor<3584xbf16>) -> tensor<3584xf32>
    %158 = stablehlo.broadcast_in_dim %157, dims = [2] : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %159 = stablehlo.convert %154 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %160 = stablehlo.power %159, %5 : tensor<2x39x3584xf32>
    %161 = stablehlo.reduce(%160 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %162 = stablehlo.multiply %161, %4 : tensor<2x39xf32>
    %163 = stablehlo.reshape %162 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %164 = stablehlo.add %163, %3 : tensor<2x39x1xf32>
    %165 = stablehlo.rsqrt %164 : tensor<2x39x1xf32>
    %166 = stablehlo.reshape %165 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %167 = stablehlo.broadcast_in_dim %166, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %168 = stablehlo.multiply %159, %167 : tensor<2x39x3584xf32>
    %169 = stablehlo.convert %168 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %170 = stablehlo.convert %169 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %171 = stablehlo.multiply %158, %170 : tensor<2x39x3584xf32>
    %172 = stablehlo.convert %171 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %173 = stablehlo.reshape %172 : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %174 = stablehlo.reshape %arg17 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %175 = stablehlo.reshape %174 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %176 = stablehlo.transpose %175, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %177 = stablehlo.dot_general %173, %176, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %178 = stablehlo.reshape %177 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %179 = stablehlo.convert %178 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %180 = stablehlo.logistic %178 : tensor<2x39x18944xbf16>
    %181 = stablehlo.convert %180 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %182 = stablehlo.multiply %179, %181 : tensor<2x39x18944xf32>
    %183 = stablehlo.convert %182 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %184 = stablehlo.convert %183 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %185 = stablehlo.reshape %arg9 : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %186 = stablehlo.reshape %185 : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %187 = stablehlo.transpose %186, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %188 = stablehlo.dot_general %173, %187, contracting_dims = [1] x [0] : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %189 = stablehlo.reshape %188 : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %190 = stablehlo.convert %189 : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %191 = stablehlo.multiply %184, %190 : tensor<2x39x18944xf32>
    %192 = stablehlo.convert %191 : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %193 = stablehlo.reshape %192 : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
    %194 = stablehlo.reshape %arg8 : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
    %195 = stablehlo.reshape %194 : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
    %196 = stablehlo.transpose %195, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
    %197 = stablehlo.dot_general %193, %196, contracting_dims = [1] x [0] : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
    %198 = stablehlo.reshape %197 : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %199 = stablehlo.add %154, %198 : tensor<2x39x3584xbf16>
    %200 = stablehlo.convert %199 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %201 = stablehlo.power %200, %5 : tensor<2x39x3584xf32>
    %202 = stablehlo.reduce(%201 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %203 = stablehlo.multiply %202, %4 : tensor<2x39xf32>
    %204 = stablehlo.reshape %203 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %205 = stablehlo.add %204, %3 : tensor<2x39x1xf32>
    %206 = stablehlo.rsqrt %205 : tensor<2x39x1xf32>
    %207 = stablehlo.reshape %206 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %208 = stablehlo.broadcast_in_dim %207, dims = [0, 1] : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %209 = stablehlo.multiply %200, %208 : tensor<2x39x3584xf32>
    %210 = stablehlo.convert %209 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %211 = stablehlo.convert %210 : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %212 = stablehlo.multiply %88, %211 : tensor<2x39x3584xf32>
    %213 = stablehlo.convert %212 : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    return %73, %84, %213 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


// -----// IR Dump After AggressivePropagationPass (sdy-aggressive-propagate) ('builtin.module' operation: @SyncTensorsGraph.420) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___rotary_emb_inv_freq"}, %arg2: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, %arg3: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, %arg4: tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg5: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, %arg6: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, %arg7: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, %arg8: tensor<3584x18944xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, %arg9: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, %arg10: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, %arg11: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg12: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg13: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg14: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, %arg15: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, %arg16: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, %arg17: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, %arg18: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___norm_weight"}) -> (tensor<2x4x39x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x4x39x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"_axis_0", ?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
    %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
    %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_5, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_4, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<2x28x39x39xf32>
    %3 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
    %4 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
    %5 = stablehlo.broadcast_in_dim %cst_1, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<f32>) -> tensor<2x39x3584xf32>
    %6 = stablehlo.convert %arg13 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %7 = stablehlo.convert %arg12 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %8 = stablehlo.multiply %6, %7 : tensor<39x39xf32>
    %9 = stablehlo.convert %8 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %10 = sdy.sharding_constraint %9 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
    %11 = stablehlo.reshape %10 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.reshape %arg5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %14 = stablehlo.reshape %13 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %15 = stablehlo.convert %14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
    %16 = stablehlo.broadcast_in_dim %15, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %17 = stablehlo.convert %arg4 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %18 = stablehlo.power %17, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %19 = stablehlo.reduce(%18 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %20 = stablehlo.multiply %19, %4 : tensor<2x39xf32>
    %21 = stablehlo.reshape %20 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %22 = stablehlo.add %21, %3 : tensor<2x39x1xf32>
    %23 = stablehlo.rsqrt %22 : tensor<2x39x1xf32>
    %24 = stablehlo.reshape %23 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %25 = stablehlo.broadcast_in_dim %24, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %26 = stablehlo.multiply %17, %25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %27 = stablehlo.convert %26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %28 = stablehlo.convert %27 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %29 = stablehlo.multiply %16, %28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %30 = stablehlo.convert %29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %31 = stablehlo.reshape %30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %32 = stablehlo.reshape %arg3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %33 = stablehlo.reshape %32 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %36 = stablehlo.reshape %35 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %37 = stablehlo.reshape %arg2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %38 = stablehlo.reshape %37 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %39 = stablehlo.broadcast_in_dim %38, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %40 = stablehlo.add %36, %39 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x512xbf16>
    %41 = stablehlo.reshape %40 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %42 = stablehlo.transpose %41, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %43 = stablehlo.convert %42 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %44 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.reshape %arg0 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
    %47 = stablehlo.convert %46 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
    %48 = stablehlo.dot_general %45, %47, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
    %49 = stablehlo.transpose %48, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
    %50 = stablehlo.concatenate %49, %49, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
    %51 = stablehlo.cosine %50 : tensor<1x39x128xf32>
    %52 = stablehlo.convert %51 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %53 = stablehlo.reshape %52 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %54 = stablehlo.convert %53 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %55 = stablehlo.reshape %54 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %56 = stablehlo.broadcast_in_dim %55, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %57 = stablehlo.multiply %43, %56 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xf32>
    %58 = stablehlo.convert %57 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %59 = stablehlo.slice %42 [0:2, 0:4, 0:39, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %60 = stablehlo.negate %59 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x64xbf16>
    %61 = stablehlo.slice %42 [0:2, 0:4, 0:39, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %62 = stablehlo.concatenate %60, %61, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
    %63 = stablehlo.convert %62 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %64 = stablehlo.sine %50 : tensor<1x39x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %66 = stablehlo.reshape %65 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %67 = stablehlo.convert %66 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %68 = stablehlo.reshape %67 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %69 = stablehlo.broadcast_in_dim %68, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %70 = stablehlo.multiply %63, %69 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xf32>
    %71 = stablehlo.convert %70 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %72 = stablehlo.add %58, %71 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xbf16>
    %73 = stablehlo.reshape %arg7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %74 = stablehlo.reshape %73 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %76 = stablehlo.dot_general %31, %75, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %77 = stablehlo.reshape %76 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %78 = stablehlo.reshape %arg6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %79 = stablehlo.reshape %78 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %80 = stablehlo.broadcast_in_dim %79, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %81 = stablehlo.add %77, %80 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x512xbf16>
    %82 = stablehlo.reshape %81 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %83 = stablehlo.transpose %82, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %84 = stablehlo.reshape %arg18 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %85 = stablehlo.reshape %84 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %86 = stablehlo.convert %85 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
    %87 = stablehlo.broadcast_in_dim %86, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %88 = stablehlo.reshape %arg15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %89 = stablehlo.reshape %88 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %90 = stablehlo.transpose %89, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %91 = stablehlo.dot_general %31, %90, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %92 = stablehlo.reshape %91 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %93 = stablehlo.reshape %arg14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %94 = stablehlo.reshape %93 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %95 = stablehlo.broadcast_in_dim %94, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
    %96 = stablehlo.add %92, %95 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x3584xbf16>
    %97 = stablehlo.reshape %96 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
    %98 = stablehlo.transpose %97, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
    %99 = stablehlo.convert %98 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %100 = stablehlo.broadcast_in_dim %55, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %101 = stablehlo.multiply %99, %100 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xf32>
    %102 = stablehlo.convert %101 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %103 = stablehlo.slice %98 [0:2, 0:28, 0:39, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %104 = stablehlo.negate %103 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x64xbf16>
    %105 = stablehlo.slice %98 [0:2, 0:28, 0:39, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %106 = stablehlo.concatenate %104, %105, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
    %107 = stablehlo.convert %106 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %108 = stablehlo.broadcast_in_dim %68, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %109 = stablehlo.multiply %107, %108 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xf32>
    %110 = stablehlo.convert %109 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %111 = stablehlo.add %102, %110 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xbf16>
    %112 = stablehlo.reshape %111 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
    %113 = stablehlo.broadcast_in_dim %72, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %114 = stablehlo.reshape %113 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %115 = stablehlo.transpose %114, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
    %116 = stablehlo.reshape %115 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
    %117 = stablehlo.dot_general %112, %116, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
    %118 = stablehlo.reshape %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %119 = stablehlo.convert %118 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %120 = stablehlo.multiply %119, %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %121 = stablehlo.convert %120 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %122 = stablehlo.reshape %arg11 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %123 = stablehlo.convert %122 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %124 = stablehlo.reshape %123 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %125 = stablehlo.broadcast_in_dim %124, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %126 = stablehlo.add %12, %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xbf16>
    %127 = stablehlo.compare  EQ, %126, %1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %128 = stablehlo.select %127, %0, %12 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    %129 = stablehlo.reshape %128 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
    %130 = stablehlo.broadcast_in_dim %129, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %131 = stablehlo.add %121, %130 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xbf16>
    %132 = stablehlo.convert %131 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %133 = stablehlo.reduce(%132 init: %cst_0) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %134 = stablehlo.broadcast_in_dim %133, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %135 = stablehlo.subtract %132, %134 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %136 = stablehlo.exponential %135 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %137 = stablehlo.reduce(%136 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %138 = stablehlo.broadcast_in_dim %137, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %139 = stablehlo.divide %136, %138 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %140 = stablehlo.convert %139 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %141 = stablehlo.reshape %140 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
    %142 = stablehlo.broadcast_in_dim %83, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %143 = stablehlo.reshape %142 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
    %144 = stablehlo.dot_general %141, %143, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
    %145 = stablehlo.reshape %144 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %146 = stablehlo.transpose %145, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
    %147 = stablehlo.reshape %146 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
    %148 = stablehlo.reshape %arg10 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %149 = stablehlo.reshape %148 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %150 = stablehlo.transpose %149, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %151 = stablehlo.dot_general %147, %150, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %152 = stablehlo.reshape %151 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %153 = stablehlo.add %arg4, %152 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xbf16>
    %154 = stablehlo.reshape %arg16 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %155 = stablehlo.reshape %154 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %156 = stablehlo.convert %155 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
    %157 = stablehlo.broadcast_in_dim %156, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %158 = stablehlo.convert %153 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %159 = stablehlo.power %158, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %160 = stablehlo.reduce(%159 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %161 = stablehlo.multiply %160, %4 : tensor<2x39xf32>
    %162 = stablehlo.reshape %161 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %163 = stablehlo.add %162, %3 : tensor<2x39x1xf32>
    %164 = stablehlo.rsqrt %163 : tensor<2x39x1xf32>
    %165 = stablehlo.reshape %164 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %166 = stablehlo.broadcast_in_dim %165, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %167 = stablehlo.multiply %158, %166 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %168 = stablehlo.convert %167 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %169 = stablehlo.convert %168 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %170 = stablehlo.multiply %157, %169 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %171 = stablehlo.convert %170 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %172 = stablehlo.reshape %171 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %173 = stablehlo.reshape %arg17 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %174 = stablehlo.reshape %173 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %175 = stablehlo.transpose %174, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %176 = stablehlo.dot_general %172, %175, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %177 = stablehlo.reshape %176 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %178 = stablehlo.convert %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %179 = stablehlo.logistic %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xbf16>
    %180 = stablehlo.convert %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %181 = stablehlo.multiply %178, %180 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xf32>
    %182 = stablehlo.convert %181 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %183 = stablehlo.convert %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %184 = stablehlo.reshape %arg9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %185 = stablehlo.reshape %184 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %186 = stablehlo.transpose %185, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %187 = stablehlo.dot_general %172, %186, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %188 = stablehlo.reshape %187 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %189 = stablehlo.convert %188 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %190 = stablehlo.multiply %183, %189 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xf32>
    %191 = stablehlo.convert %190 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %192 = stablehlo.reshape %191 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
    %193 = stablehlo.reshape %arg8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
    %194 = stablehlo.reshape %193 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
    %195 = stablehlo.transpose %194, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
    %196 = stablehlo.dot_general %192, %195, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
    %197 = stablehlo.reshape %196 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %198 = stablehlo.add %153, %197 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xbf16>
    %199 = stablehlo.convert %198 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %200 = stablehlo.power %199, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %201 = stablehlo.reduce(%200 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %202 = stablehlo.multiply %201, %4 : tensor<2x39xf32>
    %203 = stablehlo.reshape %202 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %204 = stablehlo.add %203, %3 : tensor<2x39x1xf32>
    %205 = stablehlo.rsqrt %204 : tensor<2x39x1xf32>
    %206 = stablehlo.reshape %205 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %207 = stablehlo.broadcast_in_dim %206, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %208 = stablehlo.multiply %199, %207 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %209 = stablehlo.convert %208 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %210 = stablehlo.convert %209 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %211 = stablehlo.multiply %87, %210 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %212 = stablehlo.convert %211 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    return %72, %83, %212 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


// -----// IR Dump Before ShardingConstraintToReshardPass (sdy-sharding-constraint-to-reshard) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___rotary_emb_inv_freq"}, %arg2: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, %arg3: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, %arg4: tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg5: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, %arg6: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, %arg7: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, %arg8: tensor<3584x18944xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, %arg9: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, %arg10: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, %arg11: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg12: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg13: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg14: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, %arg15: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, %arg16: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, %arg17: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, %arg18: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___norm_weight"}) -> (tensor<2x4x39x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x4x39x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"_axis_0", ?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
    %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
    %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_5, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_4, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<2x28x39x39xf32>
    %3 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
    %4 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
    %5 = stablehlo.broadcast_in_dim %cst_1, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<f32>) -> tensor<2x39x3584xf32>
    %6 = stablehlo.convert %arg13 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %7 = stablehlo.convert %arg12 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %8 = stablehlo.multiply %6, %7 : tensor<39x39xf32>
    %9 = stablehlo.convert %8 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %10 = sdy.sharding_constraint %9 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
    %11 = stablehlo.reshape %10 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.reshape %arg5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %14 = stablehlo.reshape %13 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %15 = stablehlo.convert %14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
    %16 = stablehlo.broadcast_in_dim %15, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %17 = stablehlo.convert %arg4 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %18 = stablehlo.power %17, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %19 = stablehlo.reduce(%18 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %20 = stablehlo.multiply %19, %4 : tensor<2x39xf32>
    %21 = stablehlo.reshape %20 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %22 = stablehlo.add %21, %3 : tensor<2x39x1xf32>
    %23 = stablehlo.rsqrt %22 : tensor<2x39x1xf32>
    %24 = stablehlo.reshape %23 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %25 = stablehlo.broadcast_in_dim %24, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %26 = stablehlo.multiply %17, %25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %27 = stablehlo.convert %26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %28 = stablehlo.convert %27 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %29 = stablehlo.multiply %16, %28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %30 = stablehlo.convert %29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %31 = stablehlo.reshape %30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %32 = stablehlo.reshape %arg3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %33 = stablehlo.reshape %32 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %36 = stablehlo.reshape %35 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %37 = stablehlo.reshape %arg2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %38 = stablehlo.reshape %37 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %39 = stablehlo.broadcast_in_dim %38, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %40 = stablehlo.add %36, %39 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x512xbf16>
    %41 = stablehlo.reshape %40 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %42 = stablehlo.transpose %41, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %43 = stablehlo.convert %42 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %44 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.reshape %arg0 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
    %47 = stablehlo.convert %46 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
    %48 = stablehlo.dot_general %45, %47, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
    %49 = stablehlo.transpose %48, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
    %50 = stablehlo.concatenate %49, %49, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
    %51 = stablehlo.cosine %50 : tensor<1x39x128xf32>
    %52 = stablehlo.convert %51 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %53 = stablehlo.reshape %52 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %54 = stablehlo.convert %53 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %55 = stablehlo.reshape %54 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %56 = stablehlo.broadcast_in_dim %55, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %57 = stablehlo.multiply %43, %56 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xf32>
    %58 = stablehlo.convert %57 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %59 = stablehlo.slice %42 [0:2, 0:4, 0:39, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %60 = stablehlo.negate %59 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x64xbf16>
    %61 = stablehlo.slice %42 [0:2, 0:4, 0:39, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %62 = stablehlo.concatenate %60, %61, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
    %63 = stablehlo.convert %62 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %64 = stablehlo.sine %50 : tensor<1x39x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %66 = stablehlo.reshape %65 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %67 = stablehlo.convert %66 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %68 = stablehlo.reshape %67 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %69 = stablehlo.broadcast_in_dim %68, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %70 = stablehlo.multiply %63, %69 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xf32>
    %71 = stablehlo.convert %70 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %72 = stablehlo.add %58, %71 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xbf16>
    %73 = stablehlo.reshape %arg7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %74 = stablehlo.reshape %73 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %76 = stablehlo.dot_general %31, %75, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %77 = stablehlo.reshape %76 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %78 = stablehlo.reshape %arg6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %79 = stablehlo.reshape %78 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %80 = stablehlo.broadcast_in_dim %79, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %81 = stablehlo.add %77, %80 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x512xbf16>
    %82 = stablehlo.reshape %81 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %83 = stablehlo.transpose %82, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %84 = stablehlo.reshape %arg18 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %85 = stablehlo.reshape %84 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %86 = stablehlo.convert %85 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
    %87 = stablehlo.broadcast_in_dim %86, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %88 = stablehlo.reshape %arg15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %89 = stablehlo.reshape %88 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %90 = stablehlo.transpose %89, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %91 = stablehlo.dot_general %31, %90, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %92 = stablehlo.reshape %91 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %93 = stablehlo.reshape %arg14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %94 = stablehlo.reshape %93 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %95 = stablehlo.broadcast_in_dim %94, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
    %96 = stablehlo.add %92, %95 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x3584xbf16>
    %97 = stablehlo.reshape %96 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
    %98 = stablehlo.transpose %97, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
    %99 = stablehlo.convert %98 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %100 = stablehlo.broadcast_in_dim %55, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %101 = stablehlo.multiply %99, %100 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xf32>
    %102 = stablehlo.convert %101 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %103 = stablehlo.slice %98 [0:2, 0:28, 0:39, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %104 = stablehlo.negate %103 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x64xbf16>
    %105 = stablehlo.slice %98 [0:2, 0:28, 0:39, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %106 = stablehlo.concatenate %104, %105, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
    %107 = stablehlo.convert %106 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %108 = stablehlo.broadcast_in_dim %68, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %109 = stablehlo.multiply %107, %108 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xf32>
    %110 = stablehlo.convert %109 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %111 = stablehlo.add %102, %110 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xbf16>
    %112 = stablehlo.reshape %111 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
    %113 = stablehlo.broadcast_in_dim %72, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %114 = stablehlo.reshape %113 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %115 = stablehlo.transpose %114, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
    %116 = stablehlo.reshape %115 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
    %117 = stablehlo.dot_general %112, %116, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
    %118 = stablehlo.reshape %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %119 = stablehlo.convert %118 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %120 = stablehlo.multiply %119, %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %121 = stablehlo.convert %120 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %122 = stablehlo.reshape %arg11 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %123 = stablehlo.convert %122 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %124 = stablehlo.reshape %123 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %125 = stablehlo.broadcast_in_dim %124, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %126 = stablehlo.add %12, %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xbf16>
    %127 = stablehlo.compare  EQ, %126, %1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %128 = stablehlo.select %127, %0, %12 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    %129 = stablehlo.reshape %128 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
    %130 = stablehlo.broadcast_in_dim %129, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %131 = stablehlo.add %121, %130 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xbf16>
    %132 = stablehlo.convert %131 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %133 = stablehlo.reduce(%132 init: %cst_0) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %134 = stablehlo.broadcast_in_dim %133, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %135 = stablehlo.subtract %132, %134 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %136 = stablehlo.exponential %135 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %137 = stablehlo.reduce(%136 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %138 = stablehlo.broadcast_in_dim %137, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %139 = stablehlo.divide %136, %138 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %140 = stablehlo.convert %139 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %141 = stablehlo.reshape %140 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
    %142 = stablehlo.broadcast_in_dim %83, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %143 = stablehlo.reshape %142 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
    %144 = stablehlo.dot_general %141, %143, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
    %145 = stablehlo.reshape %144 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %146 = stablehlo.transpose %145, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
    %147 = stablehlo.reshape %146 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
    %148 = stablehlo.reshape %arg10 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %149 = stablehlo.reshape %148 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %150 = stablehlo.transpose %149, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %151 = stablehlo.dot_general %147, %150, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %152 = stablehlo.reshape %151 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %153 = stablehlo.add %arg4, %152 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xbf16>
    %154 = stablehlo.reshape %arg16 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %155 = stablehlo.reshape %154 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %156 = stablehlo.convert %155 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
    %157 = stablehlo.broadcast_in_dim %156, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %158 = stablehlo.convert %153 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %159 = stablehlo.power %158, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %160 = stablehlo.reduce(%159 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %161 = stablehlo.multiply %160, %4 : tensor<2x39xf32>
    %162 = stablehlo.reshape %161 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %163 = stablehlo.add %162, %3 : tensor<2x39x1xf32>
    %164 = stablehlo.rsqrt %163 : tensor<2x39x1xf32>
    %165 = stablehlo.reshape %164 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %166 = stablehlo.broadcast_in_dim %165, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %167 = stablehlo.multiply %158, %166 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %168 = stablehlo.convert %167 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %169 = stablehlo.convert %168 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %170 = stablehlo.multiply %157, %169 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %171 = stablehlo.convert %170 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %172 = stablehlo.reshape %171 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %173 = stablehlo.reshape %arg17 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %174 = stablehlo.reshape %173 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %175 = stablehlo.transpose %174, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %176 = stablehlo.dot_general %172, %175, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %177 = stablehlo.reshape %176 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %178 = stablehlo.convert %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %179 = stablehlo.logistic %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xbf16>
    %180 = stablehlo.convert %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %181 = stablehlo.multiply %178, %180 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xf32>
    %182 = stablehlo.convert %181 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %183 = stablehlo.convert %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %184 = stablehlo.reshape %arg9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %185 = stablehlo.reshape %184 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %186 = stablehlo.transpose %185, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %187 = stablehlo.dot_general %172, %186, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %188 = stablehlo.reshape %187 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %189 = stablehlo.convert %188 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %190 = stablehlo.multiply %183, %189 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xf32>
    %191 = stablehlo.convert %190 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %192 = stablehlo.reshape %191 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
    %193 = stablehlo.reshape %arg8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
    %194 = stablehlo.reshape %193 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
    %195 = stablehlo.transpose %194, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
    %196 = stablehlo.dot_general %192, %195, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
    %197 = stablehlo.reshape %196 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %198 = stablehlo.add %153, %197 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xbf16>
    %199 = stablehlo.convert %198 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %200 = stablehlo.power %199, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %201 = stablehlo.reduce(%200 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %202 = stablehlo.multiply %201, %4 : tensor<2x39xf32>
    %203 = stablehlo.reshape %202 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %204 = stablehlo.add %203, %3 : tensor<2x39x1xf32>
    %205 = stablehlo.rsqrt %204 : tensor<2x39x1xf32>
    %206 = stablehlo.reshape %205 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %207 = stablehlo.broadcast_in_dim %206, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %208 = stablehlo.multiply %199, %207 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %209 = stablehlo.convert %208 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %210 = stablehlo.convert %209 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %211 = stablehlo.multiply %87, %210 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %212 = stablehlo.convert %211 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    return %72, %83, %212 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


// -----// IR Dump After ShardingConstraintToReshardPass (sdy-sharding-constraint-to-reshard) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___rotary_emb_inv_freq"}, %arg2: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, %arg3: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, %arg4: tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg5: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, %arg6: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, %arg7: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, %arg8: tensor<3584x18944xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, %arg9: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, %arg10: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, %arg11: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg12: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg13: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg14: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, %arg15: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, %arg16: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, %arg17: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, %arg18: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___norm_weight"}) -> (tensor<2x4x39x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x4x39x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"_axis_0", ?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
    %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
    %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_5, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_4, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<2x28x39x39xf32>
    %3 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
    %4 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
    %5 = stablehlo.broadcast_in_dim %cst_1, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<f32>) -> tensor<2x39x3584xf32>
    %6 = stablehlo.convert %arg13 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %7 = stablehlo.convert %arg12 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %8 = stablehlo.multiply %6, %7 : tensor<39x39xf32>
    %9 = stablehlo.convert %8 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %10 = sdy.reshard %9 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
    %11 = stablehlo.reshape %10 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.reshape %arg5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %14 = stablehlo.reshape %13 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %15 = stablehlo.convert %14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
    %16 = stablehlo.broadcast_in_dim %15, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %17 = stablehlo.convert %arg4 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %18 = stablehlo.power %17, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %19 = stablehlo.reduce(%18 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %20 = stablehlo.multiply %19, %4 : tensor<2x39xf32>
    %21 = stablehlo.reshape %20 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %22 = stablehlo.add %21, %3 : tensor<2x39x1xf32>
    %23 = stablehlo.rsqrt %22 : tensor<2x39x1xf32>
    %24 = stablehlo.reshape %23 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %25 = stablehlo.broadcast_in_dim %24, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %26 = stablehlo.multiply %17, %25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %27 = stablehlo.convert %26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %28 = stablehlo.convert %27 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %29 = stablehlo.multiply %16, %28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %30 = stablehlo.convert %29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %31 = stablehlo.reshape %30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %32 = stablehlo.reshape %arg3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %33 = stablehlo.reshape %32 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %36 = stablehlo.reshape %35 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %37 = stablehlo.reshape %arg2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %38 = stablehlo.reshape %37 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %39 = stablehlo.broadcast_in_dim %38, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %40 = stablehlo.add %36, %39 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x512xbf16>
    %41 = stablehlo.reshape %40 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %42 = stablehlo.transpose %41, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %43 = stablehlo.convert %42 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %44 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.reshape %arg0 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
    %47 = stablehlo.convert %46 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
    %48 = stablehlo.dot_general %45, %47, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
    %49 = stablehlo.transpose %48, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
    %50 = stablehlo.concatenate %49, %49, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
    %51 = stablehlo.cosine %50 : tensor<1x39x128xf32>
    %52 = stablehlo.convert %51 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %53 = stablehlo.reshape %52 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %54 = stablehlo.convert %53 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %55 = stablehlo.reshape %54 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %56 = stablehlo.broadcast_in_dim %55, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %57 = stablehlo.multiply %43, %56 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xf32>
    %58 = stablehlo.convert %57 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %59 = stablehlo.slice %42 [0:2, 0:4, 0:39, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %60 = stablehlo.negate %59 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x64xbf16>
    %61 = stablehlo.slice %42 [0:2, 0:4, 0:39, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %62 = stablehlo.concatenate %60, %61, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
    %63 = stablehlo.convert %62 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %64 = stablehlo.sine %50 : tensor<1x39x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %66 = stablehlo.reshape %65 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %67 = stablehlo.convert %66 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %68 = stablehlo.reshape %67 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %69 = stablehlo.broadcast_in_dim %68, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %70 = stablehlo.multiply %63, %69 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xf32>
    %71 = stablehlo.convert %70 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %72 = stablehlo.add %58, %71 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xbf16>
    %73 = stablehlo.reshape %arg7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %74 = stablehlo.reshape %73 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %76 = stablehlo.dot_general %31, %75, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %77 = stablehlo.reshape %76 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %78 = stablehlo.reshape %arg6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %79 = stablehlo.reshape %78 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %80 = stablehlo.broadcast_in_dim %79, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %81 = stablehlo.add %77, %80 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x512xbf16>
    %82 = stablehlo.reshape %81 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %83 = stablehlo.transpose %82, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %84 = stablehlo.reshape %arg18 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %85 = stablehlo.reshape %84 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %86 = stablehlo.convert %85 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
    %87 = stablehlo.broadcast_in_dim %86, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %88 = stablehlo.reshape %arg15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %89 = stablehlo.reshape %88 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %90 = stablehlo.transpose %89, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %91 = stablehlo.dot_general %31, %90, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %92 = stablehlo.reshape %91 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %93 = stablehlo.reshape %arg14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %94 = stablehlo.reshape %93 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %95 = stablehlo.broadcast_in_dim %94, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
    %96 = stablehlo.add %92, %95 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x3584xbf16>
    %97 = stablehlo.reshape %96 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
    %98 = stablehlo.transpose %97, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
    %99 = stablehlo.convert %98 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %100 = stablehlo.broadcast_in_dim %55, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %101 = stablehlo.multiply %99, %100 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xf32>
    %102 = stablehlo.convert %101 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %103 = stablehlo.slice %98 [0:2, 0:28, 0:39, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %104 = stablehlo.negate %103 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x64xbf16>
    %105 = stablehlo.slice %98 [0:2, 0:28, 0:39, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %106 = stablehlo.concatenate %104, %105, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
    %107 = stablehlo.convert %106 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %108 = stablehlo.broadcast_in_dim %68, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %109 = stablehlo.multiply %107, %108 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xf32>
    %110 = stablehlo.convert %109 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %111 = stablehlo.add %102, %110 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xbf16>
    %112 = stablehlo.reshape %111 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
    %113 = stablehlo.broadcast_in_dim %72, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %114 = stablehlo.reshape %113 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %115 = stablehlo.transpose %114, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
    %116 = stablehlo.reshape %115 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
    %117 = stablehlo.dot_general %112, %116, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
    %118 = stablehlo.reshape %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %119 = stablehlo.convert %118 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %120 = stablehlo.multiply %119, %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %121 = stablehlo.convert %120 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %122 = stablehlo.reshape %arg11 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %123 = stablehlo.convert %122 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %124 = stablehlo.reshape %123 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %125 = stablehlo.broadcast_in_dim %124, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %126 = stablehlo.add %12, %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xbf16>
    %127 = stablehlo.compare  EQ, %126, %1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %128 = stablehlo.select %127, %0, %12 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    %129 = stablehlo.reshape %128 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
    %130 = stablehlo.broadcast_in_dim %129, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %131 = stablehlo.add %121, %130 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xbf16>
    %132 = stablehlo.convert %131 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %133 = stablehlo.reduce(%132 init: %cst_0) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %134 = stablehlo.broadcast_in_dim %133, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %135 = stablehlo.subtract %132, %134 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %136 = stablehlo.exponential %135 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %137 = stablehlo.reduce(%136 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %138 = stablehlo.broadcast_in_dim %137, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %139 = stablehlo.divide %136, %138 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %140 = stablehlo.convert %139 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %141 = stablehlo.reshape %140 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
    %142 = stablehlo.broadcast_in_dim %83, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %143 = stablehlo.reshape %142 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
    %144 = stablehlo.dot_general %141, %143, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
    %145 = stablehlo.reshape %144 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %146 = stablehlo.transpose %145, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
    %147 = stablehlo.reshape %146 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
    %148 = stablehlo.reshape %arg10 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %149 = stablehlo.reshape %148 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %150 = stablehlo.transpose %149, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %151 = stablehlo.dot_general %147, %150, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %152 = stablehlo.reshape %151 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %153 = stablehlo.add %arg4, %152 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xbf16>
    %154 = stablehlo.reshape %arg16 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %155 = stablehlo.reshape %154 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %156 = stablehlo.convert %155 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
    %157 = stablehlo.broadcast_in_dim %156, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %158 = stablehlo.convert %153 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %159 = stablehlo.power %158, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %160 = stablehlo.reduce(%159 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %161 = stablehlo.multiply %160, %4 : tensor<2x39xf32>
    %162 = stablehlo.reshape %161 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %163 = stablehlo.add %162, %3 : tensor<2x39x1xf32>
    %164 = stablehlo.rsqrt %163 : tensor<2x39x1xf32>
    %165 = stablehlo.reshape %164 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %166 = stablehlo.broadcast_in_dim %165, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %167 = stablehlo.multiply %158, %166 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %168 = stablehlo.convert %167 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %169 = stablehlo.convert %168 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %170 = stablehlo.multiply %157, %169 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %171 = stablehlo.convert %170 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %172 = stablehlo.reshape %171 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %173 = stablehlo.reshape %arg17 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %174 = stablehlo.reshape %173 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %175 = stablehlo.transpose %174, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %176 = stablehlo.dot_general %172, %175, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %177 = stablehlo.reshape %176 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %178 = stablehlo.convert %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %179 = stablehlo.logistic %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xbf16>
    %180 = stablehlo.convert %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %181 = stablehlo.multiply %178, %180 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xf32>
    %182 = stablehlo.convert %181 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %183 = stablehlo.convert %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %184 = stablehlo.reshape %arg9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %185 = stablehlo.reshape %184 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %186 = stablehlo.transpose %185, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %187 = stablehlo.dot_general %172, %186, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %188 = stablehlo.reshape %187 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %189 = stablehlo.convert %188 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %190 = stablehlo.multiply %183, %189 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xf32>
    %191 = stablehlo.convert %190 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %192 = stablehlo.reshape %191 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
    %193 = stablehlo.reshape %arg8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
    %194 = stablehlo.reshape %193 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
    %195 = stablehlo.transpose %194, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
    %196 = stablehlo.dot_general %192, %195, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
    %197 = stablehlo.reshape %196 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %198 = stablehlo.add %153, %197 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xbf16>
    %199 = stablehlo.convert %198 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %200 = stablehlo.power %199, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %201 = stablehlo.reduce(%200 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %202 = stablehlo.multiply %201, %4 : tensor<2x39xf32>
    %203 = stablehlo.reshape %202 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %204 = stablehlo.add %203, %3 : tensor<2x39x1xf32>
    %205 = stablehlo.rsqrt %204 : tensor<2x39x1xf32>
    %206 = stablehlo.reshape %205 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %207 = stablehlo.broadcast_in_dim %206, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %208 = stablehlo.multiply %199, %207 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %209 = stablehlo.convert %208 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %210 = stablehlo.convert %209 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %211 = stablehlo.multiply %87, %210 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %212 = stablehlo.convert %211 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    return %72, %83, %212 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


// -----// IR Dump Before InsertExplicitReshardsPass (sdy-insert-explicit-reshards) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___rotary_emb_inv_freq"}, %arg2: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, %arg3: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, %arg4: tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg5: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, %arg6: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, %arg7: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, %arg8: tensor<3584x18944xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, %arg9: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, %arg10: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, %arg11: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg12: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg13: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg14: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, %arg15: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, %arg16: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, %arg17: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, %arg18: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___norm_weight"}) -> (tensor<2x4x39x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x4x39x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"_axis_0", ?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
    %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
    %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_5, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_4, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<2x28x39x39xf32>
    %3 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
    %4 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
    %5 = stablehlo.broadcast_in_dim %cst_1, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<f32>) -> tensor<2x39x3584xf32>
    %6 = stablehlo.convert %arg13 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %7 = stablehlo.convert %arg12 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %8 = stablehlo.multiply %6, %7 : tensor<39x39xf32>
    %9 = stablehlo.convert %8 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %10 = sdy.reshard %9 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
    %11 = stablehlo.reshape %10 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.reshape %arg5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %14 = stablehlo.reshape %13 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %15 = stablehlo.convert %14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
    %16 = stablehlo.broadcast_in_dim %15, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %17 = stablehlo.convert %arg4 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %18 = stablehlo.power %17, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %19 = stablehlo.reduce(%18 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %20 = stablehlo.multiply %19, %4 : tensor<2x39xf32>
    %21 = stablehlo.reshape %20 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %22 = stablehlo.add %21, %3 : tensor<2x39x1xf32>
    %23 = stablehlo.rsqrt %22 : tensor<2x39x1xf32>
    %24 = stablehlo.reshape %23 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %25 = stablehlo.broadcast_in_dim %24, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %26 = stablehlo.multiply %17, %25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %27 = stablehlo.convert %26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %28 = stablehlo.convert %27 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %29 = stablehlo.multiply %16, %28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %30 = stablehlo.convert %29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %31 = stablehlo.reshape %30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %32 = stablehlo.reshape %arg3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %33 = stablehlo.reshape %32 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %34 = stablehlo.transpose %33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %35 = stablehlo.dot_general %31, %34, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %36 = stablehlo.reshape %35 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %37 = stablehlo.reshape %arg2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %38 = stablehlo.reshape %37 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %39 = stablehlo.broadcast_in_dim %38, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %40 = stablehlo.add %36, %39 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x512xbf16>
    %41 = stablehlo.reshape %40 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %42 = stablehlo.transpose %41, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %43 = stablehlo.convert %42 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %44 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.reshape %arg0 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
    %47 = stablehlo.convert %46 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
    %48 = stablehlo.dot_general %45, %47, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
    %49 = stablehlo.transpose %48, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
    %50 = stablehlo.concatenate %49, %49, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
    %51 = stablehlo.cosine %50 : tensor<1x39x128xf32>
    %52 = stablehlo.convert %51 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %53 = stablehlo.reshape %52 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %54 = stablehlo.convert %53 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %55 = stablehlo.reshape %54 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %56 = stablehlo.broadcast_in_dim %55, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %57 = stablehlo.multiply %43, %56 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xf32>
    %58 = stablehlo.convert %57 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %59 = stablehlo.slice %42 [0:2, 0:4, 0:39, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %60 = stablehlo.negate %59 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x64xbf16>
    %61 = stablehlo.slice %42 [0:2, 0:4, 0:39, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %62 = stablehlo.concatenate %60, %61, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
    %63 = stablehlo.convert %62 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %64 = stablehlo.sine %50 : tensor<1x39x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %66 = stablehlo.reshape %65 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %67 = stablehlo.convert %66 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %68 = stablehlo.reshape %67 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %69 = stablehlo.broadcast_in_dim %68, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %70 = stablehlo.multiply %63, %69 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xf32>
    %71 = stablehlo.convert %70 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %72 = stablehlo.add %58, %71 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xbf16>
    %73 = stablehlo.reshape %arg7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %74 = stablehlo.reshape %73 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %76 = stablehlo.dot_general %31, %75, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %77 = stablehlo.reshape %76 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %78 = stablehlo.reshape %arg6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %79 = stablehlo.reshape %78 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %80 = stablehlo.broadcast_in_dim %79, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %81 = stablehlo.add %77, %80 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x512xbf16>
    %82 = stablehlo.reshape %81 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %83 = stablehlo.transpose %82, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %84 = stablehlo.reshape %arg18 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %85 = stablehlo.reshape %84 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %86 = stablehlo.convert %85 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
    %87 = stablehlo.broadcast_in_dim %86, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %88 = stablehlo.reshape %arg15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %89 = stablehlo.reshape %88 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %90 = stablehlo.transpose %89, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %91 = stablehlo.dot_general %31, %90, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %92 = stablehlo.reshape %91 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %93 = stablehlo.reshape %arg14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %94 = stablehlo.reshape %93 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %95 = stablehlo.broadcast_in_dim %94, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
    %96 = stablehlo.add %92, %95 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x3584xbf16>
    %97 = stablehlo.reshape %96 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
    %98 = stablehlo.transpose %97, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
    %99 = stablehlo.convert %98 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %100 = stablehlo.broadcast_in_dim %55, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %101 = stablehlo.multiply %99, %100 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xf32>
    %102 = stablehlo.convert %101 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %103 = stablehlo.slice %98 [0:2, 0:28, 0:39, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %104 = stablehlo.negate %103 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x64xbf16>
    %105 = stablehlo.slice %98 [0:2, 0:28, 0:39, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %106 = stablehlo.concatenate %104, %105, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
    %107 = stablehlo.convert %106 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %108 = stablehlo.broadcast_in_dim %68, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %109 = stablehlo.multiply %107, %108 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xf32>
    %110 = stablehlo.convert %109 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %111 = stablehlo.add %102, %110 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xbf16>
    %112 = stablehlo.reshape %111 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
    %113 = stablehlo.broadcast_in_dim %72, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %114 = stablehlo.reshape %113 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %115 = stablehlo.transpose %114, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
    %116 = stablehlo.reshape %115 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
    %117 = stablehlo.dot_general %112, %116, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
    %118 = stablehlo.reshape %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %119 = stablehlo.convert %118 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %120 = stablehlo.multiply %119, %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %121 = stablehlo.convert %120 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %122 = stablehlo.reshape %arg11 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %123 = stablehlo.convert %122 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %124 = stablehlo.reshape %123 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %125 = stablehlo.broadcast_in_dim %124, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %126 = stablehlo.add %12, %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xbf16>
    %127 = stablehlo.compare  EQ, %126, %1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %128 = stablehlo.select %127, %0, %12 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    %129 = stablehlo.reshape %128 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
    %130 = stablehlo.broadcast_in_dim %129, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %131 = stablehlo.add %121, %130 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xbf16>
    %132 = stablehlo.convert %131 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %133 = stablehlo.reduce(%132 init: %cst_0) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %134 = stablehlo.broadcast_in_dim %133, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %135 = stablehlo.subtract %132, %134 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %136 = stablehlo.exponential %135 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %137 = stablehlo.reduce(%136 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %138 = stablehlo.broadcast_in_dim %137, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %139 = stablehlo.divide %136, %138 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %140 = stablehlo.convert %139 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %141 = stablehlo.reshape %140 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
    %142 = stablehlo.broadcast_in_dim %83, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %143 = stablehlo.reshape %142 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
    %144 = stablehlo.dot_general %141, %143, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
    %145 = stablehlo.reshape %144 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %146 = stablehlo.transpose %145, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
    %147 = stablehlo.reshape %146 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
    %148 = stablehlo.reshape %arg10 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %149 = stablehlo.reshape %148 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %150 = stablehlo.transpose %149, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %151 = stablehlo.dot_general %147, %150, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %152 = stablehlo.reshape %151 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %153 = stablehlo.add %arg4, %152 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xbf16>
    %154 = stablehlo.reshape %arg16 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %155 = stablehlo.reshape %154 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %156 = stablehlo.convert %155 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
    %157 = stablehlo.broadcast_in_dim %156, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %158 = stablehlo.convert %153 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %159 = stablehlo.power %158, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %160 = stablehlo.reduce(%159 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %161 = stablehlo.multiply %160, %4 : tensor<2x39xf32>
    %162 = stablehlo.reshape %161 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %163 = stablehlo.add %162, %3 : tensor<2x39x1xf32>
    %164 = stablehlo.rsqrt %163 : tensor<2x39x1xf32>
    %165 = stablehlo.reshape %164 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %166 = stablehlo.broadcast_in_dim %165, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %167 = stablehlo.multiply %158, %166 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %168 = stablehlo.convert %167 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %169 = stablehlo.convert %168 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %170 = stablehlo.multiply %157, %169 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %171 = stablehlo.convert %170 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %172 = stablehlo.reshape %171 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %173 = stablehlo.reshape %arg17 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %174 = stablehlo.reshape %173 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %175 = stablehlo.transpose %174, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %176 = stablehlo.dot_general %172, %175, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %177 = stablehlo.reshape %176 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %178 = stablehlo.convert %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %179 = stablehlo.logistic %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xbf16>
    %180 = stablehlo.convert %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %181 = stablehlo.multiply %178, %180 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xf32>
    %182 = stablehlo.convert %181 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %183 = stablehlo.convert %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %184 = stablehlo.reshape %arg9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %185 = stablehlo.reshape %184 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %186 = stablehlo.transpose %185, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %187 = stablehlo.dot_general %172, %186, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %188 = stablehlo.reshape %187 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %189 = stablehlo.convert %188 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %190 = stablehlo.multiply %183, %189 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xf32>
    %191 = stablehlo.convert %190 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %192 = stablehlo.reshape %191 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
    %193 = stablehlo.reshape %arg8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
    %194 = stablehlo.reshape %193 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
    %195 = stablehlo.transpose %194, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
    %196 = stablehlo.dot_general %192, %195, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
    %197 = stablehlo.reshape %196 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %198 = stablehlo.add %153, %197 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xbf16>
    %199 = stablehlo.convert %198 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %200 = stablehlo.power %199, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %201 = stablehlo.reduce(%200 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %202 = stablehlo.multiply %201, %4 : tensor<2x39xf32>
    %203 = stablehlo.reshape %202 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %204 = stablehlo.add %203, %3 : tensor<2x39x1xf32>
    %205 = stablehlo.rsqrt %204 : tensor<2x39x1xf32>
    %206 = stablehlo.reshape %205 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %207 = stablehlo.broadcast_in_dim %206, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %208 = stablehlo.multiply %199, %207 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %209 = stablehlo.convert %208 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %210 = stablehlo.convert %209 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %211 = stablehlo.multiply %87, %210 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %212 = stablehlo.convert %211 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    return %72, %83, %212 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


// -----// IR Dump After InsertExplicitReshardsPass (sdy-insert-explicit-reshards) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___rotary_emb_inv_freq"}, %arg2: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, %arg3: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, %arg4: tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg5: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, %arg6: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, %arg7: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, %arg8: tensor<3584x18944xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, %arg9: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, %arg10: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, %arg11: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg12: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg13: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg14: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, %arg15: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, %arg16: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, %arg17: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, %arg18: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___norm_weight"}) -> (tensor<2x4x39x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x4x39x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"_axis_0", ?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
    %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
    %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_5, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_4, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<2x28x39x39xf32>
    %3 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
    %4 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
    %5 = stablehlo.broadcast_in_dim %cst_1, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<f32>) -> tensor<2x39x3584xf32>
    %6 = stablehlo.convert %arg13 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %7 = stablehlo.convert %arg12 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %8 = stablehlo.multiply %6, %7 : tensor<39x39xf32>
    %9 = stablehlo.convert %8 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %10 = sdy.reshard %9 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
    %11 = stablehlo.reshape %10 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.reshape %arg5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %14 = stablehlo.reshape %13 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %15 = stablehlo.convert %14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
    %16 = stablehlo.broadcast_in_dim %15, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %17 = stablehlo.convert %arg4 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %18 = stablehlo.power %17, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %19 = stablehlo.reduce(%18 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %20 = sdy.all_reduce {"_axis_0"} %19 out_sharding=<@mesh, [{}, {}]> : tensor<2x39xf32>
    %21 = stablehlo.multiply %20, %4 : tensor<2x39xf32>
    %22 = stablehlo.reshape %21 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %23 = stablehlo.add %22, %3 : tensor<2x39x1xf32>
    %24 = stablehlo.rsqrt %23 : tensor<2x39x1xf32>
    %25 = stablehlo.reshape %24 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %26 = stablehlo.broadcast_in_dim %25, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %27 = stablehlo.multiply %17, %26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %28 = stablehlo.convert %27 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %29 = stablehlo.convert %28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %30 = stablehlo.multiply %16, %29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %31 = stablehlo.convert %30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %32 = stablehlo.reshape %31 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %33 = stablehlo.reshape %arg3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %34 = stablehlo.reshape %33 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %35 = stablehlo.transpose %34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %36 = stablehlo.dot_general %32, %35, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %37 = sdy.all_reduce {"_axis_0"} %36 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x512xbf16>
    %38 = sdy.reshard %37 <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]> : tensor<78x512xbf16>
    %39 = stablehlo.reshape %38 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %40 = stablehlo.reshape %arg2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %41 = stablehlo.reshape %40 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %42 = stablehlo.broadcast_in_dim %41, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %43 = stablehlo.add %39, %42 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x512xbf16>
    %44 = stablehlo.reshape %43 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %45 = stablehlo.transpose %44, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %46 = stablehlo.convert %45 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %47 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %48 = stablehlo.reshape %47 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %49 = stablehlo.reshape %arg0 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
    %50 = stablehlo.convert %49 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
    %51 = stablehlo.dot_general %48, %50, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
    %52 = stablehlo.transpose %51, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
    %53 = stablehlo.concatenate %52, %52, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
    %54 = stablehlo.cosine %53 : tensor<1x39x128xf32>
    %55 = stablehlo.convert %54 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %56 = stablehlo.reshape %55 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %57 = stablehlo.convert %56 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %58 = stablehlo.reshape %57 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %59 = stablehlo.broadcast_in_dim %58, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %60 = stablehlo.multiply %46, %59 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xf32>
    %61 = stablehlo.convert %60 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %62 = stablehlo.slice %45 [0:2, 0:4, 0:39, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %63 = stablehlo.negate %62 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x64xbf16>
    %64 = stablehlo.slice %45 [0:2, 0:4, 0:39, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %65 = stablehlo.concatenate %63, %64, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
    %66 = stablehlo.convert %65 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %67 = stablehlo.sine %53 : tensor<1x39x128xf32>
    %68 = stablehlo.convert %67 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %69 = stablehlo.reshape %68 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %70 = stablehlo.convert %69 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %71 = stablehlo.reshape %70 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %72 = stablehlo.broadcast_in_dim %71, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %73 = stablehlo.multiply %66, %72 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xf32>
    %74 = stablehlo.convert %73 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %75 = stablehlo.add %61, %74 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xbf16>
    %76 = stablehlo.reshape %arg7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %77 = stablehlo.reshape %76 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %78 = stablehlo.transpose %77, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %79 = stablehlo.dot_general %32, %78, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %80 = sdy.all_reduce {"_axis_0"} %79 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x512xbf16>
    %81 = sdy.reshard %80 <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]> : tensor<78x512xbf16>
    %82 = stablehlo.reshape %81 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %83 = stablehlo.reshape %arg6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %84 = stablehlo.reshape %83 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %85 = stablehlo.broadcast_in_dim %84, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %86 = stablehlo.add %82, %85 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x512xbf16>
    %87 = stablehlo.reshape %86 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %88 = stablehlo.transpose %87, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %89 = stablehlo.reshape %arg18 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %90 = stablehlo.reshape %89 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %91 = stablehlo.convert %90 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
    %92 = stablehlo.broadcast_in_dim %91, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %93 = stablehlo.reshape %arg15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %94 = stablehlo.reshape %93 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %95 = stablehlo.transpose %94, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %96 = stablehlo.dot_general %32, %95, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %97 = sdy.all_reduce {"_axis_0"} %96 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x3584xbf16>
    %98 = sdy.reshard %97 <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]> : tensor<78x3584xbf16>
    %99 = stablehlo.reshape %98 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %100 = stablehlo.reshape %arg14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %101 = stablehlo.reshape %100 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %102 = stablehlo.broadcast_in_dim %101, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
    %103 = stablehlo.add %99, %102 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x3584xbf16>
    %104 = stablehlo.reshape %103 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
    %105 = stablehlo.transpose %104, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
    %106 = stablehlo.convert %105 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %107 = stablehlo.broadcast_in_dim %58, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %108 = stablehlo.multiply %106, %107 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xf32>
    %109 = stablehlo.convert %108 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %110 = stablehlo.slice %105 [0:2, 0:28, 0:39, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %111 = stablehlo.negate %110 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x64xbf16>
    %112 = stablehlo.slice %105 [0:2, 0:28, 0:39, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %113 = stablehlo.concatenate %111, %112, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
    %114 = stablehlo.convert %113 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %115 = stablehlo.broadcast_in_dim %71, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %116 = stablehlo.multiply %114, %115 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xf32>
    %117 = stablehlo.convert %116 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %118 = stablehlo.add %109, %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xbf16>
    %119 = stablehlo.reshape %118 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
    %120 = stablehlo.broadcast_in_dim %75, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %121 = stablehlo.reshape %120 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %122 = stablehlo.transpose %121, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
    %123 = stablehlo.reshape %122 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
    %124 = stablehlo.dot_general %119, %123, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
    %125 = stablehlo.reshape %124 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %126 = stablehlo.convert %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %127 = stablehlo.multiply %126, %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %128 = stablehlo.convert %127 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %129 = stablehlo.reshape %arg11 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %130 = stablehlo.convert %129 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %131 = stablehlo.reshape %130 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %132 = stablehlo.broadcast_in_dim %131, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %133 = stablehlo.add %12, %132 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xbf16>
    %134 = stablehlo.compare  EQ, %133, %1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %135 = stablehlo.select %134, %0, %12 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    %136 = stablehlo.reshape %135 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
    %137 = stablehlo.broadcast_in_dim %136, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %138 = stablehlo.add %128, %137 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xbf16>
    %139 = stablehlo.convert %138 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %140 = stablehlo.reduce(%139 init: %cst_0) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %141 = stablehlo.broadcast_in_dim %140, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %142 = stablehlo.subtract %139, %141 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %143 = stablehlo.exponential %142 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %144 = stablehlo.reduce(%143 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %145 = stablehlo.broadcast_in_dim %144, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %146 = stablehlo.divide %143, %145 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %147 = stablehlo.convert %146 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %148 = stablehlo.reshape %147 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
    %149 = stablehlo.broadcast_in_dim %88, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %150 = stablehlo.reshape %149 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
    %151 = stablehlo.dot_general %148, %150, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
    %152 = stablehlo.reshape %151 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %153 = stablehlo.transpose %152, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
    %154 = stablehlo.reshape %153 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
    %155 = stablehlo.reshape %arg10 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %156 = stablehlo.reshape %155 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %157 = stablehlo.transpose %156, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %158 = sdy.reshard %154 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x3584xbf16>
    %159 = stablehlo.dot_general %158, %157, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %160 = sdy.all_reduce {"_axis_1"} %159 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<78x3584xbf16>
    %161 = stablehlo.reshape %160 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %162 = stablehlo.add %arg4, %161 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xbf16>
    %163 = stablehlo.reshape %arg16 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %164 = stablehlo.reshape %163 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %165 = stablehlo.convert %164 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
    %166 = stablehlo.broadcast_in_dim %165, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %167 = stablehlo.convert %162 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %168 = stablehlo.power %167, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %169 = stablehlo.reduce(%168 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %170 = sdy.all_reduce {"_axis_0"} %169 out_sharding=<@mesh, [{}, {}]> : tensor<2x39xf32>
    %171 = stablehlo.multiply %170, %4 : tensor<2x39xf32>
    %172 = stablehlo.reshape %171 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %173 = stablehlo.add %172, %3 : tensor<2x39x1xf32>
    %174 = stablehlo.rsqrt %173 : tensor<2x39x1xf32>
    %175 = stablehlo.reshape %174 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %176 = stablehlo.broadcast_in_dim %175, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %177 = stablehlo.multiply %167, %176 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %178 = stablehlo.convert %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %179 = stablehlo.convert %178 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %180 = stablehlo.multiply %166, %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %181 = stablehlo.convert %180 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %182 = stablehlo.reshape %181 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %183 = stablehlo.reshape %arg17 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %184 = stablehlo.reshape %183 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %185 = stablehlo.transpose %184, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %186 = stablehlo.dot_general %182, %185, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %187 = sdy.all_reduce {"_axis_0"} %186 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x18944xbf16>
    %188 = stablehlo.reshape %187 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %189 = stablehlo.convert %188 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %190 = stablehlo.logistic %188 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xbf16>
    %191 = stablehlo.convert %190 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %192 = stablehlo.multiply %189, %191 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xf32>
    %193 = stablehlo.convert %192 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %194 = stablehlo.convert %193 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %195 = stablehlo.reshape %arg9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %196 = stablehlo.reshape %195 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %197 = stablehlo.transpose %196, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %198 = stablehlo.dot_general %182, %197, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %199 = sdy.all_reduce {"_axis_0"} %198 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x18944xbf16>
    %200 = stablehlo.reshape %199 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %201 = stablehlo.convert %200 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %202 = stablehlo.multiply %194, %201 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xf32>
    %203 = stablehlo.convert %202 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %204 = stablehlo.reshape %203 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
    %205 = stablehlo.reshape %arg8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
    %206 = stablehlo.reshape %205 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
    %207 = stablehlo.transpose %206, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
    %208 = stablehlo.dot_general %204, %207, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
    %209 = sdy.all_reduce {"_axis_1"} %208 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<78x3584xbf16>
    %210 = stablehlo.reshape %209 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %211 = stablehlo.add %162, %210 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xbf16>
    %212 = stablehlo.convert %211 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %213 = stablehlo.power %212, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %214 = stablehlo.reduce(%213 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %215 = sdy.all_reduce {"_axis_0"} %214 out_sharding=<@mesh, [{}, {}]> : tensor<2x39xf32>
    %216 = stablehlo.multiply %215, %4 : tensor<2x39xf32>
    %217 = stablehlo.reshape %216 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %218 = stablehlo.add %217, %3 : tensor<2x39x1xf32>
    %219 = stablehlo.rsqrt %218 : tensor<2x39x1xf32>
    %220 = stablehlo.reshape %219 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %221 = stablehlo.broadcast_in_dim %220, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %222 = stablehlo.multiply %212, %221 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %223 = stablehlo.convert %222 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %224 = stablehlo.convert %223 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %225 = stablehlo.multiply %92, %224 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %226 = stablehlo.convert %225 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    return %75, %88, %226 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


// -----// IR Dump Before WrapUnderManualComputationPass (wrap-under-manual-computation) ('builtin.module' operation: @SyncTensorsGraph.420) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___rotary_emb_inv_freq"}, %arg2: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, %arg3: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, %arg4: tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg5: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, %arg6: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, %arg7: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, %arg8: tensor<3584x18944xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, %arg9: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, %arg10: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, %arg11: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg12: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg13: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg14: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, %arg15: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, %arg16: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, %arg17: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, %arg18: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___norm_weight"}) -> (tensor<2x4x39x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x4x39x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"_axis_0", ?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
    %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
    %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
    %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst_5, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.broadcast_in_dim %cst_4, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<2x28x39x39xf32>
    %3 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
    %4 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
    %5 = stablehlo.broadcast_in_dim %cst_1, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<f32>) -> tensor<2x39x3584xf32>
    %6 = stablehlo.convert %arg13 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %7 = stablehlo.convert %arg12 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %8 = stablehlo.multiply %6, %7 : tensor<39x39xf32>
    %9 = stablehlo.convert %8 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %10 = sdy.reshard %9 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
    %11 = stablehlo.reshape %10 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.reshape %arg5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %14 = stablehlo.reshape %13 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %15 = stablehlo.convert %14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
    %16 = stablehlo.broadcast_in_dim %15, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %17 = stablehlo.convert %arg4 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %18 = stablehlo.power %17, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %19 = stablehlo.reduce(%18 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %20 = sdy.all_reduce {"_axis_0"} %19 out_sharding=<@mesh, [{}, {}]> : tensor<2x39xf32>
    %21 = stablehlo.multiply %20, %4 : tensor<2x39xf32>
    %22 = stablehlo.reshape %21 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %23 = stablehlo.add %22, %3 : tensor<2x39x1xf32>
    %24 = stablehlo.rsqrt %23 : tensor<2x39x1xf32>
    %25 = stablehlo.reshape %24 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %26 = stablehlo.broadcast_in_dim %25, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %27 = stablehlo.multiply %17, %26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %28 = stablehlo.convert %27 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %29 = stablehlo.convert %28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %30 = stablehlo.multiply %16, %29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %31 = stablehlo.convert %30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %32 = stablehlo.reshape %31 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %33 = stablehlo.reshape %arg3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %34 = stablehlo.reshape %33 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %35 = stablehlo.transpose %34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %36 = stablehlo.dot_general %32, %35, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %37 = sdy.all_reduce {"_axis_0"} %36 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x512xbf16>
    %38 = sdy.reshard %37 <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]> : tensor<78x512xbf16>
    %39 = stablehlo.reshape %38 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %40 = stablehlo.reshape %arg2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %41 = stablehlo.reshape %40 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %42 = stablehlo.broadcast_in_dim %41, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %43 = stablehlo.add %39, %42 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x512xbf16>
    %44 = stablehlo.reshape %43 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %45 = stablehlo.transpose %44, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %46 = stablehlo.convert %45 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %47 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %48 = stablehlo.reshape %47 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %49 = stablehlo.reshape %arg0 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
    %50 = stablehlo.convert %49 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
    %51 = stablehlo.dot_general %48, %50, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
    %52 = stablehlo.transpose %51, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
    %53 = stablehlo.concatenate %52, %52, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
    %54 = stablehlo.cosine %53 : tensor<1x39x128xf32>
    %55 = stablehlo.convert %54 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %56 = stablehlo.reshape %55 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %57 = stablehlo.convert %56 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %58 = stablehlo.reshape %57 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %59 = stablehlo.broadcast_in_dim %58, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %60 = stablehlo.multiply %46, %59 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xf32>
    %61 = stablehlo.convert %60 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %62 = stablehlo.slice %45 [0:2, 0:4, 0:39, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %63 = stablehlo.negate %62 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x64xbf16>
    %64 = stablehlo.slice %45 [0:2, 0:4, 0:39, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
    %65 = stablehlo.concatenate %63, %64, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
    %66 = stablehlo.convert %65 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
    %67 = stablehlo.sine %53 : tensor<1x39x128xf32>
    %68 = stablehlo.convert %67 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
    %69 = stablehlo.reshape %68 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
    %70 = stablehlo.convert %69 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
    %71 = stablehlo.reshape %70 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
    %72 = stablehlo.broadcast_in_dim %71, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
    %73 = stablehlo.multiply %66, %72 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xf32>
    %74 = stablehlo.convert %73 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
    %75 = stablehlo.add %61, %74 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xbf16>
    %76 = stablehlo.reshape %arg7 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
    %77 = stablehlo.reshape %76 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
    %78 = stablehlo.transpose %77, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
    %79 = stablehlo.dot_general %32, %78, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
    %80 = sdy.all_reduce {"_axis_0"} %79 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x512xbf16>
    %81 = sdy.reshard %80 <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]> : tensor<78x512xbf16>
    %82 = stablehlo.reshape %81 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
    %83 = stablehlo.reshape %arg6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %84 = stablehlo.reshape %83 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %85 = stablehlo.broadcast_in_dim %84, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
    %86 = stablehlo.add %82, %85 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x512xbf16>
    %87 = stablehlo.reshape %86 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
    %88 = stablehlo.transpose %87, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
    %89 = stablehlo.reshape %arg18 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %90 = stablehlo.reshape %89 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %91 = stablehlo.convert %90 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
    %92 = stablehlo.broadcast_in_dim %91, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %93 = stablehlo.reshape %arg15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %94 = stablehlo.reshape %93 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %95 = stablehlo.transpose %94, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %96 = stablehlo.dot_general %32, %95, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %97 = sdy.all_reduce {"_axis_0"} %96 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x3584xbf16>
    %98 = sdy.reshard %97 <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]> : tensor<78x3584xbf16>
    %99 = stablehlo.reshape %98 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %100 = stablehlo.reshape %arg14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %101 = stablehlo.reshape %100 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %102 = stablehlo.broadcast_in_dim %101, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
    %103 = stablehlo.add %99, %102 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x3584xbf16>
    %104 = stablehlo.reshape %103 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
    %105 = stablehlo.transpose %104, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
    %106 = stablehlo.convert %105 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %107 = stablehlo.broadcast_in_dim %58, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %108 = stablehlo.multiply %106, %107 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xf32>
    %109 = stablehlo.convert %108 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %110 = stablehlo.slice %105 [0:2, 0:28, 0:39, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %111 = stablehlo.negate %110 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x64xbf16>
    %112 = stablehlo.slice %105 [0:2, 0:28, 0:39, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
    %113 = stablehlo.concatenate %111, %112, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
    %114 = stablehlo.convert %113 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
    %115 = stablehlo.broadcast_in_dim %71, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
    %116 = stablehlo.multiply %114, %115 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xf32>
    %117 = stablehlo.convert %116 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
    %118 = stablehlo.add %109, %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xbf16>
    %119 = stablehlo.reshape %118 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
    %120 = stablehlo.broadcast_in_dim %75, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %121 = stablehlo.reshape %120 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %122 = stablehlo.transpose %121, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
    %123 = stablehlo.reshape %122 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
    %124 = stablehlo.dot_general %119, %123, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
    %125 = stablehlo.reshape %124 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %126 = stablehlo.convert %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %127 = stablehlo.multiply %126, %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %128 = stablehlo.convert %127 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %129 = stablehlo.reshape %arg11 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %130 = stablehlo.convert %129 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %131 = stablehlo.reshape %130 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %132 = stablehlo.broadcast_in_dim %131, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %133 = stablehlo.add %12, %132 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xbf16>
    %134 = stablehlo.compare  EQ, %133, %1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %135 = stablehlo.select %134, %0, %12 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    %136 = stablehlo.reshape %135 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
    %137 = stablehlo.broadcast_in_dim %136, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
    %138 = stablehlo.add %128, %137 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xbf16>
    %139 = stablehlo.convert %138 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
    %140 = stablehlo.reduce(%139 init: %cst_0) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %141 = stablehlo.broadcast_in_dim %140, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %142 = stablehlo.subtract %139, %141 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %143 = stablehlo.exponential %142 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %144 = stablehlo.reduce(%143 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
    %145 = stablehlo.broadcast_in_dim %144, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
    %146 = stablehlo.divide %143, %145 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
    %147 = stablehlo.convert %146 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
    %148 = stablehlo.reshape %147 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
    %149 = stablehlo.broadcast_in_dim %88, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
    %150 = stablehlo.reshape %149 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
    %151 = stablehlo.dot_general %148, %150, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
    %152 = stablehlo.reshape %151 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
    %153 = stablehlo.transpose %152, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
    %154 = stablehlo.reshape %153 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
    %155 = stablehlo.reshape %arg10 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
    %156 = stablehlo.reshape %155 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %157 = stablehlo.transpose %156, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
    %158 = sdy.reshard %154 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x3584xbf16>
    %159 = stablehlo.dot_general %158, %157, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
    %160 = sdy.all_reduce {"_axis_1"} %159 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<78x3584xbf16>
    %161 = stablehlo.reshape %160 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %162 = stablehlo.add %arg4, %161 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xbf16>
    %163 = stablehlo.reshape %arg16 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
    %164 = stablehlo.reshape %163 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
    %165 = stablehlo.convert %164 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
    %166 = stablehlo.broadcast_in_dim %165, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
    %167 = stablehlo.convert %162 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %168 = stablehlo.power %167, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %169 = stablehlo.reduce(%168 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %170 = sdy.all_reduce {"_axis_0"} %169 out_sharding=<@mesh, [{}, {}]> : tensor<2x39xf32>
    %171 = stablehlo.multiply %170, %4 : tensor<2x39xf32>
    %172 = stablehlo.reshape %171 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %173 = stablehlo.add %172, %3 : tensor<2x39x1xf32>
    %174 = stablehlo.rsqrt %173 : tensor<2x39x1xf32>
    %175 = stablehlo.reshape %174 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %176 = stablehlo.broadcast_in_dim %175, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %177 = stablehlo.multiply %167, %176 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %178 = stablehlo.convert %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %179 = stablehlo.convert %178 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %180 = stablehlo.multiply %166, %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %181 = stablehlo.convert %180 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %182 = stablehlo.reshape %181 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
    %183 = stablehlo.reshape %arg17 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %184 = stablehlo.reshape %183 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %185 = stablehlo.transpose %184, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %186 = stablehlo.dot_general %182, %185, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %187 = sdy.all_reduce {"_axis_0"} %186 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x18944xbf16>
    %188 = stablehlo.reshape %187 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %189 = stablehlo.convert %188 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %190 = stablehlo.logistic %188 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xbf16>
    %191 = stablehlo.convert %190 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %192 = stablehlo.multiply %189, %191 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xf32>
    %193 = stablehlo.convert %192 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %194 = stablehlo.convert %193 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %195 = stablehlo.reshape %arg9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
    %196 = stablehlo.reshape %195 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
    %197 = stablehlo.transpose %196, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
    %198 = stablehlo.dot_general %182, %197, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
    %199 = sdy.all_reduce {"_axis_0"} %198 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x18944xbf16>
    %200 = stablehlo.reshape %199 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
    %201 = stablehlo.convert %200 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
    %202 = stablehlo.multiply %194, %201 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xf32>
    %203 = stablehlo.convert %202 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
    %204 = stablehlo.reshape %203 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
    %205 = stablehlo.reshape %arg8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
    %206 = stablehlo.reshape %205 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
    %207 = stablehlo.transpose %206, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
    %208 = stablehlo.dot_general %204, %207, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
    %209 = sdy.all_reduce {"_axis_1"} %208 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<78x3584xbf16>
    %210 = stablehlo.reshape %209 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
    %211 = stablehlo.add %162, %210 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xbf16>
    %212 = stablehlo.convert %211 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %213 = stablehlo.power %212, %5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %214 = stablehlo.reduce(%213 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
    %215 = sdy.all_reduce {"_axis_0"} %214 out_sharding=<@mesh, [{}, {}]> : tensor<2x39xf32>
    %216 = stablehlo.multiply %215, %4 : tensor<2x39xf32>
    %217 = stablehlo.reshape %216 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
    %218 = stablehlo.add %217, %3 : tensor<2x39x1xf32>
    %219 = stablehlo.rsqrt %218 : tensor<2x39x1xf32>
    %220 = stablehlo.reshape %219 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
    %221 = stablehlo.broadcast_in_dim %220, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
    %222 = stablehlo.multiply %212, %221 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %223 = stablehlo.convert %222 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    %224 = stablehlo.convert %223 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
    %225 = stablehlo.multiply %92, %224 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
    %226 = stablehlo.convert %225 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
    return %75, %88, %226 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


// -----// IR Dump After WrapUnderManualComputationPass (wrap-under-manual-computation) ('builtin.module' operation: @SyncTensorsGraph.420) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___rotary_emb_inv_freq"}, %arg2: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, %arg3: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, %arg4: tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg5: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, %arg6: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, %arg7: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, %arg8: tensor<3584x18944xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, %arg9: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, %arg10: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, %arg11: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg12: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg13: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg14: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, %arg15: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, %arg16: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, %arg17: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, %arg18: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___norm_weight"}) -> (tensor<2x4x39x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x4x39x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"_axis_0", ?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14, %arg15, %arg16, %arg17, %arg18) in_shardings=[<@mesh, [{?}, {?}]>, <@mesh, [{?}]>, <@mesh, [{"_axis_1", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{?}, {?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}]>, <@mesh, [{"_axis_1", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, <@mesh, [{"_axis_0", ?}, {?}]>, <@mesh, [{?}, {?}]>, <@mesh, [{?}, {?}]>, <@mesh, [{"_axis_1", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}]>] out_shardings=[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, <@mesh, [{?}, {?}, {"_axis_0", ?}]>] manual_axes={} (%arg19: tensor<1x39xi64>, %arg20: tensor<64xf32>, %arg21: tensor<512xbf16>, %arg22: tensor<512x3584xbf16>, %arg23: tensor<2x39x3584xbf16>, %arg24: tensor<3584xbf16>, %arg25: tensor<512xbf16>, %arg26: tensor<512x3584xbf16>, %arg27: tensor<3584x18944xbf16>, %arg28: tensor<18944x3584xbf16>, %arg29: tensor<3584x3584xbf16>, %arg30: tensor<2x39xi64>, %arg31: tensor<39x39xi1>, %arg32: tensor<39x39xbf16>, %arg33: tensor<3584xbf16>, %arg34: tensor<3584x3584xbf16>, %arg35: tensor<3584xbf16>, %arg36: tensor<18944x3584xbf16>, %arg37: tensor<3584xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
      %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
      %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
      %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
      %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
      %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
      %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_6, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
      %2 = stablehlo.broadcast_in_dim %cst_5, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
      %3 = stablehlo.broadcast_in_dim %cst_4, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<2x28x39x39xf32>
      %4 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
      %5 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
      %6 = stablehlo.broadcast_in_dim %cst_1, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<f32>) -> tensor<2x39x3584xf32>
      %7 = stablehlo.convert %arg32 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
      %8 = stablehlo.convert %arg31 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
      %9 = stablehlo.multiply %7, %8 : tensor<39x39xf32>
      %10 = stablehlo.convert %9 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
      %11 = sdy.reshard %10 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
      %12 = stablehlo.reshape %11 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
      %13 = stablehlo.broadcast_in_dim %12, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
      %14 = stablehlo.reshape %arg24 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
      %15 = stablehlo.reshape %14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
      %16 = stablehlo.convert %15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
      %17 = stablehlo.broadcast_in_dim %16, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
      %18 = stablehlo.convert %arg23 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %19 = stablehlo.power %18, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
      %21 = sdy.all_reduce {"_axis_0"} %20 out_sharding=<@mesh, [{}, {}]> : tensor<2x39xf32>
      %22 = stablehlo.multiply %21, %5 : tensor<2x39xf32>
      %23 = stablehlo.reshape %22 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
      %24 = stablehlo.add %23, %4 : tensor<2x39x1xf32>
      %25 = stablehlo.rsqrt %24 : tensor<2x39x1xf32>
      %26 = stablehlo.reshape %25 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
      %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
      %28 = stablehlo.multiply %18, %27 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %29 = stablehlo.convert %28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      %30 = stablehlo.convert %29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %31 = stablehlo.multiply %17, %30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %32 = stablehlo.convert %31 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      %33 = stablehlo.reshape %32 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
      %34 = stablehlo.reshape %arg22 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
      %35 = stablehlo.reshape %34 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
      %36 = stablehlo.transpose %35, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
      %37 = stablehlo.dot_general %33, %36, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
      %38 = sdy.all_reduce {"_axis_0"} %37 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x512xbf16>
      %39 = sdy.reshard %38 <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]> : tensor<78x512xbf16>
      %40 = stablehlo.reshape %39 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
      %41 = stablehlo.reshape %arg21 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
      %42 = stablehlo.reshape %41 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
      %43 = stablehlo.broadcast_in_dim %42, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
      %44 = stablehlo.add %40, %43 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x512xbf16>
      %45 = stablehlo.reshape %44 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
      %46 = stablehlo.transpose %45, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
      %47 = stablehlo.convert %46 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
      %48 = stablehlo.reshape %arg20 : (tensor<64xf32>) -> tensor<1x1x64xf32>
      %49 = stablehlo.reshape %48 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
      %50 = stablehlo.reshape %arg19 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
      %51 = stablehlo.convert %50 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
      %52 = stablehlo.dot_general %49, %51, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
      %53 = stablehlo.transpose %52, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
      %54 = stablehlo.concatenate %53, %53, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
      %55 = stablehlo.cosine %54 : tensor<1x39x128xf32>
      %56 = stablehlo.convert %55 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
      %57 = stablehlo.reshape %56 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
      %58 = stablehlo.convert %57 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
      %59 = stablehlo.reshape %58 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
      %60 = stablehlo.broadcast_in_dim %59, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
      %61 = stablehlo.multiply %47, %60 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xf32>
      %62 = stablehlo.convert %61 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
      %63 = stablehlo.slice %46 [0:2, 0:4, 0:39, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
      %64 = stablehlo.negate %63 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x64xbf16>
      %65 = stablehlo.slice %46 [0:2, 0:4, 0:39, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
      %66 = stablehlo.concatenate %64, %65, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
      %67 = stablehlo.convert %66 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
      %68 = stablehlo.sine %54 : tensor<1x39x128xf32>
      %69 = stablehlo.convert %68 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
      %70 = stablehlo.reshape %69 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
      %71 = stablehlo.convert %70 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
      %72 = stablehlo.reshape %71 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
      %73 = stablehlo.broadcast_in_dim %72, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
      %74 = stablehlo.multiply %67, %73 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xf32>
      %75 = stablehlo.convert %74 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
      %76 = stablehlo.add %62, %75 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xbf16>
      %77 = stablehlo.reshape %arg26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
      %78 = stablehlo.reshape %77 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
      %79 = stablehlo.transpose %78, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
      %80 = stablehlo.dot_general %33, %79, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
      %81 = sdy.all_reduce {"_axis_0"} %80 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x512xbf16>
      %82 = sdy.reshard %81 <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]> : tensor<78x512xbf16>
      %83 = stablehlo.reshape %82 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
      %84 = stablehlo.reshape %arg25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
      %85 = stablehlo.reshape %84 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
      %86 = stablehlo.broadcast_in_dim %85, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
      %87 = stablehlo.add %83, %86 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x512xbf16>
      %88 = stablehlo.reshape %87 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
      %89 = stablehlo.transpose %88, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
      %90 = stablehlo.reshape %arg37 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
      %91 = stablehlo.reshape %90 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
      %92 = stablehlo.convert %91 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
      %93 = stablehlo.broadcast_in_dim %92, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
      %94 = stablehlo.reshape %arg34 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
      %95 = stablehlo.reshape %94 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
      %96 = stablehlo.transpose %95, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
      %97 = stablehlo.dot_general %33, %96, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
      %98 = sdy.all_reduce {"_axis_0"} %97 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x3584xbf16>
      %99 = sdy.reshard %98 <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]> : tensor<78x3584xbf16>
      %100 = stablehlo.reshape %99 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
      %101 = stablehlo.reshape %arg33 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
      %102 = stablehlo.reshape %101 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
      %103 = stablehlo.broadcast_in_dim %102, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
      %104 = stablehlo.add %100, %103 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x3584xbf16>
      %105 = stablehlo.reshape %104 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
      %106 = stablehlo.transpose %105, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
      %107 = stablehlo.convert %106 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
      %108 = stablehlo.broadcast_in_dim %59, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
      %109 = stablehlo.multiply %107, %108 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xf32>
      %110 = stablehlo.convert %109 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
      %111 = stablehlo.slice %106 [0:2, 0:28, 0:39, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
      %112 = stablehlo.negate %111 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x64xbf16>
      %113 = stablehlo.slice %106 [0:2, 0:28, 0:39, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
      %114 = stablehlo.concatenate %112, %113, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
      %115 = stablehlo.convert %114 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
      %116 = stablehlo.broadcast_in_dim %72, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
      %117 = stablehlo.multiply %115, %116 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xf32>
      %118 = stablehlo.convert %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
      %119 = stablehlo.add %110, %118 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xbf16>
      %120 = stablehlo.reshape %119 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
      %121 = stablehlo.broadcast_in_dim %76, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
      %122 = stablehlo.reshape %121 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
      %123 = stablehlo.transpose %122, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
      %124 = stablehlo.reshape %123 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
      %125 = stablehlo.dot_general %120, %124, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
      %126 = stablehlo.reshape %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
      %127 = stablehlo.convert %126 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
      %128 = stablehlo.multiply %127, %3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
      %129 = stablehlo.convert %128 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
      %130 = stablehlo.reshape %arg30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
      %131 = stablehlo.convert %130 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
      %132 = stablehlo.reshape %131 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
      %133 = stablehlo.broadcast_in_dim %132, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
      %134 = stablehlo.add %13, %133 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xbf16>
      %135 = stablehlo.compare  EQ, %134, %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
      %136 = stablehlo.select %135, %1, %13 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
      %137 = stablehlo.reshape %136 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
      %138 = stablehlo.broadcast_in_dim %137, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
      %139 = stablehlo.add %129, %138 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xbf16>
      %140 = stablehlo.convert %139 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
      %141 = stablehlo.reduce(%140 init: %cst_0) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
      %142 = stablehlo.broadcast_in_dim %141, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
      %143 = stablehlo.subtract %140, %142 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
      %144 = stablehlo.exponential %143 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
      %145 = stablehlo.reduce(%144 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
      %146 = stablehlo.broadcast_in_dim %145, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
      %147 = stablehlo.divide %144, %146 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
      %148 = stablehlo.convert %147 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
      %149 = stablehlo.reshape %148 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
      %150 = stablehlo.broadcast_in_dim %89, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
      %151 = stablehlo.reshape %150 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
      %152 = stablehlo.dot_general %149, %151, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
      %153 = stablehlo.reshape %152 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
      %154 = stablehlo.transpose %153, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
      %155 = stablehlo.reshape %154 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
      %156 = stablehlo.reshape %arg29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
      %157 = stablehlo.reshape %156 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
      %158 = stablehlo.transpose %157, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
      %159 = sdy.reshard %155 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x3584xbf16>
      %160 = stablehlo.dot_general %159, %158, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
      %161 = sdy.all_reduce {"_axis_1"} %160 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<78x3584xbf16>
      %162 = stablehlo.reshape %161 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
      %163 = stablehlo.add %arg23, %162 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xbf16>
      %164 = stablehlo.reshape %arg35 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
      %165 = stablehlo.reshape %164 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
      %166 = stablehlo.convert %165 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
      %167 = stablehlo.broadcast_in_dim %166, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
      %168 = stablehlo.convert %163 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %169 = stablehlo.power %168, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %170 = stablehlo.reduce(%169 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
      %171 = sdy.all_reduce {"_axis_0"} %170 out_sharding=<@mesh, [{}, {}]> : tensor<2x39xf32>
      %172 = stablehlo.multiply %171, %5 : tensor<2x39xf32>
      %173 = stablehlo.reshape %172 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
      %174 = stablehlo.add %173, %4 : tensor<2x39x1xf32>
      %175 = stablehlo.rsqrt %174 : tensor<2x39x1xf32>
      %176 = stablehlo.reshape %175 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
      %177 = stablehlo.broadcast_in_dim %176, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
      %178 = stablehlo.multiply %168, %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %179 = stablehlo.convert %178 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      %180 = stablehlo.convert %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %181 = stablehlo.multiply %167, %180 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %182 = stablehlo.convert %181 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      %183 = stablehlo.reshape %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
      %184 = stablehlo.reshape %arg36 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
      %185 = stablehlo.reshape %184 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
      %186 = stablehlo.transpose %185, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
      %187 = stablehlo.dot_general %183, %186, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
      %188 = sdy.all_reduce {"_axis_0"} %187 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x18944xbf16>
      %189 = stablehlo.reshape %188 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
      %190 = stablehlo.convert %189 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
      %191 = stablehlo.logistic %189 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xbf16>
      %192 = stablehlo.convert %191 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
      %193 = stablehlo.multiply %190, %192 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xf32>
      %194 = stablehlo.convert %193 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
      %195 = stablehlo.convert %194 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
      %196 = stablehlo.reshape %arg28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
      %197 = stablehlo.reshape %196 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
      %198 = stablehlo.transpose %197, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
      %199 = stablehlo.dot_general %183, %198, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
      %200 = sdy.all_reduce {"_axis_0"} %199 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x18944xbf16>
      %201 = stablehlo.reshape %200 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
      %202 = stablehlo.convert %201 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
      %203 = stablehlo.multiply %195, %202 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xf32>
      %204 = stablehlo.convert %203 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
      %205 = stablehlo.reshape %204 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
      %206 = stablehlo.reshape %arg27 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
      %207 = stablehlo.reshape %206 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
      %208 = stablehlo.transpose %207, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
      %209 = stablehlo.dot_general %205, %208, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
      %210 = sdy.all_reduce {"_axis_1"} %209 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<78x3584xbf16>
      %211 = stablehlo.reshape %210 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
      %212 = stablehlo.add %163, %211 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xbf16>
      %213 = stablehlo.convert %212 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %214 = stablehlo.power %213, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %215 = stablehlo.reduce(%214 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
      %216 = sdy.all_reduce {"_axis_0"} %215 out_sharding=<@mesh, [{}, {}]> : tensor<2x39xf32>
      %217 = stablehlo.multiply %216, %5 : tensor<2x39xf32>
      %218 = stablehlo.reshape %217 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
      %219 = stablehlo.add %218, %4 : tensor<2x39x1xf32>
      %220 = stablehlo.rsqrt %219 : tensor<2x39x1xf32>
      %221 = stablehlo.reshape %220 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
      %222 = stablehlo.broadcast_in_dim %221, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
      %223 = stablehlo.multiply %213, %222 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %224 = stablehlo.convert %223 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      %225 = stablehlo.convert %224 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %226 = stablehlo.multiply %93, %225 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %227 = stablehlo.convert %226 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      sdy.return %76, %89, %227 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
    } : (tensor<1x39xi64>, tensor<64xf32>, tensor<512xbf16>, tensor<512x3584xbf16>, tensor<2x39x3584xbf16>, tensor<3584xbf16>, tensor<512xbf16>, tensor<512x3584xbf16>, tensor<3584x18944xbf16>, tensor<18944x3584xbf16>, tensor<3584x3584xbf16>, tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>, tensor<3584xbf16>, tensor<3584x3584xbf16>, tensor<3584xbf16>, tensor<18944x3584xbf16>, tensor<3584xbf16>) -> (tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>)
    return %0#0, %0#1, %0#2 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


// -----// IR Dump Before ReshardToCollectivesPass (sdy-reshard-to-collectives) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___rotary_emb_inv_freq"}, %arg2: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, %arg3: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, %arg4: tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg5: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, %arg6: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, %arg7: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, %arg8: tensor<3584x18944xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, %arg9: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, %arg10: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, %arg11: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg12: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg13: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg14: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, %arg15: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, %arg16: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, %arg17: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, %arg18: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___norm_weight"}) -> (tensor<2x4x39x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x4x39x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"_axis_0", ?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14, %arg15, %arg16, %arg17, %arg18) in_shardings=[<@mesh, [{?}, {?}]>, <@mesh, [{?}]>, <@mesh, [{"_axis_1", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{?}, {?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}]>, <@mesh, [{"_axis_1", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, <@mesh, [{"_axis_0", ?}, {?}]>, <@mesh, [{?}, {?}]>, <@mesh, [{?}, {?}]>, <@mesh, [{"_axis_1", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}]>] out_shardings=[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, <@mesh, [{?}, {?}, {"_axis_0", ?}]>] manual_axes={} (%arg19: tensor<1x39xi64>, %arg20: tensor<64xf32>, %arg21: tensor<512xbf16>, %arg22: tensor<512x3584xbf16>, %arg23: tensor<2x39x3584xbf16>, %arg24: tensor<3584xbf16>, %arg25: tensor<512xbf16>, %arg26: tensor<512x3584xbf16>, %arg27: tensor<3584x18944xbf16>, %arg28: tensor<18944x3584xbf16>, %arg29: tensor<3584x3584xbf16>, %arg30: tensor<2x39xi64>, %arg31: tensor<39x39xi1>, %arg32: tensor<39x39xbf16>, %arg33: tensor<3584xbf16>, %arg34: tensor<3584x3584xbf16>, %arg35: tensor<3584xbf16>, %arg36: tensor<18944x3584xbf16>, %arg37: tensor<3584xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
      %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
      %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
      %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
      %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
      %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
      %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_6, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
      %2 = stablehlo.broadcast_in_dim %cst_5, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
      %3 = stablehlo.broadcast_in_dim %cst_4, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<2x28x39x39xf32>
      %4 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
      %5 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
      %6 = stablehlo.broadcast_in_dim %cst_1, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<f32>) -> tensor<2x39x3584xf32>
      %7 = stablehlo.convert %arg32 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
      %8 = stablehlo.convert %arg31 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
      %9 = stablehlo.multiply %7, %8 : tensor<39x39xf32>
      %10 = stablehlo.convert %9 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
      %11 = sdy.reshard %10 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
      %12 = stablehlo.reshape %11 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
      %13 = stablehlo.broadcast_in_dim %12, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
      %14 = stablehlo.reshape %arg24 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
      %15 = stablehlo.reshape %14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
      %16 = stablehlo.convert %15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
      %17 = stablehlo.broadcast_in_dim %16, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
      %18 = stablehlo.convert %arg23 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %19 = stablehlo.power %18, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
      %21 = sdy.all_reduce {"_axis_0"} %20 out_sharding=<@mesh, [{}, {}]> : tensor<2x39xf32>
      %22 = stablehlo.multiply %21, %5 : tensor<2x39xf32>
      %23 = stablehlo.reshape %22 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
      %24 = stablehlo.add %23, %4 : tensor<2x39x1xf32>
      %25 = stablehlo.rsqrt %24 : tensor<2x39x1xf32>
      %26 = stablehlo.reshape %25 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
      %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
      %28 = stablehlo.multiply %18, %27 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %29 = stablehlo.convert %28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      %30 = stablehlo.convert %29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %31 = stablehlo.multiply %17, %30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %32 = stablehlo.convert %31 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      %33 = stablehlo.reshape %32 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
      %34 = stablehlo.reshape %arg22 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
      %35 = stablehlo.reshape %34 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
      %36 = stablehlo.transpose %35, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
      %37 = stablehlo.dot_general %33, %36, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
      %38 = sdy.all_reduce {"_axis_0"} %37 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x512xbf16>
      %39 = sdy.reshard %38 <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]> : tensor<78x512xbf16>
      %40 = stablehlo.reshape %39 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
      %41 = stablehlo.reshape %arg21 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
      %42 = stablehlo.reshape %41 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
      %43 = stablehlo.broadcast_in_dim %42, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
      %44 = stablehlo.add %40, %43 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x512xbf16>
      %45 = stablehlo.reshape %44 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
      %46 = stablehlo.transpose %45, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
      %47 = stablehlo.convert %46 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
      %48 = stablehlo.reshape %arg20 : (tensor<64xf32>) -> tensor<1x1x64xf32>
      %49 = stablehlo.reshape %48 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
      %50 = stablehlo.reshape %arg19 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
      %51 = stablehlo.convert %50 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
      %52 = stablehlo.dot_general %49, %51, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
      %53 = stablehlo.transpose %52, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
      %54 = stablehlo.concatenate %53, %53, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
      %55 = stablehlo.cosine %54 : tensor<1x39x128xf32>
      %56 = stablehlo.convert %55 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
      %57 = stablehlo.reshape %56 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
      %58 = stablehlo.convert %57 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
      %59 = stablehlo.reshape %58 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
      %60 = stablehlo.broadcast_in_dim %59, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
      %61 = stablehlo.multiply %47, %60 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xf32>
      %62 = stablehlo.convert %61 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
      %63 = stablehlo.slice %46 [0:2, 0:4, 0:39, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
      %64 = stablehlo.negate %63 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x64xbf16>
      %65 = stablehlo.slice %46 [0:2, 0:4, 0:39, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
      %66 = stablehlo.concatenate %64, %65, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
      %67 = stablehlo.convert %66 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
      %68 = stablehlo.sine %54 : tensor<1x39x128xf32>
      %69 = stablehlo.convert %68 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
      %70 = stablehlo.reshape %69 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
      %71 = stablehlo.convert %70 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
      %72 = stablehlo.reshape %71 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
      %73 = stablehlo.broadcast_in_dim %72, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
      %74 = stablehlo.multiply %67, %73 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xf32>
      %75 = stablehlo.convert %74 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
      %76 = stablehlo.add %62, %75 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xbf16>
      %77 = stablehlo.reshape %arg26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
      %78 = stablehlo.reshape %77 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
      %79 = stablehlo.transpose %78, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
      %80 = stablehlo.dot_general %33, %79, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
      %81 = sdy.all_reduce {"_axis_0"} %80 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x512xbf16>
      %82 = sdy.reshard %81 <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]> : tensor<78x512xbf16>
      %83 = stablehlo.reshape %82 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
      %84 = stablehlo.reshape %arg25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
      %85 = stablehlo.reshape %84 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
      %86 = stablehlo.broadcast_in_dim %85, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
      %87 = stablehlo.add %83, %86 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x512xbf16>
      %88 = stablehlo.reshape %87 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
      %89 = stablehlo.transpose %88, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
      %90 = stablehlo.reshape %arg37 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
      %91 = stablehlo.reshape %90 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
      %92 = stablehlo.convert %91 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
      %93 = stablehlo.broadcast_in_dim %92, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
      %94 = stablehlo.reshape %arg34 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
      %95 = stablehlo.reshape %94 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
      %96 = stablehlo.transpose %95, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
      %97 = stablehlo.dot_general %33, %96, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
      %98 = sdy.all_reduce {"_axis_0"} %97 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x3584xbf16>
      %99 = sdy.reshard %98 <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]> : tensor<78x3584xbf16>
      %100 = stablehlo.reshape %99 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
      %101 = stablehlo.reshape %arg33 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
      %102 = stablehlo.reshape %101 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
      %103 = stablehlo.broadcast_in_dim %102, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
      %104 = stablehlo.add %100, %103 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x3584xbf16>
      %105 = stablehlo.reshape %104 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
      %106 = stablehlo.transpose %105, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
      %107 = stablehlo.convert %106 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
      %108 = stablehlo.broadcast_in_dim %59, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
      %109 = stablehlo.multiply %107, %108 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xf32>
      %110 = stablehlo.convert %109 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
      %111 = stablehlo.slice %106 [0:2, 0:28, 0:39, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
      %112 = stablehlo.negate %111 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x64xbf16>
      %113 = stablehlo.slice %106 [0:2, 0:28, 0:39, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
      %114 = stablehlo.concatenate %112, %113, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
      %115 = stablehlo.convert %114 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
      %116 = stablehlo.broadcast_in_dim %72, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
      %117 = stablehlo.multiply %115, %116 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xf32>
      %118 = stablehlo.convert %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
      %119 = stablehlo.add %110, %118 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xbf16>
      %120 = stablehlo.reshape %119 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
      %121 = stablehlo.broadcast_in_dim %76, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
      %122 = stablehlo.reshape %121 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
      %123 = stablehlo.transpose %122, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
      %124 = stablehlo.reshape %123 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
      %125 = stablehlo.dot_general %120, %124, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
      %126 = stablehlo.reshape %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
      %127 = stablehlo.convert %126 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
      %128 = stablehlo.multiply %127, %3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
      %129 = stablehlo.convert %128 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
      %130 = stablehlo.reshape %arg30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
      %131 = stablehlo.convert %130 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
      %132 = stablehlo.reshape %131 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
      %133 = stablehlo.broadcast_in_dim %132, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
      %134 = stablehlo.add %13, %133 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xbf16>
      %135 = stablehlo.compare  EQ, %134, %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
      %136 = stablehlo.select %135, %1, %13 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
      %137 = stablehlo.reshape %136 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
      %138 = stablehlo.broadcast_in_dim %137, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
      %139 = stablehlo.add %129, %138 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xbf16>
      %140 = stablehlo.convert %139 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
      %141 = stablehlo.reduce(%140 init: %cst_0) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
      %142 = stablehlo.broadcast_in_dim %141, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
      %143 = stablehlo.subtract %140, %142 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
      %144 = stablehlo.exponential %143 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
      %145 = stablehlo.reduce(%144 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
      %146 = stablehlo.broadcast_in_dim %145, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
      %147 = stablehlo.divide %144, %146 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
      %148 = stablehlo.convert %147 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
      %149 = stablehlo.reshape %148 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
      %150 = stablehlo.broadcast_in_dim %89, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
      %151 = stablehlo.reshape %150 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
      %152 = stablehlo.dot_general %149, %151, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
      %153 = stablehlo.reshape %152 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
      %154 = stablehlo.transpose %153, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
      %155 = stablehlo.reshape %154 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
      %156 = stablehlo.reshape %arg29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
      %157 = stablehlo.reshape %156 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
      %158 = stablehlo.transpose %157, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
      %159 = sdy.reshard %155 <@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x3584xbf16>
      %160 = stablehlo.dot_general %159, %158, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
      %161 = sdy.all_reduce {"_axis_1"} %160 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<78x3584xbf16>
      %162 = stablehlo.reshape %161 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
      %163 = stablehlo.add %arg23, %162 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xbf16>
      %164 = stablehlo.reshape %arg35 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
      %165 = stablehlo.reshape %164 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
      %166 = stablehlo.convert %165 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
      %167 = stablehlo.broadcast_in_dim %166, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
      %168 = stablehlo.convert %163 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %169 = stablehlo.power %168, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %170 = stablehlo.reduce(%169 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
      %171 = sdy.all_reduce {"_axis_0"} %170 out_sharding=<@mesh, [{}, {}]> : tensor<2x39xf32>
      %172 = stablehlo.multiply %171, %5 : tensor<2x39xf32>
      %173 = stablehlo.reshape %172 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
      %174 = stablehlo.add %173, %4 : tensor<2x39x1xf32>
      %175 = stablehlo.rsqrt %174 : tensor<2x39x1xf32>
      %176 = stablehlo.reshape %175 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
      %177 = stablehlo.broadcast_in_dim %176, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
      %178 = stablehlo.multiply %168, %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %179 = stablehlo.convert %178 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      %180 = stablehlo.convert %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %181 = stablehlo.multiply %167, %180 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %182 = stablehlo.convert %181 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      %183 = stablehlo.reshape %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
      %184 = stablehlo.reshape %arg36 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
      %185 = stablehlo.reshape %184 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
      %186 = stablehlo.transpose %185, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
      %187 = stablehlo.dot_general %183, %186, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
      %188 = sdy.all_reduce {"_axis_0"} %187 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x18944xbf16>
      %189 = stablehlo.reshape %188 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
      %190 = stablehlo.convert %189 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
      %191 = stablehlo.logistic %189 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xbf16>
      %192 = stablehlo.convert %191 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
      %193 = stablehlo.multiply %190, %192 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xf32>
      %194 = stablehlo.convert %193 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
      %195 = stablehlo.convert %194 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
      %196 = stablehlo.reshape %arg28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
      %197 = stablehlo.reshape %196 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
      %198 = stablehlo.transpose %197, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
      %199 = stablehlo.dot_general %183, %198, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
      %200 = sdy.all_reduce {"_axis_0"} %199 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x18944xbf16>
      %201 = stablehlo.reshape %200 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
      %202 = stablehlo.convert %201 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
      %203 = stablehlo.multiply %195, %202 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xf32>
      %204 = stablehlo.convert %203 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
      %205 = stablehlo.reshape %204 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
      %206 = stablehlo.reshape %arg27 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
      %207 = stablehlo.reshape %206 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
      %208 = stablehlo.transpose %207, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
      %209 = stablehlo.dot_general %205, %208, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
      %210 = sdy.all_reduce {"_axis_1"} %209 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<78x3584xbf16>
      %211 = stablehlo.reshape %210 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
      %212 = stablehlo.add %163, %211 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xbf16>
      %213 = stablehlo.convert %212 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %214 = stablehlo.power %213, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %215 = stablehlo.reduce(%214 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
      %216 = sdy.all_reduce {"_axis_0"} %215 out_sharding=<@mesh, [{}, {}]> : tensor<2x39xf32>
      %217 = stablehlo.multiply %216, %5 : tensor<2x39xf32>
      %218 = stablehlo.reshape %217 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
      %219 = stablehlo.add %218, %4 : tensor<2x39x1xf32>
      %220 = stablehlo.rsqrt %219 : tensor<2x39x1xf32>
      %221 = stablehlo.reshape %220 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
      %222 = stablehlo.broadcast_in_dim %221, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
      %223 = stablehlo.multiply %213, %222 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %224 = stablehlo.convert %223 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      %225 = stablehlo.convert %224 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %226 = stablehlo.multiply %93, %225 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %227 = stablehlo.convert %226 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      sdy.return %76, %89, %227 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
    } : (tensor<1x39xi64>, tensor<64xf32>, tensor<512xbf16>, tensor<512x3584xbf16>, tensor<2x39x3584xbf16>, tensor<3584xbf16>, tensor<512xbf16>, tensor<512x3584xbf16>, tensor<3584x18944xbf16>, tensor<18944x3584xbf16>, tensor<3584x3584xbf16>, tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>, tensor<3584xbf16>, tensor<3584x3584xbf16>, tensor<3584xbf16>, tensor<18944x3584xbf16>, tensor<3584xbf16>) -> (tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>)
    return %0#0, %0#1, %0#2 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


// -----// IR Dump After ReshardToCollectivesPass (sdy-reshard-to-collectives) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___rotary_emb_inv_freq"}, %arg2: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, %arg3: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, %arg4: tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg5: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, %arg6: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, %arg7: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, %arg8: tensor<3584x18944xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, %arg9: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, %arg10: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, %arg11: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg12: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg13: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg14: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, %arg15: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, %arg16: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, %arg17: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, %arg18: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___norm_weight"}) -> (tensor<2x4x39x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x4x39x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"_axis_0", ?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14, %arg15, %arg16, %arg17, %arg18) in_shardings=[<@mesh, [{?}, {?}]>, <@mesh, [{?}]>, <@mesh, [{"_axis_1", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{?}, {?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}]>, <@mesh, [{"_axis_1", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, <@mesh, [{"_axis_0", ?}, {?}]>, <@mesh, [{?}, {?}]>, <@mesh, [{?}, {?}]>, <@mesh, [{"_axis_1", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}]>] out_shardings=[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, <@mesh, [{?}, {?}, {"_axis_0", ?}]>] manual_axes={} (%arg19: tensor<1x39xi64>, %arg20: tensor<64xf32>, %arg21: tensor<512xbf16>, %arg22: tensor<512x3584xbf16>, %arg23: tensor<2x39x3584xbf16>, %arg24: tensor<3584xbf16>, %arg25: tensor<512xbf16>, %arg26: tensor<512x3584xbf16>, %arg27: tensor<3584x18944xbf16>, %arg28: tensor<18944x3584xbf16>, %arg29: tensor<3584x3584xbf16>, %arg30: tensor<2x39xi64>, %arg31: tensor<39x39xi1>, %arg32: tensor<39x39xbf16>, %arg33: tensor<3584xbf16>, %arg34: tensor<3584x3584xbf16>, %arg35: tensor<3584xbf16>, %arg36: tensor<18944x3584xbf16>, %arg37: tensor<3584xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
      %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
      %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
      %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
      %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
      %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
      %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_6, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
      %2 = stablehlo.broadcast_in_dim %cst_5, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
      %3 = stablehlo.broadcast_in_dim %cst_4, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<2x28x39x39xf32>
      %4 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
      %5 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
      %6 = stablehlo.broadcast_in_dim %cst_1, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<f32>) -> tensor<2x39x3584xf32>
      %7 = stablehlo.convert %arg32 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
      %8 = stablehlo.convert %arg31 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
      %9 = stablehlo.multiply %7, %8 : tensor<39x39xf32>
      %10 = stablehlo.convert %9 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
      %11 = stablehlo.reshape %10 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
      %12 = stablehlo.broadcast_in_dim %11, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
      %13 = stablehlo.reshape %arg24 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
      %14 = stablehlo.reshape %13 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
      %15 = stablehlo.convert %14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
      %16 = stablehlo.broadcast_in_dim %15, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
      %17 = stablehlo.convert %arg23 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %18 = stablehlo.power %17, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %19 = stablehlo.reduce(%18 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
      %20 = sdy.all_reduce {"_axis_0"} %19 out_sharding=<@mesh, [{}, {}]> : tensor<2x39xf32>
      %21 = stablehlo.multiply %20, %5 : tensor<2x39xf32>
      %22 = stablehlo.reshape %21 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
      %23 = stablehlo.add %22, %4 : tensor<2x39x1xf32>
      %24 = stablehlo.rsqrt %23 : tensor<2x39x1xf32>
      %25 = stablehlo.reshape %24 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
      %26 = stablehlo.broadcast_in_dim %25, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
      %27 = stablehlo.multiply %17, %26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %28 = stablehlo.convert %27 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      %29 = stablehlo.convert %28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %30 = stablehlo.multiply %16, %29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %31 = stablehlo.convert %30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      %32 = stablehlo.reshape %31 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
      %33 = stablehlo.reshape %arg22 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
      %34 = stablehlo.reshape %33 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
      %35 = stablehlo.transpose %34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
      %36 = stablehlo.dot_general %32, %35, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
      %37 = sdy.all_reduce {"_axis_0"} %36 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x512xbf16>
      %38 = sdy.all_slice [{"_axis_0"}, {}] %37 out_sharding=<@mesh, [{"_axis_0"}, {"_axis_1"}]> : tensor<78x512xbf16>
      %39 = stablehlo.reshape %38 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
      %40 = stablehlo.reshape %arg21 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
      %41 = stablehlo.reshape %40 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
      %42 = stablehlo.broadcast_in_dim %41, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
      %43 = stablehlo.add %39, %42 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x512xbf16>
      %44 = stablehlo.reshape %43 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
      %45 = stablehlo.transpose %44, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
      %46 = stablehlo.convert %45 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
      %47 = stablehlo.reshape %arg20 : (tensor<64xf32>) -> tensor<1x1x64xf32>
      %48 = stablehlo.reshape %47 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
      %49 = stablehlo.reshape %arg19 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
      %50 = stablehlo.convert %49 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
      %51 = stablehlo.dot_general %48, %50, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
      %52 = stablehlo.transpose %51, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
      %53 = stablehlo.concatenate %52, %52, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
      %54 = stablehlo.cosine %53 : tensor<1x39x128xf32>
      %55 = stablehlo.convert %54 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
      %56 = stablehlo.reshape %55 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
      %57 = stablehlo.convert %56 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
      %58 = stablehlo.reshape %57 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
      %59 = stablehlo.broadcast_in_dim %58, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
      %60 = stablehlo.multiply %46, %59 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xf32>
      %61 = stablehlo.convert %60 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
      %62 = stablehlo.slice %45 [0:2, 0:4, 0:39, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
      %63 = stablehlo.negate %62 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x64xbf16>
      %64 = stablehlo.slice %45 [0:2, 0:4, 0:39, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
      %65 = stablehlo.concatenate %63, %64, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
      %66 = stablehlo.convert %65 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
      %67 = stablehlo.sine %53 : tensor<1x39x128xf32>
      %68 = stablehlo.convert %67 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
      %69 = stablehlo.reshape %68 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
      %70 = stablehlo.convert %69 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
      %71 = stablehlo.reshape %70 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
      %72 = stablehlo.broadcast_in_dim %71, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
      %73 = stablehlo.multiply %66, %72 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xf32>
      %74 = stablehlo.convert %73 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
      %75 = stablehlo.add %61, %74 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xbf16>
      %76 = stablehlo.reshape %arg26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
      %77 = stablehlo.reshape %76 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
      %78 = stablehlo.transpose %77, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
      %79 = stablehlo.dot_general %32, %78, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
      %80 = sdy.all_reduce {"_axis_0"} %79 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x512xbf16>
      %81 = sdy.all_slice [{"_axis_0"}, {}] %80 out_sharding=<@mesh, [{"_axis_0"}, {"_axis_1"}]> : tensor<78x512xbf16>
      %82 = stablehlo.reshape %81 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
      %83 = stablehlo.reshape %arg25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
      %84 = stablehlo.reshape %83 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
      %85 = stablehlo.broadcast_in_dim %84, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
      %86 = stablehlo.add %82, %85 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x512xbf16>
      %87 = stablehlo.reshape %86 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
      %88 = stablehlo.transpose %87, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
      %89 = stablehlo.reshape %arg37 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
      %90 = stablehlo.reshape %89 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
      %91 = stablehlo.convert %90 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
      %92 = stablehlo.broadcast_in_dim %91, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
      %93 = stablehlo.reshape %arg34 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
      %94 = stablehlo.reshape %93 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
      %95 = stablehlo.transpose %94, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
      %96 = stablehlo.dot_general %32, %95, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
      %97 = sdy.all_reduce {"_axis_0"} %96 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x3584xbf16>
      %98 = sdy.all_slice [{"_axis_0"}, {}] %97 out_sharding=<@mesh, [{"_axis_0"}, {"_axis_1"}]> : tensor<78x3584xbf16>
      %99 = stablehlo.reshape %98 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
      %100 = stablehlo.reshape %arg33 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
      %101 = stablehlo.reshape %100 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
      %102 = stablehlo.broadcast_in_dim %101, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
      %103 = stablehlo.add %99, %102 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x3584xbf16>
      %104 = stablehlo.reshape %103 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
      %105 = stablehlo.transpose %104, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
      %106 = stablehlo.convert %105 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
      %107 = stablehlo.broadcast_in_dim %58, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
      %108 = stablehlo.multiply %106, %107 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xf32>
      %109 = stablehlo.convert %108 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
      %110 = stablehlo.slice %105 [0:2, 0:28, 0:39, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
      %111 = stablehlo.negate %110 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x64xbf16>
      %112 = stablehlo.slice %105 [0:2, 0:28, 0:39, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
      %113 = stablehlo.concatenate %111, %112, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
      %114 = stablehlo.convert %113 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
      %115 = stablehlo.broadcast_in_dim %71, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
      %116 = stablehlo.multiply %114, %115 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xf32>
      %117 = stablehlo.convert %116 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
      %118 = stablehlo.add %109, %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xbf16>
      %119 = stablehlo.reshape %118 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
      %120 = stablehlo.broadcast_in_dim %75, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
      %121 = stablehlo.reshape %120 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
      %122 = stablehlo.transpose %121, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
      %123 = stablehlo.reshape %122 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
      %124 = stablehlo.dot_general %119, %123, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
      %125 = stablehlo.reshape %124 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
      %126 = stablehlo.convert %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
      %127 = stablehlo.multiply %126, %3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
      %128 = stablehlo.convert %127 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
      %129 = stablehlo.reshape %arg30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
      %130 = stablehlo.convert %129 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
      %131 = stablehlo.reshape %130 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
      %132 = stablehlo.broadcast_in_dim %131, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
      %133 = stablehlo.add %12, %132 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xbf16>
      %134 = stablehlo.compare  EQ, %133, %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
      %135 = stablehlo.select %134, %1, %12 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
      %136 = stablehlo.reshape %135 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
      %137 = stablehlo.broadcast_in_dim %136, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
      %138 = stablehlo.add %128, %137 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xbf16>
      %139 = stablehlo.convert %138 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
      %140 = stablehlo.reduce(%139 init: %cst_0) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
      %141 = stablehlo.broadcast_in_dim %140, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
      %142 = stablehlo.subtract %139, %141 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
      %143 = stablehlo.exponential %142 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
      %144 = stablehlo.reduce(%143 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
      %145 = stablehlo.broadcast_in_dim %144, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
      %146 = stablehlo.divide %143, %145 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
      %147 = stablehlo.convert %146 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
      %148 = stablehlo.reshape %147 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
      %149 = stablehlo.broadcast_in_dim %88, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
      %150 = stablehlo.reshape %149 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
      %151 = stablehlo.dot_general %148, %150, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
      %152 = stablehlo.reshape %151 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
      %153 = stablehlo.transpose %152, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
      %154 = stablehlo.reshape %153 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
      %155 = stablehlo.reshape %arg29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
      %156 = stablehlo.reshape %155 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
      %157 = stablehlo.transpose %156, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
      %158 = sdy.all_gather [{"_axis_0"}, {}] %154 out_sharding=<@mesh, [{}, {"_axis_1"}]> : tensor<78x3584xbf16>
      %159 = stablehlo.dot_general %158, %157, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
      %160 = sdy.all_reduce {"_axis_1"} %159 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<78x3584xbf16>
      %161 = stablehlo.reshape %160 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
      %162 = stablehlo.add %arg23, %161 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xbf16>
      %163 = stablehlo.reshape %arg35 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
      %164 = stablehlo.reshape %163 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
      %165 = stablehlo.convert %164 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
      %166 = stablehlo.broadcast_in_dim %165, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
      %167 = stablehlo.convert %162 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %168 = stablehlo.power %167, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %169 = stablehlo.reduce(%168 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
      %170 = sdy.all_reduce {"_axis_0"} %169 out_sharding=<@mesh, [{}, {}]> : tensor<2x39xf32>
      %171 = stablehlo.multiply %170, %5 : tensor<2x39xf32>
      %172 = stablehlo.reshape %171 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
      %173 = stablehlo.add %172, %4 : tensor<2x39x1xf32>
      %174 = stablehlo.rsqrt %173 : tensor<2x39x1xf32>
      %175 = stablehlo.reshape %174 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
      %176 = stablehlo.broadcast_in_dim %175, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
      %177 = stablehlo.multiply %167, %176 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %178 = stablehlo.convert %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      %179 = stablehlo.convert %178 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %180 = stablehlo.multiply %166, %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %181 = stablehlo.convert %180 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      %182 = stablehlo.reshape %181 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
      %183 = stablehlo.reshape %arg36 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
      %184 = stablehlo.reshape %183 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
      %185 = stablehlo.transpose %184, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
      %186 = stablehlo.dot_general %182, %185, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
      %187 = sdy.all_reduce {"_axis_0"} %186 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x18944xbf16>
      %188 = stablehlo.reshape %187 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
      %189 = stablehlo.convert %188 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
      %190 = stablehlo.logistic %188 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xbf16>
      %191 = stablehlo.convert %190 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
      %192 = stablehlo.multiply %189, %191 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xf32>
      %193 = stablehlo.convert %192 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
      %194 = stablehlo.convert %193 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
      %195 = stablehlo.reshape %arg28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
      %196 = stablehlo.reshape %195 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
      %197 = stablehlo.transpose %196, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
      %198 = stablehlo.dot_general %182, %197, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
      %199 = sdy.all_reduce {"_axis_0"} %198 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x18944xbf16>
      %200 = stablehlo.reshape %199 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
      %201 = stablehlo.convert %200 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
      %202 = stablehlo.multiply %194, %201 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xf32>
      %203 = stablehlo.convert %202 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
      %204 = stablehlo.reshape %203 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
      %205 = stablehlo.reshape %arg27 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
      %206 = stablehlo.reshape %205 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
      %207 = stablehlo.transpose %206, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
      %208 = stablehlo.dot_general %204, %207, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
      %209 = sdy.all_reduce {"_axis_1"} %208 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<78x3584xbf16>
      %210 = stablehlo.reshape %209 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
      %211 = stablehlo.add %162, %210 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xbf16>
      %212 = stablehlo.convert %211 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %213 = stablehlo.power %212, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %214 = stablehlo.reduce(%213 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
      %215 = sdy.all_reduce {"_axis_0"} %214 out_sharding=<@mesh, [{}, {}]> : tensor<2x39xf32>
      %216 = stablehlo.multiply %215, %5 : tensor<2x39xf32>
      %217 = stablehlo.reshape %216 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
      %218 = stablehlo.add %217, %4 : tensor<2x39x1xf32>
      %219 = stablehlo.rsqrt %218 : tensor<2x39x1xf32>
      %220 = stablehlo.reshape %219 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
      %221 = stablehlo.broadcast_in_dim %220, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
      %222 = stablehlo.multiply %212, %221 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %223 = stablehlo.convert %222 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      %224 = stablehlo.convert %223 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %225 = stablehlo.multiply %92, %224 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %226 = stablehlo.convert %225 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      sdy.return %75, %88, %226 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
    } : (tensor<1x39xi64>, tensor<64xf32>, tensor<512xbf16>, tensor<512x3584xbf16>, tensor<2x39x3584xbf16>, tensor<3584xbf16>, tensor<512xbf16>, tensor<512x3584xbf16>, tensor<3584x18944xbf16>, tensor<18944x3584xbf16>, tensor<3584x3584xbf16>, tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>, tensor<3584xbf16>, tensor<3584x3584xbf16>, tensor<3584xbf16>, tensor<18944x3584xbf16>, tensor<3584xbf16>) -> (tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>)
    return %0#0, %0#1, %0#2 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


// -----// IR Dump Before UpdateGlobalToLocalShapesPass (update-global-to-local-shapes) ('builtin.module' operation: @SyncTensorsGraph.420) //----- //
module @SyncTensorsGraph.420 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<1x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___rotary_emb_inv_freq"}, %arg2: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, %arg3: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, %arg4: tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg5: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, %arg6: tensor<512xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, %arg7: tensor<512x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, %arg8: tensor<3584x18944xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, %arg9: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, %arg10: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, %arg11: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg12: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg13: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg14: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, %arg15: tensor<3584x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, %arg16: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, %arg17: tensor<18944x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, %arg18: tensor<3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___norm_weight"}) -> (tensor<2x4x39x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x4x39x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x39x3584xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"_axis_0", ?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:3 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14, %arg15, %arg16, %arg17, %arg18) in_shardings=[<@mesh, [{?}, {?}]>, <@mesh, [{?}]>, <@mesh, [{"_axis_1", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{?}, {?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}]>, <@mesh, [{"_axis_1", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, <@mesh, [{"_axis_0", ?}, {?}]>, <@mesh, [{?}, {?}]>, <@mesh, [{?}, {?}]>, <@mesh, [{"_axis_1", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}]>] out_shardings=[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, <@mesh, [{?}, {?}, {"_axis_0", ?}]>] manual_axes={} (%arg19: tensor<1x39xi64>, %arg20: tensor<64xf32>, %arg21: tensor<512xbf16>, %arg22: tensor<512x3584xbf16>, %arg23: tensor<2x39x3584xbf16>, %arg24: tensor<3584xbf16>, %arg25: tensor<512xbf16>, %arg26: tensor<512x3584xbf16>, %arg27: tensor<3584x18944xbf16>, %arg28: tensor<18944x3584xbf16>, %arg29: tensor<3584x3584xbf16>, %arg30: tensor<2x39xi64>, %arg31: tensor<39x39xi1>, %arg32: tensor<39x39xbf16>, %arg33: tensor<3584xbf16>, %arg34: tensor<3584x3584xbf16>, %arg35: tensor<3584xbf16>, %arg36: tensor<18944x3584xbf16>, %arg37: tensor<3584xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
      %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
      %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
      %cst_2 = stablehlo.constant dense<2.7901787E-4> : tensor<f32>
      %cst_3 = stablehlo.constant dense<9.99999997E-7> : tensor<f32>
      %cst_4 = stablehlo.constant dense<0.0883883461> : tensor<f32>
      %cst_5 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_6 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_6, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
      %2 = stablehlo.broadcast_in_dim %cst_5, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
      %3 = stablehlo.broadcast_in_dim %cst_4, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<2x28x39x39xf32>
      %4 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<2x39x1xf32>
      %5 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<2x39xf32>
      %6 = stablehlo.broadcast_in_dim %cst_1, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<f32>) -> tensor<2x39x3584xf32>
      %7 = stablehlo.convert %arg32 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
      %8 = stablehlo.convert %arg31 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
      %9 = stablehlo.multiply %7, %8 : tensor<39x39xf32>
      %10 = stablehlo.convert %9 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
      %11 = stablehlo.reshape %10 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
      %12 = stablehlo.broadcast_in_dim %11, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
      %13 = stablehlo.reshape %arg24 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
      %14 = stablehlo.reshape %13 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
      %15 = stablehlo.convert %14 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
      %16 = stablehlo.broadcast_in_dim %15, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
      %17 = stablehlo.convert %arg23 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %18 = stablehlo.power %17, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %19 = stablehlo.reduce(%18 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
      %20 = sdy.all_reduce {"_axis_0"} %19 out_sharding=<@mesh, [{}, {}]> : tensor<2x39xf32>
      %21 = stablehlo.multiply %20, %5 : tensor<2x39xf32>
      %22 = stablehlo.reshape %21 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
      %23 = stablehlo.add %22, %4 : tensor<2x39x1xf32>
      %24 = stablehlo.rsqrt %23 : tensor<2x39x1xf32>
      %25 = stablehlo.reshape %24 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
      %26 = stablehlo.broadcast_in_dim %25, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
      %27 = stablehlo.multiply %17, %26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %28 = stablehlo.convert %27 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      %29 = stablehlo.convert %28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %30 = stablehlo.multiply %16, %29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %31 = stablehlo.convert %30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      %32 = stablehlo.reshape %31 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
      %33 = stablehlo.reshape %arg22 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
      %34 = stablehlo.reshape %33 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
      %35 = stablehlo.transpose %34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
      %36 = stablehlo.dot_general %32, %35, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
      %37 = sdy.all_reduce {"_axis_0"} %36 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x512xbf16>
      %38 = sdy.all_slice [{"_axis_0"}, {}] %37 out_sharding=<@mesh, [{"_axis_0"}, {"_axis_1"}]> : tensor<78x512xbf16>
      %39 = stablehlo.reshape %38 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
      %40 = stablehlo.reshape %arg21 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
      %41 = stablehlo.reshape %40 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
      %42 = stablehlo.broadcast_in_dim %41, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
      %43 = stablehlo.add %39, %42 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x512xbf16>
      %44 = stablehlo.reshape %43 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
      %45 = stablehlo.transpose %44, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
      %46 = stablehlo.convert %45 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
      %47 = stablehlo.reshape %arg20 : (tensor<64xf32>) -> tensor<1x1x64xf32>
      %48 = stablehlo.reshape %47 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
      %49 = stablehlo.reshape %arg19 : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
      %50 = stablehlo.convert %49 : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
      %51 = stablehlo.dot_general %48, %50, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
      %52 = stablehlo.transpose %51, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
      %53 = stablehlo.concatenate %52, %52, dim = 2 : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
      %54 = stablehlo.cosine %53 : tensor<1x39x128xf32>
      %55 = stablehlo.convert %54 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
      %56 = stablehlo.reshape %55 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
      %57 = stablehlo.convert %56 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
      %58 = stablehlo.reshape %57 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
      %59 = stablehlo.broadcast_in_dim %58, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
      %60 = stablehlo.multiply %46, %59 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xf32>
      %61 = stablehlo.convert %60 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
      %62 = stablehlo.slice %45 [0:2, 0:4, 0:39, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
      %63 = stablehlo.negate %62 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x64xbf16>
      %64 = stablehlo.slice %45 [0:2, 0:4, 0:39, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x64xbf16>
      %65 = stablehlo.concatenate %63, %64, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x64xbf16>, tensor<2x4x39x64xbf16>) -> tensor<2x4x39x128xbf16>
      %66 = stablehlo.convert %65 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x39x128xf32>
      %67 = stablehlo.sine %53 : tensor<1x39x128xf32>
      %68 = stablehlo.convert %67 : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
      %69 = stablehlo.reshape %68 : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
      %70 = stablehlo.convert %69 : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
      %71 = stablehlo.reshape %70 : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
      %72 = stablehlo.broadcast_in_dim %71, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x4x39x128xf32>
      %73 = stablehlo.multiply %66, %72 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xf32>
      %74 = stablehlo.convert %73 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x39x128xf32>) -> tensor<2x4x39x128xbf16>
      %75 = stablehlo.add %61, %74 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x4x39x128xbf16>
      %76 = stablehlo.reshape %arg26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16>
      %77 = stablehlo.reshape %76 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16>
      %78 = stablehlo.transpose %77, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16>
      %79 = stablehlo.dot_general %32, %78, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x512xbf16>) -> tensor<78x512xbf16>
      %80 = sdy.all_reduce {"_axis_0"} %79 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x512xbf16>
      %81 = sdy.all_slice [{"_axis_0"}, {}] %80 out_sharding=<@mesh, [{"_axis_0"}, {"_axis_1"}]> : tensor<78x512xbf16>
      %82 = stablehlo.reshape %81 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x512xbf16>) -> tensor<2x39x512xbf16>
      %83 = stablehlo.reshape %arg25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
      %84 = stablehlo.reshape %83 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
      %85 = stablehlo.broadcast_in_dim %84, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<512xbf16>) -> tensor<2x39x512xbf16>
      %86 = stablehlo.add %82, %85 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x512xbf16>
      %87 = stablehlo.reshape %86 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x512xbf16>) -> tensor<2x39x4x128xbf16>
      %88 = stablehlo.transpose %87, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<2x39x4x128xbf16>) -> tensor<2x4x39x128xbf16>
      %89 = stablehlo.reshape %arg37 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
      %90 = stablehlo.reshape %89 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
      %91 = stablehlo.convert %90 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
      %92 = stablehlo.broadcast_in_dim %91, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
      %93 = stablehlo.reshape %arg34 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
      %94 = stablehlo.reshape %93 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
      %95 = stablehlo.transpose %94, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
      %96 = stablehlo.dot_general %32, %95, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
      %97 = sdy.all_reduce {"_axis_0"} %96 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x3584xbf16>
      %98 = sdy.all_slice [{"_axis_0"}, {}] %97 out_sharding=<@mesh, [{"_axis_0"}, {"_axis_1"}]> : tensor<78x3584xbf16>
      %99 = stablehlo.reshape %98 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
      %100 = stablehlo.reshape %arg33 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
      %101 = stablehlo.reshape %100 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
      %102 = stablehlo.broadcast_in_dim %101, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : (tensor<3584xbf16>) -> tensor<2x39x3584xbf16>
      %103 = stablehlo.add %99, %102 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x3584xbf16>
      %104 = stablehlo.reshape %103 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x28x128xbf16>
      %105 = stablehlo.transpose %104, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<2x39x28x128xbf16>) -> tensor<2x28x39x128xbf16>
      %106 = stablehlo.convert %105 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
      %107 = stablehlo.broadcast_in_dim %58, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
      %108 = stablehlo.multiply %106, %107 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xf32>
      %109 = stablehlo.convert %108 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
      %110 = stablehlo.slice %105 [0:2, 0:28, 0:39, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
      %111 = stablehlo.negate %110 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x64xbf16>
      %112 = stablehlo.slice %105 [0:2, 0:28, 0:39, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x64xbf16>
      %113 = stablehlo.concatenate %111, %112, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x64xbf16>, tensor<2x28x39x64xbf16>) -> tensor<2x28x39x128xbf16>
      %114 = stablehlo.convert %113 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x39x128xf32>
      %115 = stablehlo.broadcast_in_dim %71, dims = [2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<39x128xf32>) -> tensor<2x28x39x128xf32>
      %116 = stablehlo.multiply %114, %115 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xf32>
      %117 = stablehlo.convert %116 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xf32>) -> tensor<2x28x39x128xbf16>
      %118 = stablehlo.add %109, %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x128xbf16>
      %119 = stablehlo.reshape %118 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x128xbf16>) -> tensor<56x39x128xbf16>
      %120 = stablehlo.broadcast_in_dim %75, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
      %121 = stablehlo.reshape %120 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x7x39x128xbf16>) -> tensor<2x28x39x128xbf16>
      %122 = stablehlo.transpose %121, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x28x128x39xbf16>
      %123 = stablehlo.reshape %122 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x128x39xbf16>) -> tensor<56x128x39xbf16>
      %124 = stablehlo.dot_general %119, %123, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x128xbf16>, tensor<56x128x39xbf16>) -> tensor<56x39x39xbf16>
      %125 = stablehlo.reshape %124 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x39xbf16>) -> tensor<2x28x39x39xbf16>
      %126 = stablehlo.convert %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
      %127 = stablehlo.multiply %126, %3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
      %128 = stablehlo.convert %127 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
      %129 = stablehlo.reshape %arg30 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
      %130 = stablehlo.convert %129 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
      %131 = stablehlo.reshape %130 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
      %132 = stablehlo.broadcast_in_dim %131, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
      %133 = stablehlo.add %12, %132 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xbf16>
      %134 = stablehlo.compare  EQ, %133, %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
      %135 = stablehlo.select %134, %1, %12 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
      %136 = stablehlo.reshape %135 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>) -> tensor<2x39x39xbf16>
      %137 = stablehlo.broadcast_in_dim %136, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x39x39xbf16>) -> tensor<2x28x39x39xbf16>
      %138 = stablehlo.add %128, %137 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xbf16>
      %139 = stablehlo.convert %138 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<2x28x39x39xf32>
      %140 = stablehlo.reduce(%139 init: %cst_0) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
      %141 = stablehlo.broadcast_in_dim %140, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
      %142 = stablehlo.subtract %139, %141 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
      %143 = stablehlo.exponential %142 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
      %144 = stablehlo.reduce(%143 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}]>]>} : (tensor<2x28x39x39xf32>, tensor<f32>) -> tensor<2x28x39xf32>
      %145 = stablehlo.broadcast_in_dim %144, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39xf32>) -> tensor<2x28x39x39xf32>
      %146 = stablehlo.divide %143, %145 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : tensor<2x28x39x39xf32>
      %147 = stablehlo.convert %146 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xf32>) -> tensor<2x28x39x39xbf16>
      %148 = stablehlo.reshape %147 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x28x39x39xbf16>) -> tensor<56x39x39xbf16>
      %149 = stablehlo.broadcast_in_dim %88, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}, {?}]>]>} : (tensor<2x4x39x128xbf16>) -> tensor<2x4x7x39x128xbf16>
      %150 = stablehlo.reshape %149 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<2x4x7x39x128xbf16>) -> tensor<56x39x128xbf16>
      %151 = stablehlo.dot_general %148, %150, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", "_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x39xbf16>, tensor<56x39x128xbf16>) -> tensor<56x39x128xbf16>
      %152 = stablehlo.reshape %151 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>]>} : (tensor<56x39x128xbf16>) -> tensor<2x28x39x128xbf16>
      %153 = stablehlo.transpose %152, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {"_axis_1", ?}, {?}]>]>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<2x28x39x128xbf16>) -> tensor<2x39x28x128xbf16>
      %154 = stablehlo.reshape %153 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<2x39x28x128xbf16>) -> tensor<78x3584xbf16>
      %155 = stablehlo.reshape %arg29 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16>
      %156 = stablehlo.reshape %155 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16>
      %157 = stablehlo.transpose %156, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16>
      %158 = sdy.all_gather [{"_axis_0"}, {}] %154 out_sharding=<@mesh, [{}, {"_axis_1"}]> : tensor<78x3584xbf16>
      %159 = stablehlo.dot_general %158, %157, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<78x3584xbf16>
      %160 = sdy.all_reduce {"_axis_1"} %159 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<78x3584xbf16>
      %161 = stablehlo.reshape %160 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
      %162 = stablehlo.add %arg23, %161 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xbf16>
      %163 = stablehlo.reshape %arg35 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16>
      %164 = stablehlo.reshape %163 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16>
      %165 = stablehlo.convert %164 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}]>]>} : (tensor<3584xbf16>) -> tensor<3584xf32>
      %166 = stablehlo.broadcast_in_dim %165, dims = [2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3584xf32>) -> tensor<2x39x3584xf32>
      %167 = stablehlo.convert %162 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %168 = stablehlo.power %167, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %169 = stablehlo.reduce(%168 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
      %170 = sdy.all_reduce {"_axis_0"} %169 out_sharding=<@mesh, [{}, {}]> : tensor<2x39xf32>
      %171 = stablehlo.multiply %170, %5 : tensor<2x39xf32>
      %172 = stablehlo.reshape %171 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
      %173 = stablehlo.add %172, %4 : tensor<2x39x1xf32>
      %174 = stablehlo.rsqrt %173 : tensor<2x39x1xf32>
      %175 = stablehlo.reshape %174 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
      %176 = stablehlo.broadcast_in_dim %175, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
      %177 = stablehlo.multiply %167, %176 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %178 = stablehlo.convert %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      %179 = stablehlo.convert %178 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %180 = stablehlo.multiply %166, %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %181 = stablehlo.convert %180 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      %182 = stablehlo.reshape %181 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<78x3584xbf16>
      %183 = stablehlo.reshape %arg36 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
      %184 = stablehlo.reshape %183 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
      %185 = stablehlo.transpose %184, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
      %186 = stablehlo.dot_general %182, %185, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
      %187 = sdy.all_reduce {"_axis_0"} %186 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x18944xbf16>
      %188 = stablehlo.reshape %187 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
      %189 = stablehlo.convert %188 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
      %190 = stablehlo.logistic %188 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xbf16>
      %191 = stablehlo.convert %190 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
      %192 = stablehlo.multiply %189, %191 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xf32>
      %193 = stablehlo.convert %192 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
      %194 = stablehlo.convert %193 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
      %195 = stablehlo.reshape %arg28 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<18944x3584xbf16>) -> tensor<1x18944x3584xbf16>
      %196 = stablehlo.reshape %195 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>} : (tensor<1x18944x3584xbf16>) -> tensor<18944x3584xbf16>
      %197 = stablehlo.transpose %196, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<18944x3584xbf16>) -> tensor<3584x18944xbf16>
      %198 = stablehlo.dot_general %182, %197, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<78x3584xbf16>, tensor<3584x18944xbf16>) -> tensor<78x18944xbf16>
      %199 = sdy.all_reduce {"_axis_0"} %198 out_sharding=<@mesh, [{?}, {"_axis_1", ?}]> : tensor<78x18944xbf16>
      %200 = stablehlo.reshape %199 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<78x18944xbf16>) -> tensor<2x39x18944xbf16>
      %201 = stablehlo.convert %200 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<2x39x18944xf32>
      %202 = stablehlo.multiply %194, %201 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : tensor<2x39x18944xf32>
      %203 = stablehlo.convert %202 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xf32>) -> tensor<2x39x18944xbf16>
      %204 = stablehlo.reshape %203 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_1", ?}]>]>} : (tensor<2x39x18944xbf16>) -> tensor<78x18944xbf16>
      %205 = stablehlo.reshape %arg27 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<3584x18944xbf16>) -> tensor<1x3584x18944xbf16>
      %206 = stablehlo.reshape %205 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>]>} : (tensor<1x3584x18944xbf16>) -> tensor<3584x18944xbf16>
      %207 = stablehlo.transpose %206, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<3584x18944xbf16>) -> tensor<18944x3584xbf16>
      %208 = stablehlo.dot_general %204, %207, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<78x18944xbf16>, tensor<18944x3584xbf16>) -> tensor<78x3584xbf16>
      %209 = sdy.all_reduce {"_axis_1"} %208 out_sharding=<@mesh, [{?}, {"_axis_0", ?}]> : tensor<78x3584xbf16>
      %210 = stablehlo.reshape %209 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<78x3584xbf16>) -> tensor<2x39x3584xbf16>
      %211 = stablehlo.add %162, %210 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xbf16>
      %212 = stablehlo.convert %211 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %213 = stablehlo.power %212, %6 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %214 = stablehlo.reduce(%213 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<2x39x3584xf32>, tensor<f32>) -> tensor<2x39xf32>
      %215 = sdy.all_reduce {"_axis_0"} %214 out_sharding=<@mesh, [{}, {}]> : tensor<2x39xf32>
      %216 = stablehlo.multiply %215, %5 : tensor<2x39xf32>
      %217 = stablehlo.reshape %216 : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
      %218 = stablehlo.add %217, %4 : tensor<2x39x1xf32>
      %219 = stablehlo.rsqrt %218 : tensor<2x39x1xf32>
      %220 = stablehlo.reshape %219 : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
      %221 = stablehlo.broadcast_in_dim %220, dims = [0, 1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39xf32>) -> tensor<2x39x3584xf32>
      %222 = stablehlo.multiply %212, %221 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %223 = stablehlo.convert %222 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      %224 = stablehlo.convert %223 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xf32>
      %225 = stablehlo.multiply %92, %224 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<2x39x3584xf32>
      %226 = stablehlo.convert %225 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<2x39x3584xf32>) -> tensor<2x39x3584xbf16>
      sdy.return %75, %88, %226 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
    } : (tensor<1x39xi64>, tensor<64xf32>, tensor<512xbf16>, tensor<512x3584xbf16>, tensor<2x39x3584xbf16>, tensor<3584xbf16>, tensor<512xbf16>, tensor<512x3584xbf16>, tensor<3584x18944xbf16>, tensor<18944x3584xbf16>, tensor<3584x3584xbf16>, tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>, tensor<3584xbf16>, tensor<3584x3584xbf16>, tensor<3584xbf16>, tensor<18944x3584xbf16>, tensor<3584xbf16>) -> (tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>)
    return %0#0, %0#1, %0#2 : tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>
  }
}


loc("aten__mm"): error: number of output elements (39936) doesn't match expected number of elements (9984)
// -----// IR Dump After UpdateGlobalToLocalShapesPass Failed (update-global-to-local-shapes) ('builtin.module' operation: @SyncTensorsGraph.420) //----- //
"builtin.module"() <{sym_name = "SyncTensorsGraph.420"}> ({
  "sdy.mesh"() <{mesh = #sdy.mesh<["_axis_0"=2, "_axis_1"=4]>, sym_name = "mesh"}> : () -> ()
  "func.func"() <{arg_attrs = [{ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___rotary_emb_inv_freq"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_bias"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_k_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___input_layernorm_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_bias"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_v_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_down_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_up_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_o_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_bias"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___self_attn_q_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___post_attention_layernorm_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___layers__modules__0___mlp_gate_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___norm_weight"}], function_type = (tensor<1x39xi64>, tensor<64xf32>, tensor<512xbf16>, tensor<512x3584xbf16>, tensor<2x39x3584xbf16>, tensor<3584xbf16>, tensor<512xbf16>, tensor<512x3584xbf16>, tensor<3584x18944xbf16>, tensor<18944x3584xbf16>, tensor<3584x3584xbf16>, tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>, tensor<3584xbf16>, tensor<3584x3584xbf16>, tensor<3584xbf16>, tensor<18944x3584xbf16>, tensor<3584xbf16>) -> (tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>), res_attrs = [{ttcore.shard_status = #ttcore.shard_status<unsharded>}, {ttcore.shard_status = #ttcore.shard_status<unsharded>}, {ttcore.shard_status = #ttcore.shard_status<unsharded>}], sym_name = "main"}> ({
  ^bb0(%arg0: tensor<1x39xi64>, %arg1: tensor<64xf32>, %arg2: tensor<512xbf16>, %arg3: tensor<512x3584xbf16>, %arg4: tensor<2x39x3584xbf16>, %arg5: tensor<3584xbf16>, %arg6: tensor<512xbf16>, %arg7: tensor<512x3584xbf16>, %arg8: tensor<3584x18944xbf16>, %arg9: tensor<18944x3584xbf16>, %arg10: tensor<3584x3584xbf16>, %arg11: tensor<2x39xi64>, %arg12: tensor<39x39xi1>, %arg13: tensor<39x39xbf16>, %arg14: tensor<3584xbf16>, %arg15: tensor<3584x3584xbf16>, %arg16: tensor<3584xbf16>, %arg17: tensor<18944x3584xbf16>, %arg18: tensor<3584xbf16>):
    %0:3 = "sdy.manual_computation"(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14, %arg15, %arg16, %arg17, %arg18) <{in_shardings = #sdy.sharding_per_value<[<@mesh, [{?}, {?}]>, <@mesh, [{?}]>, <@mesh, [{"_axis_1", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{?}, {?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}]>, <@mesh, [{"_axis_1", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}]>, <@mesh, [{"_axis_0", ?}, {?}]>, <@mesh, [{?}, {?}]>, <@mesh, [{?}, {?}]>, <@mesh, [{"_axis_1", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}]>, <@mesh, [{"_axis_1", ?}, {"_axis_0", ?}]>, <@mesh, [{"_axis_0", ?}]>]>, manual_axes = #sdy<manual_axes{"_axis_0", "_axis_1"}>, out_shardings = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, <@mesh, [{"_axis_0", ?}, {"_axis_1", ?}, {?}, {?}]>, <@mesh, [{?}, {?}, {"_axis_0", ?}]>]>}> ({
    ^bb0(%arg19: tensor<1x39xi64>, %arg20: tensor<64xf32>, %arg21: tensor<128xbf16>, %arg22: tensor<128x1792xbf16>, %arg23: tensor<2x39x1792xbf16>, %arg24: tensor<1792xbf16>, %arg25: tensor<128xbf16>, %arg26: tensor<128x1792xbf16>, %arg27: tensor<1792x4736xbf16>, %arg28: tensor<4736x1792xbf16>, %arg29: tensor<1792x896xbf16>, %arg30: tensor<1x39xi64>, %arg31: tensor<39x39xi1>, %arg32: tensor<39x39xbf16>, %arg33: tensor<896xbf16>, %arg34: tensor<896x1792xbf16>, %arg35: tensor<1792xbf16>, %arg36: tensor<4736x1792xbf16>, %arg37: tensor<1792xbf16>):
      %1 = "stablehlo.constant"() <{value = dense<0.000000e+00> : tensor<f32>}> : () -> tensor<f32>
      %2 = "stablehlo.constant"() <{value = dense<0xFF800000> : tensor<f32>}> : () -> tensor<f32>
      %3 = "stablehlo.constant"() <{value = dense<2.000000e+00> : tensor<f32>}> : () -> tensor<f32>
      %4 = "stablehlo.constant"() <{value = dense<2.7901787E-4> : tensor<f32>}> : () -> tensor<f32>
      %5 = "stablehlo.constant"() <{value = dense<9.99999997E-7> : tensor<f32>}> : () -> tensor<f32>
      %6 = "stablehlo.constant"() <{value = dense<0.0883883461> : tensor<f32>}> : () -> tensor<f32>
      %7 = "stablehlo.constant"() <{value = dense<0.000000e+00> : tensor<bf16>}> : () -> tensor<bf16>
      %8 = "stablehlo.constant"() <{value = dense<-3.389530e+38> : tensor<bf16>}> : () -> tensor<bf16>
      %9 = "stablehlo.broadcast_in_dim"(%8) <{broadcast_dimensions = array<i64>}> : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %10 = "stablehlo.broadcast_in_dim"(%7) <{broadcast_dimensions = array<i64>}> : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %11 = "stablehlo.broadcast_in_dim"(%6) <{broadcast_dimensions = array<i64>}> : (tensor<f32>) -> tensor<1x7x39x39xf32>
      %12 = "stablehlo.broadcast_in_dim"(%5) <{broadcast_dimensions = array<i64>}> : (tensor<f32>) -> tensor<2x39x1xf32>
      %13 = "stablehlo.broadcast_in_dim"(%4) <{broadcast_dimensions = array<i64>}> : (tensor<f32>) -> tensor<2x39xf32>
      %14 = "stablehlo.broadcast_in_dim"(%3) <{broadcast_dimensions = array<i64>}> : (tensor<f32>) -> tensor<2x39x1792xf32>
      %15 = "stablehlo.convert"(%arg32) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
      %16 = "stablehlo.convert"(%arg31) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
      %17 = "stablehlo.multiply"(%15, %16) : (tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
      %18 = "stablehlo.convert"(%17) : (tensor<39x39xf32>) -> tensor<39x39xbf16>
      %19 = "stablehlo.reshape"(%18) : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
      %20 = "stablehlo.broadcast_in_dim"(%19) <{broadcast_dimensions = array<i64: 1, 2, 3>}> : (tensor<1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
      %21 = "stablehlo.reshape"(%arg24) : (tensor<1792xbf16>) -> tensor<1x1x1792xbf16>
      %22 = "stablehlo.reshape"(%21) : (tensor<1x1x1792xbf16>) -> tensor<1792xbf16>
      %23 = "stablehlo.convert"(%22) : (tensor<1792xbf16>) -> tensor<1792xf32>
      %24 = "stablehlo.broadcast_in_dim"(%23) <{broadcast_dimensions = array<i64: 2>}> : (tensor<1792xf32>) -> tensor<2x39x1792xf32>
      %25 = "stablehlo.convert"(%arg23) : (tensor<2x39x1792xbf16>) -> tensor<2x39x1792xf32>
      %26 = "stablehlo.power"(%25, %14) : (tensor<2x39x1792xf32>, tensor<2x39x1792xf32>) -> tensor<2x39x1792xf32>
      %27 = "stablehlo.reduce"(%26, %1) <{dimensions = array<i64: 2>}> ({
      ^bb0(%arg66: tensor<f32>, %arg67: tensor<f32>):
        %258 = "stablehlo.add"(%arg66, %arg67) : (tensor<f32>, tensor<f32>) -> tensor<f32>
        "stablehlo.return"(%258) : (tensor<f32>) -> ()
      }) : (tensor<2x39x1792xf32>, tensor<f32>) -> tensor<2x39xf32>
      %28 = "stablehlo.all_reduce"(%27) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 4], [1, 5], [2, 6], [3, 7]]> : tensor<4x2xi64>}> ({
      ^bb0(%arg64: tensor<f32>, %arg65: tensor<f32>):
        %257 = "stablehlo.add"(%arg64, %arg65) : (tensor<f32>, tensor<f32>) -> tensor<f32>
        "stablehlo.return"(%257) : (tensor<f32>) -> ()
      }) : (tensor<2x39xf32>) -> tensor<2x39xf32>
      %29 = "stablehlo.multiply"(%28, %13) : (tensor<2x39xf32>, tensor<2x39xf32>) -> tensor<2x39xf32>
      %30 = "stablehlo.reshape"(%29) : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
      %31 = "stablehlo.add"(%30, %12) : (tensor<2x39x1xf32>, tensor<2x39x1xf32>) -> tensor<2x39x1xf32>
      %32 = "stablehlo.rsqrt"(%31) : (tensor<2x39x1xf32>) -> tensor<2x39x1xf32>
      %33 = "stablehlo.reshape"(%32) : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
      %34 = "stablehlo.broadcast_in_dim"(%33) <{broadcast_dimensions = array<i64: 0, 1>}> : (tensor<2x39xf32>) -> tensor<2x39x1792xf32>
      %35 = "stablehlo.multiply"(%25, %34) : (tensor<2x39x1792xf32>, tensor<2x39x1792xf32>) -> tensor<2x39x1792xf32>
      %36 = "stablehlo.convert"(%35) : (tensor<2x39x1792xf32>) -> tensor<2x39x1792xbf16>
      %37 = "stablehlo.convert"(%36) : (tensor<2x39x1792xbf16>) -> tensor<2x39x1792xf32>
      %38 = "stablehlo.multiply"(%24, %37) : (tensor<2x39x1792xf32>, tensor<2x39x1792xf32>) -> tensor<2x39x1792xf32>
      %39 = "stablehlo.convert"(%38) : (tensor<2x39x1792xf32>) -> tensor<2x39x1792xbf16>
      %40 = "stablehlo.reshape"(%39) : (tensor<2x39x1792xbf16>) -> tensor<78x1792xbf16>
      %41 = "stablehlo.reshape"(%arg22) : (tensor<128x1792xbf16>) -> tensor<1x128x1792xbf16>
      %42 = "stablehlo.reshape"(%41) : (tensor<1x128x1792xbf16>) -> tensor<128x1792xbf16>
      %43 = "stablehlo.transpose"(%42) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<128x1792xbf16>) -> tensor<1792x128xbf16>
      %44 = "stablehlo.dot_general"(%40, %43) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<78x1792xbf16>, tensor<1792x128xbf16>) -> tensor<78x128xbf16>
      %45 = "stablehlo.all_reduce"(%44) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 4], [1, 5], [2, 6], [3, 7]]> : tensor<4x2xi64>}> ({
      ^bb0(%arg62: tensor<bf16>, %arg63: tensor<bf16>):
        %256 = "stablehlo.add"(%arg62, %arg63) : (tensor<bf16>, tensor<bf16>) -> tensor<bf16>
        "stablehlo.return"(%256) : (tensor<bf16>) -> ()
      }) : (tensor<78x128xbf16>) -> tensor<78x128xbf16>
      %46 = "stablehlo.reshape"(%45) : (tensor<78x128xbf16>) -> tensor<2x39x512xbf16>
      %47 = "stablehlo.all_to_all"(%46) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, concat_dimension = 0 : i64, replica_groups = dense<[[0, 4], [1, 5], [2, 6], [3, 7]]> : tensor<4x2xi64>, split_count = 2 : i64, split_dimension = 0 : i64}> : (tensor<2x39x512xbf16>) -> tensor<2x39x512xbf16>
      %48 = "stablehlo.slice"(%47) <{limit_indices = array<i64: 1, 39, 512>, start_indices = array<i64: 0, 0, 0>, strides = array<i64: 1, 1, 1>}> : (tensor<2x39x512xbf16>) -> tensor<1x39x512xbf16>
      %49 = "stablehlo.reshape"(%48) : (tensor<1x39x512xbf16>) -> tensor<39x512xbf16>
      %50 = "stablehlo.reshape"(%49) : (tensor<39x512xbf16>) -> tensor<1x39x128xbf16>
      %51 = "stablehlo.reshape"(%arg21) : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
      %52 = "stablehlo.reshape"(%51) : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
      %53 = "stablehlo.broadcast_in_dim"(%52) <{broadcast_dimensions = array<i64: 2>}> : (tensor<128xbf16>) -> tensor<1x39x128xbf16>
      %54 = "stablehlo.add"(%50, %53) : (tensor<1x39x128xbf16>, tensor<1x39x128xbf16>) -> tensor<1x39x128xbf16>
      %55 = "stablehlo.reshape"(%54) : (tensor<1x39x128xbf16>) -> tensor<1x39x1x128xbf16>
      %56 = "stablehlo.transpose"(%55) <{permutation = array<i64: 0, 2, 1, 3>}> {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<1x39x1x128xbf16>) -> tensor<1x1x39x128xbf16>
      %57 = "stablehlo.convert"(%56) {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,4,39,128]{3,1,2,0}"} : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
      %58 = "stablehlo.reshape"(%arg20) : (tensor<64xf32>) -> tensor<1x1x64xf32>
      %59 = "stablehlo.reshape"(%58) : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
      %60 = "stablehlo.reshape"(%arg19) : (tensor<1x39xi64>) -> tensor<1x1x39xi64>
      %61 = "stablehlo.convert"(%60) : (tensor<1x1x39xi64>) -> tensor<1x1x39xf32>
      %62 = "stablehlo.dot_general"(%59, %61) <{dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>}> : (tensor<1x64x1xf32>, tensor<1x1x39xf32>) -> tensor<1x64x39xf32>
      %63 = "stablehlo.transpose"(%62) <{permutation = array<i64: 0, 2, 1>}> {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,39,64]{1,2,0}"} : (tensor<1x64x39xf32>) -> tensor<1x39x64xf32>
      %64 = "stablehlo.concatenate"(%63, %63) <{dimension = 2 : i64}> : (tensor<1x39x64xf32>, tensor<1x39x64xf32>) -> tensor<1x39x128xf32>
      %65 = "stablehlo.cosine"(%64) : (tensor<1x39x128xf32>) -> tensor<1x39x128xf32>
      %66 = "stablehlo.convert"(%65) : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
      %67 = "stablehlo.reshape"(%66) : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
      %68 = "stablehlo.convert"(%67) : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
      %69 = "stablehlo.reshape"(%68) : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
      %70 = "stablehlo.broadcast_in_dim"(%69) <{broadcast_dimensions = array<i64: 2, 3>}> : (tensor<39x128xf32>) -> tensor<1x1x39x128xf32>
      %71 = "stablehlo.multiply"(%57, %70) : (tensor<1x1x39x128xf32>, tensor<1x1x39x128xf32>) -> tensor<1x1x39x128xf32>
      %72 = "stablehlo.convert"(%71) : (tensor<1x1x39x128xf32>) -> tensor<1x1x39x128xbf16>
      %73 = "stablehlo.slice"(%56) <{limit_indices = array<i64: 1, 1, 39, 128>, start_indices = array<i64: 0, 0, 0, 64>, strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x64xbf16>
      %74 = "stablehlo.negate"(%73) : (tensor<1x1x39x64xbf16>) -> tensor<1x1x39x64xbf16>
      %75 = "stablehlo.slice"(%56) <{limit_indices = array<i64: 1, 1, 39, 64>, start_indices = array<i64: 0, 0, 0, 0>, strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x64xbf16>
      %76 = "stablehlo.concatenate"(%74, %75) <{dimension = 3 : i64}> : (tensor<1x1x39x64xbf16>, tensor<1x1x39x64xbf16>) -> tensor<1x1x39x128xbf16>
      %77 = "stablehlo.convert"(%76) : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
      %78 = "stablehlo.sine"(%64) : (tensor<1x39x128xf32>) -> tensor<1x39x128xf32>
      %79 = "stablehlo.convert"(%78) : (tensor<1x39x128xf32>) -> tensor<1x39x128xbf16>
      %80 = "stablehlo.reshape"(%79) : (tensor<1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
      %81 = "stablehlo.convert"(%80) : (tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xf32>
      %82 = "stablehlo.reshape"(%81) : (tensor<1x1x39x128xf32>) -> tensor<39x128xf32>
      %83 = "stablehlo.broadcast_in_dim"(%82) <{broadcast_dimensions = array<i64: 2, 3>}> : (tensor<39x128xf32>) -> tensor<1x1x39x128xf32>
      %84 = "stablehlo.multiply"(%77, %83) : (tensor<1x1x39x128xf32>, tensor<1x1x39x128xf32>) -> tensor<1x1x39x128xf32>
      %85 = "stablehlo.convert"(%84) : (tensor<1x1x39x128xf32>) -> tensor<1x1x39x128xbf16>
      %86 = "stablehlo.add"(%72, %85) : (tensor<1x1x39x128xbf16>, tensor<1x1x39x128xbf16>) -> tensor<1x1x39x128xbf16>
      %87 = "stablehlo.reshape"(%arg26) : (tensor<128x1792xbf16>) -> tensor<1x128x1792xbf16>
      %88 = "stablehlo.reshape"(%87) : (tensor<1x128x1792xbf16>) -> tensor<128x1792xbf16>
      %89 = "stablehlo.transpose"(%88) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<128x1792xbf16>) -> tensor<1792x128xbf16>
      %90 = "stablehlo.dot_general"(%40, %89) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<78x1792xbf16>, tensor<1792x128xbf16>) -> tensor<78x128xbf16>
      %91 = "stablehlo.all_reduce"(%90) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 4], [1, 5], [2, 6], [3, 7]]> : tensor<4x2xi64>}> ({
      ^bb0(%arg60: tensor<bf16>, %arg61: tensor<bf16>):
        %255 = "stablehlo.add"(%arg60, %arg61) : (tensor<bf16>, tensor<bf16>) -> tensor<bf16>
        "stablehlo.return"(%255) : (tensor<bf16>) -> ()
      }) : (tensor<78x128xbf16>) -> tensor<78x128xbf16>
      %92 = "stablehlo.reshape"(%91) : (tensor<78x128xbf16>) -> tensor<2x39x512xbf16>
      %93 = "stablehlo.all_to_all"(%92) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, concat_dimension = 0 : i64, replica_groups = dense<[[0, 4], [1, 5], [2, 6], [3, 7]]> : tensor<4x2xi64>, split_count = 2 : i64, split_dimension = 0 : i64}> : (tensor<2x39x512xbf16>) -> tensor<2x39x512xbf16>
      %94 = "stablehlo.slice"(%93) <{limit_indices = array<i64: 1, 39, 512>, start_indices = array<i64: 0, 0, 0>, strides = array<i64: 1, 1, 1>}> : (tensor<2x39x512xbf16>) -> tensor<1x39x512xbf16>
      %95 = "stablehlo.reshape"(%94) : (tensor<1x39x512xbf16>) -> tensor<39x512xbf16>
      %96 = "stablehlo.reshape"(%95) : (tensor<39x512xbf16>) -> tensor<1x39x128xbf16>
      %97 = "stablehlo.reshape"(%arg25) : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
      %98 = "stablehlo.reshape"(%97) : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
      %99 = "stablehlo.broadcast_in_dim"(%98) <{broadcast_dimensions = array<i64: 2>}> : (tensor<128xbf16>) -> tensor<1x39x128xbf16>
      %100 = "stablehlo.add"(%96, %99) : (tensor<1x39x128xbf16>, tensor<1x39x128xbf16>) -> tensor<1x39x128xbf16>
      %101 = "stablehlo.reshape"(%100) : (tensor<1x39x128xbf16>) -> tensor<1x39x1x128xbf16>
      %102 = "stablehlo.transpose"(%101) <{permutation = array<i64: 0, 2, 1, 3>}> {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,39,128]{3,1,2,0}"} : (tensor<1x39x1x128xbf16>) -> tensor<1x1x39x128xbf16>
      %103 = "stablehlo.reshape"(%arg37) : (tensor<1792xbf16>) -> tensor<1x1x1792xbf16>
      %104 = "stablehlo.reshape"(%103) : (tensor<1x1x1792xbf16>) -> tensor<1792xbf16>
      %105 = "stablehlo.convert"(%104) : (tensor<1792xbf16>) -> tensor<1792xf32>
      %106 = "stablehlo.broadcast_in_dim"(%105) <{broadcast_dimensions = array<i64: 2>}> : (tensor<1792xf32>) -> tensor<2x39x1792xf32>
      %107 = "stablehlo.reshape"(%arg34) : (tensor<896x1792xbf16>) -> tensor<1x896x1792xbf16>
      %108 = "stablehlo.reshape"(%107) : (tensor<1x896x1792xbf16>) -> tensor<896x1792xbf16>
      %109 = "stablehlo.transpose"(%108) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<896x1792xbf16>) -> tensor<1792x896xbf16>
      %110 = "stablehlo.dot_general"(%40, %109) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<78x1792xbf16>, tensor<1792x896xbf16>) -> tensor<78x896xbf16>
      %111 = "stablehlo.all_reduce"(%110) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 4], [1, 5], [2, 6], [3, 7]]> : tensor<4x2xi64>}> ({
      ^bb0(%arg58: tensor<bf16>, %arg59: tensor<bf16>):
        %254 = "stablehlo.add"(%arg58, %arg59) : (tensor<bf16>, tensor<bf16>) -> tensor<bf16>
        "stablehlo.return"(%254) : (tensor<bf16>) -> ()
      }) : (tensor<78x896xbf16>) -> tensor<78x896xbf16>
      %112 = "stablehlo.reshape"(%111) : (tensor<78x896xbf16>) -> tensor<2x39x3584xbf16>
      %113 = "stablehlo.all_to_all"(%112) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, concat_dimension = 0 : i64, replica_groups = dense<[[0, 4], [1, 5], [2, 6], [3, 7]]> : tensor<4x2xi64>, split_count = 2 : i64, split_dimension = 0 : i64}> : (tensor<2x39x3584xbf16>) -> tensor<2x39x3584xbf16>
      %114 = "stablehlo.slice"(%113) <{limit_indices = array<i64: 1, 39, 3584>, start_indices = array<i64: 0, 0, 0>, strides = array<i64: 1, 1, 1>}> : (tensor<2x39x3584xbf16>) -> tensor<1x39x3584xbf16>
      %115 = "stablehlo.reshape"(%114) : (tensor<1x39x3584xbf16>) -> tensor<39x3584xbf16>
      %116 = "stablehlo.reshape"(%115) : (tensor<39x3584xbf16>) -> tensor<1x39x896xbf16>
      %117 = "stablehlo.reshape"(%arg33) : (tensor<896xbf16>) -> tensor<1x1x896xbf16>
      %118 = "stablehlo.reshape"(%117) : (tensor<1x1x896xbf16>) -> tensor<896xbf16>
      %119 = "stablehlo.broadcast_in_dim"(%118) <{broadcast_dimensions = array<i64: 2>}> : (tensor<896xbf16>) -> tensor<1x39x896xbf16>
      %120 = "stablehlo.add"(%116, %119) : (tensor<1x39x896xbf16>, tensor<1x39x896xbf16>) -> tensor<1x39x896xbf16>
      %121 = "stablehlo.reshape"(%120) : (tensor<1x39x896xbf16>) -> tensor<1x39x7x128xbf16>
      %122 = "stablehlo.transpose"(%121) <{permutation = array<i64: 0, 2, 1, 3>}> {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,39,128]{3,1,2,0}"} : (tensor<1x39x7x128xbf16>) -> tensor<1x7x39x128xbf16>
      %123 = "stablehlo.convert"(%122) {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,28,39,128]{3,1,2,0}"} : (tensor<1x7x39x128xbf16>) -> tensor<1x7x39x128xf32>
      %124 = "stablehlo.broadcast_in_dim"(%69) <{broadcast_dimensions = array<i64: 2, 3>}> : (tensor<39x128xf32>) -> tensor<1x7x39x128xf32>
      %125 = "stablehlo.multiply"(%123, %124) : (tensor<1x7x39x128xf32>, tensor<1x7x39x128xf32>) -> tensor<1x7x39x128xf32>
      %126 = "stablehlo.convert"(%125) : (tensor<1x7x39x128xf32>) -> tensor<1x7x39x128xbf16>
      %127 = "stablehlo.slice"(%122) <{limit_indices = array<i64: 1, 7, 39, 128>, start_indices = array<i64: 0, 0, 0, 64>, strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x7x39x128xbf16>) -> tensor<1x7x39x64xbf16>
      %128 = "stablehlo.negate"(%127) : (tensor<1x7x39x64xbf16>) -> tensor<1x7x39x64xbf16>
      %129 = "stablehlo.slice"(%122) <{limit_indices = array<i64: 1, 7, 39, 64>, start_indices = array<i64: 0, 0, 0, 0>, strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x7x39x128xbf16>) -> tensor<1x7x39x64xbf16>
      %130 = "stablehlo.concatenate"(%128, %129) <{dimension = 3 : i64}> : (tensor<1x7x39x64xbf16>, tensor<1x7x39x64xbf16>) -> tensor<1x7x39x128xbf16>
      %131 = "stablehlo.convert"(%130) : (tensor<1x7x39x128xbf16>) -> tensor<1x7x39x128xf32>
      %132 = "stablehlo.broadcast_in_dim"(%82) <{broadcast_dimensions = array<i64: 2, 3>}> : (tensor<39x128xf32>) -> tensor<1x7x39x128xf32>
      %133 = "stablehlo.multiply"(%131, %132) : (tensor<1x7x39x128xf32>, tensor<1x7x39x128xf32>) -> tensor<1x7x39x128xf32>
      %134 = "stablehlo.convert"(%133) : (tensor<1x7x39x128xf32>) -> tensor<1x7x39x128xbf16>
      %135 = "stablehlo.add"(%126, %134) : (tensor<1x7x39x128xbf16>, tensor<1x7x39x128xbf16>) -> tensor<1x7x39x128xbf16>
      %136 = "stablehlo.reshape"(%135) : (tensor<1x7x39x128xbf16>) -> tensor<7x39x128xbf16>
      %137 = "stablehlo.broadcast_in_dim"(%86) <{broadcast_dimensions = array<i64: 0, 1, 3, 4>}> : (tensor<1x1x39x128xbf16>) -> tensor<1x1x7x39x128xbf16>
      %138 = "stablehlo.reshape"(%137) : (tensor<1x1x7x39x128xbf16>) -> tensor<1x7x39x128xbf16>
      %139 = "stablehlo.transpose"(%138) <{permutation = array<i64: 0, 1, 3, 2>}> {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,128,39]{2,3,1,0}"} : (tensor<1x7x39x128xbf16>) -> tensor<1x7x128x39xbf16>
      %140 = "stablehlo.reshape"(%139) : (tensor<1x7x128x39xbf16>) -> tensor<7x128x39xbf16>
      %141 = "stablehlo.dot_general"(%136, %140) <{dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>}> : (tensor<7x39x128xbf16>, tensor<7x128x39xbf16>) -> tensor<7x39x39xbf16>
      %142 = "stablehlo.reshape"(%141) : (tensor<7x39x39xbf16>) -> tensor<1x7x39x39xbf16>
      %143 = "stablehlo.convert"(%142) : (tensor<1x7x39x39xbf16>) -> tensor<1x7x39x39xf32>
      %144 = "stablehlo.multiply"(%143, %11) : (tensor<1x7x39x39xf32>, tensor<1x7x39x39xf32>) -> tensor<1x7x39x39xf32>
      %145 = "stablehlo.convert"(%144) : (tensor<1x7x39x39xf32>) -> tensor<1x7x39x39xbf16>
      %146 = "stablehlo.reshape"(%arg30) : (tensor<1x39xi64>) -> tensor<1x1x1x39xi64>
      %147 = "stablehlo.convert"(%146) : (tensor<1x1x1x39xi64>) -> tensor<1x1x1x39xbf16>
      %148 = "stablehlo.reshape"(%147) : (tensor<1x1x1x39xbf16>) -> tensor<1x1x39xbf16>
      %149 = "stablehlo.broadcast_in_dim"(%148) <{broadcast_dimensions = array<i64: 0, 1, 3>}> : (tensor<1x1x39xbf16>) -> tensor<1x1x39x39xbf16>
      %150 = "stablehlo.add"(%20, %149) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
      %151 = "stablehlo.compare"(%150, %10) <{comparison_direction = #stablehlo<comparison_direction EQ>}> : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xi1>
      %152 = "stablehlo.select"(%151, %9, %20) : (tensor<1x1x39x39xi1>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
      %153 = "stablehlo.reshape"(%152) : (tensor<1x1x39x39xbf16>) -> tensor<1x39x39xbf16>
      %154 = "stablehlo.broadcast_in_dim"(%153) <{broadcast_dimensions = array<i64: 0, 2, 3>}> : (tensor<1x39x39xbf16>) -> tensor<1x7x39x39xbf16>
      %155 = "stablehlo.add"(%145, %154) : (tensor<1x7x39x39xbf16>, tensor<1x7x39x39xbf16>) -> tensor<1x7x39x39xbf16>
      %156 = "stablehlo.convert"(%155) : (tensor<1x7x39x39xbf16>) -> tensor<1x7x39x39xf32>
      %157 = "stablehlo.reduce"(%156, %2) <{dimensions = array<i64: 3>}> ({
      ^bb0(%arg56: tensor<f32>, %arg57: tensor<f32>):
        %253 = "stablehlo.maximum"(%arg56, %arg57) : (tensor<f32>, tensor<f32>) -> tensor<f32>
        "stablehlo.return"(%253) : (tensor<f32>) -> ()
      }) : (tensor<1x7x39x39xf32>, tensor<f32>) -> tensor<1x7x39xf32>
      %158 = "stablehlo.broadcast_in_dim"(%157) <{broadcast_dimensions = array<i64: 0, 1, 2>}> : (tensor<1x7x39xf32>) -> tensor<1x7x39x39xf32>
      %159 = "stablehlo.subtract"(%156, %158) : (tensor<1x7x39x39xf32>, tensor<1x7x39x39xf32>) -> tensor<1x7x39x39xf32>
      %160 = "stablehlo.exponential"(%159) : (tensor<1x7x39x39xf32>) -> tensor<1x7x39x39xf32>
      %161 = "stablehlo.reduce"(%160, %1) <{dimensions = array<i64: 3>}> ({
      ^bb0(%arg54: tensor<f32>, %arg55: tensor<f32>):
        %252 = "stablehlo.add"(%arg54, %arg55) : (tensor<f32>, tensor<f32>) -> tensor<f32>
        "stablehlo.return"(%252) : (tensor<f32>) -> ()
      }) : (tensor<1x7x39x39xf32>, tensor<f32>) -> tensor<1x7x39xf32>
      %162 = "stablehlo.broadcast_in_dim"(%161) <{broadcast_dimensions = array<i64: 0, 1, 2>}> : (tensor<1x7x39xf32>) -> tensor<1x7x39x39xf32>
      %163 = "stablehlo.divide"(%160, %162) : (tensor<1x7x39x39xf32>, tensor<1x7x39x39xf32>) -> tensor<1x7x39x39xf32>
      %164 = "stablehlo.convert"(%163) : (tensor<1x7x39x39xf32>) -> tensor<1x7x39x39xbf16>
      %165 = "stablehlo.reshape"(%164) : (tensor<1x7x39x39xbf16>) -> tensor<7x39x39xbf16>
      %166 = "stablehlo.broadcast_in_dim"(%102) <{broadcast_dimensions = array<i64: 0, 1, 3, 4>}> : (tensor<1x1x39x128xbf16>) -> tensor<1x1x7x39x128xbf16>
      %167 = "stablehlo.reshape"(%166) : (tensor<1x1x7x39x128xbf16>) -> tensor<7x39x128xbf16>
      %168 = "stablehlo.dot_general"(%165, %167) <{dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>}> : (tensor<7x39x39xbf16>, tensor<7x39x128xbf16>) -> tensor<7x39x128xbf16>
      %169 = "stablehlo.reshape"(%168) : (tensor<7x39x128xbf16>) -> tensor<1x7x39x128xbf16>
      %170 = "stablehlo.transpose"(%169) <{permutation = array<i64: 0, 2, 1, 3>}> {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,39,28,128]{3,1,2,0}"} : (tensor<1x7x39x128xbf16>) -> tensor<1x39x7x128xbf16>
      %171 = "stablehlo.reshape"(%170) : (tensor<1x39x7x128xbf16>) -> tensor<39x896xbf16>
      %172 = "stablehlo.reshape"(%arg29) : (tensor<1792x896xbf16>) -> tensor<1x1792x896xbf16>
      %173 = "stablehlo.reshape"(%172) : (tensor<1x1792x896xbf16>) -> tensor<1792x896xbf16>
      %174 = "stablehlo.transpose"(%173) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<1792x896xbf16>) -> tensor<896x1792xbf16>
      %175 = "stablehlo.all_gather"(%171) <{all_gather_dim = 0 : i64, channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 4], [1, 5], [2, 6], [3, 7]]> : tensor<4x2xi64>}> : (tensor<39x896xbf16>) -> tensor<78x896xbf16>
      %176 = "stablehlo.dot_general"(%175, %174) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<78x896xbf16>, tensor<896x1792xbf16>) -> tensor<78x1792xbf16>
      %177 = "stablehlo.all_reduce"(%176) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7]]> : tensor<2x4xi64>}> ({
      ^bb0(%arg52: tensor<bf16>, %arg53: tensor<bf16>):
        %251 = "stablehlo.add"(%arg52, %arg53) : (tensor<bf16>, tensor<bf16>) -> tensor<bf16>
        "stablehlo.return"(%251) : (tensor<bf16>) -> ()
      }) : (tensor<78x1792xbf16>) -> tensor<78x1792xbf16>
      %178 = "stablehlo.reshape"(%177) : (tensor<78x1792xbf16>) -> tensor<2x39x1792xbf16>
      %179 = "stablehlo.add"(%arg23, %178) : (tensor<2x39x1792xbf16>, tensor<2x39x1792xbf16>) -> tensor<2x39x1792xbf16>
      %180 = "stablehlo.reshape"(%arg35) : (tensor<1792xbf16>) -> tensor<1x1x1792xbf16>
      %181 = "stablehlo.reshape"(%180) : (tensor<1x1x1792xbf16>) -> tensor<1792xbf16>
      %182 = "stablehlo.convert"(%181) : (tensor<1792xbf16>) -> tensor<1792xf32>
      %183 = "stablehlo.broadcast_in_dim"(%182) <{broadcast_dimensions = array<i64: 2>}> : (tensor<1792xf32>) -> tensor<2x39x1792xf32>
      %184 = "stablehlo.convert"(%179) : (tensor<2x39x1792xbf16>) -> tensor<2x39x1792xf32>
      %185 = "stablehlo.power"(%184, %14) : (tensor<2x39x1792xf32>, tensor<2x39x1792xf32>) -> tensor<2x39x1792xf32>
      %186 = "stablehlo.reduce"(%185, %1) <{dimensions = array<i64: 2>}> ({
      ^bb0(%arg50: tensor<f32>, %arg51: tensor<f32>):
        %250 = "stablehlo.add"(%arg50, %arg51) : (tensor<f32>, tensor<f32>) -> tensor<f32>
        "stablehlo.return"(%250) : (tensor<f32>) -> ()
      }) : (tensor<2x39x1792xf32>, tensor<f32>) -> tensor<2x39xf32>
      %187 = "stablehlo.all_reduce"(%186) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 4], [1, 5], [2, 6], [3, 7]]> : tensor<4x2xi64>}> ({
      ^bb0(%arg48: tensor<f32>, %arg49: tensor<f32>):
        %249 = "stablehlo.add"(%arg48, %arg49) : (tensor<f32>, tensor<f32>) -> tensor<f32>
        "stablehlo.return"(%249) : (tensor<f32>) -> ()
      }) : (tensor<2x39xf32>) -> tensor<2x39xf32>
      %188 = "stablehlo.multiply"(%187, %13) : (tensor<2x39xf32>, tensor<2x39xf32>) -> tensor<2x39xf32>
      %189 = "stablehlo.reshape"(%188) : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
      %190 = "stablehlo.add"(%189, %12) : (tensor<2x39x1xf32>, tensor<2x39x1xf32>) -> tensor<2x39x1xf32>
      %191 = "stablehlo.rsqrt"(%190) : (tensor<2x39x1xf32>) -> tensor<2x39x1xf32>
      %192 = "stablehlo.reshape"(%191) : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
      %193 = "stablehlo.broadcast_in_dim"(%192) <{broadcast_dimensions = array<i64: 0, 1>}> : (tensor<2x39xf32>) -> tensor<2x39x1792xf32>
      %194 = "stablehlo.multiply"(%184, %193) : (tensor<2x39x1792xf32>, tensor<2x39x1792xf32>) -> tensor<2x39x1792xf32>
      %195 = "stablehlo.convert"(%194) : (tensor<2x39x1792xf32>) -> tensor<2x39x1792xbf16>
      %196 = "stablehlo.convert"(%195) : (tensor<2x39x1792xbf16>) -> tensor<2x39x1792xf32>
      %197 = "stablehlo.multiply"(%183, %196) : (tensor<2x39x1792xf32>, tensor<2x39x1792xf32>) -> tensor<2x39x1792xf32>
      %198 = "stablehlo.convert"(%197) : (tensor<2x39x1792xf32>) -> tensor<2x39x1792xbf16>
      %199 = "stablehlo.reshape"(%198) : (tensor<2x39x1792xbf16>) -> tensor<78x1792xbf16>
      %200 = "stablehlo.reshape"(%arg36) : (tensor<4736x1792xbf16>) -> tensor<1x4736x1792xbf16>
      %201 = "stablehlo.reshape"(%200) : (tensor<1x4736x1792xbf16>) -> tensor<4736x1792xbf16>
      %202 = "stablehlo.transpose"(%201) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<4736x1792xbf16>) -> tensor<1792x4736xbf16>
      %203 = "stablehlo.dot_general"(%199, %202) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<78x1792xbf16>, tensor<1792x4736xbf16>) -> tensor<78x4736xbf16>
      %204 = "stablehlo.all_reduce"(%203) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 4], [1, 5], [2, 6], [3, 7]]> : tensor<4x2xi64>}> ({
      ^bb0(%arg46: tensor<bf16>, %arg47: tensor<bf16>):
        %248 = "stablehlo.add"(%arg46, %arg47) : (tensor<bf16>, tensor<bf16>) -> tensor<bf16>
        "stablehlo.return"(%248) : (tensor<bf16>) -> ()
      }) : (tensor<78x4736xbf16>) -> tensor<78x4736xbf16>
      %205 = "stablehlo.reshape"(%204) : (tensor<78x4736xbf16>) -> tensor<2x39x4736xbf16>
      %206 = "stablehlo.convert"(%205) : (tensor<2x39x4736xbf16>) -> tensor<2x39x4736xf32>
      %207 = "stablehlo.logistic"(%205) : (tensor<2x39x4736xbf16>) -> tensor<2x39x4736xbf16>
      %208 = "stablehlo.convert"(%207) : (tensor<2x39x4736xbf16>) -> tensor<2x39x4736xf32>
      %209 = "stablehlo.multiply"(%206, %208) : (tensor<2x39x4736xf32>, tensor<2x39x4736xf32>) -> tensor<2x39x4736xf32>
      %210 = "stablehlo.convert"(%209) : (tensor<2x39x4736xf32>) -> tensor<2x39x4736xbf16>
      %211 = "stablehlo.convert"(%210) : (tensor<2x39x4736xbf16>) -> tensor<2x39x4736xf32>
      %212 = "stablehlo.reshape"(%arg28) : (tensor<4736x1792xbf16>) -> tensor<1x4736x1792xbf16>
      %213 = "stablehlo.reshape"(%212) : (tensor<1x4736x1792xbf16>) -> tensor<4736x1792xbf16>
      %214 = "stablehlo.transpose"(%213) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,18944]{0,1}"} : (tensor<4736x1792xbf16>) -> tensor<1792x4736xbf16>
      %215 = "stablehlo.dot_general"(%199, %214) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<78x1792xbf16>, tensor<1792x4736xbf16>) -> tensor<78x4736xbf16>
      %216 = "stablehlo.all_reduce"(%215) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 4], [1, 5], [2, 6], [3, 7]]> : tensor<4x2xi64>}> ({
      ^bb0(%arg44: tensor<bf16>, %arg45: tensor<bf16>):
        %247 = "stablehlo.add"(%arg44, %arg45) : (tensor<bf16>, tensor<bf16>) -> tensor<bf16>
        "stablehlo.return"(%247) : (tensor<bf16>) -> ()
      }) : (tensor<78x4736xbf16>) -> tensor<78x4736xbf16>
      %217 = "stablehlo.reshape"(%216) : (tensor<78x4736xbf16>) -> tensor<2x39x4736xbf16>
      %218 = "stablehlo.convert"(%217) : (tensor<2x39x4736xbf16>) -> tensor<2x39x4736xf32>
      %219 = "stablehlo.multiply"(%211, %218) : (tensor<2x39x4736xf32>, tensor<2x39x4736xf32>) -> tensor<2x39x4736xf32>
      %220 = "stablehlo.convert"(%219) : (tensor<2x39x4736xf32>) -> tensor<2x39x4736xbf16>
      %221 = "stablehlo.reshape"(%220) : (tensor<2x39x4736xbf16>) -> tensor<78x4736xbf16>
      %222 = "stablehlo.reshape"(%arg27) : (tensor<1792x4736xbf16>) -> tensor<1x1792x4736xbf16>
      %223 = "stablehlo.reshape"(%222) : (tensor<1x1792x4736xbf16>) -> tensor<1792x4736xbf16>
      %224 = "stablehlo.transpose"(%223) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[18944,3584]{0,1}"} : (tensor<1792x4736xbf16>) -> tensor<4736x1792xbf16>
      %225 = "stablehlo.dot_general"(%221, %224) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<78x4736xbf16>, tensor<4736x1792xbf16>) -> tensor<78x1792xbf16>
      %226 = "stablehlo.all_reduce"(%225) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7]]> : tensor<2x4xi64>}> ({
      ^bb0(%arg42: tensor<bf16>, %arg43: tensor<bf16>):
        %246 = "stablehlo.add"(%arg42, %arg43) : (tensor<bf16>, tensor<bf16>) -> tensor<bf16>
        "stablehlo.return"(%246) : (tensor<bf16>) -> ()
      }) : (tensor<78x1792xbf16>) -> tensor<78x1792xbf16>
      %227 = "stablehlo.reshape"(%226) : (tensor<78x1792xbf16>) -> tensor<2x39x1792xbf16>
      %228 = "stablehlo.add"(%179, %227) : (tensor<2x39x1792xbf16>, tensor<2x39x1792xbf16>) -> tensor<2x39x1792xbf16>
      %229 = "stablehlo.convert"(%228) : (tensor<2x39x1792xbf16>) -> tensor<2x39x1792xf32>
      %230 = "stablehlo.power"(%229, %14) : (tensor<2x39x1792xf32>, tensor<2x39x1792xf32>) -> tensor<2x39x1792xf32>
      %231 = "stablehlo.reduce"(%230, %1) <{dimensions = array<i64: 2>}> ({
      ^bb0(%arg40: tensor<f32>, %arg41: tensor<f32>):
        %245 = "stablehlo.add"(%arg40, %arg41) : (tensor<f32>, tensor<f32>) -> tensor<f32>
        "stablehlo.return"(%245) : (tensor<f32>) -> ()
      }) : (tensor<2x39x1792xf32>, tensor<f32>) -> tensor<2x39xf32>
      %232 = "stablehlo.all_reduce"(%231) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 4], [1, 5], [2, 6], [3, 7]]> : tensor<4x2xi64>}> ({
      ^bb0(%arg38: tensor<f32>, %arg39: tensor<f32>):
        %244 = "stablehlo.add"(%arg38, %arg39) : (tensor<f32>, tensor<f32>) -> tensor<f32>
        "stablehlo.return"(%244) : (tensor<f32>) -> ()
      }) : (tensor<2x39xf32>) -> tensor<2x39xf32>
      %233 = "stablehlo.multiply"(%232, %13) : (tensor<2x39xf32>, tensor<2x39xf32>) -> tensor<2x39xf32>
      %234 = "stablehlo.reshape"(%233) : (tensor<2x39xf32>) -> tensor<2x39x1xf32>
      %235 = "stablehlo.add"(%234, %12) : (tensor<2x39x1xf32>, tensor<2x39x1xf32>) -> tensor<2x39x1xf32>
      %236 = "stablehlo.rsqrt"(%235) : (tensor<2x39x1xf32>) -> tensor<2x39x1xf32>
      %237 = "stablehlo.reshape"(%236) : (tensor<2x39x1xf32>) -> tensor<2x39xf32>
      %238 = "stablehlo.broadcast_in_dim"(%237) <{broadcast_dimensions = array<i64: 0, 1>}> : (tensor<2x39xf32>) -> tensor<2x39x1792xf32>
      %239 = "stablehlo.multiply"(%229, %238) : (tensor<2x39x1792xf32>, tensor<2x39x1792xf32>) -> tensor<2x39x1792xf32>
      %240 = "stablehlo.convert"(%239) : (tensor<2x39x1792xf32>) -> tensor<2x39x1792xbf16>
      %241 = "stablehlo.convert"(%240) : (tensor<2x39x1792xbf16>) -> tensor<2x39x1792xf32>
      %242 = "stablehlo.multiply"(%106, %241) : (tensor<2x39x1792xf32>, tensor<2x39x1792xf32>) -> tensor<2x39x1792xf32>
      %243 = "stablehlo.convert"(%242) : (tensor<2x39x1792xf32>) -> tensor<2x39x1792xbf16>
      "sdy.return"(%86, %102, %243) : (tensor<1x1x39x128xbf16>, tensor<1x1x39x128xbf16>, tensor<2x39x1792xbf16>) -> ()
    }) : (tensor<1x39xi64>, tensor<64xf32>, tensor<512xbf16>, tensor<512x3584xbf16>, tensor<2x39x3584xbf16>, tensor<3584xbf16>, tensor<512xbf16>, tensor<512x3584xbf16>, tensor<3584x18944xbf16>, tensor<18944x3584xbf16>, tensor<3584x3584xbf16>, tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>, tensor<3584xbf16>, tensor<3584x3584xbf16>, tensor<3584xbf16>, tensor<18944x3584xbf16>, tensor<3584xbf16>) -> (tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>)
    "func.return"(%0#0, %0#1, %0#2) : (tensor<2x4x39x128xbf16>, tensor<2x4x39x128xbf16>, tensor<2x39x3584xbf16>) -> ()
  }) : () -> ()
}) {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} : () -> ()


#loc1 = loc("xla__device_data")
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<2x39x!vhlo.i64_v1> loc("xla__device_data"), %arg1: !vhlo.tensor_v1<39x39x!vhlo.bool_v1> loc("xla__device_data"), %arg2: !vhlo.tensor_v1<39x39x!vhlo.bf16_v1> loc("xla__device_data")) -> (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1> loc(#loc)
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<-3.389530e+38> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1> loc(#loc)
    %2 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1> loc(#loc)
    %3 = "vhlo.broadcast_in_dim_v1"(%0) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1> loc(#loc)
    %4 = "vhlo.convert_v1"(%arg2) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.f32_v1> loc(#loc2)
    %5 = "vhlo.convert_v1"(%arg1) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<39x39x!vhlo.bool_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.f32_v1> loc(#loc2)
    %6 = "vhlo.multiply_v1"(%4, %5) : (!vhlo.tensor_v1<39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.f32_v1> loc(#loc3)
    %7 = "vhlo.convert_v1"(%6) : (!vhlo.tensor_v1<39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.bf16_v1> loc(#loc2)
    %8 = "vhlo.custom_call_v1"(%7) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.bf16_v1> loc(#loc4)
    %9 = "vhlo.reshape_v1"(%8) : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x39x39x!vhlo.bf16_v1> loc(#loc5)
    %10 = "vhlo.broadcast_in_dim_v1"(%9) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[1, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1> loc(#loc6)
    %11 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<2x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<2x1x1x39x!vhlo.i64_v1> loc(#loc5)
    %12 = "vhlo.convert_v1"(%11) : (!vhlo.tensor_v1<2x1x1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<2x1x1x39x!vhlo.bf16_v1> loc(#loc7)
    %13 = "vhlo.reshape_v1"(%12) : (!vhlo.tensor_v1<2x1x1x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x!vhlo.bf16_v1> loc(#loc7)
    %14 = "vhlo.broadcast_in_dim_v1"(%13) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x1x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1> loc(#loc7)
    %15 = "vhlo.add_v1"(%10, %14) : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1> loc(#loc7)
    %16 = "vhlo.compare_v1"(%15, %3) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 EQ>}> : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bool_v1> loc(#loc8)
    %17 = "vhlo.select_v1"(%16, %2, %10) : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bool_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1> loc(#loc9)
    "vhlo.return_v1"(%17) : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1,4]<=[8] last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("xla__cast")
#loc3 = loc("aten__mul")
#loc4 = loc("xla__custom_sharding")
#loc5 = loc("aten__view")
#loc6 = loc("aten__expand")
#loc7 = loc("aten__add")
#loc8 = loc("aten__eq")
#loc9 = loc("aten__masked_fill")
// -----// IR Dump Before VhloToVersionPass (vhlo-to-version) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<2x39x!vhlo.i64_v1>, %arg1: !vhlo.tensor_v1<39x39x!vhlo.bool_v1>, %arg2: !vhlo.tensor_v1<39x39x!vhlo.bf16_v1>) -> (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1>
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<-3.389530e+38> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1>
    %2 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %3 = "vhlo.broadcast_in_dim_v1"(%0) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %4 = "vhlo.convert_v1"(%arg2) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.f32_v1>
    %5 = "vhlo.convert_v1"(%arg1) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<39x39x!vhlo.bool_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.f32_v1>
    %6 = "vhlo.multiply_v1"(%4, %5) : (!vhlo.tensor_v1<39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.f32_v1>
    %7 = "vhlo.convert_v1"(%6) : (!vhlo.tensor_v1<39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.bf16_v1>
    %8 = "vhlo.custom_call_v1"(%7) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.bf16_v1>
    %9 = "vhlo.reshape_v1"(%8) : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x39x39x!vhlo.bf16_v1>
    %10 = "vhlo.broadcast_in_dim_v1"(%9) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[1, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %11 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<2x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<2x1x1x39x!vhlo.i64_v1>
    %12 = "vhlo.convert_v1"(%11) : (!vhlo.tensor_v1<2x1x1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<2x1x1x39x!vhlo.bf16_v1>
    %13 = "vhlo.reshape_v1"(%12) : (!vhlo.tensor_v1<2x1x1x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x!vhlo.bf16_v1>
    %14 = "vhlo.broadcast_in_dim_v1"(%13) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x1x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %15 = "vhlo.add_v1"(%10, %14) : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %16 = "vhlo.compare_v1"(%15, %3) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 EQ>}> : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bool_v1>
    %17 = "vhlo.select_v1"(%16, %2, %10) : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bool_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    "vhlo.return_v1"(%17) : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1,4]<=[8] last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}


// -----// IR Dump Before VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<2x39x!vhlo.i64_v1>, %arg1: !vhlo.tensor_v1<39x39x!vhlo.bool_v1>, %arg2: !vhlo.tensor_v1<39x39x!vhlo.bf16_v1>) -> (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1>
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<-3.389530e+38> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1>
    %2 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %3 = "vhlo.broadcast_in_dim_v1"(%0) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %4 = "vhlo.convert_v1"(%arg2) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.f32_v1>
    %5 = "vhlo.convert_v1"(%arg1) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<39x39x!vhlo.bool_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.f32_v1>
    %6 = "vhlo.multiply_v1"(%4, %5) : (!vhlo.tensor_v1<39x39x!vhlo.f32_v1>, !vhlo.tensor_v1<39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.f32_v1>
    %7 = "vhlo.convert_v1"(%6) : (!vhlo.tensor_v1<39x39x!vhlo.f32_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.bf16_v1>
    %8 = "vhlo.custom_call_v1"(%7) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<39x39x!vhlo.bf16_v1>
    %9 = "vhlo.reshape_v1"(%8) : (!vhlo.tensor_v1<39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x39x39x!vhlo.bf16_v1>
    %10 = "vhlo.broadcast_in_dim_v1"(%9) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[1, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %11 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<2x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<2x1x1x39x!vhlo.i64_v1>
    %12 = "vhlo.convert_v1"(%11) : (!vhlo.tensor_v1<2x1x1x39x!vhlo.i64_v1>) -> !vhlo.tensor_v1<2x1x1x39x!vhlo.bf16_v1>
    %13 = "vhlo.reshape_v1"(%12) : (!vhlo.tensor_v1<2x1x1x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x!vhlo.bf16_v1>
    %14 = "vhlo.broadcast_in_dim_v1"(%13) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x1x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %15 = "vhlo.add_v1"(%10, %14) : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    %16 = "vhlo.compare_v1"(%15, %3) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 EQ>}> : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bool_v1>
    %17 = "vhlo.select_v1"(%16, %2, %10) : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bool_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>
    "vhlo.return_v1"(%17) : (!vhlo.tensor_v1<2x1x39x39x!vhlo.bf16_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1,4]<=[8] last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}


// -----// IR Dump After VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}"}, %arg1: tensor<39x39xi1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"}, %arg2: tensor<39x39xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"}) -> tensor<2x1x39x39xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.convert %arg2 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %3 = stablehlo.convert %arg1 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %4 = stablehlo.multiply %2, %3 : tensor<39x39xf32>
    %5 = stablehlo.convert %4 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %6 = stablehlo.custom_call @Sharding(%5) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %9 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %10 = stablehlo.convert %9 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %11 = stablehlo.reshape %10 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.add %8, %12 : tensor<2x1x39x39xbf16>
    %14 = stablehlo.compare  EQ, %13, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %15 = stablehlo.select %14, %0, %8 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    return %15 : tensor<2x1x39x39xbf16>
  }
}


#loc1 = loc("xla__device_data")
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}"} loc("xla__device_data"), %arg1: tensor<39x39xi1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("xla__device_data"), %arg2: tensor<39x39xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("xla__device_data")) -> tensor<2x1x39x39xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16> loc(#loc)
    %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16> loc(#loc)
    %2 = stablehlo.convert %arg2 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32> loc(#loc2)
    %3 = stablehlo.convert %arg1 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32> loc(#loc2)
    %4 = stablehlo.multiply %2, %3 : tensor<39x39xf32> loc(#loc3)
    %5 = stablehlo.convert %4 : (tensor<39x39xf32>) -> tensor<39x39xbf16> loc(#loc2)
    %6 = stablehlo.custom_call @Sharding(%5) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16> loc(#loc4)
    %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16> loc(#loc5)
    %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16> loc(#loc6)
    %9 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64> loc(#loc5)
    %10 = stablehlo.convert %9 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16> loc(#loc7)
    %11 = stablehlo.reshape %10 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16> loc(#loc7)
    %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16> loc(#loc7)
    %13 = stablehlo.add %8, %12 : tensor<2x1x39x39xbf16> loc(#loc7)
    %14 = stablehlo.compare  EQ, %13, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1> loc(#loc8)
    %15 = stablehlo.select %14, %0, %8 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16> loc(#loc9)
    return %15 : tensor<2x1x39x39xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("xla__cast")
#loc3 = loc("aten__mul")
#loc4 = loc("xla__custom_sharding")
#loc5 = loc("aten__view")
#loc6 = loc("aten__expand")
#loc7 = loc("aten__add")
#loc8 = loc("aten__eq")
#loc9 = loc("aten__masked_fill")
#loc1 = loc("xla__device_data")
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>} loc("xla__device_data"), %arg1: tensor<39x39xi1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>} loc("xla__device_data"), %arg2: tensor<39x39xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>} loc("xla__device_data")) -> tensor<2x1x39x39xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16> loc(#loc)
    %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16> loc(#loc)
    %2 = stablehlo.convert %arg2 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32> loc(#loc2)
    %3 = stablehlo.convert %arg1 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32> loc(#loc2)
    %4 = stablehlo.multiply %2, %3 : tensor<39x39xf32> loc(#loc3)
    %5 = stablehlo.convert %4 : (tensor<39x39xf32>) -> tensor<39x39xbf16> loc(#loc2)
    %6 = stablehlo.custom_call @Sharding(%5) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16> loc(#loc4)
    %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16> loc(#loc5)
    %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16> loc(#loc6)
    %9 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64> loc(#loc5)
    %10 = stablehlo.convert %9 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16> loc(#loc7)
    %11 = stablehlo.reshape %10 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16> loc(#loc7)
    %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16> loc(#loc7)
    %13 = stablehlo.add %8, %12 : tensor<2x1x39x39xbf16> loc(#loc7)
    %14 = stablehlo.compare  EQ, %13, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1> loc(#loc8)
    %15 = stablehlo.select %14, %0, %8 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16> loc(#loc9)
    return %15 : tensor<2x1x39x39xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("xla__cast")
#loc3 = loc("aten__mul")
#loc4 = loc("xla__custom_sharding")
#loc5 = loc("aten__view")
#loc6 = loc("aten__expand")
#loc7 = loc("aten__add")
#loc8 = loc("aten__eq")
#loc9 = loc("aten__masked_fill")
// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>}, %arg1: tensor<39x39xi1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>}, %arg2: tensor<39x39xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>}) -> tensor<2x1x39x39xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.convert %arg2 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %3 = stablehlo.convert %arg1 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %4 = stablehlo.multiply %2, %3 : tensor<39x39xf32>
    %5 = stablehlo.convert %4 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %6 = stablehlo.custom_call @Sharding(%5) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %9 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %10 = stablehlo.convert %9 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %11 = stablehlo.reshape %10 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.add %8, %12 : tensor<2x1x39x39xbf16>
    %14 = stablehlo.compare  EQ, %13, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %15 = stablehlo.select %14, %0, %8 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    return %15 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>}, %arg1: tensor<39x39xi1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>}, %arg2: tensor<39x39xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>}) -> tensor<2x1x39x39xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.convert %arg2 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %3 = stablehlo.convert %arg1 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %4 = stablehlo.multiply %2, %3 : tensor<39x39xf32>
    %5 = stablehlo.convert %4 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %6 = stablehlo.custom_call @Sharding(%5) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %9 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %10 = stablehlo.convert %9 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %11 = stablehlo.reshape %10 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.add %8, %12 : tensor<2x1x39x39xbf16>
    %14 = stablehlo.compare  EQ, %13, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %15 = stablehlo.select %14, %0, %8 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    return %15 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before TTPopulateArgumentTypes (tt-populate-argument-types) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>}, %arg1: tensor<39x39xi1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>}, %arg2: tensor<39x39xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>}) -> tensor<2x1x39x39xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.convert %arg2 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %3 = stablehlo.convert %arg1 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %4 = stablehlo.multiply %2, %3 : tensor<39x39xf32>
    %5 = stablehlo.convert %4 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %6 = stablehlo.custom_call @Sharding(%5) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %9 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %10 = stablehlo.convert %9 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %11 = stablehlo.reshape %10 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.add %8, %12 : tensor<2x1x39x39xbf16>
    %14 = stablehlo.compare  EQ, %13, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %15 = stablehlo.select %14, %0, %8 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    return %15 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before ApplyArgumentShardStatusPass (apply-argument-shard-status) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>}, %arg1: tensor<39x39xi1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>}, %arg2: tensor<39x39xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>}) -> tensor<2x1x39x39xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.convert %arg2 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %3 = stablehlo.convert %arg1 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %4 = stablehlo.multiply %2, %3 : tensor<39x39xf32>
    %5 = stablehlo.convert %4 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %6 = stablehlo.custom_call @Sharding(%5) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %9 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %10 = stablehlo.convert %9 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %11 = stablehlo.reshape %10 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.add %8, %12 : tensor<2x1x39x39xbf16>
    %14 = stablehlo.compare  EQ, %13, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %15 = stablehlo.select %14, %0, %8 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    return %15 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump After ApplyArgumentShardStatusPass (apply-argument-shard-status) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.convert %arg2 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %3 = stablehlo.convert %arg1 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %4 = stablehlo.multiply %2, %3 : tensor<39x39xf32>
    %5 = stablehlo.convert %4 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %6 = stablehlo.custom_call @Sharding(%5) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %9 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %10 = stablehlo.convert %9 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %11 = stablehlo.reshape %10 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.add %8, %12 : tensor<2x1x39x39xbf16>
    %14 = stablehlo.compare  EQ, %13, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %15 = stablehlo.select %14, %0, %8 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    return %15 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before ConvertXlaSdyToSdyPass (convert-xla-sdy-to-sdy) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x39xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.convert %arg2 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %3 = stablehlo.convert %arg1 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %4 = stablehlo.multiply %2, %3 : tensor<39x39xf32>
    %5 = stablehlo.convert %4 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %6 = stablehlo.custom_call @Sharding(%5) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %9 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %10 = stablehlo.convert %9 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %11 = stablehlo.reshape %10 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.add %8, %12 : tensor<2x1x39x39xbf16>
    %14 = stablehlo.compare  EQ, %13, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %15 = stablehlo.select %14, %0, %8 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    return %15 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump After ConvertXlaSdyToSdyPass (convert-xla-sdy-to-sdy) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.convert %arg2 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %3 = stablehlo.convert %arg1 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %4 = stablehlo.multiply %2, %3 : tensor<39x39xf32>
    %5 = stablehlo.convert %4 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %6 = stablehlo.custom_call @Sharding(%5) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %7 = sdy.sharding_constraint %5 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
    %8 = stablehlo.reshape %7 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %9 = stablehlo.broadcast_in_dim %8, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %10 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %11 = stablehlo.convert %10 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %12 = stablehlo.reshape %11 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %13 = stablehlo.broadcast_in_dim %12, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %14 = stablehlo.add %9, %13 : tensor<2x1x39x39xbf16>
    %15 = stablehlo.compare  EQ, %14, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %16 = stablehlo.select %15, %0, %9 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    return %16 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before AnalyzeMeshPass (analyze-mesh) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.convert %arg2 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %3 = stablehlo.convert %arg1 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %4 = stablehlo.multiply %2, %3 : tensor<39x39xf32>
    %5 = stablehlo.convert %4 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %6 = stablehlo.custom_call @Sharding(%5) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %7 = sdy.sharding_constraint %5 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
    %8 = stablehlo.reshape %7 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %9 = stablehlo.broadcast_in_dim %8, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %10 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %11 = stablehlo.convert %10 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %12 = stablehlo.reshape %11 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %13 = stablehlo.broadcast_in_dim %12, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %14 = stablehlo.add %9, %13 : tensor<2x1x39x39xbf16>
    %15 = stablehlo.compare  EQ, %14, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %16 = stablehlo.select %15, %0, %9 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    return %16 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before ApplyShardingConstraintsPass (sdy-apply-sharding-constraints) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.convert %arg2 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %3 = stablehlo.convert %arg1 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %4 = stablehlo.multiply %2, %3 : tensor<39x39xf32>
    %5 = stablehlo.convert %4 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %6 = stablehlo.custom_call @Sharding(%5) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %7 = sdy.sharding_constraint %5 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
    %8 = stablehlo.reshape %7 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %9 = stablehlo.broadcast_in_dim %8, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %10 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %11 = stablehlo.convert %10 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %12 = stablehlo.reshape %11 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %13 = stablehlo.broadcast_in_dim %12, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %14 = stablehlo.add %9, %13 : tensor<2x1x39x39xbf16>
    %15 = stablehlo.compare  EQ, %14, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %16 = stablehlo.select %15, %0, %9 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    return %16 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before AggressivePropagationPass (sdy-aggressive-propagate) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.convert %arg2 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %3 = stablehlo.convert %arg1 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %4 = stablehlo.multiply %2, %3 : tensor<39x39xf32>
    %5 = stablehlo.convert %4 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %6 = stablehlo.custom_call @Sharding(%5) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %7 = sdy.sharding_constraint %5 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
    %8 = stablehlo.reshape %7 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %9 = stablehlo.broadcast_in_dim %8, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %10 = stablehlo.reshape %arg0 : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %11 = stablehlo.convert %10 : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %12 = stablehlo.reshape %11 : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %13 = stablehlo.broadcast_in_dim %12, dims = [0, 1, 3] : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %14 = stablehlo.add %9, %13 : tensor<2x1x39x39xbf16>
    %15 = stablehlo.compare  EQ, %14, %1 : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %16 = stablehlo.select %15, %0, %9 : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    return %16 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump After AggressivePropagationPass (sdy-aggressive-propagate) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_0, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.convert %arg2 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %3 = stablehlo.convert %arg1 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %4 = stablehlo.multiply %2, %3 : tensor<39x39xf32>
    %5 = stablehlo.convert %4 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %6 = sdy.sharding_constraint %5 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
    %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %9 = stablehlo.reshape %arg0 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %10 = stablehlo.convert %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %11 = stablehlo.reshape %10 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.add %8, %12 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xbf16>
    %14 = stablehlo.compare  EQ, %13, %1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %15 = stablehlo.select %14, %0, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    return %15 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before ShardingConstraintToReshardPass (sdy-sharding-constraint-to-reshard) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_0, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.convert %arg2 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %3 = stablehlo.convert %arg1 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %4 = stablehlo.multiply %2, %3 : tensor<39x39xf32>
    %5 = stablehlo.convert %4 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %6 = sdy.sharding_constraint %5 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
    %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %9 = stablehlo.reshape %arg0 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %10 = stablehlo.convert %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %11 = stablehlo.reshape %10 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.add %8, %12 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xbf16>
    %14 = stablehlo.compare  EQ, %13, %1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %15 = stablehlo.select %14, %0, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    return %15 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump After ShardingConstraintToReshardPass (sdy-sharding-constraint-to-reshard) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_0, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.convert %arg2 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %3 = stablehlo.convert %arg1 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %4 = stablehlo.multiply %2, %3 : tensor<39x39xf32>
    %5 = stablehlo.convert %4 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %6 = sdy.reshard %5 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
    %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %9 = stablehlo.reshape %arg0 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %10 = stablehlo.convert %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %11 = stablehlo.reshape %10 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.add %8, %12 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xbf16>
    %14 = stablehlo.compare  EQ, %13, %1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %15 = stablehlo.select %14, %0, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    return %15 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before InsertExplicitReshardsPass (sdy-insert-explicit-reshards) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_0, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.convert %arg2 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %3 = stablehlo.convert %arg1 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %4 = stablehlo.multiply %2, %3 : tensor<39x39xf32>
    %5 = stablehlo.convert %4 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %6 = sdy.reshard %5 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
    %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %9 = stablehlo.reshape %arg0 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %10 = stablehlo.convert %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %11 = stablehlo.reshape %10 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.add %8, %12 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xbf16>
    %14 = stablehlo.compare  EQ, %13, %1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %15 = stablehlo.select %14, %0, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    return %15 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before WrapUnderManualComputationPass (wrap-under-manual-computation) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_0, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %1 = stablehlo.broadcast_in_dim %cst, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
    %2 = stablehlo.convert %arg2 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
    %3 = stablehlo.convert %arg1 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
    %4 = stablehlo.multiply %2, %3 : tensor<39x39xf32>
    %5 = stablehlo.convert %4 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
    %6 = sdy.reshard %5 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
    %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
    %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    %9 = stablehlo.reshape %arg0 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
    %10 = stablehlo.convert %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
    %11 = stablehlo.reshape %10 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
    %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
    %13 = stablehlo.add %8, %12 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xbf16>
    %14 = stablehlo.compare  EQ, %13, %1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
    %15 = stablehlo.select %14, %0, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
    return %15 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump After WrapUnderManualComputationPass (wrap-under-manual-computation) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2) in_shardings=[<@mesh, [{"_axis_0", ?}, {?}]>, <@mesh, [{?}, {?}]>, <@mesh, [{?}, {?}]>] out_shardings=[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>] manual_axes={} (%arg3: tensor<2x39xi64>, %arg4: tensor<39x39xi1>, %arg5: tensor<39x39xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_0, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
      %2 = stablehlo.broadcast_in_dim %cst, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
      %3 = stablehlo.convert %arg5 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
      %4 = stablehlo.convert %arg4 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
      %5 = stablehlo.multiply %3, %4 : tensor<39x39xf32>
      %6 = stablehlo.convert %5 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
      %7 = sdy.reshard %6 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
      %8 = stablehlo.reshape %7 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
      %9 = stablehlo.broadcast_in_dim %8, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
      %10 = stablehlo.reshape %arg3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
      %11 = stablehlo.convert %10 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
      %12 = stablehlo.reshape %11 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
      %13 = stablehlo.broadcast_in_dim %12, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
      %14 = stablehlo.add %9, %13 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xbf16>
      %15 = stablehlo.compare  EQ, %14, %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
      %16 = stablehlo.select %15, %1, %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
      sdy.return %16 : tensor<2x1x39x39xbf16>
    } : (tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>) -> tensor<2x1x39x39xbf16>
    return %0 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before ReshardToCollectivesPass (sdy-reshard-to-collectives) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2) in_shardings=[<@mesh, [{"_axis_0", ?}, {?}]>, <@mesh, [{?}, {?}]>, <@mesh, [{?}, {?}]>] out_shardings=[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>] manual_axes={} (%arg3: tensor<2x39xi64>, %arg4: tensor<39x39xi1>, %arg5: tensor<39x39xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_0, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
      %2 = stablehlo.broadcast_in_dim %cst, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
      %3 = stablehlo.convert %arg5 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
      %4 = stablehlo.convert %arg4 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
      %5 = stablehlo.multiply %3, %4 : tensor<39x39xf32>
      %6 = stablehlo.convert %5 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
      %7 = sdy.reshard %6 <@mesh, [{?}, {?}]> : tensor<39x39xbf16>
      %8 = stablehlo.reshape %7 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
      %9 = stablehlo.broadcast_in_dim %8, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
      %10 = stablehlo.reshape %arg3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
      %11 = stablehlo.convert %10 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
      %12 = stablehlo.reshape %11 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
      %13 = stablehlo.broadcast_in_dim %12, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
      %14 = stablehlo.add %9, %13 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xbf16>
      %15 = stablehlo.compare  EQ, %14, %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
      %16 = stablehlo.select %15, %1, %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
      sdy.return %16 : tensor<2x1x39x39xbf16>
    } : (tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>) -> tensor<2x1x39x39xbf16>
    return %0 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump After ReshardToCollectivesPass (sdy-reshard-to-collectives) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2) in_shardings=[<@mesh, [{"_axis_0", ?}, {?}]>, <@mesh, [{?}, {?}]>, <@mesh, [{?}, {?}]>] out_shardings=[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>] manual_axes={} (%arg3: tensor<2x39xi64>, %arg4: tensor<39x39xi1>, %arg5: tensor<39x39xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_0, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
      %2 = stablehlo.broadcast_in_dim %cst, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
      %3 = stablehlo.convert %arg5 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
      %4 = stablehlo.convert %arg4 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
      %5 = stablehlo.multiply %3, %4 : tensor<39x39xf32>
      %6 = stablehlo.convert %5 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
      %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
      %9 = stablehlo.reshape %arg3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
      %10 = stablehlo.convert %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
      %11 = stablehlo.reshape %10 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
      %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
      %13 = stablehlo.add %8, %12 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xbf16>
      %14 = stablehlo.compare  EQ, %13, %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
      %15 = stablehlo.select %14, %1, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
      sdy.return %15 : tensor<2x1x39x39xbf16>
    } : (tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>) -> tensor<2x1x39x39xbf16>
    return %0 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before UpdateGlobalToLocalShapesPass (update-global-to-local-shapes) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2) in_shardings=[<@mesh, [{"_axis_0", ?}, {?}]>, <@mesh, [{?}, {?}]>, <@mesh, [{?}, {?}]>] out_shardings=[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>] manual_axes={} (%arg3: tensor<2x39xi64>, %arg4: tensor<39x39xi1>, %arg5: tensor<39x39xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_0, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
      %2 = stablehlo.broadcast_in_dim %cst, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<bf16>) -> tensor<2x1x39x39xbf16>
      %3 = stablehlo.convert %arg5 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
      %4 = stablehlo.convert %arg4 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
      %5 = stablehlo.multiply %3, %4 : tensor<39x39xf32>
      %6 = stablehlo.convert %5 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
      %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
      %9 = stablehlo.reshape %arg3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x39xi64>) -> tensor<2x1x1x39xi64>
      %10 = stablehlo.convert %9 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x1x39xi64>) -> tensor<2x1x1x39xbf16>
      %11 = stablehlo.reshape %10 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<2x1x1x39xbf16>) -> tensor<2x1x39xbf16>
      %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39xbf16>) -> tensor<2x1x39x39xbf16>
      %13 = stablehlo.add %8, %12 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xbf16>
      %14 = stablehlo.compare  EQ, %13, %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<2x1x39x39xbf16>, tensor<2x1x39x39xbf16>) -> tensor<2x1x39x39xi1>
      %15 = stablehlo.select %14, %1, %8 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>]>} : tensor<2x1x39x39xi1>, tensor<2x1x39x39xbf16>
      sdy.return %15 : tensor<2x1x39x39xbf16>
    } : (tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>) -> tensor<2x1x39x39xbf16>
    return %0 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump After UpdateGlobalToLocalShapesPass (update-global-to-local-shapes) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2) in_shardings=[<@mesh, [{"_axis_0", ?}, {?}]>, <@mesh, [{?}, {?}]>, <@mesh, [{?}, {?}]>] out_shardings=[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>] manual_axes={"_axis_0", "_axis_1"} (%arg3: tensor<1x39xi64>, %arg4: tensor<39x39xi1>, %arg5: tensor<39x39xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %2 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %3 = stablehlo.convert %arg5 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
      %4 = stablehlo.convert %arg4 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
      %5 = stablehlo.multiply %3, %4 : tensor<39x39xf32>
      %6 = stablehlo.convert %5 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
      %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
      %9 = stablehlo.reshape %arg3 : (tensor<1x39xi64>) -> tensor<1x1x1x39xi64>
      %10 = stablehlo.convert %9 : (tensor<1x1x1x39xi64>) -> tensor<1x1x1x39xbf16>
      %11 = stablehlo.reshape %10 : (tensor<1x1x1x39xbf16>) -> tensor<1x1x39xbf16>
      %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] : (tensor<1x1x39xbf16>) -> tensor<1x1x39x39xbf16>
      %13 = stablehlo.add %8, %12 : tensor<1x1x39x39xbf16>
      %14 = stablehlo.compare  EQ, %13, %2 : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xi1>
      %15 = stablehlo.select %14, %1, %8 : tensor<1x1x39x39xi1>, tensor<1x1x39x39xbf16>
      sdy.return %15 : tensor<1x1x39x39xbf16>
    } : (tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>) -> tensor<2x1x39x39xbf16>
    return %0 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before CloseShardingsPass (sdy-close-shardings) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2) in_shardings=[<@mesh, [{"_axis_0", ?}, {?}]>, <@mesh, [{?}, {?}]>, <@mesh, [{?}, {?}]>] out_shardings=[<@mesh, [{"_axis_0", ?}, {?}, {?}, {?}]>] manual_axes={"_axis_0", "_axis_1"} (%arg3: tensor<1x39xi64>, %arg4: tensor<39x39xi1>, %arg5: tensor<39x39xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %2 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %3 = stablehlo.convert %arg5 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
      %4 = stablehlo.convert %arg4 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
      %5 = stablehlo.multiply %3, %4 : tensor<39x39xf32>
      %6 = stablehlo.convert %5 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
      %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
      %9 = stablehlo.reshape %arg3 : (tensor<1x39xi64>) -> tensor<1x1x1x39xi64>
      %10 = stablehlo.convert %9 : (tensor<1x1x1x39xi64>) -> tensor<1x1x1x39xbf16>
      %11 = stablehlo.reshape %10 : (tensor<1x1x1x39xbf16>) -> tensor<1x1x39xbf16>
      %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] : (tensor<1x1x39xbf16>) -> tensor<1x1x39x39xbf16>
      %13 = stablehlo.add %8, %12 : tensor<1x1x39x39xbf16>
      %14 = stablehlo.compare  EQ, %13, %2 : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xi1>
      %15 = stablehlo.select %14, %1, %8 : tensor<1x1x39x39xi1>, tensor<1x1x39x39xbf16>
      sdy.return %15 : tensor<1x1x39x39xbf16>
    } : (tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>) -> tensor<2x1x39x39xbf16>
    return %0 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump After CloseShardingsPass (sdy-close-shardings) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2) in_shardings=[<@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {}]>] out_shardings=[<@mesh, [{"_axis_0"}, {}, {}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg3: tensor<1x39xi64>, %arg4: tensor<39x39xi1>, %arg5: tensor<39x39xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %2 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %3 = stablehlo.convert %arg5 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
      %4 = stablehlo.convert %arg4 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
      %5 = stablehlo.multiply %3, %4 : tensor<39x39xf32>
      %6 = stablehlo.convert %5 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
      %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
      %9 = stablehlo.reshape %arg3 : (tensor<1x39xi64>) -> tensor<1x1x1x39xi64>
      %10 = stablehlo.convert %9 : (tensor<1x1x1x39xi64>) -> tensor<1x1x1x39xbf16>
      %11 = stablehlo.reshape %10 : (tensor<1x1x1x39xbf16>) -> tensor<1x1x39xbf16>
      %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] : (tensor<1x1x39xbf16>) -> tensor<1x1x39x39xbf16>
      %13 = stablehlo.add %8, %12 : tensor<1x1x39x39xbf16>
      %14 = stablehlo.compare  EQ, %13, %2 : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xi1>
      %15 = stablehlo.select %14, %1, %8 : tensor<1x1x39x39xi1>, tensor<1x1x39x39xbf16>
      sdy.return %15 : tensor<1x1x39x39xbf16>
    } : (tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>) -> tensor<2x1x39x39xbf16>
    return %0 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2) in_shardings=[<@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {}]>] out_shardings=[<@mesh, [{"_axis_0"}, {}, {}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg3: tensor<1x39xi64>, %arg4: tensor<39x39xi1>, %arg5: tensor<39x39xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %2 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %3 = stablehlo.convert %arg5 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
      %4 = stablehlo.convert %arg4 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
      %5 = stablehlo.multiply %3, %4 : tensor<39x39xf32>
      %6 = stablehlo.convert %5 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
      %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
      %9 = stablehlo.reshape %arg3 : (tensor<1x39xi64>) -> tensor<1x1x1x39xi64>
      %10 = stablehlo.convert %9 : (tensor<1x1x1x39xi64>) -> tensor<1x1x1x39xbf16>
      %11 = stablehlo.reshape %10 : (tensor<1x1x1x39xbf16>) -> tensor<1x1x39xbf16>
      %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] : (tensor<1x1x39xbf16>) -> tensor<1x1x39x39xbf16>
      %13 = stablehlo.add %8, %12 : tensor<1x1x39x39xbf16>
      %14 = stablehlo.compare  EQ, %13, %2 : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xi1>
      %15 = stablehlo.select %14, %1, %8 : tensor<1x1x39x39xi1>, tensor<1x1x39x39xbf16>
      sdy.return %15 : tensor<1x1x39x39xbf16>
    } : (tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>) -> tensor<2x1x39x39xbf16>
    return %0 : tensor<2x1x39x39xbf16>
  }
}


#loc1 = loc("xla__device_data")
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]> loc(#loc)
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("xla__device_data"), %arg1: tensor<39x39xi1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("xla__device_data"), %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("xla__device_data")) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2) in_shardings=[<@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {}]>] out_shardings=[<@mesh, [{"_axis_0"}, {}, {}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg3: tensor<1x39xi64> loc("xla__device_data"), %arg4: tensor<39x39xi1> loc("xla__device_data"), %arg5: tensor<39x39xbf16> loc("xla__device_data")) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16> loc(#loc)
      %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16> loc(#loc)
      %1 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16> loc(#loc)
      %2 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16> loc(#loc)
      %3 = stablehlo.convert %arg5 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32> loc(#loc2)
      %4 = stablehlo.convert %arg4 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32> loc(#loc2)
      %5 = stablehlo.multiply %3, %4 : tensor<39x39xf32> loc(#loc3)
      %6 = stablehlo.convert %5 : (tensor<39x39xf32>) -> tensor<39x39xbf16> loc(#loc2)
      %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16> loc(#loc4)
      %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<1x1x39x39xbf16> loc(#loc5)
      %9 = stablehlo.reshape %arg3 : (tensor<1x39xi64>) -> tensor<1x1x1x39xi64> loc(#loc4)
      %10 = stablehlo.convert %9 : (tensor<1x1x1x39xi64>) -> tensor<1x1x1x39xbf16> loc(#loc6)
      %11 = stablehlo.reshape %10 : (tensor<1x1x1x39xbf16>) -> tensor<1x1x39xbf16> loc(#loc6)
      %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] : (tensor<1x1x39xbf16>) -> tensor<1x1x39x39xbf16> loc(#loc6)
      %13 = stablehlo.add %8, %12 : tensor<1x1x39x39xbf16> loc(#loc6)
      %14 = stablehlo.compare  EQ, %13, %2 : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xi1> loc(#loc7)
      %15 = stablehlo.select %14, %1, %8 : tensor<1x1x39x39xi1>, tensor<1x1x39x39xbf16> loc(#loc8)
      sdy.return %15 : tensor<1x1x39x39xbf16> loc(#loc)
    } : (tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>) -> tensor<2x1x39x39xbf16> loc(#loc)
    return %0 : tensor<2x1x39x39xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("xla__cast")
#loc3 = loc("aten__mul")
#loc4 = loc("aten__view")
#loc5 = loc("aten__expand")
#loc6 = loc("aten__add")
#loc7 = loc("aten__eq")
#loc8 = loc("aten__masked_fill")
// -----// IR Dump Before ConvertArithToStableHLO (convert-arith-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2) in_shardings=[<@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {}]>] out_shardings=[<@mesh, [{"_axis_0"}, {}, {}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg3: tensor<1x39xi64>, %arg4: tensor<39x39xi1>, %arg5: tensor<39x39xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %2 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %3 = stablehlo.convert %arg5 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
      %4 = stablehlo.convert %arg4 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
      %5 = stablehlo.multiply %3, %4 : tensor<39x39xf32>
      %6 = stablehlo.convert %5 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
      %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
      %9 = stablehlo.reshape %arg3 : (tensor<1x39xi64>) -> tensor<1x1x1x39xi64>
      %10 = stablehlo.convert %9 : (tensor<1x1x1x39xi64>) -> tensor<1x1x1x39xbf16>
      %11 = stablehlo.reshape %10 : (tensor<1x1x1x39xbf16>) -> tensor<1x1x39xbf16>
      %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] : (tensor<1x1x39xbf16>) -> tensor<1x1x39x39xbf16>
      %13 = stablehlo.add %8, %12 : tensor<1x1x39x39xbf16>
      %14 = stablehlo.compare  EQ, %13, %2 : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xi1>
      %15 = stablehlo.select %14, %1, %8 : tensor<1x1x39x39xi1>, tensor<1x1x39x39xbf16>
      sdy.return %15 : tensor<1x1x39x39xbf16>
    } : (tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>) -> tensor<2x1x39x39xbf16>
    return %0 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before LegalizeStableHLOCompositeToTTIR (legalize-stablehlo-composite-to-ttir) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2) in_shardings=[<@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {}]>] out_shardings=[<@mesh, [{"_axis_0"}, {}, {}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg3: tensor<1x39xi64>, %arg4: tensor<39x39xi1>, %arg5: tensor<39x39xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %2 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %3 = stablehlo.convert %arg5 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
      %4 = stablehlo.convert %arg4 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
      %5 = stablehlo.multiply %3, %4 : tensor<39x39xf32>
      %6 = stablehlo.convert %5 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
      %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
      %9 = stablehlo.reshape %arg3 : (tensor<1x39xi64>) -> tensor<1x1x1x39xi64>
      %10 = stablehlo.convert %9 : (tensor<1x1x1x39xi64>) -> tensor<1x1x1x39xbf16>
      %11 = stablehlo.reshape %10 : (tensor<1x1x1x39xbf16>) -> tensor<1x1x39xbf16>
      %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] : (tensor<1x1x39xbf16>) -> tensor<1x1x39x39xbf16>
      %13 = stablehlo.add %8, %12 : tensor<1x1x39x39xbf16>
      %14 = stablehlo.compare  EQ, %13, %2 : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xi1>
      %15 = stablehlo.select %14, %1, %8 : tensor<1x1x39x39xi1>, tensor<1x1x39x39xbf16>
      sdy.return %15 : tensor<1x1x39x39xbf16>
    } : (tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>) -> tensor<2x1x39x39xbf16>
    return %0 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before StablehloLegalizeCompositeToCallPass (stablehlo-legalize-composite-to-call) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2) in_shardings=[<@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {}]>] out_shardings=[<@mesh, [{"_axis_0"}, {}, {}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg3: tensor<1x39xi64>, %arg4: tensor<39x39xi1>, %arg5: tensor<39x39xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %2 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %3 = stablehlo.convert %arg5 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
      %4 = stablehlo.convert %arg4 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
      %5 = stablehlo.multiply %3, %4 : tensor<39x39xf32>
      %6 = stablehlo.convert %5 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
      %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
      %9 = stablehlo.reshape %arg3 : (tensor<1x39xi64>) -> tensor<1x1x1x39xi64>
      %10 = stablehlo.convert %9 : (tensor<1x1x1x39xi64>) -> tensor<1x1x1x39xbf16>
      %11 = stablehlo.reshape %10 : (tensor<1x1x1x39xbf16>) -> tensor<1x1x39xbf16>
      %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] : (tensor<1x1x39xbf16>) -> tensor<1x1x39x39xbf16>
      %13 = stablehlo.add %8, %12 : tensor<1x1x39x39xbf16>
      %14 = stablehlo.compare  EQ, %13, %2 : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xi1>
      %15 = stablehlo.select %14, %1, %8 : tensor<1x1x39x39xi1>, tensor<1x1x39x39xbf16>
      sdy.return %15 : tensor<1x1x39x39xbf16>
    } : (tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>) -> tensor<2x1x39x39xbf16>
    return %0 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2) in_shardings=[<@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {}]>] out_shardings=[<@mesh, [{"_axis_0"}, {}, {}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg3: tensor<1x39xi64>, %arg4: tensor<39x39xi1>, %arg5: tensor<39x39xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %2 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %3 = stablehlo.convert %arg5 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
      %4 = stablehlo.convert %arg4 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
      %5 = stablehlo.multiply %3, %4 : tensor<39x39xf32>
      %6 = stablehlo.convert %5 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
      %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
      %9 = stablehlo.reshape %arg3 : (tensor<1x39xi64>) -> tensor<1x1x1x39xi64>
      %10 = stablehlo.convert %9 : (tensor<1x1x1x39xi64>) -> tensor<1x1x1x39xbf16>
      %11 = stablehlo.reshape %10 : (tensor<1x1x1x39xbf16>) -> tensor<1x1x39xbf16>
      %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] : (tensor<1x1x39xbf16>) -> tensor<1x1x39x39xbf16>
      %13 = stablehlo.add %8, %12 : tensor<1x1x39x39xbf16>
      %14 = stablehlo.compare  EQ, %13, %2 : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xi1>
      %15 = stablehlo.select %14, %1, %8 : tensor<1x1x39x39xi1>, tensor<1x1x39x39xbf16>
      sdy.return %15 : tensor<1x1x39x39xbf16>
    } : (tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>) -> tensor<2x1x39x39xbf16>
    return %0 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2) in_shardings=[<@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {}]>] out_shardings=[<@mesh, [{"_axis_0"}, {}, {}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg3: tensor<1x39xi64>, %arg4: tensor<39x39xi1>, %arg5: tensor<39x39xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %2 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %3 = stablehlo.convert %arg5 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
      %4 = stablehlo.convert %arg4 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
      %5 = stablehlo.multiply %3, %4 : tensor<39x39xf32>
      %6 = stablehlo.convert %5 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
      %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
      %9 = stablehlo.reshape %arg3 : (tensor<1x39xi64>) -> tensor<1x1x1x39xi64>
      %10 = stablehlo.convert %9 : (tensor<1x1x1x39xi64>) -> tensor<1x1x1x39xbf16>
      %11 = stablehlo.reshape %10 : (tensor<1x1x1x39xbf16>) -> tensor<1x1x39xbf16>
      %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] : (tensor<1x1x39xbf16>) -> tensor<1x1x39x39xbf16>
      %13 = stablehlo.add %8, %12 : tensor<1x1x39x39xbf16>
      %14 = stablehlo.compare  EQ, %13, %2 : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xi1>
      %15 = stablehlo.select %14, %1, %8 : tensor<1x1x39x39xi1>, tensor<1x1x39x39xbf16>
      sdy.return %15 : tensor<1x1x39x39xbf16>
    } : (tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>) -> tensor<2x1x39x39xbf16>
    return %0 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before ConvertStableHLOToTTIR (convert-stablehlo-to-ttir) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]>
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2) in_shardings=[<@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {}]>] out_shardings=[<@mesh, [{"_axis_0"}, {}, {}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg3: tensor<1x39xi64>, %arg4: tensor<39x39xi1>, %arg5: tensor<39x39xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %cst_0 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %2 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<bf16>) -> tensor<1x1x39x39xbf16>
      %3 = stablehlo.convert %arg5 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xbf16>) -> tensor<39x39xf32>
      %4 = stablehlo.convert %arg4 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}, mhlo.sharding = "{replicated}"} : (tensor<39x39xi1>) -> tensor<39x39xf32>
      %5 = stablehlo.multiply %3, %4 : tensor<39x39xf32>
      %6 = stablehlo.convert %5 : (tensor<39x39xf32>) -> tensor<39x39xbf16>
      %7 = stablehlo.reshape %6 : (tensor<39x39xbf16>) -> tensor<1x39x39xbf16>
      %8 = stablehlo.broadcast_in_dim %7, dims = [1, 2, 3] : (tensor<1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
      %9 = stablehlo.reshape %arg3 : (tensor<1x39xi64>) -> tensor<1x1x1x39xi64>
      %10 = stablehlo.convert %9 : (tensor<1x1x1x39xi64>) -> tensor<1x1x1x39xbf16>
      %11 = stablehlo.reshape %10 : (tensor<1x1x1x39xbf16>) -> tensor<1x1x39xbf16>
      %12 = stablehlo.broadcast_in_dim %11, dims = [0, 1, 3] : (tensor<1x1x39xbf16>) -> tensor<1x1x39x39xbf16>
      %13 = stablehlo.add %8, %12 : tensor<1x1x39x39xbf16>
      %14 = stablehlo.compare  EQ, %13, %2 : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xi1>
      %15 = stablehlo.select %14, %1, %8 : tensor<1x1x39x39xi1>, tensor<1x1x39x39xbf16>
      sdy.return %15 : tensor<1x1x39x39xbf16>
    } : (tensor<2x39xi64>, tensor<39x39xi1>, tensor<39x39xbf16>) -> tensor<2x1x39x39xbf16>
    return %0 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump After ConvertStableHLOToTTIR (convert-stablehlo-to-ttir) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xi64>) -> tensor<1x39xi64>
    %1 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xi1>) -> tensor<39x39xi1>
    %2 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %3 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<bf16>}> : () -> tensor<bf16>
    %4 = "ttir.constant"() <{value = dense<-3.389530e+38> : tensor<bf16>}> : () -> tensor<bf16>
    %5 = ttir.empty() : tensor<1x1x1x1xbf16>
    %6 = "ttir.reshape"(%4, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
    %7 = ttir.empty() : tensor<1x1x39x39xbf16>
    %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %9 = ttir.empty() : tensor<1x1x1x1xbf16>
    %10 = "ttir.reshape"(%3, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
    %11 = ttir.empty() : tensor<1x1x39x39xbf16>
    %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %13 = ttir.empty() : tensor<39x39xf32>
    %14 = "ttir.typecast"(%2, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
    %15 = ttir.empty() : tensor<39x39xf32>
    %16 = "ttir.typecast"(%1, %15) <{conservative_folding = false}> : (tensor<39x39xi1>, tensor<39x39xf32>) -> tensor<39x39xf32>
    %17 = ttir.empty() : tensor<39x39xf32>
    %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
    %19 = ttir.empty() : tensor<39x39xbf16>
    %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %21 = ttir.empty() : tensor<1x39x39xbf16>
    %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x39x39xbf16>) -> tensor<1x39x39xbf16>
    %23 = ttir.empty() : tensor<1x1x39x39xbf16>
    %24 = "ttir.reshape"(%22, %23) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %25 = ttir.empty() : tensor<1x1x39x39xbf16>
    %26 = "ttir.broadcast"(%24, %25) <{broadcast_dimensions = array<i64: 1, 1, 1, 1>}> : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %27 = ttir.empty() : tensor<1x1x1x39xi64>
    %28 = "ttir.reshape"(%0, %27) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xi64>, tensor<1x1x1x39xi64>) -> tensor<1x1x1x39xi64>
    %29 = ttir.empty() : tensor<1x1x1x39xbf16>
    %30 = "ttir.typecast"(%28, %29) <{conservative_folding = false}> : (tensor<1x1x1x39xi64>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
    %31 = ttir.empty() : tensor<1x1x39xbf16>
    %32 = "ttir.reshape"(%30, %31) <{shape = [1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39xbf16>) -> tensor<1x1x39xbf16>
    %33 = ttir.empty() : tensor<1x1x1x39xbf16>
    %34 = "ttir.reshape"(%32, %33) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x1x39xbf16>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
    %35 = ttir.empty() : tensor<1x1x39x39xbf16>
    %36 = "ttir.broadcast"(%34, %35) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %37 = ttir.empty() : tensor<1x1x39x39xbf16>
    %38 = "ttir.add"(%26, %36, %37) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %39 = ttir.empty() : tensor<1x1x39x39xi1>
    %40 = "ttir.eq"(%38, %12, %39) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xi1>) -> tensor<1x1x39x39xi1>
    %41 = ttir.empty() : tensor<1x1x39x39xbf16>
    %42 = "ttir.where"(%40, %8, %26, %41) : (tensor<1x1x39x39xi1>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %43 = "ttir.mesh_shard"(%42) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    return %43 : tensor<2x1x39x39xbf16>
  }
}


#loc1 = loc("xla__device_data")
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("xla__device_data"), %arg1: tensor<39x39xi1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("xla__device_data"), %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("xla__device_data")) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xi64>) -> tensor<1x39xi64> loc(#loc)
    %1 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xi1>) -> tensor<39x39xi1> loc(#loc)
    %2 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16> loc(#loc)
    %3 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<bf16>}> : () -> tensor<bf16> loc(#loc)
    %4 = "ttir.constant"() <{value = dense<-3.389530e+38> : tensor<bf16>}> : () -> tensor<bf16> loc(#loc)
    %5 = ttir.empty() : tensor<1x1x1x1xbf16> loc(#loc)
    %6 = "ttir.reshape"(%4, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16> loc(#loc)
    %7 = ttir.empty() : tensor<1x1x39x39xbf16> loc(#loc)
    %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16> loc(#loc)
    %9 = ttir.empty() : tensor<1x1x1x1xbf16> loc(#loc)
    %10 = "ttir.reshape"(%3, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16> loc(#loc)
    %11 = ttir.empty() : tensor<1x1x39x39xbf16> loc(#loc)
    %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16> loc(#loc)
    %13 = ttir.empty() : tensor<39x39xf32> loc(#loc2)
    %14 = "ttir.typecast"(%2, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32> loc(#loc2)
    %15 = ttir.empty() : tensor<39x39xf32> loc(#loc2)
    %16 = "ttir.typecast"(%1, %15) <{conservative_folding = false}> : (tensor<39x39xi1>, tensor<39x39xf32>) -> tensor<39x39xf32> loc(#loc2)
    %17 = ttir.empty() : tensor<39x39xf32> loc(#loc3)
    %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32> loc(#loc3)
    %19 = ttir.empty() : tensor<39x39xbf16> loc(#loc2)
    %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16> loc(#loc2)
    %21 = ttir.empty() : tensor<1x39x39xbf16> loc(#loc4)
    %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x39x39xbf16>) -> tensor<1x39x39xbf16> loc(#loc4)
    %23 = ttir.empty() : tensor<1x1x39x39xbf16> loc(#loc5)
    %24 = "ttir.reshape"(%22, %23) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16> loc(#loc5)
    %25 = ttir.empty() : tensor<1x1x39x39xbf16> loc(#loc5)
    %26 = "ttir.broadcast"(%24, %25) <{broadcast_dimensions = array<i64: 1, 1, 1, 1>}> : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16> loc(#loc5)
    %27 = ttir.empty() : tensor<1x1x1x39xi64> loc(#loc4)
    %28 = "ttir.reshape"(%0, %27) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xi64>, tensor<1x1x1x39xi64>) -> tensor<1x1x1x39xi64> loc(#loc4)
    %29 = ttir.empty() : tensor<1x1x1x39xbf16> loc(#loc6)
    %30 = "ttir.typecast"(%28, %29) <{conservative_folding = false}> : (tensor<1x1x1x39xi64>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16> loc(#loc6)
    %31 = ttir.empty() : tensor<1x1x39xbf16> loc(#loc6)
    %32 = "ttir.reshape"(%30, %31) <{shape = [1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39xbf16>) -> tensor<1x1x39xbf16> loc(#loc6)
    %33 = ttir.empty() : tensor<1x1x1x39xbf16> loc(#loc6)
    %34 = "ttir.reshape"(%32, %33) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x1x39xbf16>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16> loc(#loc6)
    %35 = ttir.empty() : tensor<1x1x39x39xbf16> loc(#loc6)
    %36 = "ttir.broadcast"(%34, %35) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16> loc(#loc6)
    %37 = ttir.empty() : tensor<1x1x39x39xbf16> loc(#loc6)
    %38 = "ttir.add"(%26, %36, %37) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16> loc(#loc6)
    %39 = ttir.empty() : tensor<1x1x39x39xi1> loc(#loc7)
    %40 = "ttir.eq"(%38, %12, %39) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xi1>) -> tensor<1x1x39x39xi1> loc(#loc7)
    %41 = ttir.empty() : tensor<1x1x39x39xbf16> loc(#loc8)
    %42 = "ttir.where"(%40, %8, %26, %41) : (tensor<1x1x39x39xi1>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16> loc(#loc8)
    %43 = "ttir.mesh_shard"(%42) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16> loc(#loc)
    return %43 : tensor<2x1x39x39xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("xla__cast")
#loc3 = loc("aten__mul")
#loc4 = loc("aten__view")
#loc5 = loc("aten__expand")
#loc6 = loc("aten__add")
#loc7 = loc("aten__eq")
#loc8 = loc("aten__masked_fill")
// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xi64>) -> tensor<1x39xi64>
    %1 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xi1>) -> tensor<39x39xi1>
    %2 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %3 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<bf16>}> : () -> tensor<bf16>
    %4 = "ttir.constant"() <{value = dense<-3.389530e+38> : tensor<bf16>}> : () -> tensor<bf16>
    %5 = ttir.empty() : tensor<1x1x1x1xbf16>
    %6 = "ttir.reshape"(%4, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
    %7 = ttir.empty() : tensor<1x1x39x39xbf16>
    %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %9 = ttir.empty() : tensor<1x1x1x1xbf16>
    %10 = "ttir.reshape"(%3, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
    %11 = ttir.empty() : tensor<1x1x39x39xbf16>
    %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %13 = ttir.empty() : tensor<39x39xf32>
    %14 = "ttir.typecast"(%2, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
    %15 = ttir.empty() : tensor<39x39xf32>
    %16 = "ttir.typecast"(%1, %15) <{conservative_folding = false}> : (tensor<39x39xi1>, tensor<39x39xf32>) -> tensor<39x39xf32>
    %17 = ttir.empty() : tensor<39x39xf32>
    %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
    %19 = ttir.empty() : tensor<39x39xbf16>
    %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %21 = ttir.empty() : tensor<1x39x39xbf16>
    %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x39x39xbf16>) -> tensor<1x39x39xbf16>
    %23 = ttir.empty() : tensor<1x1x39x39xbf16>
    %24 = "ttir.reshape"(%22, %23) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %25 = ttir.empty() : tensor<1x1x39x39xbf16>
    %26 = "ttir.broadcast"(%24, %25) <{broadcast_dimensions = array<i64: 1, 1, 1, 1>}> : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %27 = ttir.empty() : tensor<1x1x1x39xi64>
    %28 = "ttir.reshape"(%0, %27) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xi64>, tensor<1x1x1x39xi64>) -> tensor<1x1x1x39xi64>
    %29 = ttir.empty() : tensor<1x1x1x39xbf16>
    %30 = "ttir.typecast"(%28, %29) <{conservative_folding = false}> : (tensor<1x1x1x39xi64>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
    %31 = ttir.empty() : tensor<1x1x39xbf16>
    %32 = "ttir.reshape"(%30, %31) <{shape = [1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39xbf16>) -> tensor<1x1x39xbf16>
    %33 = ttir.empty() : tensor<1x1x1x39xbf16>
    %34 = "ttir.reshape"(%32, %33) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x1x39xbf16>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
    %35 = ttir.empty() : tensor<1x1x39x39xbf16>
    %36 = "ttir.broadcast"(%34, %35) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %37 = ttir.empty() : tensor<1x1x39x39xbf16>
    %38 = "ttir.add"(%26, %36, %37) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %39 = ttir.empty() : tensor<1x1x39x39xi1>
    %40 = "ttir.eq"(%38, %12, %39) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xi1>) -> tensor<1x1x39x39xi1>
    %41 = ttir.empty() : tensor<1x1x39x39xbf16>
    %42 = "ttir.where"(%40, %8, %26, %41) : (tensor<1x1x39x39xi1>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %43 = "ttir.mesh_shard"(%42) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    return %43 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
    %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
    %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xi64>) -> tensor<1x39xi64>
    %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xi1>) -> tensor<39x39xi1>
    %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %5 = ttir.empty() : tensor<1x1x1x1xbf16>
    %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
    %7 = ttir.empty() : tensor<1x1x39x39xbf16>
    %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %9 = ttir.empty() : tensor<1x1x1x1xbf16>
    %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
    %11 = ttir.empty() : tensor<1x1x39x39xbf16>
    %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %13 = ttir.empty() : tensor<39x39xf32>
    %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
    %15 = ttir.empty() : tensor<39x39xf32>
    %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xi1>, tensor<39x39xf32>) -> tensor<39x39xf32>
    %17 = ttir.empty() : tensor<39x39xf32>
    %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
    %19 = ttir.empty() : tensor<39x39xbf16>
    %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %21 = ttir.empty() : tensor<1x1x39x39xbf16>
    %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %23 = ttir.empty() : tensor<1x1x1x39xi64>
    %24 = "ttir.reshape"(%2, %23) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xi64>, tensor<1x1x1x39xi64>) -> tensor<1x1x1x39xi64>
    %25 = ttir.empty() : tensor<1x1x1x39xbf16>
    %26 = "ttir.typecast"(%24, %25) <{conservative_folding = false}> : (tensor<1x1x1x39xi64>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
    %27 = ttir.empty() : tensor<1x1x39x39xbf16>
    %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %29 = ttir.empty() : tensor<1x1x39x39xbf16>
    %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %31 = ttir.empty() : tensor<1x1x39x39xi1>
    %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xi1>) -> tensor<1x1x39x39xi1>
    %33 = ttir.empty() : tensor<1x1x39x39xbf16>
    %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xi1>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    return %35 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before ElementTypeNormalization (ttir-element-type-normalization) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  func.func @main(%arg0: tensor<2x39xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xi1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
    %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
    %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xi64>) -> tensor<1x39xi64>
    %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xi1>) -> tensor<39x39xi1>
    %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %5 = ttir.empty() : tensor<1x1x1x1xbf16>
    %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
    %7 = ttir.empty() : tensor<1x1x39x39xbf16>
    %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %9 = ttir.empty() : tensor<1x1x1x1xbf16>
    %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
    %11 = ttir.empty() : tensor<1x1x39x39xbf16>
    %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %13 = ttir.empty() : tensor<39x39xf32>
    %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
    %15 = ttir.empty() : tensor<39x39xf32>
    %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xi1>, tensor<39x39xf32>) -> tensor<39x39xf32>
    %17 = ttir.empty() : tensor<39x39xf32>
    %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
    %19 = ttir.empty() : tensor<39x39xbf16>
    %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %21 = ttir.empty() : tensor<1x1x39x39xbf16>
    %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %23 = ttir.empty() : tensor<1x1x1x39xi64>
    %24 = "ttir.reshape"(%2, %23) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xi64>, tensor<1x1x1x39xi64>) -> tensor<1x1x1x39xi64>
    %25 = ttir.empty() : tensor<1x1x1x39xbf16>
    %26 = "ttir.typecast"(%24, %25) <{conservative_folding = false}> : (tensor<1x1x1x39xi64>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
    %27 = ttir.empty() : tensor<1x1x39x39xbf16>
    %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %29 = ttir.empty() : tensor<1x1x39x39xbf16>
    %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %31 = ttir.empty() : tensor<1x1x39x39xi1>
    %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xi1>) -> tensor<1x1x39x39xi1>
    %33 = ttir.empty() : tensor<1x1x39x39xbf16>
    %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xi1>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    return %35 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump After ElementTypeNormalization (ttir-element-type-normalization) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
    %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
    %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
    %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %5 = ttir.empty() : tensor<1x1x1x1xbf16>
    %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
    %7 = ttir.empty() : tensor<1x1x39x39xbf16>
    %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %9 = ttir.empty() : tensor<1x1x1x1xbf16>
    %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
    %11 = ttir.empty() : tensor<1x1x39x39xbf16>
    %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %13 = ttir.empty() : tensor<39x39xf32>
    %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
    %15 = ttir.empty() : tensor<39x39xf32>
    %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
    %17 = ttir.empty() : tensor<39x39xf32>
    %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
    %19 = ttir.empty() : tensor<39x39xbf16>
    %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %21 = ttir.empty() : tensor<1x1x39x39xbf16>
    %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %23 = ttir.empty() : tensor<1x1x1x39xsi32>
    %24 = "ttir.reshape"(%2, %23) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xsi32>, tensor<1x1x1x39xsi32>) -> tensor<1x1x1x39xsi32>
    %25 = ttir.empty() : tensor<1x1x1x39xbf16>
    %26 = "ttir.typecast"(%24, %25) <{conservative_folding = false}> : (tensor<1x1x1x39xsi32>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
    %27 = ttir.empty() : tensor<1x1x39x39xbf16>
    %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %29 = ttir.empty() : tensor<1x1x39x39xbf16>
    %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %31 = ttir.empty() : tensor<1x1x39x39xbf16>
    %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %33 = ttir.empty() : tensor<1x1x39x39xbf16>
    %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    return %35 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump Before TTCoreWrapDeviceModulePass (ttcore-wrap-device-module) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
    %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
    %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
    %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %5 = ttir.empty() : tensor<1x1x1x1xbf16>
    %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
    %7 = ttir.empty() : tensor<1x1x39x39xbf16>
    %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %9 = ttir.empty() : tensor<1x1x1x1xbf16>
    %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
    %11 = ttir.empty() : tensor<1x1x39x39xbf16>
    %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %13 = ttir.empty() : tensor<39x39xf32>
    %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
    %15 = ttir.empty() : tensor<39x39xf32>
    %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
    %17 = ttir.empty() : tensor<39x39xf32>
    %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
    %19 = ttir.empty() : tensor<39x39xbf16>
    %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
    %21 = ttir.empty() : tensor<1x1x39x39xbf16>
    %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %23 = ttir.empty() : tensor<1x1x1x39xsi32>
    %24 = "ttir.reshape"(%2, %23) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xsi32>, tensor<1x1x1x39xsi32>) -> tensor<1x1x1x39xsi32>
    %25 = ttir.empty() : tensor<1x1x1x39xbf16>
    %26 = "ttir.typecast"(%24, %25) <{conservative_folding = false}> : (tensor<1x1x1x39xsi32>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
    %27 = ttir.empty() : tensor<1x1x39x39xbf16>
    %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %29 = ttir.empty() : tensor<1x1x39x39xbf16>
    %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %31 = ttir.empty() : tensor<1x1x39x39xbf16>
    %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %33 = ttir.empty() : tensor<1x1x39x39xbf16>
    %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
    %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
    return %35 : tensor<2x1x39x39xbf16>
  }
}


// -----// IR Dump After TTCoreWrapDeviceModulePass (ttcore-wrap-device-module) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x39x39xbf16>
        %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %9 = ttir.empty() : tensor<1x1x1x1xbf16>
        %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %11 = ttir.empty() : tensor<1x1x39x39xbf16>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xf32>
        %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %17 = ttir.empty() : tensor<39x39xf32>
        %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %19 = ttir.empty() : tensor<39x39xbf16>
        %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %21 = ttir.empty() : tensor<1x1x39x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %23 = ttir.empty() : tensor<1x1x1x39xsi32>
        %24 = "ttir.reshape"(%2, %23) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xsi32>, tensor<1x1x1x39xsi32>) -> tensor<1x1x1x39xsi32>
        %25 = ttir.empty() : tensor<1x1x1x39xbf16>
        %26 = "ttir.typecast"(%24, %25) <{conservative_folding = false}> : (tensor<1x1x1x39xsi32>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16>
        %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %31 = ttir.empty() : tensor<1x1x39x39xbf16>
        %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %33 = ttir.empty() : tensor<1x1x39x39xbf16>
        %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %35 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIRHoistTransform (ttir-cpu-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x39x39xbf16>
        %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %9 = ttir.empty() : tensor<1x1x1x1xbf16>
        %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %11 = ttir.empty() : tensor<1x1x39x39xbf16>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xf32>
        %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %17 = ttir.empty() : tensor<39x39xf32>
        %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %19 = ttir.empty() : tensor<39x39xbf16>
        %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %21 = ttir.empty() : tensor<1x1x39x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %23 = ttir.empty() : tensor<1x1x1x39xsi32>
        %24 = "ttir.reshape"(%2, %23) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xsi32>, tensor<1x1x1x39xsi32>) -> tensor<1x1x1x39xsi32>
        %25 = ttir.empty() : tensor<1x1x1x39xbf16>
        %26 = "ttir.typecast"(%24, %25) <{conservative_folding = false}> : (tensor<1x1x1x39xsi32>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16>
        %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %31 = ttir.empty() : tensor<1x1x39x39xbf16>
        %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %33 = ttir.empty() : tensor<1x1x39x39xbf16>
        %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %35 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTCoreRegisterDevicePass (ttcore-register-device) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x39x39xbf16>
        %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %9 = ttir.empty() : tensor<1x1x1x1xbf16>
        %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %11 = ttir.empty() : tensor<1x1x39x39xbf16>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xf32>
        %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %17 = ttir.empty() : tensor<39x39xf32>
        %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %19 = ttir.empty() : tensor<39x39xbf16>
        %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %21 = ttir.empty() : tensor<1x1x39x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %23 = ttir.empty() : tensor<1x1x1x39xsi32>
        %24 = "ttir.reshape"(%2, %23) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xsi32>, tensor<1x1x1x39xsi32>) -> tensor<1x1x1x39xsi32>
        %25 = ttir.empty() : tensor<1x1x1x39xbf16>
        %26 = "ttir.typecast"(%24, %25) <{conservative_folding = false}> : (tensor<1x1x1x39xsi32>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16>
        %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %31 = ttir.empty() : tensor<1x1x39x39xbf16>
        %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %33 = ttir.empty() : tensor<1x1x39x39xbf16>
        %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %35 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump After TTCoreRegisterDevicePass (ttcore-register-device) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x39x39xbf16>
        %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %9 = ttir.empty() : tensor<1x1x1x1xbf16>
        %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %11 = ttir.empty() : tensor<1x1x39x39xbf16>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xf32>
        %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %17 = ttir.empty() : tensor<39x39xf32>
        %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %19 = ttir.empty() : tensor<39x39xbf16>
        %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %21 = ttir.empty() : tensor<1x1x39x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %23 = ttir.empty() : tensor<1x1x1x39xsi32>
        %24 = "ttir.reshape"(%2, %23) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xsi32>, tensor<1x1x1x39xsi32>) -> tensor<1x1x1x39xsi32>
        %25 = ttir.empty() : tensor<1x1x1x39xbf16>
        %26 = "ttir.typecast"(%24, %25) <{conservative_folding = false}> : (tensor<1x1x1x39xsi32>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16>
        %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %31 = ttir.empty() : tensor<1x1x39x39xbf16>
        %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %33 = ttir.empty() : tensor<1x1x39x39xbf16>
        %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %35 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTPopulateArgumentTypes (tt-populate-argument-types) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x39x39xbf16>
        %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %9 = ttir.empty() : tensor<1x1x1x1xbf16>
        %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %11 = ttir.empty() : tensor<1x1x39x39xbf16>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xf32>
        %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %17 = ttir.empty() : tensor<39x39xf32>
        %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %19 = ttir.empty() : tensor<39x39xbf16>
        %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %21 = ttir.empty() : tensor<1x1x39x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %23 = ttir.empty() : tensor<1x1x1x39xsi32>
        %24 = "ttir.reshape"(%2, %23) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xsi32>, tensor<1x1x1x39xsi32>) -> tensor<1x1x1x39xsi32>
        %25 = ttir.empty() : tensor<1x1x1x39xbf16>
        %26 = "ttir.typecast"(%24, %25) <{conservative_folding = false}> : (tensor<1x1x1x39xsi32>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16>
        %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %31 = ttir.empty() : tensor<1x1x39x39xbf16>
        %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %33 = ttir.empty() : tensor<1x1x39x39xbf16>
        %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %35 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x39x39xbf16>
        %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %9 = ttir.empty() : tensor<1x1x1x1xbf16>
        %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %11 = ttir.empty() : tensor<1x1x39x39xbf16>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xf32>
        %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %17 = ttir.empty() : tensor<39x39xf32>
        %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %19 = ttir.empty() : tensor<39x39xbf16>
        %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %21 = ttir.empty() : tensor<1x1x39x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %23 = ttir.empty() : tensor<1x1x1x39xsi32>
        %24 = "ttir.reshape"(%2, %23) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xsi32>, tensor<1x1x1x39xsi32>) -> tensor<1x1x1x39xsi32>
        %25 = ttir.empty() : tensor<1x1x1x39xbf16>
        %26 = "ttir.typecast"(%24, %25) <{conservative_folding = false}> : (tensor<1x1x1x39xsi32>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16>
        %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %31 = ttir.empty() : tensor<1x1x39x39xbf16>
        %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %33 = ttir.empty() : tensor<1x1x39x39xbf16>
        %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %35 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIRFusing (ttir-fusing) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x39x39xbf16>
        %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %9 = ttir.empty() : tensor<1x1x1x1xbf16>
        %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %11 = ttir.empty() : tensor<1x1x39x39xbf16>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xf32>
        %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %17 = ttir.empty() : tensor<39x39xf32>
        %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %19 = ttir.empty() : tensor<39x39xbf16>
        %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %21 = ttir.empty() : tensor<1x1x39x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %23 = ttir.empty() : tensor<1x1x1x39xsi32>
        %24 = "ttir.reshape"(%2, %23) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xsi32>, tensor<1x1x1x39xsi32>) -> tensor<1x1x1x39xsi32>
        %25 = ttir.empty() : tensor<1x1x1x39xbf16>
        %26 = "ttir.typecast"(%24, %25) <{conservative_folding = false}> : (tensor<1x1x1x39xsi32>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16>
        %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %31 = ttir.empty() : tensor<1x1x39x39xbf16>
        %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %33 = ttir.empty() : tensor<1x1x39x39xbf16>
        %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %35 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIRQuantDequantConversion (ttir-quant-dequant-conversion) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x39x39xbf16>
        %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %9 = ttir.empty() : tensor<1x1x1x1xbf16>
        %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %11 = ttir.empty() : tensor<1x1x39x39xbf16>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xf32>
        %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %17 = ttir.empty() : tensor<39x39xf32>
        %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %19 = ttir.empty() : tensor<39x39xbf16>
        %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %21 = ttir.empty() : tensor<1x1x39x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %23 = ttir.empty() : tensor<1x1x1x39xsi32>
        %24 = "ttir.reshape"(%2, %23) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xsi32>, tensor<1x1x1x39xsi32>) -> tensor<1x1x1x39xsi32>
        %25 = ttir.empty() : tensor<1x1x1x39xbf16>
        %26 = "ttir.typecast"(%24, %25) <{conservative_folding = false}> : (tensor<1x1x1x39xsi32>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16>
        %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %31 = ttir.empty() : tensor<1x1x39x39xbf16>
        %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %33 = ttir.empty() : tensor<1x1x39x39xbf16>
        %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %35 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIRToTTIRDecomposition (ttir-to-ttir-decomposition) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x39x39xbf16>
        %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %9 = ttir.empty() : tensor<1x1x1x1xbf16>
        %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %11 = ttir.empty() : tensor<1x1x39x39xbf16>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xf32>
        %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %17 = ttir.empty() : tensor<39x39xf32>
        %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %19 = ttir.empty() : tensor<39x39xbf16>
        %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %21 = ttir.empty() : tensor<1x1x39x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %23 = ttir.empty() : tensor<1x1x1x39xsi32>
        %24 = "ttir.reshape"(%2, %23) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xsi32>, tensor<1x1x1x39xsi32>) -> tensor<1x1x1x39xsi32>
        %25 = ttir.empty() : tensor<1x1x1x39xbf16>
        %26 = "ttir.typecast"(%24, %25) <{conservative_folding = false}> : (tensor<1x1x1x39xsi32>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16>
        %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %31 = ttir.empty() : tensor<1x1x39x39xbf16>
        %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %33 = ttir.empty() : tensor<1x1x39x39xbf16>
        %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %35 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIRFusing (ttir-fusing) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x39x39xbf16>
        %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %9 = ttir.empty() : tensor<1x1x1x1xbf16>
        %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %11 = ttir.empty() : tensor<1x1x39x39xbf16>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xf32>
        %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %17 = ttir.empty() : tensor<39x39xf32>
        %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %19 = ttir.empty() : tensor<39x39xbf16>
        %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %21 = ttir.empty() : tensor<1x1x39x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %23 = ttir.empty() : tensor<1x1x1x39xsi32>
        %24 = "ttir.reshape"(%2, %23) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xsi32>, tensor<1x1x1x39xsi32>) -> tensor<1x1x1x39xsi32>
        %25 = ttir.empty() : tensor<1x1x1x39xbf16>
        %26 = "ttir.typecast"(%24, %25) <{conservative_folding = false}> : (tensor<1x1x1x39xsi32>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16>
        %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %31 = ttir.empty() : tensor<1x1x39x39xbf16>
        %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %33 = ttir.empty() : tensor<1x1x39x39xbf16>
        %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %35 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x39x39xbf16>
        %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %9 = ttir.empty() : tensor<1x1x1x1xbf16>
        %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %11 = ttir.empty() : tensor<1x1x39x39xbf16>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xf32>
        %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %17 = ttir.empty() : tensor<39x39xf32>
        %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %19 = ttir.empty() : tensor<39x39xbf16>
        %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %21 = ttir.empty() : tensor<1x1x39x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %23 = ttir.empty() : tensor<1x1x1x39xsi32>
        %24 = "ttir.reshape"(%2, %23) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xsi32>, tensor<1x1x1x39xsi32>) -> tensor<1x1x1x39xsi32>
        %25 = ttir.empty() : tensor<1x1x1x39xbf16>
        %26 = "ttir.typecast"(%24, %25) <{conservative_folding = false}> : (tensor<1x1x1x39xsi32>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16>
        %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %31 = ttir.empty() : tensor<1x1x39x39xbf16>
        %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %33 = ttir.empty() : tensor<1x1x39x39xbf16>
        %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %35 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x39x39xbf16>
        %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %9 = ttir.empty() : tensor<1x1x1x1xbf16>
        %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %11 = ttir.empty() : tensor<1x1x39x39xbf16>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xf32>
        %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %17 = ttir.empty() : tensor<39x39xf32>
        %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %19 = ttir.empty() : tensor<39x39xbf16>
        %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %21 = ttir.empty() : tensor<1x1x39x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %23 = ttir.empty() : tensor<1x1x1x39xsi32>
        %24 = "ttir.reshape"(%2, %23) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xsi32>, tensor<1x1x1x39xsi32>) -> tensor<1x1x1x39xsi32>
        %25 = ttir.empty() : tensor<1x1x1x39xbf16>
        %26 = "ttir.typecast"(%24, %25) <{conservative_folding = false}> : (tensor<1x1x1x39xsi32>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16>
        %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %31 = ttir.empty() : tensor<1x1x39x39xbf16>
        %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %33 = ttir.empty() : tensor<1x1x39x39xbf16>
        %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %35 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x39x39xbf16>
        %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %9 = ttir.empty() : tensor<1x1x1x1xbf16>
        %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %11 = ttir.empty() : tensor<1x1x39x39xbf16>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xf32>
        %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %17 = ttir.empty() : tensor<39x39xf32>
        %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %19 = ttir.empty() : tensor<39x39xbf16>
        %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %21 = ttir.empty() : tensor<1x1x39x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %23 = ttir.empty() : tensor<1x1x1x39xsi32>
        %24 = "ttir.reshape"(%2, %23) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xsi32>, tensor<1x1x1x39xsi32>) -> tensor<1x1x1x39xsi32>
        %25 = ttir.empty() : tensor<1x1x1x39xbf16>
        %26 = "ttir.typecast"(%24, %25) <{conservative_folding = false}> : (tensor<1x1x1x39xsi32>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16>
        %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %31 = ttir.empty() : tensor<1x1x39x39xbf16>
        %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %33 = ttir.empty() : tensor<1x1x39x39xbf16>
        %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %35 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIRFlattenSlidingWindow (ttir-flatten-sliding-window) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x39x39xbf16>
        %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %9 = ttir.empty() : tensor<1x1x1x1xbf16>
        %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %11 = ttir.empty() : tensor<1x1x39x39xbf16>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xf32>
        %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %17 = ttir.empty() : tensor<39x39xf32>
        %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %19 = ttir.empty() : tensor<39x39xbf16>
        %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %21 = ttir.empty() : tensor<1x1x39x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %23 = ttir.empty() : tensor<1x1x1x39xsi32>
        %24 = "ttir.reshape"(%2, %23) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xsi32>, tensor<1x1x1x39xsi32>) -> tensor<1x1x1x39xsi32>
        %25 = ttir.empty() : tensor<1x1x1x39xbf16>
        %26 = "ttir.typecast"(%24, %25) <{conservative_folding = false}> : (tensor<1x1x1x39xsi32>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16>
        %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %31 = ttir.empty() : tensor<1x1x39x39xbf16>
        %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %33 = ttir.empty() : tensor<1x1x39x39xbf16>
        %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %35 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIRExplicateTMs (ttir-explicate-tms) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x39x39xbf16>
        %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %9 = ttir.empty() : tensor<1x1x1x1xbf16>
        %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %11 = ttir.empty() : tensor<1x1x39x39xbf16>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xf32>
        %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %17 = ttir.empty() : tensor<39x39xf32>
        %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %19 = ttir.empty() : tensor<39x39xbf16>
        %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %21 = ttir.empty() : tensor<1x1x39x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %23 = ttir.empty() : tensor<1x1x1x39xsi32>
        %24 = "ttir.reshape"(%2, %23) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xsi32>, tensor<1x1x1x39xsi32>) -> tensor<1x1x1x39xsi32>
        %25 = ttir.empty() : tensor<1x1x1x39xbf16>
        %26 = "ttir.typecast"(%24, %25) <{conservative_folding = false}> : (tensor<1x1x1x39xsi32>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16>
        %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %31 = ttir.empty() : tensor<1x1x39x39xbf16>
        %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %33 = ttir.empty() : tensor<1x1x39x39xbf16>
        %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %35 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIREraseInverseOps (ttir-erase-inverse-ops) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x39x39xbf16>
        %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %9 = ttir.empty() : tensor<1x1x1x1xbf16>
        %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %11 = ttir.empty() : tensor<1x1x39x39xbf16>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xf32>
        %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %17 = ttir.empty() : tensor<39x39xf32>
        %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %19 = ttir.empty() : tensor<39x39xbf16>
        %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %21 = ttir.empty() : tensor<1x1x39x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %23 = ttir.empty() : tensor<1x1x1x39xsi32>
        %24 = "ttir.reshape"(%2, %23) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xsi32>, tensor<1x1x1x39xsi32>) -> tensor<1x1x1x39xsi32>
        %25 = ttir.empty() : tensor<1x1x1x39xbf16>
        %26 = "ttir.typecast"(%24, %25) <{conservative_folding = false}> : (tensor<1x1x1x39xsi32>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16>
        %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %31 = ttir.empty() : tensor<1x1x39x39xbf16>
        %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %33 = ttir.empty() : tensor<1x1x39x39xbf16>
        %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %35 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump After TTIREraseInverseOps (ttir-erase-inverse-ops) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x39x39xbf16>
        %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %9 = ttir.empty() : tensor<1x1x1x1xbf16>
        %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %11 = ttir.empty() : tensor<1x1x39x39xbf16>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xf32>
        %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %17 = ttir.empty() : tensor<39x39xf32>
        %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %19 = ttir.empty() : tensor<39x39xbf16>
        %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %21 = ttir.empty() : tensor<1x1x39x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %23 = ttir.empty() : tensor<1x39xbf16>
        %24 = "ttir.typecast"(%2, %23) <{conservative_folding = false}> : (tensor<1x39xsi32>, tensor<1x39xbf16>) -> tensor<1x39xbf16>
        %25 = ttir.empty() : tensor<1x1x1x39xbf16>
        %26 = "ttir.reshape"(%24, %25) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16>
        %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %31 = ttir.empty() : tensor<1x1x39x39xbf16>
        %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %33 = ttir.empty() : tensor<1x1x39x39xbf16>
        %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %35 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIRFusing (ttir-fusing) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x39x39xbf16>
        %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %9 = ttir.empty() : tensor<1x1x1x1xbf16>
        %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %11 = ttir.empty() : tensor<1x1x39x39xbf16>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xf32>
        %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %17 = ttir.empty() : tensor<39x39xf32>
        %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %19 = ttir.empty() : tensor<39x39xbf16>
        %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %21 = ttir.empty() : tensor<1x1x39x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %23 = ttir.empty() : tensor<1x39xbf16>
        %24 = "ttir.typecast"(%2, %23) <{conservative_folding = false}> : (tensor<1x39xsi32>, tensor<1x39xbf16>) -> tensor<1x39xbf16>
        %25 = ttir.empty() : tensor<1x1x1x39xbf16>
        %26 = "ttir.reshape"(%24, %25) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16>
        %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %31 = ttir.empty() : tensor<1x1x39x39xbf16>
        %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %33 = ttir.empty() : tensor<1x1x39x39xbf16>
        %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %35 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIRImplicitBroadcastFold (ttir-implicit-broadcast-fold) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x39x39xbf16>
        %8 = "ttir.broadcast"(%6, %7) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %9 = ttir.empty() : tensor<1x1x1x1xbf16>
        %10 = "ttir.reshape"(%1, %9) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %11 = ttir.empty() : tensor<1x1x39x39xbf16>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 1, 1, 39, 39>}> : (tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.typecast"(%4, %13) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xf32>
        %16 = "ttir.typecast"(%3, %15) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %17 = ttir.empty() : tensor<39x39xf32>
        %18 = "ttir.multiply"(%14, %16, %17) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %19 = ttir.empty() : tensor<39x39xbf16>
        %20 = "ttir.typecast"(%18, %19) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %21 = ttir.empty() : tensor<1x1x39x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %23 = ttir.empty() : tensor<1x39xbf16>
        %24 = "ttir.typecast"(%2, %23) <{conservative_folding = false}> : (tensor<1x39xsi32>, tensor<1x39xbf16>) -> tensor<1x39xbf16>
        %25 = ttir.empty() : tensor<1x1x1x39xbf16>
        %26 = "ttir.reshape"(%24, %25) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.broadcast"(%26, %27) <{broadcast_dimensions = array<i64: 1, 1, 39, 1>}> : (tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16>
        %30 = "ttir.add"(%22, %28, %29) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %31 = ttir.empty() : tensor<1x1x39x39xbf16>
        %32 = "ttir.eq"(%30, %12, %31) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %33 = ttir.empty() : tensor<1x1x39x39xbf16>
        %34 = "ttir.where"(%32, %8, %22, %33) : (tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %35 = "ttir.mesh_shard"(%34) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %35 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump After TTIRImplicitBroadcastFold (ttir-implicit-broadcast-fold) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x1x1xbf16>
        %8 = "ttir.reshape"(%1, %7) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %9 = ttir.empty() : tensor<39x39xf32>
        %10 = "ttir.typecast"(%4, %9) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %11 = ttir.empty() : tensor<39x39xf32>
        %12 = "ttir.typecast"(%3, %11) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.multiply"(%10, %12, %13) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xbf16>
        %16 = "ttir.typecast"(%14, %15) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %17 = ttir.empty() : tensor<1x1x39x39xbf16>
        %18 = "ttir.reshape"(%16, %17) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %19 = ttir.empty() : tensor<1x39xbf16>
        %20 = "ttir.typecast"(%2, %19) <{conservative_folding = false}> : (tensor<1x39xsi32>, tensor<1x39xbf16>) -> tensor<1x39xbf16>
        %21 = ttir.empty() : tensor<1x1x1x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %23 = ttir.empty() : tensor<1x1x39x39xbf16>
        %24 = "ttir.add"(%18, %22, %23) : (tensor<1x1x39x39xbf16>, tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %25 = ttir.empty() : tensor<1x1x39x39xbf16>
        %26 = "ttir.eq"(%24, %8, %25) : (tensor<1x1x39x39xbf16>, tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.where"(%26, %6, %18, %27) : (tensor<1x1x39x39xbf16>, tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = "ttir.mesh_shard"(%28) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %29 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTIRQuantDataTypeConversionPass (ttir-quant-data-type-conversion) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x1x1xbf16>
        %8 = "ttir.reshape"(%1, %7) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %9 = ttir.empty() : tensor<39x39xf32>
        %10 = "ttir.typecast"(%4, %9) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %11 = ttir.empty() : tensor<39x39xf32>
        %12 = "ttir.typecast"(%3, %11) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.multiply"(%10, %12, %13) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xbf16>
        %16 = "ttir.typecast"(%14, %15) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %17 = ttir.empty() : tensor<1x1x39x39xbf16>
        %18 = "ttir.reshape"(%16, %17) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %19 = ttir.empty() : tensor<1x39xbf16>
        %20 = "ttir.typecast"(%2, %19) <{conservative_folding = false}> : (tensor<1x39xsi32>, tensor<1x39xbf16>) -> tensor<1x39xbf16>
        %21 = ttir.empty() : tensor<1x1x1x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %23 = ttir.empty() : tensor<1x1x39x39xbf16>
        %24 = "ttir.add"(%18, %22, %23) : (tensor<1x1x39x39xbf16>, tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %25 = ttir.empty() : tensor<1x1x39x39xbf16>
        %26 = "ttir.eq"(%24, %8, %25) : (tensor<1x1x39x39xbf16>, tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.where"(%26, %6, %18, %27) : (tensor<1x1x39x39xbf16>, tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = "ttir.mesh_shard"(%28) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %29 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump Before TTNNLayout (ttnn-layout) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32>) -> tensor<1x39xsi32>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %7 = ttir.empty() : tensor<1x1x1x1xbf16>
        %8 = "ttir.reshape"(%1, %7) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1x1x1xbf16>) -> tensor<1x1x1x1xbf16>
        %9 = ttir.empty() : tensor<39x39xf32>
        %10 = "ttir.typecast"(%4, %9) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %11 = ttir.empty() : tensor<39x39xf32>
        %12 = "ttir.typecast"(%3, %11) <{conservative_folding = false}> : (tensor<39x39xbf16>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %13 = ttir.empty() : tensor<39x39xf32>
        %14 = "ttir.multiply"(%10, %12, %13) : (tensor<39x39xf32>, tensor<39x39xf32>, tensor<39x39xf32>) -> tensor<39x39xf32>
        %15 = ttir.empty() : tensor<39x39xbf16>
        %16 = "ttir.typecast"(%14, %15) <{conservative_folding = false}> : (tensor<39x39xf32>, tensor<39x39xbf16>) -> tensor<39x39xbf16>
        %17 = ttir.empty() : tensor<1x1x39x39xbf16>
        %18 = "ttir.reshape"(%16, %17) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %19 = ttir.empty() : tensor<1x39xbf16>
        %20 = "ttir.typecast"(%2, %19) <{conservative_folding = false}> : (tensor<1x39xsi32>, tensor<1x39xbf16>) -> tensor<1x39xbf16>
        %21 = ttir.empty() : tensor<1x1x1x39xbf16>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16>, tensor<1x1x1x39xbf16>) -> tensor<1x1x1x39xbf16>
        %23 = ttir.empty() : tensor<1x1x39x39xbf16>
        %24 = "ttir.add"(%18, %22, %23) : (tensor<1x1x39x39xbf16>, tensor<1x1x1x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %25 = ttir.empty() : tensor<1x1x39x39xbf16>
        %26 = "ttir.eq"(%24, %8, %25) : (tensor<1x1x39x39xbf16>, tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16>
        %28 = "ttir.where"(%26, %6, %18, %27) : (tensor<1x1x39x39xbf16>, tensor<1x1x1x1xbf16>, tensor<1x1x39x39xbf16>, tensor<1x1x39x39xbf16>) -> tensor<1x1x39x39xbf16>
        %29 = "ttir.mesh_shard"(%28) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16>) -> tensor<2x1x39x39xbf16>
        return %29 : tensor<2x1x39x39xbf16>
      }
    }
  }
}


// -----// IR Dump After TTNNLayout (ttnn-layout) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<78x39xbf16, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 64 + d2, d3), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #system_memory>>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16, #ttnn_layout3>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16, #ttnn_layout3>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout>) -> tensor<1x39xsi32, #ttnn_layout>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xbf16, #ttnn_layout1>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xbf16, #ttnn_layout1>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16, #ttnn_layout4>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout3>, tensor<1x1x1x1xbf16, #ttnn_layout4>) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %7 = ttir.empty() : tensor<1x1x1x1xbf16, #ttnn_layout4>
        %8 = "ttir.reshape"(%1, %7) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout3>, tensor<1x1x1x1xbf16, #ttnn_layout4>) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %9 = ttir.empty() : tensor<39x39xf32, #ttnn_layout5>
        %10 = "ttir.typecast"(%4, %9) <{conservative_folding = false}> : (tensor<39x39xbf16, #ttnn_layout1>, tensor<39x39xf32, #ttnn_layout5>) -> tensor<39x39xf32, #ttnn_layout5>
        %11 = ttir.empty() : tensor<39x39xf32, #ttnn_layout5>
        %12 = "ttir.typecast"(%3, %11) <{conservative_folding = false}> : (tensor<39x39xbf16, #ttnn_layout1>, tensor<39x39xf32, #ttnn_layout5>) -> tensor<39x39xf32, #ttnn_layout5>
        %13 = ttir.empty() : tensor<39x39xf32, #ttnn_layout5>
        %14 = "ttir.multiply"(%10, %12, %13) : (tensor<39x39xf32, #ttnn_layout5>, tensor<39x39xf32, #ttnn_layout5>, tensor<39x39xf32, #ttnn_layout5>) -> tensor<39x39xf32, #ttnn_layout5>
        %15 = ttir.empty() : tensor<39x39xbf16, #ttnn_layout1>
        %16 = "ttir.typecast"(%14, %15) <{conservative_folding = false}> : (tensor<39x39xf32, #ttnn_layout5>, tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xbf16, #ttnn_layout1>
        %17 = ttir.empty() : tensor<1x1x39x39xbf16, #ttnn_layout6>
        %18 = "ttir.reshape"(%16, %17) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16, #ttnn_layout1>, tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %19 = ttir.empty() : tensor<1x39xbf16, #ttnn_layout7>
        %20 = "ttir.typecast"(%2, %19) <{conservative_folding = false}> : (tensor<1x39xsi32, #ttnn_layout>, tensor<1x39xbf16, #ttnn_layout7>) -> tensor<1x39xbf16, #ttnn_layout7>
        %21 = ttir.empty() : tensor<1x1x1x39xbf16, #ttnn_layout8>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16, #ttnn_layout7>, tensor<1x1x1x39xbf16, #ttnn_layout8>) -> tensor<1x1x1x39xbf16, #ttnn_layout8>
        %23 = ttir.empty() : tensor<1x1x39x39xbf16, #ttnn_layout6>
        %24 = "ttir.add"(%18, %22, %23) : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x39xbf16, #ttnn_layout8>, tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %25 = ttir.empty() : tensor<1x1x39x39xbf16, #ttnn_layout6>
        %26 = "ttir.eq"(%24, %8, %25) : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x1xbf16, #ttnn_layout4>, tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16, #ttnn_layout6>
        %28 = "ttir.where"(%26, %6, %18, %27) : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x1xbf16, #ttnn_layout4>, tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16, #ttnn_layout9>
        %30 = ttir.to_layout %28, %29 : tensor<1x1x39x39xbf16, #ttnn_layout6> into tensor<1x1x39x39xbf16, #ttnn_layout9> -> tensor<1x1x39x39xbf16, #ttnn_layout9>
        %31 = "ttir.mesh_shard"(%30) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16, #ttnn_layout9>) -> tensor<2x1x39x39xbf16, #ttnn_layout2>
        return %31 : tensor<2x1x39x39xbf16, #ttnn_layout2>
      }
    }
  }
}


// -----// IR Dump Before ConvertTTIRToTTNN (convert-ttir-to-ttnn) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<78x39xbf16, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 64 + d2, d3), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #system_memory>>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = -3.38953139E+38 : f32, shape = array<i32>}> : () -> tensor<bf16, #ttnn_layout3>
        %1 = "ttir.full"() <{fill_value = 0.000000e+00 : f32, shape = array<i32>}> : () -> tensor<bf16, #ttnn_layout3>
        %2 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout>) -> tensor<1x39xsi32, #ttnn_layout>
        %3 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xbf16, #ttnn_layout1>
        %4 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xbf16, #ttnn_layout1>
        %5 = ttir.empty() : tensor<1x1x1x1xbf16, #ttnn_layout4>
        %6 = "ttir.reshape"(%0, %5) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout3>, tensor<1x1x1x1xbf16, #ttnn_layout4>) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %7 = ttir.empty() : tensor<1x1x1x1xbf16, #ttnn_layout4>
        %8 = "ttir.reshape"(%1, %7) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout3>, tensor<1x1x1x1xbf16, #ttnn_layout4>) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %9 = ttir.empty() : tensor<39x39xf32, #ttnn_layout5>
        %10 = "ttir.typecast"(%4, %9) <{conservative_folding = false}> : (tensor<39x39xbf16, #ttnn_layout1>, tensor<39x39xf32, #ttnn_layout5>) -> tensor<39x39xf32, #ttnn_layout5>
        %11 = ttir.empty() : tensor<39x39xf32, #ttnn_layout5>
        %12 = "ttir.typecast"(%3, %11) <{conservative_folding = false}> : (tensor<39x39xbf16, #ttnn_layout1>, tensor<39x39xf32, #ttnn_layout5>) -> tensor<39x39xf32, #ttnn_layout5>
        %13 = ttir.empty() : tensor<39x39xf32, #ttnn_layout5>
        %14 = "ttir.multiply"(%10, %12, %13) : (tensor<39x39xf32, #ttnn_layout5>, tensor<39x39xf32, #ttnn_layout5>, tensor<39x39xf32, #ttnn_layout5>) -> tensor<39x39xf32, #ttnn_layout5>
        %15 = ttir.empty() : tensor<39x39xbf16, #ttnn_layout1>
        %16 = "ttir.typecast"(%14, %15) <{conservative_folding = false}> : (tensor<39x39xf32, #ttnn_layout5>, tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xbf16, #ttnn_layout1>
        %17 = ttir.empty() : tensor<1x1x39x39xbf16, #ttnn_layout6>
        %18 = "ttir.reshape"(%16, %17) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16, #ttnn_layout1>, tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %19 = ttir.empty() : tensor<1x39xbf16, #ttnn_layout7>
        %20 = "ttir.typecast"(%2, %19) <{conservative_folding = false}> : (tensor<1x39xsi32, #ttnn_layout>, tensor<1x39xbf16, #ttnn_layout7>) -> tensor<1x39xbf16, #ttnn_layout7>
        %21 = ttir.empty() : tensor<1x1x1x39xbf16, #ttnn_layout8>
        %22 = "ttir.reshape"(%20, %21) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16, #ttnn_layout7>, tensor<1x1x1x39xbf16, #ttnn_layout8>) -> tensor<1x1x1x39xbf16, #ttnn_layout8>
        %23 = ttir.empty() : tensor<1x1x39x39xbf16, #ttnn_layout6>
        %24 = "ttir.add"(%18, %22, %23) : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x39xbf16, #ttnn_layout8>, tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %25 = ttir.empty() : tensor<1x1x39x39xbf16, #ttnn_layout6>
        %26 = "ttir.eq"(%24, %8, %25) : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x1xbf16, #ttnn_layout4>, tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %27 = ttir.empty() : tensor<1x1x39x39xbf16, #ttnn_layout6>
        %28 = "ttir.where"(%26, %6, %18, %27) : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x1xbf16, #ttnn_layout4>, tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %29 = ttir.empty() : tensor<1x1x39x39xbf16, #ttnn_layout9>
        %30 = ttir.to_layout %28, %29 : tensor<1x1x39x39xbf16, #ttnn_layout6> into tensor<1x1x39x39xbf16, #ttnn_layout9> -> tensor<1x1x39x39xbf16, #ttnn_layout9>
        %31 = "ttir.mesh_shard"(%30) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16, #ttnn_layout9>) -> tensor<2x1x39x39xbf16, #ttnn_layout2>
        return %31 : tensor<2x1x39x39xbf16, #ttnn_layout2>
      }
    }
  }
}


// -----// IR Dump After ConvertTTIRToTTNN (convert-ttir-to-ttnn) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<78x39xbf16, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 64 + d2, d3), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #system_memory>>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout3>
        %2 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout3>
        %3 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout>
        %4 = "ttnn.mesh_shard"(%arg1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout1>
        %5 = "ttnn.mesh_shard"(%arg2, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout1>
        %6 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x1x1x1>}> : (!ttnn.device) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %7 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout3>) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %8 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x1x1x1>}> : (!ttnn.device) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %9 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout3>) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %10 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<39x39>}> : (!ttnn.device) -> tensor<39x39xf32, #ttnn_layout5>
        %11 = "ttnn.typecast"(%5) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xf32, #ttnn_layout5>
        %12 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<39x39>}> : (!ttnn.device) -> tensor<39x39xf32, #ttnn_layout5>
        %13 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xf32, #ttnn_layout5>
        %14 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<39x39>}> : (!ttnn.device) -> tensor<39x39xf32, #ttnn_layout5>
        %15 = "ttnn.multiply"(%11, %13) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xf32, #ttnn_layout5>, tensor<39x39xf32, #ttnn_layout5>) -> tensor<39x39xf32, #ttnn_layout5>
        %16 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<39x39>}> : (!ttnn.device) -> tensor<39x39xbf16, #ttnn_layout1>
        %17 = "ttnn.typecast"(%15) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout5>) -> tensor<39x39xbf16, #ttnn_layout1>
        %18 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x1x39x39>}> : (!ttnn.device) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %19 = "ttnn.reshape"(%17) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %20 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x39>}> : (!ttnn.device) -> tensor<1x39xbf16, #ttnn_layout7>
        %21 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x39xsi32, #ttnn_layout>) -> tensor<1x39xbf16, #ttnn_layout7>
        %22 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x1x1x39>}> : (!ttnn.device) -> tensor<1x1x1x39xbf16, #ttnn_layout8>
        %23 = "ttnn.reshape"(%21) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16, #ttnn_layout7>) -> tensor<1x1x1x39xbf16, #ttnn_layout8>
        %24 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x1x39x39>}> : (!ttnn.device) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %25 = "ttnn.add"(%19, %23) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x39xbf16, #ttnn_layout8>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %26 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x1x39x39>}> : (!ttnn.device) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %27 = "ttnn.eq"(%25, %9) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x1xbf16, #ttnn_layout4>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %28 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x1x39x39>}> : (!ttnn.device) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %29 = "ttnn.where"(%27, %7, %19) : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x1xbf16, #ttnn_layout4>, tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %30 = "ttnn.zeros"() <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, shape = #ttnn.shape<1x1x39x39>}> : () -> tensor<1x1x39x39xbf16, #ttnn_layout9>
        %31 = "ttnn.to_layout"(%29) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout9>
        %32 = "ttnn.mesh_shard"(%31, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16, #ttnn_layout9>, !ttnn.device) -> tensor<2x1x39x39xbf16, #ttnn_layout2>
        return %32 : tensor<2x1x39x39xbf16, #ttnn_layout2>
      }
    }
  }
}


// -----// IR Dump Before TTNNFusing (ttnn-fusing) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<78x39xbf16, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 64 + d2, d3), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #system_memory>>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout3>
        %2 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout3>
        %3 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout>
        %4 = "ttnn.mesh_shard"(%arg1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout1>
        %5 = "ttnn.mesh_shard"(%arg2, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout1>
        %6 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x1x1x1>}> : (!ttnn.device) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %7 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout3>) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %8 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x1x1x1>}> : (!ttnn.device) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %9 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout3>) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %10 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<39x39>}> : (!ttnn.device) -> tensor<39x39xf32, #ttnn_layout5>
        %11 = "ttnn.typecast"(%5) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xf32, #ttnn_layout5>
        %12 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<39x39>}> : (!ttnn.device) -> tensor<39x39xf32, #ttnn_layout5>
        %13 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xf32, #ttnn_layout5>
        %14 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<39x39>}> : (!ttnn.device) -> tensor<39x39xf32, #ttnn_layout5>
        %15 = "ttnn.multiply"(%11, %13) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xf32, #ttnn_layout5>, tensor<39x39xf32, #ttnn_layout5>) -> tensor<39x39xf32, #ttnn_layout5>
        %16 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<39x39>}> : (!ttnn.device) -> tensor<39x39xbf16, #ttnn_layout1>
        %17 = "ttnn.typecast"(%15) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout5>) -> tensor<39x39xbf16, #ttnn_layout1>
        %18 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x1x39x39>}> : (!ttnn.device) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %19 = "ttnn.reshape"(%17) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %20 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x39>}> : (!ttnn.device) -> tensor<1x39xbf16, #ttnn_layout7>
        %21 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x39xsi32, #ttnn_layout>) -> tensor<1x39xbf16, #ttnn_layout7>
        %22 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x1x1x39>}> : (!ttnn.device) -> tensor<1x1x1x39xbf16, #ttnn_layout8>
        %23 = "ttnn.reshape"(%21) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16, #ttnn_layout7>) -> tensor<1x1x1x39xbf16, #ttnn_layout8>
        %24 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x1x39x39>}> : (!ttnn.device) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %25 = "ttnn.add"(%19, %23) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x39xbf16, #ttnn_layout8>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %26 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x1x39x39>}> : (!ttnn.device) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %27 = "ttnn.eq"(%25, %9) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x1xbf16, #ttnn_layout4>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %28 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x1x39x39>}> : (!ttnn.device) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %29 = "ttnn.where"(%27, %7, %19) : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x1xbf16, #ttnn_layout4>, tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %30 = "ttnn.zeros"() <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, shape = #ttnn.shape<1x1x39x39>}> : () -> tensor<1x1x39x39xbf16, #ttnn_layout9>
        %31 = "ttnn.to_layout"(%29) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout9>
        %32 = "ttnn.mesh_shard"(%31, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16, #ttnn_layout9>, !ttnn.device) -> tensor<2x1x39x39xbf16, #ttnn_layout2>
        return %32 : tensor<2x1x39x39xbf16, #ttnn_layout2>
      }
    }
  }
}


// -----// IR Dump After TTNNFusing (ttnn-fusing) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<78x39xbf16, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 64 + d2, d3), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #system_memory>>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout3>
        %2 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout3>
        %3 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout>
        %4 = "ttnn.mesh_shard"(%arg1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout1>
        %5 = "ttnn.mesh_shard"(%arg2, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout1>
        %6 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout3>) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout3>) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %8 = "ttnn.typecast"(%5) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xf32, #ttnn_layout5>
        %9 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xf32, #ttnn_layout5>
        %10 = "ttnn.multiply"(%8, %9) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xf32, #ttnn_layout5>, tensor<39x39xf32, #ttnn_layout5>) -> tensor<39x39xf32, #ttnn_layout5>
        %11 = "ttnn.typecast"(%10) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout5>) -> tensor<39x39xbf16, #ttnn_layout1>
        %12 = "ttnn.reshape"(%11) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %13 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x39xsi32, #ttnn_layout>) -> tensor<1x39xbf16, #ttnn_layout7>
        %14 = "ttnn.reshape"(%13) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16, #ttnn_layout7>) -> tensor<1x1x1x39xbf16, #ttnn_layout8>
        %15 = "ttnn.add"(%12, %14) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x39xbf16, #ttnn_layout8>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %16 = "ttnn.eq"(%15, %7) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x1xbf16, #ttnn_layout4>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %17 = "ttnn.where"(%16, %6, %12) : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x1xbf16, #ttnn_layout4>, tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %18 = "ttnn.to_layout"(%17) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout9>
        %19 = "ttnn.mesh_shard"(%18, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16, #ttnn_layout9>, !ttnn.device) -> tensor<2x1x39x39xbf16, #ttnn_layout2>
        return %19 : tensor<2x1x39x39xbf16, #ttnn_layout2>
      }
    }
  }
}


// -----// IR Dump Before TTNNWorkarounds (ttnn-workaround) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<78x39xbf16, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 64 + d2, d3), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #system_memory>>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout3>
        %2 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout3>
        %3 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout>
        %4 = "ttnn.mesh_shard"(%arg1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout1>
        %5 = "ttnn.mesh_shard"(%arg2, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout1>
        %6 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout3>) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout3>) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %8 = "ttnn.typecast"(%5) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xf32, #ttnn_layout5>
        %9 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xf32, #ttnn_layout5>
        %10 = "ttnn.multiply"(%8, %9) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xf32, #ttnn_layout5>, tensor<39x39xf32, #ttnn_layout5>) -> tensor<39x39xf32, #ttnn_layout5>
        %11 = "ttnn.typecast"(%10) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout5>) -> tensor<39x39xbf16, #ttnn_layout1>
        %12 = "ttnn.reshape"(%11) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %13 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x39xsi32, #ttnn_layout>) -> tensor<1x39xbf16, #ttnn_layout7>
        %14 = "ttnn.reshape"(%13) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16, #ttnn_layout7>) -> tensor<1x1x1x39xbf16, #ttnn_layout8>
        %15 = "ttnn.add"(%12, %14) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x39xbf16, #ttnn_layout8>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %16 = "ttnn.eq"(%15, %7) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x1xbf16, #ttnn_layout4>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %17 = "ttnn.where"(%16, %6, %12) : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x1xbf16, #ttnn_layout4>, tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %18 = "ttnn.to_layout"(%17) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout9>
        %19 = "ttnn.mesh_shard"(%18, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16, #ttnn_layout9>, !ttnn.device) -> tensor<2x1x39x39xbf16, #ttnn_layout2>
        return %19 : tensor<2x1x39x39xbf16, #ttnn_layout2>
      }
    }
  }
}


// -----// IR Dump After TTNNWorkarounds (ttnn-workaround) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<78x39xbf16, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 64 + d2, d3), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #system_memory>>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout3>
        %2 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout3>
        %3 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout>
        %4 = "ttnn.mesh_shard"(%arg1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout1>
        %5 = "ttnn.mesh_shard"(%arg2, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout1>
        %6 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout3>) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout3>) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %8 = "ttnn.typecast"(%5) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xf32, #ttnn_layout5>
        %9 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xf32, #ttnn_layout5>
        %10 = "ttnn.multiply"(%8, %9) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xf32, #ttnn_layout5>, tensor<39x39xf32, #ttnn_layout5>) -> tensor<39x39xf32, #ttnn_layout5>
        %11 = "ttnn.typecast"(%10) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout5>) -> tensor<39x39xbf16, #ttnn_layout1>
        %12 = "ttnn.reshape"(%11) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %13 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x39xsi32, #ttnn_layout>) -> tensor<1x39xbf16, #ttnn_layout7>
        %14 = "ttnn.reshape"(%13) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16, #ttnn_layout7>) -> tensor<1x1x1x39xbf16, #ttnn_layout8>
        %15 = "ttnn.add"(%12, %14) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x39xbf16, #ttnn_layout8>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %16 = "ttnn.eq"(%15, %7) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x1xbf16, #ttnn_layout4>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %17 = "ttnn.repeat"(%6) <{repeat_dims = #ttnn.shape<1x1x39x39>}> : (tensor<1x1x1x1xbf16, #ttnn_layout4>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %18 = "ttnn.where"(%16, %17, %12) : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %19 = "ttnn.to_layout"(%18) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout9>
        %20 = "ttnn.mesh_shard"(%19, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16, #ttnn_layout9>, !ttnn.device) -> tensor<2x1x39x39xbf16, #ttnn_layout2>
        return %20 : tensor<2x1x39x39xbf16, #ttnn_layout2>
      }
    }
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<78x39xbf16, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 64 + d2, d3), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #system_memory>>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout3>
        %2 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout3>
        %3 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout>
        %4 = "ttnn.mesh_shard"(%arg1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout1>
        %5 = "ttnn.mesh_shard"(%arg2, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout1>
        %6 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout3>) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout3>) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %8 = "ttnn.typecast"(%5) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xf32, #ttnn_layout5>
        %9 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xf32, #ttnn_layout5>
        %10 = "ttnn.multiply"(%8, %9) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xf32, #ttnn_layout5>, tensor<39x39xf32, #ttnn_layout5>) -> tensor<39x39xf32, #ttnn_layout5>
        %11 = "ttnn.typecast"(%10) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout5>) -> tensor<39x39xbf16, #ttnn_layout1>
        %12 = "ttnn.reshape"(%11) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %13 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x39xsi32, #ttnn_layout>) -> tensor<1x39xbf16, #ttnn_layout7>
        %14 = "ttnn.reshape"(%13) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16, #ttnn_layout7>) -> tensor<1x1x1x39xbf16, #ttnn_layout8>
        %15 = "ttnn.add"(%12, %14) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x39xbf16, #ttnn_layout8>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %16 = "ttnn.eq"(%15, %7) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x1xbf16, #ttnn_layout4>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %17 = "ttnn.repeat"(%6) <{repeat_dims = #ttnn.shape<1x1x39x39>}> : (tensor<1x1x1x1xbf16, #ttnn_layout4>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %18 = "ttnn.where"(%16, %17, %12) : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %19 = "ttnn.to_layout"(%18) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout9>
        %20 = "ttnn.mesh_shard"(%19, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16, #ttnn_layout9>, !ttnn.device) -> tensor<2x1x39x39xbf16, #ttnn_layout2>
        return %20 : tensor<2x1x39x39xbf16, #ttnn_layout2>
      }
    }
  }
}


// -----// IR Dump Before ConstEvalHoistTransform (const-eval-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<78x39xbf16, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 64 + d2, d3), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #system_memory>>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16, #ttnn_layout2> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout3>
        %2 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout3>
        %3 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout>
        %4 = "ttnn.mesh_shard"(%arg1, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout1>
        %5 = "ttnn.mesh_shard"(%arg2, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout1>
        %6 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout3>) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout3>) -> tensor<1x1x1x1xbf16, #ttnn_layout4>
        %8 = "ttnn.typecast"(%5) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xf32, #ttnn_layout5>
        %9 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<39x39xf32, #ttnn_layout5>
        %10 = "ttnn.multiply"(%8, %9) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xf32, #ttnn_layout5>, tensor<39x39xf32, #ttnn_layout5>) -> tensor<39x39xf32, #ttnn_layout5>
        %11 = "ttnn.typecast"(%10) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout5>) -> tensor<39x39xbf16, #ttnn_layout1>
        %12 = "ttnn.reshape"(%11) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16, #ttnn_layout1>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %13 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x39xsi32, #ttnn_layout>) -> tensor<1x39xbf16, #ttnn_layout7>
        %14 = "ttnn.reshape"(%13) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16, #ttnn_layout7>) -> tensor<1x1x1x39xbf16, #ttnn_layout8>
        %15 = "ttnn.add"(%12, %14) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x39xbf16, #ttnn_layout8>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %16 = "ttnn.eq"(%15, %7) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x1x1xbf16, #ttnn_layout4>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %17 = "ttnn.repeat"(%6) <{repeat_dims = #ttnn.shape<1x1x39x39>}> : (tensor<1x1x1x1xbf16, #ttnn_layout4>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %18 = "ttnn.where"(%16, %17, %12) : (tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x39x39xbf16, #ttnn_layout6>, tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout6>
        %19 = "ttnn.to_layout"(%18) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x1x39x39xbf16, #ttnn_layout6>) -> tensor<1x1x39x39xbf16, #ttnn_layout9>
        %20 = "ttnn.mesh_shard"(%19, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16, #ttnn_layout9>, !ttnn.device) -> tensor<2x1x39x39xbf16, #ttnn_layout2>
        return %20 : tensor<2x1x39x39xbf16, #ttnn_layout2>
      }
    }
  }
}


// -----// IR Dump After ConstEvalHoistTransform (const-eval-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 64 + d2, d3), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<78x39xbf16, #system_memory>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #system_memory>>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0() -> tensor<1x1x39x39xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<1x1x39x39>}> : (tensor<1x1x1x1xbf16, #ttnn_layout2>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        return %3 : tensor<1x1x39x39xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<1x1x1x1xbf16, #ttnn_layout2> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        return %2 : tensor<1x1x1x1xbf16, #ttnn_layout2>
      }
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16, #ttnn_layout5> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        %2 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %3 = "ttnn.mesh_shard"(%arg0, %2) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout3>
        %4 = "ttnn.mesh_shard"(%arg1, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout4>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout4>
        %5 = "ttnn.mesh_shard"(%arg2, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout4>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout4>
        %6 = "ttnn.typecast"(%5) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<39x39xf32, #ttnn_layout6>
        %7 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<39x39xf32, #ttnn_layout6>
        %8 = "ttnn.multiply"(%6, %7) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xf32, #ttnn_layout6>, tensor<39x39xf32, #ttnn_layout6>) -> tensor<39x39xf32, #ttnn_layout6>
        %9 = "ttnn.typecast"(%8) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout6>) -> tensor<39x39xbf16, #ttnn_layout4>
        %10 = "ttnn.reshape"(%9) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %11 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x39xsi32, #ttnn_layout3>) -> tensor<1x39xbf16, #ttnn_layout7>
        %12 = "ttnn.reshape"(%11) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16, #ttnn_layout7>) -> tensor<1x1x1x39xbf16, #ttnn_layout8>
        %13 = "ttnn.add"(%10, %12) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x1x39xbf16, #ttnn_layout8>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %14 = "ttnn.eq"(%13, %1) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x1x1xbf16, #ttnn_layout2>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %15 = "ttnn.where"(%14, %0, %10) : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x39x39xbf16, #ttnn_layout>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %16 = "ttnn.to_layout"(%15) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>) -> tensor<1x1x39x39xbf16, #ttnn_layout9>
        %17 = "ttnn.mesh_shard"(%16, %2) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16, #ttnn_layout9>, !ttnn.device) -> tensor<2x1x39x39xbf16, #ttnn_layout5>
        return %17 : tensor<2x1x39x39xbf16, #ttnn_layout5>
      }
    }
  }
}


// -----// IR Dump Before ConstEvalHoistTransform (const-eval-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 64 + d2, d3), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<78x39xbf16, #system_memory>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #system_memory>>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0() -> tensor<1x1x39x39xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<1x1x39x39>}> : (tensor<1x1x1x1xbf16, #ttnn_layout2>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        return %3 : tensor<1x1x39x39xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<1x1x1x1xbf16, #ttnn_layout2> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        return %2 : tensor<1x1x1x1xbf16, #ttnn_layout2>
      }
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16, #ttnn_layout5> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        %2 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %3 = "ttnn.mesh_shard"(%arg0, %2) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout3>
        %4 = "ttnn.mesh_shard"(%arg1, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout4>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout4>
        %5 = "ttnn.mesh_shard"(%arg2, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout4>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout4>
        %6 = "ttnn.typecast"(%5) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<39x39xf32, #ttnn_layout6>
        %7 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<39x39xf32, #ttnn_layout6>
        %8 = "ttnn.multiply"(%6, %7) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xf32, #ttnn_layout6>, tensor<39x39xf32, #ttnn_layout6>) -> tensor<39x39xf32, #ttnn_layout6>
        %9 = "ttnn.typecast"(%8) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout6>) -> tensor<39x39xbf16, #ttnn_layout4>
        %10 = "ttnn.reshape"(%9) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %11 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x39xsi32, #ttnn_layout3>) -> tensor<1x39xbf16, #ttnn_layout7>
        %12 = "ttnn.reshape"(%11) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16, #ttnn_layout7>) -> tensor<1x1x1x39xbf16, #ttnn_layout8>
        %13 = "ttnn.add"(%10, %12) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x1x39xbf16, #ttnn_layout8>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %14 = "ttnn.eq"(%13, %1) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x1x1xbf16, #ttnn_layout2>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %15 = "ttnn.where"(%14, %0, %10) : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x39x39xbf16, #ttnn_layout>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %16 = "ttnn.to_layout"(%15) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>) -> tensor<1x1x39x39xbf16, #ttnn_layout9>
        %17 = "ttnn.mesh_shard"(%16, %2) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16, #ttnn_layout9>, !ttnn.device) -> tensor<2x1x39x39xbf16, #ttnn_layout5>
        return %17 : tensor<2x1x39x39xbf16, #ttnn_layout5>
      }
    }
  }
}


// -----// IR Dump After ConstEvalHoistTransform (const-eval-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 64 + d2, d3), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<78x39xbf16, #system_memory>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #system_memory>>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0() -> tensor<1x1x39x39xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<1x1x39x39>}> : (tensor<1x1x1x1xbf16, #ttnn_layout2>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        return %3 : tensor<1x1x39x39xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<1x1x1x1xbf16, #ttnn_layout2> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        return %2 : tensor<1x1x1x1xbf16, #ttnn_layout2>
      }
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16, #ttnn_layout5> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        %2 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %3 = "ttnn.mesh_shard"(%arg0, %2) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout3>
        %4 = "ttnn.mesh_shard"(%arg1, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout4>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout4>
        %5 = "ttnn.mesh_shard"(%arg2, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout4>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout4>
        %6 = "ttnn.typecast"(%5) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<39x39xf32, #ttnn_layout6>
        %7 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<39x39xf32, #ttnn_layout6>
        %8 = "ttnn.multiply"(%6, %7) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xf32, #ttnn_layout6>, tensor<39x39xf32, #ttnn_layout6>) -> tensor<39x39xf32, #ttnn_layout6>
        %9 = "ttnn.typecast"(%8) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout6>) -> tensor<39x39xbf16, #ttnn_layout4>
        %10 = "ttnn.reshape"(%9) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %11 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x39xsi32, #ttnn_layout3>) -> tensor<1x39xbf16, #ttnn_layout7>
        %12 = "ttnn.reshape"(%11) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16, #ttnn_layout7>) -> tensor<1x1x1x39xbf16, #ttnn_layout8>
        %13 = "ttnn.add"(%10, %12) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x1x39xbf16, #ttnn_layout8>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %14 = "ttnn.eq"(%13, %1) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x1x1xbf16, #ttnn_layout2>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %15 = "ttnn.where"(%14, %0, %10) : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x39x39xbf16, #ttnn_layout>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %16 = "ttnn.to_layout"(%15) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>) -> tensor<1x1x39x39xbf16, #ttnn_layout9>
        %17 = "ttnn.mesh_shard"(%16, %2) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16, #ttnn_layout9>, !ttnn.device) -> tensor<2x1x39x39xbf16, #ttnn_layout5>
        return %17 : tensor<2x1x39x39xbf16, #ttnn_layout5>
      }
    }
  }
}


// -----// IR Dump Before TTNNDecomposeLayouts (ttnn-decompose-layouts) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 64 + d2, d3), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<78x39xbf16, #system_memory>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #system_memory>>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0() -> tensor<1x1x39x39xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<1x1x39x39>}> : (tensor<1x1x1x1xbf16, #ttnn_layout2>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        return %3 : tensor<1x1x39x39xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<1x1x1x1xbf16, #ttnn_layout2> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        return %2 : tensor<1x1x1x1xbf16, #ttnn_layout2>
      }
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16, #ttnn_layout5> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        %2 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %3 = "ttnn.mesh_shard"(%arg0, %2) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout3>
        %4 = "ttnn.mesh_shard"(%arg1, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout4>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout4>
        %5 = "ttnn.mesh_shard"(%arg2, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout4>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout4>
        %6 = "ttnn.typecast"(%5) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<39x39xf32, #ttnn_layout6>
        %7 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<39x39xf32, #ttnn_layout6>
        %8 = "ttnn.multiply"(%6, %7) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xf32, #ttnn_layout6>, tensor<39x39xf32, #ttnn_layout6>) -> tensor<39x39xf32, #ttnn_layout6>
        %9 = "ttnn.typecast"(%8) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout6>) -> tensor<39x39xbf16, #ttnn_layout4>
        %10 = "ttnn.reshape"(%9) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %11 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x39xsi32, #ttnn_layout3>) -> tensor<1x39xbf16, #ttnn_layout7>
        %12 = "ttnn.reshape"(%11) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16, #ttnn_layout7>) -> tensor<1x1x1x39xbf16, #ttnn_layout8>
        %13 = "ttnn.add"(%10, %12) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x1x39xbf16, #ttnn_layout8>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %14 = "ttnn.eq"(%13, %1) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x1x1xbf16, #ttnn_layout2>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %15 = "ttnn.where"(%14, %0, %10) : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x39x39xbf16, #ttnn_layout>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %16 = "ttnn.to_layout"(%15) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>) -> tensor<1x1x39x39xbf16, #ttnn_layout9>
        %17 = "ttnn.mesh_shard"(%16, %2) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16, #ttnn_layout9>, !ttnn.device) -> tensor<2x1x39x39xbf16, #ttnn_layout5>
        return %17 : tensor<2x1x39x39xbf16, #ttnn_layout5>
      }
    }
  }
}


// -----// IR Dump After TTNNDecomposeLayouts (ttnn-decompose-layouts) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 64 + d2, d3), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<78x39xbf16, #system_memory>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #dram>, <interleaved>>
#ttnn_layout10 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #system_memory>>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0() -> tensor<1x1x39x39xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<1x1x39x39>}> : (tensor<1x1x1x1xbf16, #ttnn_layout2>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        return %3 : tensor<1x1x39x39xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<1x1x1x1xbf16, #ttnn_layout2> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        return %2 : tensor<1x1x1x1xbf16, #ttnn_layout2>
      }
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16, #ttnn_layout5> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        %2 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %3 = "ttnn.mesh_shard"(%arg0, %2) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout3>
        %4 = "ttnn.mesh_shard"(%arg1, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout4>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout4>
        %5 = "ttnn.mesh_shard"(%arg2, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout4>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout4>
        %6 = "ttnn.typecast"(%5) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<39x39xf32, #ttnn_layout6>
        %7 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<39x39xf32, #ttnn_layout6>
        %8 = "ttnn.multiply"(%6, %7) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xf32, #ttnn_layout6>, tensor<39x39xf32, #ttnn_layout6>) -> tensor<39x39xf32, #ttnn_layout6>
        %9 = "ttnn.typecast"(%8) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout6>) -> tensor<39x39xbf16, #ttnn_layout4>
        %10 = "ttnn.reshape"(%9) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %11 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x39xsi32, #ttnn_layout3>) -> tensor<1x39xbf16, #ttnn_layout7>
        %12 = "ttnn.reshape"(%11) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16, #ttnn_layout7>) -> tensor<1x1x1x39xbf16, #ttnn_layout8>
        %13 = "ttnn.add"(%10, %12) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x1x39xbf16, #ttnn_layout8>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %14 = "ttnn.eq"(%13, %1) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x1x1xbf16, #ttnn_layout2>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %15 = "ttnn.where"(%14, %0, %10) : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x39x39xbf16, #ttnn_layout>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %16 = "ttnn.to_layout"(%15) <{layout = #ttnn.layout<row_major>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>) -> tensor<1x1x39x39xbf16, #ttnn_layout9>
        %17 = "ttnn.from_device"(%16) : (tensor<1x1x39x39xbf16, #ttnn_layout9>) -> tensor<1x1x39x39xbf16, #ttnn_layout10>
        %18 = "ttnn.mesh_shard"(%17, %2) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16, #ttnn_layout10>, !ttnn.device) -> tensor<2x1x39x39xbf16, #ttnn_layout5>
        return %18 : tensor<2x1x39x39xbf16, #ttnn_layout5>
      }
    }
  }
}


// -----// IR Dump Before TTCoreOptimizationBarrierFold (ttcore-optimization-barrier-fold) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 64 + d2, d3), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<78x39xbf16, #system_memory>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #dram>, <interleaved>>
#ttnn_layout10 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #system_memory>>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0() -> tensor<1x1x39x39xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<1x1x39x39>}> : (tensor<1x1x1x1xbf16, #ttnn_layout2>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        return %3 : tensor<1x1x39x39xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<1x1x1x1xbf16, #ttnn_layout2> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        return %2 : tensor<1x1x1x1xbf16, #ttnn_layout2>
      }
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16, #ttnn_layout5> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        %2 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %3 = "ttnn.mesh_shard"(%arg0, %2) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout3>
        %4 = "ttnn.mesh_shard"(%arg1, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout4>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout4>
        %5 = "ttnn.mesh_shard"(%arg2, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout4>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout4>
        %6 = "ttnn.typecast"(%5) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<39x39xf32, #ttnn_layout6>
        %7 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<39x39xf32, #ttnn_layout6>
        %8 = "ttnn.multiply"(%6, %7) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xf32, #ttnn_layout6>, tensor<39x39xf32, #ttnn_layout6>) -> tensor<39x39xf32, #ttnn_layout6>
        %9 = "ttnn.typecast"(%8) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout6>) -> tensor<39x39xbf16, #ttnn_layout4>
        %10 = "ttnn.reshape"(%9) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %11 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x39xsi32, #ttnn_layout3>) -> tensor<1x39xbf16, #ttnn_layout7>
        %12 = "ttnn.reshape"(%11) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16, #ttnn_layout7>) -> tensor<1x1x1x39xbf16, #ttnn_layout8>
        %13 = "ttnn.add"(%10, %12) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x1x39xbf16, #ttnn_layout8>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %14 = "ttnn.eq"(%13, %1) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x1x1xbf16, #ttnn_layout2>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %15 = "ttnn.where"(%14, %0, %10) : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x39x39xbf16, #ttnn_layout>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %16 = "ttnn.to_layout"(%15) <{layout = #ttnn.layout<row_major>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>) -> tensor<1x1x39x39xbf16, #ttnn_layout9>
        %17 = "ttnn.from_device"(%16) : (tensor<1x1x39x39xbf16, #ttnn_layout9>) -> tensor<1x1x39x39xbf16, #ttnn_layout10>
        %18 = "ttnn.mesh_shard"(%17, %2) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16, #ttnn_layout10>, !ttnn.device) -> tensor<2x1x39x39xbf16, #ttnn_layout5>
        return %18 : tensor<2x1x39x39xbf16, #ttnn_layout5>
      }
    }
  }
}


// -----// IR Dump Before TTNNDeallocate (ttnn-deallocate) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 64 + d2, d3), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<78x39xbf16, #system_memory>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #dram>, <interleaved>>
#ttnn_layout10 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #system_memory>>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0() -> tensor<1x1x39x39xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<1x1x39x39>}> : (tensor<1x1x1x1xbf16, #ttnn_layout2>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        return %3 : tensor<1x1x39x39xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<1x1x1x1xbf16, #ttnn_layout2> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        return %2 : tensor<1x1x1x1xbf16, #ttnn_layout2>
      }
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16, #ttnn_layout5> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        %2 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %3 = "ttnn.mesh_shard"(%arg0, %2) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout3>
        %4 = "ttnn.mesh_shard"(%arg1, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout4>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout4>
        %5 = "ttnn.mesh_shard"(%arg2, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout4>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout4>
        %6 = "ttnn.typecast"(%5) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<39x39xf32, #ttnn_layout6>
        %7 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<39x39xf32, #ttnn_layout6>
        %8 = "ttnn.multiply"(%6, %7) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xf32, #ttnn_layout6>, tensor<39x39xf32, #ttnn_layout6>) -> tensor<39x39xf32, #ttnn_layout6>
        %9 = "ttnn.typecast"(%8) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout6>) -> tensor<39x39xbf16, #ttnn_layout4>
        %10 = "ttnn.reshape"(%9) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %11 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x39xsi32, #ttnn_layout3>) -> tensor<1x39xbf16, #ttnn_layout7>
        %12 = "ttnn.reshape"(%11) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16, #ttnn_layout7>) -> tensor<1x1x1x39xbf16, #ttnn_layout8>
        %13 = "ttnn.add"(%10, %12) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x1x39xbf16, #ttnn_layout8>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %14 = "ttnn.eq"(%13, %1) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x1x1xbf16, #ttnn_layout2>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %15 = "ttnn.where"(%14, %0, %10) : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x39x39xbf16, #ttnn_layout>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %16 = "ttnn.to_layout"(%15) <{layout = #ttnn.layout<row_major>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>) -> tensor<1x1x39x39xbf16, #ttnn_layout9>
        %17 = "ttnn.from_device"(%16) : (tensor<1x1x39x39xbf16, #ttnn_layout9>) -> tensor<1x1x39x39xbf16, #ttnn_layout10>
        %18 = "ttnn.mesh_shard"(%17, %2) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16, #ttnn_layout10>, !ttnn.device) -> tensor<2x1x39x39xbf16, #ttnn_layout5>
        return %18 : tensor<2x1x39x39xbf16, #ttnn_layout5>
      }
    }
  }
}


// -----// IR Dump After TTNNDeallocate (ttnn-deallocate) ('builtin.module' operation: @SyncTensorsGraph.49) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 64 + d2, d3), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<78x39xbf16, #system_memory>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #dram>, <interleaved>>
#ttnn_layout10 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #system_memory>>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]>
      func.func @main_const_eval_0() -> tensor<1x1x39x39xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<bf16, #ttnn_layout1>) -> ()
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<1x1x39x39>}> : (tensor<1x1x1x1xbf16, #ttnn_layout2>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x1x1x1xbf16, #ttnn_layout2>) -> ()
        return %3 : tensor<1x1x39x39xbf16, #ttnn_layout>
      }
      func.func @main_const_eval_1() -> tensor<1x1x1x1xbf16, #ttnn_layout2> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<bf16, #ttnn_layout1>) -> ()
        return %2 : tensor<1x1x1x1xbf16, #ttnn_layout2>
      }
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<39x39xbf16, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<39x39xbf16, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<2x1x39x39xbf16, #ttnn_layout5> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<1x1x39x39xbf16, #ttnn_layout>
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x1x1x1xbf16, #ttnn_layout2>
        %2 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device
        %3 = "ttnn.mesh_shard"(%arg0, %2) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout3>
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<2x39xsi32, #ttnn_layout3>) -> ()
        %4 = "ttnn.mesh_shard"(%arg1, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout4>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout4>
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<39x39xbf16, #ttnn_layout4>) -> ()
        %5 = "ttnn.mesh_shard"(%arg2, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout4>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout4>
        "ttnn.deallocate"(%arg2) <{force = false}> : (tensor<39x39xbf16, #ttnn_layout4>) -> ()
        %6 = "ttnn.typecast"(%5) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<39x39xf32, #ttnn_layout6>
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<39x39xbf16, #ttnn_layout4>) -> ()
        %7 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<39x39xf32, #ttnn_layout6>
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<39x39xbf16, #ttnn_layout4>) -> ()
        %8 = "ttnn.multiply"(%6, %7) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xf32, #ttnn_layout6>, tensor<39x39xf32, #ttnn_layout6>) -> tensor<39x39xf32, #ttnn_layout6>
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<39x39xf32, #ttnn_layout6>) -> ()
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<39x39xf32, #ttnn_layout6>) -> ()
        %9 = "ttnn.typecast"(%8) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout6>) -> tensor<39x39xbf16, #ttnn_layout4>
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<39x39xf32, #ttnn_layout6>) -> ()
        %10 = "ttnn.reshape"(%9) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<39x39xbf16, #ttnn_layout4>) -> ()
        %11 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x39xsi32, #ttnn_layout3>) -> tensor<1x39xbf16, #ttnn_layout7>
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x39xsi32, #ttnn_layout3>) -> ()
        %12 = "ttnn.reshape"(%11) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16, #ttnn_layout7>) -> tensor<1x1x1x39xbf16, #ttnn_layout8>
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x39xbf16, #ttnn_layout7>) -> ()
        %13 = "ttnn.add"(%10, %12) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x1x39xbf16, #ttnn_layout8>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x1x1x39xbf16, #ttnn_layout8>) -> ()
        %14 = "ttnn.eq"(%13, %1) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x1x1xbf16, #ttnn_layout2>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<1x1x39x39xbf16, #ttnn_layout>) -> ()
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x1x1x1xbf16, #ttnn_layout2>) -> ()
        %15 = "ttnn.where"(%14, %0, %10) : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x39x39xbf16, #ttnn_layout>) -> tensor<1x1x39x39xbf16, #ttnn_layout>
        "ttnn.deallocate"(%14) <{force = false}> : (tensor<1x1x39x39xbf16, #ttnn_layout>) -> ()
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x1x39x39xbf16, #ttnn_layout>) -> ()
        "ttnn.deallocate"(%0) <{force = false}> : (tensor<1x1x39x39xbf16, #ttnn_layout>) -> ()
        %16 = "ttnn.to_layout"(%15) <{layout = #ttnn.layout<row_major>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>) -> tensor<1x1x39x39xbf16, #ttnn_layout9>
        "ttnn.deallocate"(%15) <{force = false}> : (tensor<1x1x39x39xbf16, #ttnn_layout>) -> ()
        %17 = "ttnn.from_device"(%16) : (tensor<1x1x39x39xbf16, #ttnn_layout9>) -> tensor<1x1x39x39xbf16, #ttnn_layout10>
        "ttnn.deallocate"(%16) <{force = false}> : (tensor<1x1x39x39xbf16, #ttnn_layout9>) -> ()
        %18 = "ttnn.mesh_shard"(%17, %2) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16, #ttnn_layout10>, !ttnn.device) -> tensor<2x1x39x39xbf16, #ttnn_layout5>
        "ttnn.deallocate"(%17) <{force = false}> : (tensor<1x1x39x39xbf16, #ttnn_layout10>) -> ()
        return %18 : tensor<2x1x39x39xbf16, #ttnn_layout5>
      }
    }
  }
}


#dram = #ttnn.buffer_type<dram>
#loc2 = loc("xla__device_data")
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073150080, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 101440, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073166976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 64 + d2, d3), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<78x39xbf16, #system_memory>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #dram>, <interleaved>>
#ttnn_layout10 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 39 + d1 * 39 + d2, d3), <1x1>, memref<39x39xbf16, #system_memory>>
module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.49 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]> loc(#loc)
      func.func @main_const_eval_0() -> tensor<1x1x39x39xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1x1x1xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<bf16, #ttnn_layout1>) -> () loc(#loc)
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<1x1x39x39>}> : (tensor<1x1x1x1xbf16, #ttnn_layout2>) -> tensor<1x1x39x39xbf16, #ttnn_layout> loc(#loc1)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x1x1x1xbf16, #ttnn_layout2>) -> () loc(#loc1)
        return %3 : tensor<1x1x39x39xbf16, #ttnn_layout> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_1() -> tensor<1x1x1x1xbf16, #ttnn_layout2> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1x1x1xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<bf16, #ttnn_layout1>) -> () loc(#loc)
        return %2 : tensor<1x1x1x1xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func @main(%arg0: tensor<2x39xsi32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("xla__device_data"), %arg1: tensor<39x39xbf16, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("xla__device_data"), %arg2: tensor<39x39xbf16, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("xla__device_data")) -> (tensor<2x1x39x39xbf16, #ttnn_layout5> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<1x1x39x39xbf16, #ttnn_layout> loc(#loc)
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x1x1x1xbf16, #ttnn_layout2> loc(#loc)
        %2 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device loc(#loc)
        %3 = "ttnn.mesh_shard"(%arg0, %2) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x39xsi32, #ttnn_layout3>, !ttnn.device) -> tensor<1x39xsi32, #ttnn_layout3> loc(#loc)
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<2x39xsi32, #ttnn_layout3>) -> () loc(#loc)
        %4 = "ttnn.mesh_shard"(%arg1, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout4>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<39x39xbf16, #ttnn_layout4>) -> () loc(#loc)
        %5 = "ttnn.mesh_shard"(%arg2, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<39x39xbf16, #ttnn_layout4>, !ttnn.device) -> tensor<39x39xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%arg2) <{force = false}> : (tensor<39x39xbf16, #ttnn_layout4>) -> () loc(#loc)
        %6 = "ttnn.typecast"(%5) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<39x39xf32, #ttnn_layout6> loc(#loc3)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<39x39xbf16, #ttnn_layout4>) -> () loc(#loc3)
        %7 = "ttnn.typecast"(%4) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<39x39xf32, #ttnn_layout6> loc(#loc3)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<39x39xbf16, #ttnn_layout4>) -> () loc(#loc3)
        %8 = "ttnn.multiply"(%6, %7) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<39x39xf32, #ttnn_layout6>, tensor<39x39xf32, #ttnn_layout6>) -> tensor<39x39xf32, #ttnn_layout6> loc(#loc4)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<39x39xf32, #ttnn_layout6>) -> () loc(#loc4)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<39x39xf32, #ttnn_layout6>) -> () loc(#loc4)
        %9 = "ttnn.typecast"(%8) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<39x39xf32, #ttnn_layout6>) -> tensor<39x39xbf16, #ttnn_layout4> loc(#loc3)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<39x39xf32, #ttnn_layout6>) -> () loc(#loc3)
        %10 = "ttnn.reshape"(%9) <{shape = [1 : i32, 1 : i32, 39 : i32, 39 : i32]}> : (tensor<39x39xbf16, #ttnn_layout4>) -> tensor<1x1x39x39xbf16, #ttnn_layout> loc(#loc3)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<39x39xbf16, #ttnn_layout4>) -> () loc(#loc3)
        %11 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x39xsi32, #ttnn_layout3>) -> tensor<1x39xbf16, #ttnn_layout7> loc(#loc5)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x39xsi32, #ttnn_layout3>) -> () loc(#loc5)
        %12 = "ttnn.reshape"(%11) <{shape = [1 : i32, 1 : i32, 1 : i32, 39 : i32]}> : (tensor<1x39xbf16, #ttnn_layout7>) -> tensor<1x1x1x39xbf16, #ttnn_layout8> loc(#loc5)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x39xbf16, #ttnn_layout7>) -> () loc(#loc5)
        %13 = "ttnn.add"(%10, %12) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x1x39xbf16, #ttnn_layout8>) -> tensor<1x1x39x39xbf16, #ttnn_layout> loc(#loc5)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x1x1x39xbf16, #ttnn_layout8>) -> () loc(#loc5)
        %14 = "ttnn.eq"(%13, %1) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x1x1xbf16, #ttnn_layout2>) -> tensor<1x1x39x39xbf16, #ttnn_layout> loc(#loc6)
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<1x1x39x39xbf16, #ttnn_layout>) -> () loc(#loc6)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x1x1x1xbf16, #ttnn_layout2>) -> () loc(#loc6)
        %15 = "ttnn.where"(%14, %0, %10) : (tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x39x39xbf16, #ttnn_layout>, tensor<1x1x39x39xbf16, #ttnn_layout>) -> tensor<1x1x39x39xbf16, #ttnn_layout> loc(#loc1)
        "ttnn.deallocate"(%14) <{force = false}> : (tensor<1x1x39x39xbf16, #ttnn_layout>) -> () loc(#loc1)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x1x39x39xbf16, #ttnn_layout>) -> () loc(#loc1)
        "ttnn.deallocate"(%0) <{force = false}> : (tensor<1x1x39x39xbf16, #ttnn_layout>) -> () loc(#loc1)
        %16 = "ttnn.to_layout"(%15) <{layout = #ttnn.layout<row_major>}> : (tensor<1x1x39x39xbf16, #ttnn_layout>) -> tensor<1x1x39x39xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%15) <{force = false}> : (tensor<1x1x39x39xbf16, #ttnn_layout>) -> () loc(#loc)
        %17 = "ttnn.from_device"(%16) : (tensor<1x1x39x39xbf16, #ttnn_layout9>) -> tensor<1x1x39x39xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%16) <{force = false}> : (tensor<1x1x39x39xbf16, #ttnn_layout9>) -> () loc(#loc)
        %18 = "ttnn.mesh_shard"(%17, %2) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x39x39xbf16, #ttnn_layout10>, !ttnn.device) -> tensor<2x1x39x39xbf16, #ttnn_layout5> loc(#loc)
        "ttnn.deallocate"(%17) <{force = false}> : (tensor<1x1x39x39xbf16, #ttnn_layout10>) -> () loc(#loc)
        return %18 : tensor<2x1x39x39xbf16, #ttnn_layout5> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc1 = loc("aten__masked_fill")
#loc3 = loc("xla__cast")
#loc4 = loc("aten__mul")
#loc5 = loc("aten__add")
#loc6 = loc("aten__eq")
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User is requesting to copy the data from a runtime tensor with data type: Int32 into buffer with expected data type: Int64, the values will be casted, this may impact the throughput and the integrity of the data.
Running tests/runner/test_models.py::test_all_models[full-inference] - pytorch_qwen_2_5_7b_instruct_nlp_causal_lm_huggingface
FAILED

=================================== FAILURES ===================================
_______________________ test_all_models[full-inference] ________________________

run_mode = <RunMode.INFERENCE: 'inference'>, op_by_op = None
record_property = <function record_property.<locals>.append_property at 0x7f4997591260>
test_metadata = <tests.runner.test_utils.ModelTestConfig object at 0x7f49a8d0bf10>
request = <FixtureRequest for <Function test_all_models[full-inference]>>
capteesys = <_pytest.capture.CaptureFixture object at 0x7f49975e26d0>

    @pytest.mark.model_test
    @pytest.mark.no_auto_properties
    @pytest.mark.parametrize(
        "run_mode",
        [
            pytest.param(RunMode.INFERENCE, id="inference", marks=pytest.mark.inference),
            # pytest.param(RunMode.TRAINING, id="training", marks=pytest.mark.training),
        ],
    )
    @pytest.mark.parametrize(
        "op_by_op",
        [None],
        ids=["full"],  # When op-by-op flow is required/supported, add here.
    )
    # @pytest.mark.parametrize(
    #     "test_entry",
    #     test_entries,
    #     ids=create_test_id_generator(MODELS_ROOT),
    # )
    def test_all_models(
        run_mode, op_by_op, record_property, test_metadata, request, capteesys
    ):
    
        loader_path = '/localdev/hshah/tt-xla/third_party/tt_forge_models/qwen_2_5/casual_lm/pytorch/loader.py'
        # variant = ModelVariant.QWEN_3_8B # PCC: 0.78
        # variant = ModelVariant.QWEN_3_14B # PCC: 0.72
        variant = ModelVariant.QWEN_2_5_7B_INSTRUCT # Failure due to invalid reshape
        # variant = ModelVariant.QWEN_2_5_14B_INSTRUCT # Failure due to invalid reshape
        # variant = ModelVariant.MISTRAL_7B_INSTRUCT_V03 # Passed with high PCC: 0.998
        # variant = ModelVariant.MINISTRAL_8B # Passed with low PCC: 0.23
    
        # Ensure per-model requirements are installed, and roll back after the test
        with RequirementsManager.for_loader(loader_path):
    
            # Get the model loader and model info from desired model, variant.
            loader = ModelLoader(variant=variant)
            model_info = ModelLoader.get_model_info(variant=variant)
            print(f"Running {request.node.nodeid} - {model_info.name}", flush=True)
    
            succeeded = False
            try:
                # Only run the actual model test if not marked for skip. The record properties
                # function in finally block will always be called and handles the pytest.skip.
                if test_metadata.status != ModelTestStatus.NOT_SUPPORTED_SKIP:
                    tester = DynamicTorchModelTester(
                        run_mode,
                        loader=loader,
                        comparison_config=test_metadata.to_comparison_config(),
                    )
    
>                   tester.test()

tests/runner/test_models.py:78: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/infra/testers/single_chip/model/model_tester.py:123: in test
    self._test_inference()
tests/infra/testers/single_chip/model/model_tester.py:136: in _test_inference
    tt_res = self._run_on_tt_device(self._workload)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tests/infra/testers/single_chip/model/model_tester.py:146: in _run_on_tt_device
    return self._device_runner.run_on_tt_device(compiled_workload)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tests/infra/runners/device_runner.py:30: in run_on_tt_device
    return self.run_on_device(workload, DeviceType.TT, device_num)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tests/infra/runners/device_runner.py:40: in run_on_device
    return self._run_on_device(device_workload, device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tests/infra/runners/torch_device_runner.py:30: in _run_on_device
    return workload.execute()
           ^^^^^^^^^^^^^^^^^^
tests/infra/workloads/workload.py:67: in execute
    return self.model(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1749: in _wrapped_call_impl
    return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:655: in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:969: in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2/modeling_qwen2.py:703: in forward
    outputs: BaseModelOutputWithPast = self.model(
/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:969: in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2/modeling_qwen2.py:419: in forward
    causal_mask = self._update_causal_mask(
/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2/modeling_qwen2.py:419: in torch_dynamo_resume_in_forward_at_419
    causal_mask = self._update_causal_mask(
/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:838: in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tt_torch.backend.backend.XLAExecutor object at 0x7f454076bb10>
args = (tensor([[[[ 0.0000e+00, -3.3895e+38, -3.3895e+38,  ..., -3.3895e+38,
           -3.3895e+38, -3.3895e+38],
          ...        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38]], device='xla:0'))
output = (<[RuntimeError('Check failed: data()->tensor_data: ') raised in repr()] Tensor object at 0x7f430056e750>, <[RuntimeEr...f4300491d90>, <[RuntimeError('Check failed: data()->tensor_data: ') raised in repr()] Tensor object at 0x7f430050d850>)

    def __call__(self, *args):
    
        output = self.module(*args)
        # This tells torch-xla to cut the graph at only what is required to
        # compute all tensors in the `output` list.
>       torch_xla._XLAC._xla_sync_multi(list(output), self.devices, wait=False)
E       ValueError: Error code: 13

python_package/tt_torch/backend/backend.py:84: ValueError
=============================== warnings summary ===============================
venv/lib/python3.11/site-packages/pyparsing.py:108
  /localdev/hshah/tt-xla/venv/lib/python3.11/site-packages/pyparsing.py:108: DeprecationWarning: module 'sre_constants' is deprecated
    import sre_constants

<frozen importlib._bootstrap>:241
  <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute

<frozen importlib._bootstrap>:241
  <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute

tests/runner/test_models.py::test_all_models[full-inference]
  /localdev/hshah/tt-xla/tests/infra/connectors/torch_device_connector.py:29: DeprecationWarning: Use torch_xla.device instead
    xm.xla_device(device_num)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED tests/runner/test_models.py::test_all_models[full-inference] - ValueError: Error code: 13
================== 1 failed, 4 warnings in 196.76s (0:03:16) ===================
sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
