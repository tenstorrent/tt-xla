name: Test (call)

on:
  workflow_call:
    inputs:
      test_mark:
        description: 'Test mark to run'
        required: false
        default: 'push'
        type: string
      docker_image:
        description: 'Docker image to use for the build'
        required: true
        type: string
      run_id:
        description: 'Run ID to download artifacts from  (or else it will search)'
        required: false
        type: string
      codecov:
        description: 'Enable codecov upload'
        required: false
        type: boolean
      test_matrix:
        description: 'Test job matrix to use'
        required: false
        type: string
        default: |
          [
            { "runs-on": "n150",        "name": "run_jax",               "dir": "./tests/jax/single_chip",   "extra_test_marks": "not large" },
            { "runs-on": "n150",        "name": "run_torch",             "dir": "./tests/torch/single_chip"},
            { "runs-on": "n150",        "name": "run_large_jax_models",  "dir": "./tests/jax/single_chip",   "extra_test_marks": "large" },
            { "runs-on": "p150b",       "name": "run_jax",               "dir": "./tests/jax/single_chip",   "extra_test_marks": "not large" },
            { "runs-on": "p150b",       "name": "run_torch",             "dir": "./tests/torch/single_chip" },
            { "runs-on": "p150b",       "name": "run_large_jax_models",  "dir": "./tests/jax/single_chip",   "extra_test_marks": "large" },
            { "runs-on": "n300",        "name": "run_jax",               "dir": "./tests/jax/multi_chip/n300", "codecov": "true" },
            { "runs-on": "n300-llmbox", "name": "run_jax_4_devices",     "dir": "./tests/jax/multi_chip/llmbox/4_devices" },
            { "runs-on": "n300-llmbox", "name": "run_jax_8_devices",     "dir": "./tests/jax/multi_chip/llmbox/8_devices" }
          ]
      use-shared-runners:
        description: 'Use shared runners from Civ2'
        required: false
        default: false
        type: boolean

env:
  IRD_LF_CACHE: ${{ vars.IRD_LF_CACHE }}

jobs:

  # Run tests on TT hardware
  run-tests:
    timeout-minutes: 120
    strategy:
      fail-fast: false
      matrix:
        build: ${{ fromJson(inputs.test_matrix) }}

    runs-on: ${{ (inputs.use-shared-runners || matrix.build.use-shared-runners) && format('tt-ubuntu-2204-{0}-stable', matrix.build.runs-on) || fromJson(format('["{0}", "in-service"]', matrix.build.runs-on)) }}

    # Keep this name in sync with the fetch-job-id step
    name: "run-tests ${{ inputs.test_mark }} (${{ matrix.build.runs-on }}, ${{ matrix.build.name }}, ${{ matrix.build.test_group_id }})"

    container:
      image: ${{ (inputs.use-shared-runners || matrix.build.use-shared-runners) && format('harbor.ci.tenstorrent.net/{0}', inputs.docker_image) || inputs.docker_image }}
      options: --device /dev/tenstorrent
      volumes:
        - /dev/hugepages:/dev/hugepages
        - /dev/hugepages-1G:/dev/hugepages-1G
        - /etc/udev/rules.d:/etc/udev/rules.d
        - /lib/modules:/lib/modules
        - /opt/tt_metal_infra/provisioning/provisioning_env:/opt/tt_metal_infra/provisioning/provisioning_env
        - /mnt/dockercache:/mnt/dockercache

    steps:
    - name: Mark repo as safe for git
      run: |
        git config --global --add safe.directory /__w/tt-xla/tt-xla
        git config --global --add safe.directory /__w/tt-xla/tt-xla/third_party/tt_forge_models

    - uses: actions/checkout@v4
      with:
        submodules: recursive
        lfs: true

    - name: Fetch job id
      id: fetch-job-id
      uses: tenstorrent/tt-github-actions/.github/actions/job_id@main
      with:
        job_name: "run-tests ${{ inputs.test_mark }} (${{ matrix.build.runs-on }}, ${{ matrix.build.name }}, ${{ matrix.build.test_group_id }})"

    - name: Set reusable strings
      id: strings
      shell: bash
      env:
        JOB_ID: ${{ steps.fetch-job-id.outputs.job_id }}
      run: |
        echo "work-dir=$(pwd)" >> "$GITHUB_OUTPUT"
        echo "build-output-dir=$(pwd)/build" >> "$GITHUB_OUTPUT"
        echo "test_report_path=report_$JOB_ID.xml" >> "$GITHUB_OUTPUT"
        if [[ "${{ inputs.codecov }}" == "true" && "${{ matrix.build.codecov }}" == "true" ]]; then
          echo "do_codecov=true" >> "$GITHUB_OUTPUT"
          echo "build=codecov" >> "$GITHUB_OUTPUT"
        else
          echo "build=release" >> "$GITHUB_OUTPUT"
        fi

    - name: Download build artifacts
      if: steps.strings.outputs.do_codecov
      uses: tenstorrent/tt-forge/.github/actions/download-artifact@main
      with:
        name: build-artifacts
        path: build
        github_token: ${{ github.token }}

    - name: Download wheel
      if: ${{ inputs.run_id }}
      uses: tenstorrent/tt-forge/.github/actions/download-artifact@main
      with:
        name: xla-whl-${{ steps.strings.outputs.build }}
        run_id: ${{ inputs.run_id }}
        github_token: ${{ github.token }}

    - name: Find and download alternative wheel
      if: ${{ !inputs.run_id }}
      uses: dawidd6/action-download-artifact@v9
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        workflow_conclusion: success
        workflow_search: true
        workflow: on-push.yml
        name: xla-whl-codecov
        repo: tenstorrent/tt-xla
        check_artifacts: true
        search_artifacts: true

    - name: Install wheel
      shell: bash
      run: |
        source venv/activate
        pip install ${{ steps.strings.outputs.work-dir }}/pjrt_plugin_tt*.whl

    - name: Run tests
      env:
        HF_HOME: /mnt/dockercache/huggingface
        TEST_GROUP_CNT: ${{ matrix.build.test_group_cnt || 1}}
        TEST_GROUP_ID: ${{ matrix.build.test_group_id || 1}}
        GITHUB_TOKEN: ${{ secrets.GH_TOKEN }}
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
      shell: bash
      run: |
        source venv/activate
        # NOTE: Torch tests must be run in separate processes to avoid current issues with test isolation
        # See issue: https://github.com/tenstorrent/tt-xla/issues/795
        if [[ "${{ matrix.build.name }}" == "run_torch" || "${{ matrix.build.name }}" == "run_large_jax_models" ]]; then
          PYTEST_FORKED="--forked"
        else
          PYTEST_FORKED=""
        fi
        if [[ -n "${{ matrix.build.extra_test_marks }}" ]]; then
          MARKS="${{ inputs.test_mark }} and ${{ matrix.build.extra_test_marks }}"
        else
          MARKS="${{ inputs.test_mark }}"
        fi
        pytest $PYTEST_FORKED --log-memory -sv \
                ${{ matrix.build.dir }}  \
                -m "$MARKS" \
                --splits $TEST_GROUP_CNT \
                --group $TEST_GROUP_ID \
                --splitting-algorithm least_duration \
                --junitxml=${{ steps.strings.outputs.test_report_path }} \
                2>&1 | tee pytest.log

    - name: Upload Test Log
      uses: actions/upload-artifact@v4
      if: success() || failure()
      with:
        name: test-log-${{ matrix.build.runs-on }}-${{ inputs.test_mark }}-${{ steps.fetch-job-id.outputs.job_id }}
        path: pytest.log

    - name: Upload Test Report
      uses: actions/upload-artifact@v4
      if: success() || failure()
      with:
        name: test-reports-${{ matrix.build.runs-on }}-${{ inputs.test_mark }}-${{ steps.fetch-job-id.outputs.job_id }}
        path: ${{ steps.strings.outputs.test_report_path }}

    - name: Show Test Report
      continue-on-error: true
      uses: mikepenz/action-junit-report@v5
      if: success() || failure()
      with:
        report_paths: ${{ steps.strings.outputs.test_report_path }}
        check_name: TT-XLA Tests
        comment: true
        updateComment: true
        detailed_summary: true
        group_suite: true
        token: ${{ github.token }}

    - name: Prepare code coverage report
      if: steps.strings.outputs.do_codecov && (success() || failure())
      run: |
        lcov --directory build --capture --output-file coverage.info
        lcov --extract coverage.info '**/tt-xla/src/*' --output-file coverage.info
        sed -i 's|SF:/__w/tt-xla/tt-xla/src/|SF:src/|' coverage.info
        lcov --list coverage.info

    - name: Upload coverage reports to Codecov
      if: steps.strings.outputs.do_codecov && (success() || failure())
      uses: codecov/codecov-action@v5
      with:
        files: coverage.info
        disable_search: true
        token: ${{ secrets.CODECOV_TOKEN }}
