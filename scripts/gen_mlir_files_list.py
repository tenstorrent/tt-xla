#!/usr/bin/env python3
# SPDX-FileCopyrightText: (c) 2026 Tenstorrent AI ULC
#
# SPDX-License-Identifier: Apache-2.0
"""
Generate a MLIR_FILES list for test_serialize_and_builder_integration.

Usage:
    python scripts/gen_mlir_files_list.py <test_name> [<test_name> ...] [options]

Examples:
    python scripts/gen_mlir_files_list.py test_phi1_5
    python scripts/gen_mlir_files_list.py test_phi1_5 test_gemma_2_2b test_llama_3_2_1b
    python scripts/gen_mlir_files_list.py test_phi1_5 --no-builder-test
    python scripts/gen_mlir_files_list.py test_phi1_5 --no-run

The script (for each test, one at a time):
  1. Empties tt-xla/modules/irs/ to avoid stale files from previous runs.
  2. Runs the test from tests/benchmark/test_llms.py with --serialize.
  3. Scans modules/irs/ for generated MLIR files and writes mlir_files_generated.py.
  4. Immediately runs test_serialize_and_builder_integration against those files.
  5. Repeats from step 1 for the next test.
"""

import argparse
import os
import shutil
import subprocess
import sys
from pathlib import Path

MODULES_IRS_DIR = Path("modules/irs")
BENCHMARK_TEST_FILE = "tests/benchmark/test_llms.py"
BUILDER_TEST = (
    "tests/torch/test_torch_filecheck.py::test_serialize_and_builder_integration"
)
GENERATED_MLIR_LIST = Path("tests/torch/mlir_files_generated.py")

# Maps filename prefix to MLIR target name used in MLIR_FILES
PREFIX_TO_TARGET = {
    "shlo_compiler_": "stablehlo",
    "ttir_": "ttir",
    "ttnn_": "ttnn",
}

# More specific sub-prefixes of PREFIX_TO_TARGET entries that should be excluded
# (e.g. cleaned/frontend variants that aren't suitable for the builder test).
SKIP_PREFIXES = ("shlo_compiler_cleaned_",)


def classify_mlir_file(filename: str) -> str | None:
    """Return the MLIR target for a given filename, or None if it should be skipped.

    Check explicit skips first (they are more specific sub-prefixes of TARGET entries),
    then match against known targets. Anything unrecognised is silently dropped.
    """
    for skip in SKIP_PREFIXES:
        if filename.startswith(skip):
            return None
    for prefix, target in PREFIX_TO_TARGET.items():
        if filename.startswith(prefix):
            return target
    return None


def empty_modules_irs(modules_irs: Path) -> None:
    """Remove all files in modules/irs without deleting the directory itself."""
    if modules_irs.exists():
        for item in modules_irs.iterdir():
            if item.is_file():
                item.unlink()
            elif item.is_dir():
                shutil.rmtree(item)
        print(f"Emptied {modules_irs}/")
    else:
        modules_irs.mkdir(parents=True)
        print(f"Created {modules_irs}/")


def run_benchmark_test(test_name: str) -> int:
    """Run the benchmark test with --serialize and return the exit code."""
    cmd = [
        "pytest",
        "-sv",
        f"{BENCHMARK_TEST_FILE}::{test_name}",
        "--serialize",
    ]
    print(f"Running: {' '.join(cmd)}\n")
    result = subprocess.run(cmd)
    return result.returncode


def collect_mlir_files(modules_irs: Path) -> list[tuple[str, str]]:
    """Scan modules_irs and return a sorted list of (target, path) tuples."""
    entries = []
    for mlir_file in sorted(modules_irs.glob("*.mlir")):
        target = classify_mlir_file(mlir_file.name)
        if target is not None:
            entries.append((target, str(mlir_file)))
    return entries


def write_mlir_files_list(entries: list[tuple[str, str]], output_path: Path) -> None:
    """Write the MLIR_FILES list as an importable Python module."""
    lines = [
        "# AUTO-GENERATED by scripts/gen_mlir_files_list.py â€” do not edit by hand.\n",
        "# Re-run the script to regenerate this file.\n",
        "\n",
        "MLIR_FILES = [\n",
    ]
    for target, path in entries:
        lines.append(f'    ("{target}", "{path}"),\n')
    lines.append("]\n")

    output_path.write_text("".join(lines))
    print(f"Wrote {len(entries)} entries to {output_path}")


def _print_mlir_files(entries: list[tuple[str, str]]) -> None:
    print("\n# MLIR_FILES:\n")
    print("MLIR_FILES = [")
    for target, path in entries:
        print(f'    ("{target}", "{path}"),')
    print("]")


def run_builder_integration_test() -> int:
    """Run test_serialize_and_builder_integration and return the exit code."""
    cmd = ["pytest", "-sv", BUILDER_TEST]
    print(f"\nRunning: {' '.join(cmd)}\n")
    result = subprocess.run(cmd)
    return result.returncode


def main() -> int:
    parser = argparse.ArgumentParser(
        description="Generate MLIR_FILES list and run test_serialize_and_builder_integration."
    )
    parser.add_argument(
        "test_names",
        nargs="+",
        help="One or more test functions in tests/benchmark/test_llms.py (e.g. test_phi1_5 test_gemma_2_2b)",
    )
    parser.add_argument(
        "--no-run",
        action="store_true",
        default=False,
        help="Skip running benchmark tests; only collect files already in modules/irs/",
    )
    parser.add_argument(
        "--no-empty",
        action="store_true",
        default=False,
        help="Skip emptying modules/irs/ before each test run (useful with --no-run)",
    )
    parser.add_argument(
        "--no-builder-test",
        action="store_true",
        default=False,
        help="Skip running test_serialize_and_builder_integration after generating the list",
    )
    args = parser.parse_args()

    # Always operate relative to the tt-xla repo root
    repo_root = Path(__file__).resolve().parent.parent
    os.chdir(repo_root)

    failed_tests: list[str] = []
    builder_test_failures: list[str] = []

    if args.no_run:
        # Just collect whatever is already in modules/irs/ and run once
        entries = collect_mlir_files(MODULES_IRS_DIR)
        if not entries:
            print("No matching MLIR files found in modules/irs/.", file=sys.stderr)
            return 1
        write_mlir_files_list(entries, GENERATED_MLIR_LIST)
        _print_mlir_files(entries)
        if not args.no_builder_test:
            return run_builder_integration_test()
        return 0

    for i, test_name in enumerate(args.test_names):
        print(f"\n{'='*60}")
        print(f"[{i+1}/{len(args.test_names)}] {test_name}")
        print(f"{'='*60}\n")

        if not args.no_empty:
            empty_modules_irs(MODULES_IRS_DIR)

        exit_code = run_benchmark_test(test_name)
        if exit_code != 0:
            print(
                f"\nWarning: {test_name} exited with code {exit_code}. "
                "Collecting any MLIR files that were generated anyway.",
                file=sys.stderr,
            )
            failed_tests.append(test_name)

        entries = collect_mlir_files(MODULES_IRS_DIR)
        if not entries:
            print(
                f"Warning: no MLIR files found for {test_name}, skipping builder test.",
                file=sys.stderr,
            )
            continue

        print(f"Collected {len(entries)} MLIR files from {test_name}.")
        write_mlir_files_list(entries, GENERATED_MLIR_LIST)
        _print_mlir_files(entries)

        if not args.no_builder_test:
            builder_exit_code = run_builder_integration_test()
            if builder_exit_code != 0:
                builder_test_failures.append(test_name)

    if failed_tests:
        print(
            f"\nWarning: benchmark tests that did not pass: {', '.join(failed_tests)}",
            file=sys.stderr,
        )
    if builder_test_failures:
        print(
            f"\nWarning: builder integration test failed for: {', '.join(builder_test_failures)}",
            file=sys.stderr,
        )

    return 1 if (failed_tests or builder_test_failures) else 0


if __name__ == "__main__":
    sys.exit(main())
