#loc1 = loc("unknown|unknown|-1|unknownxla__device_data")
module @SyncTensorsGraph.4178 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x1>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.4178 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x1>]>} {
      func.func @main(%arg0: tensor<512x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___visual_projection_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg1: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_post_layernorm_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg2: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_post_layernorm_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg3: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_11_mlp_fc2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg4: tensor<768x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_11_mlp_fc2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg5: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_11_mlp_fc1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg6: tensor<3072x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_11_mlp_fc1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg7: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_11_layer_norm2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg8: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_11_layer_norm2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg9: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_11_self_attn_out_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg10: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_11_self_attn_out_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg11: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_11_self_attn_v_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg12: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_11_self_attn_v_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg13: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_11_layer_norm1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg14: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_11_layer_norm1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg15: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_10_mlp_fc2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg16: tensor<768x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_10_mlp_fc2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg17: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_10_mlp_fc1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg18: tensor<3072x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_10_mlp_fc1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg19: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_10_layer_norm2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg20: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_10_layer_norm2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg21: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_10_self_attn_out_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg22: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_10_self_attn_out_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg23: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_10_self_attn_v_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg24: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_10_self_attn_v_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg25: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_10_layer_norm1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg26: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_10_layer_norm1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg27: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_9_mlp_fc2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg28: tensor<768x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_9_mlp_fc2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg29: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_9_mlp_fc1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg30: tensor<3072x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_9_mlp_fc1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg31: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_9_layer_norm2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg32: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_9_layer_norm2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg33: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_9_self_attn_out_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg34: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_9_self_attn_out_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg35: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_9_self_attn_v_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg36: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_9_self_attn_v_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg37: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_9_layer_norm1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg38: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_9_layer_norm1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg39: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_8_mlp_fc2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg40: tensor<768x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_8_mlp_fc2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg41: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_8_mlp_fc1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg42: tensor<3072x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_8_mlp_fc1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg43: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_8_layer_norm2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg44: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_8_layer_norm2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg45: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_8_self_attn_out_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg46: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_8_self_attn_out_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg47: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_8_self_attn_v_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg48: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_8_self_attn_v_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg49: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_8_layer_norm1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg50: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_8_layer_norm1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg51: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_7_mlp_fc2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg52: tensor<768x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_7_mlp_fc2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg53: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_7_mlp_fc1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg54: tensor<3072x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_7_mlp_fc1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg55: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_7_layer_norm2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg56: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_7_layer_norm2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg57: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_7_self_attn_out_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg58: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_7_self_attn_out_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg59: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_7_self_attn_v_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg60: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_7_self_attn_v_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg61: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_7_layer_norm1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg62: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_7_layer_norm1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg63: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_6_mlp_fc2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg64: tensor<768x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_6_mlp_fc2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg65: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_6_mlp_fc1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg66: tensor<3072x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_6_mlp_fc1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg67: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_6_layer_norm2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg68: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_6_layer_norm2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg69: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_6_self_attn_out_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg70: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_6_self_attn_out_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg71: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_6_self_attn_v_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg72: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_6_self_attn_v_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg73: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_6_layer_norm1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg74: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_6_layer_norm1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg75: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_5_mlp_fc2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg76: tensor<768x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_5_mlp_fc2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg77: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_5_mlp_fc1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg78: tensor<3072x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_5_mlp_fc1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg79: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_5_layer_norm2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg80: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_5_layer_norm2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg81: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_5_self_attn_out_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg82: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_5_self_attn_out_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg83: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_5_self_attn_v_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg84: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_5_self_attn_v_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg85: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_5_layer_norm1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg86: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_5_layer_norm1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg87: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_4_mlp_fc2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg88: tensor<768x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_4_mlp_fc2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg89: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_4_mlp_fc1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg90: tensor<3072x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_4_mlp_fc1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg91: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_4_layer_norm2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg92: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_4_layer_norm2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg93: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_4_self_attn_out_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg94: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_4_self_attn_out_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg95: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_4_self_attn_v_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg96: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_4_self_attn_v_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg97: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_4_layer_norm1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg98: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_4_layer_norm1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg99: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_3_mlp_fc2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg100: tensor<768x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_3_mlp_fc2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg101: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_3_mlp_fc1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg102: tensor<3072x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_3_mlp_fc1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg103: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_3_layer_norm2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg104: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_3_layer_norm2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg105: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_3_self_attn_out_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg106: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_3_self_attn_out_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg107: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_3_self_attn_v_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg108: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_3_self_attn_v_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg109: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_3_layer_norm1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg110: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_3_layer_norm1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg111: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_2_mlp_fc2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg112: tensor<768x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_2_mlp_fc2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg113: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_2_mlp_fc1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg114: tensor<3072x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_2_mlp_fc1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg115: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_2_layer_norm2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg116: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_2_layer_norm2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg117: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_2_self_attn_out_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg118: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_2_self_attn_out_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg119: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_2_self_attn_v_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg120: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_2_self_attn_v_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg121: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_2_layer_norm1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg122: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_2_layer_norm1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg123: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_1_mlp_fc2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg124: tensor<768x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_1_mlp_fc2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg125: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_1_mlp_fc1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg126: tensor<3072x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_1_mlp_fc1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg127: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_1_layer_norm2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg128: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_1_layer_norm2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg129: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_1_self_attn_out_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg130: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_1_self_attn_out_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg131: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_1_self_attn_v_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg132: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_1_self_attn_v_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg133: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_1_layer_norm1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg134: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_1_layer_norm1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg135: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_0_mlp_fc2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg136: tensor<768x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_0_mlp_fc2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg137: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_0_mlp_fc1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg138: tensor<3072x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_0_mlp_fc1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg139: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_0_layer_norm2_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg140: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_0_layer_norm2_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg141: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_0_self_attn_out_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg142: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_0_self_attn_out_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg143: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_0_self_attn_v_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg144: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_0_self_attn_v_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg145: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_0_layer_norm1_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg146: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_0_layer_norm1_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg147: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_pre_layrnorm_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg148: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_pre_layrnorm_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg149: tensor<1x50xi64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_embeddings_position_ids"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg150: tensor<50x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_embeddings_position_embedding_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg151: tensor<768x3x32x32xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_embeddings_patch_embedding_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg152: tensor<2x3x224x224xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "args_0"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg153: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_embeddings_class_embedding"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg154: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_0_self_attn_k_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg155: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_0_self_attn_k_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg156: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_0_self_attn_q_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg157: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_0_self_attn_q_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg158: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_1_self_attn_k_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg159: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_1_self_attn_k_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg160: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_1_self_attn_q_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg161: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_1_self_attn_q_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg162: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_2_self_attn_k_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg163: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_2_self_attn_k_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg164: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_2_self_attn_q_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg165: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_2_self_attn_q_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg166: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_3_self_attn_k_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg167: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_3_self_attn_k_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg168: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_3_self_attn_q_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg169: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_3_self_attn_q_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg170: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_4_self_attn_k_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg171: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_4_self_attn_k_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg172: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_4_self_attn_q_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg173: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_4_self_attn_q_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg174: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_5_self_attn_k_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg175: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_5_self_attn_k_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg176: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_5_self_attn_q_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg177: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_5_self_attn_q_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg178: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_6_self_attn_k_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg179: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_6_self_attn_k_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg180: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_6_self_attn_q_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg181: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_6_self_attn_q_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg182: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_7_self_attn_k_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg183: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_7_self_attn_k_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg184: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_7_self_attn_q_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg185: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_7_self_attn_q_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg186: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_8_self_attn_k_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg187: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_8_self_attn_k_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg188: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_8_self_attn_q_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg189: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_8_self_attn_q_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg190: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_9_self_attn_k_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg191: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_9_self_attn_k_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg192: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_9_self_attn_q_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg193: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_9_self_attn_q_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg194: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_10_self_attn_k_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg195: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_10_self_attn_k_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg196: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_10_self_attn_q_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg197: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_10_self_attn_q_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg198: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_11_self_attn_k_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg199: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_11_self_attn_k_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg200: tensor<768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_11_self_attn_q_proj_bias"} loc("unknown|unknown|-1|unknownxla__device_data"), %arg201: tensor<768x768xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___vision_model_encoder_layers_11_self_attn_q_proj_weight"} loc("unknown|unknown|-1|unknownxla__device_data")) -> (tensor<2x512xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x50x768xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.constant"() <{value = dense<1.001360e-05> : tensor<2x1xbf16>}> : () -> tensor<2x1xbf16> loc(#loc)
        %1 = "ttir.constant"() <{value = dense<1.304630e-03> : tensor<2xbf16>}> : () -> tensor<2xbf16> loc(#loc)
        %2 = "ttir.constant"() <{value = dense<1.703130e+00> : tensor<2x50x3072xbf16>}> : () -> tensor<2x50x3072xbf16> loc(#loc)
        %3 = "ttir.constant"() <{value = dense<1.250000e-01> : tensor<2x12x50x50xbf16>}> : () -> tensor<2x12x50x50xbf16> loc(#loc)
        %4 = "ttir.constant"() <{value = dense<1.001360e-05> : tensor<2x50x1xbf16>}> : () -> tensor<2x50x1xbf16> loc(#loc)
        %5 = "ttir.constant"() <{value = dense<1.304630e-03> : tensor<2x50xbf16>}> : () -> tensor<2x50xbf16> loc(#loc)
        %6 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<f32>}> : () -> tensor<f32> loc(#loc)
        %7 = "ttir.constant"() <{value = dense<0xFF800000> : tensor<f32>}> : () -> tensor<f32> loc(#loc)
        %8 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<bf16>}> : () -> tensor<bf16> loc(#loc)
        %9 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %10 = "ttir.reshape"(%arg153, %9) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %11 = ttir.empty() : tensor<1x768xbf16> loc(#loc3)
        %12 = "ttir.reshape"(%10, %11) <{shape = [1 : i32, 768 : i32]}> : (tensor<1x1x768xbf16>, tensor<1x768xbf16>) -> tensor<1x768xbf16> loc(#loc3)
        %13 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc3)
        %14 = "ttir.reshape"(%12, %13) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<1x768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc3)
        %15 = ttir.empty() : tensor<2x1x768xbf16> loc(#loc3)
        %16 = "ttir.broadcast"(%14, %15) <{broadcast_dimensions = array<i64: 2, 1, 1>}> : (tensor<1x1x768xbf16>, tensor<2x1x768xbf16>) -> tensor<2x1x768xbf16> loc(#loc3)
        %17 = ttir.empty() : tensor<2x768x7x7xbf16> loc(#loc4)
        %18 = "ttir.convolution"(%arg152, %arg151, %17) <{batch_group_count = 1 : i64, convolution_layout = #ttir<convolution_layout input_batch = 0, input_feature = 1, input_spatial_dimensions = 2x3, kernel_output_feature = 0, kernel_input_feature = 1, kernel_spatial_dimensions = 2x3, output_batch = 0, output_feature = 1, output_spatial_dimensions = 2x3>, feature_group_count = 1 : i64, input_dilation = array<i64: 1, 1>, padding = array<i64: 0, 0, 0, 0>, weight_dilation = array<i64: 1, 1>, window_reversal = array<i1: false, false>, window_strides = array<i64: 32, 32>}> : (tensor<2x3x224x224xbf16>, tensor<768x3x32x32xbf16>, tensor<2x768x7x7xbf16>) -> tensor<2x768x7x7xbf16> loc(#loc4)
        %19 = ttir.empty() : tensor<2x768x49xbf16> loc(#loc5)
        %20 = "ttir.reshape"(%18, %19) <{shape = [2 : i32, 768 : i32, 49 : i32]}> : (tensor<2x768x7x7xbf16>, tensor<2x768x49xbf16>) -> tensor<2x768x49xbf16> loc(#loc5)
        %21 = ttir.empty() : tensor<2x49x768xbf16> loc(#loc6)
        %22 = "ttir.permute"(%20, %21) <{permutation = array<i64: 0, 2, 1>}> : (tensor<2x768x49xbf16>, tensor<2x49x768xbf16>) -> tensor<2x49x768xbf16> loc(#loc6)
        %23 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc7)
        %24 = "ttir.concat"(%16, %22, %23) <{dim = 1 : si32}> : (tensor<2x1x768xbf16>, tensor<2x49x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc7)
        %25 = ttir.empty() : tensor<1x50x768xbf16> loc(#loc2)
        %26 = "ttir.reshape"(%arg150, %25) <{shape = [1 : i32, 50 : i32, 768 : i32]}> : (tensor<50x768xbf16>, tensor<1x50x768xbf16>) -> tensor<1x50x768xbf16> loc(#loc2)
        %27 = ttir.empty() : tensor<50x768xbf16> loc(#loc2)
        %28 = "ttir.reshape"(%26, %27) <{shape = [50 : i32, 768 : i32]}> : (tensor<1x50x768xbf16>, tensor<50x768xbf16>) -> tensor<50x768xbf16> loc(#loc2)
        %29 = ttir.empty() : tensor<1x1x50xi64> loc(#loc2)
        %30 = "ttir.reshape"(%arg149, %29) <{shape = [1 : i32, 1 : i32, 50 : i32]}> : (tensor<1x50xi64>, tensor<1x1x50xi64>) -> tensor<1x1x50xi64> loc(#loc2)
        %31 = ttir.empty() : tensor<50xi64> loc(#loc8)
        %32 = "ttir.reshape"(%30, %31) <{shape = [50 : i32]}> : (tensor<1x1x50xi64>, tensor<50xi64>) -> tensor<50xi64> loc(#loc8)
        %33 = ttir.empty() : tensor<50xui32> loc(#loc9)
        %34 = "ttir.typecast"(%32, %33) <{conservative_folding = false}> : (tensor<50xi64>, tensor<50xui32>) -> tensor<50xui32> loc(#loc9)
        %35 = ttir.empty() : tensor<50x768xbf16> loc(#loc9)
        %36 = "ttir.gather"(%28, %34, %35) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 768>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<50x768xbf16>, tensor<50xui32>, tensor<50x768xbf16>) -> tensor<50x768xbf16> loc(#loc9)
        %37 = ttir.empty() : tensor<1x50x768xbf16> loc(#loc10)
        %38 = "ttir.reshape"(%36, %37) <{shape = [1 : i32, 50 : i32, 768 : i32]}> : (tensor<50x768xbf16>, tensor<1x50x768xbf16>) -> tensor<1x50x768xbf16> loc(#loc10)
        %39 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc10)
        %40 = "ttir.broadcast"(%38, %39) <{broadcast_dimensions = array<i64: 2, 1, 1>}> : (tensor<1x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc10)
        %41 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc10)
        %42 = "ttir.add"(%24, %40, %41) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc10)
        %43 = ttir.empty() : tensor<2x50xbf16> loc(#loc11)
        %44 = "ttir.sum"(%42, %43) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc11)
        %45 = ttir.empty() : tensor<2x50xbf16> loc(#loc11)
        %46 = "ttir.multiply"(%44, %5, %45) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc11)
        %47 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc12)
        %48 = "ttir.reshape"(%46, %47) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc12)
        %49 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc12)
        %50 = "ttir.broadcast"(%48, %49) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc12)
        %51 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc12)
        %52 = "ttir.subtract"(%42, %50, %51) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc12)
        %53 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc11)
        %54 = "ttir.multiply"(%52, %52, %53) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc11)
        %55 = ttir.empty() : tensor<2x50xbf16> loc(#loc11)
        %56 = "ttir.sum"(%54, %55) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc11)
        %57 = ttir.empty() : tensor<2x50xbf16> loc(#loc11)
        %58 = "ttir.multiply"(%56, %5, %57) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc11)
        %59 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc11)
        %60 = "ttir.reshape"(%58, %59) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc11)
        %61 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc13)
        %62 = "ttir.add"(%60, %4, %61) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc13)
        %63 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc14)
        %64 = "ttir.rsqrt"(%62, %63) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc14)
        %65 = ttir.empty() : tensor<2x50xbf16> loc(#loc15)
        %66 = "ttir.reshape"(%64, %65) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc15)
        %67 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc15)
        %68 = "ttir.reshape"(%66, %67) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc15)
        %69 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc15)
        %70 = "ttir.broadcast"(%68, %69) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc15)
        %71 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc15)
        %72 = "ttir.multiply"(%52, %70, %71) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc15)
        %73 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %74 = "ttir.reshape"(%arg148, %73) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %75 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %76 = "ttir.reshape"(%74, %75) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %77 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc15)
        %78 = "ttir.reshape"(%76, %77) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc15)
        %79 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc15)
        %80 = "ttir.broadcast"(%78, %79) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc15)
        %81 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc15)
        %82 = "ttir.multiply"(%72, %80, %81) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc15)
        %83 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %84 = "ttir.reshape"(%arg147, %83) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %85 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %86 = "ttir.reshape"(%84, %85) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %87 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc13)
        %88 = "ttir.reshape"(%86, %87) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc13)
        %89 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc13)
        %90 = "ttir.broadcast"(%88, %89) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc13)
        %91 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc13)
        %92 = "ttir.add"(%82, %90, %91) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc13)
        %93 = ttir.empty() : tensor<2x50xbf16> loc(#loc16)
        %94 = "ttir.sum"(%92, %93) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc16)
        %95 = ttir.empty() : tensor<2x50xbf16> loc(#loc16)
        %96 = "ttir.multiply"(%94, %5, %95) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc16)
        %97 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc17)
        %98 = "ttir.reshape"(%96, %97) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc17)
        %99 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc17)
        %100 = "ttir.broadcast"(%98, %99) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc17)
        %101 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc17)
        %102 = "ttir.subtract"(%92, %100, %101) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc17)
        %103 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc16)
        %104 = "ttir.multiply"(%102, %102, %103) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc16)
        %105 = ttir.empty() : tensor<2x50xbf16> loc(#loc16)
        %106 = "ttir.sum"(%104, %105) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc16)
        %107 = ttir.empty() : tensor<2x50xbf16> loc(#loc16)
        %108 = "ttir.multiply"(%106, %5, %107) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc16)
        %109 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc16)
        %110 = "ttir.reshape"(%108, %109) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc16)
        %111 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc18)
        %112 = "ttir.add"(%110, %4, %111) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc18)
        %113 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc19)
        %114 = "ttir.rsqrt"(%112, %113) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc19)
        %115 = ttir.empty() : tensor<2x50xbf16> loc(#loc20)
        %116 = "ttir.reshape"(%114, %115) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc20)
        %117 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc20)
        %118 = "ttir.reshape"(%116, %117) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc20)
        %119 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc20)
        %120 = "ttir.broadcast"(%118, %119) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc20)
        %121 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc20)
        %122 = "ttir.multiply"(%102, %120, %121) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc20)
        %123 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %124 = "ttir.reshape"(%arg146, %123) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %125 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %126 = "ttir.reshape"(%124, %125) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %127 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc20)
        %128 = "ttir.reshape"(%126, %127) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc20)
        %129 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc20)
        %130 = "ttir.broadcast"(%128, %129) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc20)
        %131 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc20)
        %132 = "ttir.multiply"(%122, %130, %131) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc20)
        %133 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %134 = "ttir.reshape"(%arg145, %133) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %135 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %136 = "ttir.reshape"(%134, %135) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %137 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc18)
        %138 = "ttir.reshape"(%136, %137) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc18)
        %139 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc18)
        %140 = "ttir.broadcast"(%138, %139) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc18)
        %141 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc18)
        %142 = "ttir.add"(%132, %140, %141) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc18)
        %143 = ttir.empty() : tensor<100x768xbf16> loc(#loc21)
        %144 = "ttir.reshape"(%142, %143) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc21)
        %145 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %146 = "ttir.reshape"(%arg157, %145) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %147 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %148 = "ttir.reshape"(%146, %147) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %149 = ttir.empty() : tensor<768x768xbf16> loc(#loc22)
        %150 = "ttir.permute"(%148, %149) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc22)
        %151 = "ttir.dot_general"(%144, %150) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc23)
        %152 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc21)
        %153 = "ttir.reshape"(%151, %152) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc21)
        %154 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %155 = "ttir.reshape"(%arg156, %154) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %156 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %157 = "ttir.reshape"(%155, %156) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %158 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc24)
        %159 = "ttir.reshape"(%157, %158) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc24)
        %160 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc24)
        %161 = "ttir.broadcast"(%159, %160) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc24)
        %162 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc24)
        %163 = "ttir.add"(%153, %161, %162) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc24)
        %164 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc25)
        %165 = "ttir.reshape"(%163, %164) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc25)
        %166 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc26)
        %167 = "ttir.permute"(%165, %166) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc26)
        %168 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc27)
        %169 = "ttir.reshape"(%167, %168) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc27)
        %170 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %171 = "ttir.reshape"(%arg155, %170) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %172 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %173 = "ttir.reshape"(%171, %172) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %174 = ttir.empty() : tensor<768x768xbf16> loc(#loc28)
        %175 = "ttir.permute"(%173, %174) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc28)
        %176 = "ttir.dot_general"(%144, %175) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc29)
        %177 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc30)
        %178 = "ttir.reshape"(%176, %177) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc30)
        %179 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %180 = "ttir.reshape"(%arg154, %179) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %181 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %182 = "ttir.reshape"(%180, %181) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %183 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc31)
        %184 = "ttir.reshape"(%182, %183) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc31)
        %185 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc31)
        %186 = "ttir.broadcast"(%184, %185) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc31)
        %187 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc31)
        %188 = "ttir.add"(%178, %186, %187) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc31)
        %189 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc32)
        %190 = "ttir.reshape"(%188, %189) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc32)
        %191 = ttir.empty() : tensor<2x12x64x50xbf16> loc(#loc33)
        %192 = "ttir.permute"(%190, %191) <{permutation = array<i64: 0, 2, 3, 1>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x64x50xbf16>) -> tensor<2x12x64x50xbf16> loc(#loc33)
        %193 = ttir.empty() : tensor<24x64x50xbf16> loc(#loc27)
        %194 = "ttir.reshape"(%192, %193) <{shape = [24 : i32, 64 : i32, 50 : i32]}> : (tensor<2x12x64x50xbf16>, tensor<24x64x50xbf16>) -> tensor<24x64x50xbf16> loc(#loc27)
        %195 = "ttir.dot_general"(%169, %194) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x64xbf16>, tensor<24x64x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc34)
        %196 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc27)
        %197 = "ttir.reshape"(%195, %196) <{shape = [2 : i32, 12 : i32, 50 : i32, 50 : i32]}> : (tensor<24x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc27)
        %198 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc35)
        %199 = "ttir.multiply"(%197, %3, %198) : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc35)
        %200 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc36)
        %201 = "ttir.typecast"(%199, %200) <{conservative_folding = false}> : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc36)
        %202 = ttir.empty() : tensor<2x12x50xf32> loc(#loc37)
        %203 = "ttir.max"(%201, %202) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc37)
        %204 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc37)
        %205 = "ttir.reshape"(%203, %204) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc37)
        %206 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc37)
        %207 = "ttir.broadcast"(%205, %206) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc37)
        %208 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc37)
        %209 = "ttir.subtract"(%201, %207, %208) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc37)
        %210 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc37)
        %211 = "ttir.exp"(%209, %210) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc37)
        %212 = ttir.empty() : tensor<2x12x50xf32> loc(#loc37)
        %213 = "ttir.sum"(%211, %212) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc37)
        %214 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc37)
        %215 = "ttir.reshape"(%213, %214) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc37)
        %216 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc37)
        %217 = "ttir.broadcast"(%215, %216) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc37)
        %218 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc37)
        %219 = "ttir.div"(%211, %217, %218) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc37)
        %220 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc38)
        %221 = "ttir.typecast"(%219, %220) <{conservative_folding = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc38)
        %222 = ttir.empty() : tensor<24x50x50xbf16> loc(#loc39)
        %223 = "ttir.reshape"(%221, %222) <{shape = [24 : i32, 50 : i32, 50 : i32]}> : (tensor<2x12x50x50xbf16>, tensor<24x50x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc39)
        %224 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %225 = "ttir.reshape"(%arg144, %224) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %226 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %227 = "ttir.reshape"(%225, %226) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %228 = ttir.empty() : tensor<768x768xbf16> loc(#loc40)
        %229 = "ttir.permute"(%227, %228) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc40)
        %230 = "ttir.dot_general"(%144, %229) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc41)
        %231 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc42)
        %232 = "ttir.reshape"(%230, %231) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc42)
        %233 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %234 = "ttir.reshape"(%arg143, %233) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %235 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %236 = "ttir.reshape"(%234, %235) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %237 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc43)
        %238 = "ttir.reshape"(%236, %237) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc43)
        %239 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc43)
        %240 = "ttir.broadcast"(%238, %239) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc43)
        %241 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc43)
        %242 = "ttir.add"(%232, %240, %241) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc43)
        %243 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc44)
        %244 = "ttir.reshape"(%242, %243) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc44)
        %245 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc45)
        %246 = "ttir.permute"(%244, %245) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc45)
        %247 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc39)
        %248 = "ttir.reshape"(%246, %247) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc39)
        %249 = "ttir.dot_general"(%223, %248) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x50xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc46)
        %250 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc39)
        %251 = "ttir.reshape"(%249, %250) <{shape = [2 : i32, 12 : i32, 50 : i32, 64 : i32]}> : (tensor<24x50x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc39)
        %252 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc47)
        %253 = "ttir.permute"(%251, %252) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x12x50x64xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc47)
        %254 = ttir.empty() : tensor<100x768xbf16> loc(#loc48)
        %255 = "ttir.reshape"(%253, %254) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x12x64xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc48)
        %256 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %257 = "ttir.reshape"(%arg142, %256) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %258 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %259 = "ttir.reshape"(%257, %258) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %260 = ttir.empty() : tensor<768x768xbf16> loc(#loc49)
        %261 = "ttir.permute"(%259, %260) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc49)
        %262 = "ttir.dot_general"(%255, %261) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc50)
        %263 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc48)
        %264 = "ttir.reshape"(%262, %263) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc48)
        %265 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %266 = "ttir.reshape"(%arg141, %265) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %267 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %268 = "ttir.reshape"(%266, %267) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %269 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc51)
        %270 = "ttir.reshape"(%268, %269) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc51)
        %271 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc51)
        %272 = "ttir.broadcast"(%270, %271) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc51)
        %273 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc51)
        %274 = "ttir.add"(%264, %272, %273) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc51)
        %275 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc52)
        %276 = "ttir.add"(%92, %274, %275) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc52)
        %277 = ttir.empty() : tensor<2x50xbf16> loc(#loc53)
        %278 = "ttir.sum"(%276, %277) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc53)
        %279 = ttir.empty() : tensor<2x50xbf16> loc(#loc53)
        %280 = "ttir.multiply"(%278, %5, %279) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc53)
        %281 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc54)
        %282 = "ttir.reshape"(%280, %281) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc54)
        %283 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc54)
        %284 = "ttir.broadcast"(%282, %283) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc54)
        %285 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc54)
        %286 = "ttir.subtract"(%276, %284, %285) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc54)
        %287 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc53)
        %288 = "ttir.multiply"(%286, %286, %287) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc53)
        %289 = ttir.empty() : tensor<2x50xbf16> loc(#loc53)
        %290 = "ttir.sum"(%288, %289) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc53)
        %291 = ttir.empty() : tensor<2x50xbf16> loc(#loc53)
        %292 = "ttir.multiply"(%290, %5, %291) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc53)
        %293 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc53)
        %294 = "ttir.reshape"(%292, %293) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc53)
        %295 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc55)
        %296 = "ttir.add"(%294, %4, %295) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc55)
        %297 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc56)
        %298 = "ttir.rsqrt"(%296, %297) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc56)
        %299 = ttir.empty() : tensor<2x50xbf16> loc(#loc57)
        %300 = "ttir.reshape"(%298, %299) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc57)
        %301 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc57)
        %302 = "ttir.reshape"(%300, %301) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc57)
        %303 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc57)
        %304 = "ttir.broadcast"(%302, %303) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc57)
        %305 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc57)
        %306 = "ttir.multiply"(%286, %304, %305) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc57)
        %307 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %308 = "ttir.reshape"(%arg140, %307) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %309 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %310 = "ttir.reshape"(%308, %309) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %311 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc57)
        %312 = "ttir.reshape"(%310, %311) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc57)
        %313 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc57)
        %314 = "ttir.broadcast"(%312, %313) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc57)
        %315 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc57)
        %316 = "ttir.multiply"(%306, %314, %315) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc57)
        %317 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %318 = "ttir.reshape"(%arg139, %317) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %319 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %320 = "ttir.reshape"(%318, %319) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %321 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc55)
        %322 = "ttir.reshape"(%320, %321) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc55)
        %323 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc55)
        %324 = "ttir.broadcast"(%322, %323) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc55)
        %325 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc55)
        %326 = "ttir.add"(%316, %324, %325) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc55)
        %327 = ttir.empty() : tensor<100x768xbf16> loc(#loc58)
        %328 = "ttir.reshape"(%326, %327) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc58)
        %329 = ttir.empty() : tensor<1x3072x768xbf16> loc(#loc2)
        %330 = "ttir.reshape"(%arg138, %329) <{shape = [1 : i32, 3072 : i32, 768 : i32]}> : (tensor<3072x768xbf16>, tensor<1x3072x768xbf16>) -> tensor<1x3072x768xbf16> loc(#loc2)
        %331 = ttir.empty() : tensor<3072x768xbf16> loc(#loc2)
        %332 = "ttir.reshape"(%330, %331) <{shape = [3072 : i32, 768 : i32]}> : (tensor<1x3072x768xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc2)
        %333 = ttir.empty() : tensor<768x3072xbf16> loc(#loc59)
        %334 = "ttir.permute"(%332, %333) <{permutation = array<i64: 1, 0>}> : (tensor<3072x768xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc59)
        %335 = "ttir.dot_general"(%328, %334) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc60)
        %336 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc58)
        %337 = "ttir.reshape"(%335, %336) <{shape = [2 : i32, 50 : i32, 3072 : i32]}> : (tensor<100x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc58)
        %338 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc2)
        %339 = "ttir.reshape"(%arg137, %338) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc2)
        %340 = ttir.empty() : tensor<3072xbf16> loc(#loc2)
        %341 = "ttir.reshape"(%339, %340) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc2)
        %342 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc61)
        %343 = "ttir.reshape"(%341, %342) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc61)
        %344 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc61)
        %345 = "ttir.broadcast"(%343, %344) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc61)
        %346 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc61)
        %347 = "ttir.add"(%337, %345, %346) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc61)
        %348 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc62)
        %349 = "ttir.multiply"(%347, %2, %348) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc62)
        %350 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc63)
        %351 = "ttir.sigmoid"(%349, %350) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc63)
        %352 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc62)
        %353 = "ttir.multiply"(%347, %351, %352) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc62)
        %354 = ttir.empty() : tensor<100x3072xbf16> loc(#loc64)
        %355 = "ttir.reshape"(%353, %354) <{shape = [100 : i32, 3072 : i32]}> : (tensor<2x50x3072xbf16>, tensor<100x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc64)
        %356 = ttir.empty() : tensor<1x768x3072xbf16> loc(#loc2)
        %357 = "ttir.reshape"(%arg136, %356) <{shape = [1 : i32, 768 : i32, 3072 : i32]}> : (tensor<768x3072xbf16>, tensor<1x768x3072xbf16>) -> tensor<1x768x3072xbf16> loc(#loc2)
        %358 = ttir.empty() : tensor<768x3072xbf16> loc(#loc2)
        %359 = "ttir.reshape"(%357, %358) <{shape = [768 : i32, 3072 : i32]}> : (tensor<1x768x3072xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc2)
        %360 = ttir.empty() : tensor<3072x768xbf16> loc(#loc65)
        %361 = "ttir.permute"(%359, %360) <{permutation = array<i64: 1, 0>}> : (tensor<768x3072xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc65)
        %362 = "ttir.dot_general"(%355, %361) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x3072xbf16>, tensor<3072x768xbf16>) -> tensor<100x768xbf16> loc(#loc66)
        %363 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc64)
        %364 = "ttir.reshape"(%362, %363) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc64)
        %365 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %366 = "ttir.reshape"(%arg135, %365) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %367 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %368 = "ttir.reshape"(%366, %367) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %369 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc67)
        %370 = "ttir.reshape"(%368, %369) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc67)
        %371 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc67)
        %372 = "ttir.broadcast"(%370, %371) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc67)
        %373 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc67)
        %374 = "ttir.add"(%364, %372, %373) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc67)
        %375 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc68)
        %376 = "ttir.add"(%276, %374, %375) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc68)
        %377 = ttir.empty() : tensor<2x50xbf16> loc(#loc69)
        %378 = "ttir.sum"(%376, %377) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc69)
        %379 = ttir.empty() : tensor<2x50xbf16> loc(#loc69)
        %380 = "ttir.multiply"(%378, %5, %379) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc69)
        %381 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc70)
        %382 = "ttir.reshape"(%380, %381) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc70)
        %383 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc70)
        %384 = "ttir.broadcast"(%382, %383) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc70)
        %385 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc70)
        %386 = "ttir.subtract"(%376, %384, %385) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc70)
        %387 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc69)
        %388 = "ttir.multiply"(%386, %386, %387) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc69)
        %389 = ttir.empty() : tensor<2x50xbf16> loc(#loc69)
        %390 = "ttir.sum"(%388, %389) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc69)
        %391 = ttir.empty() : tensor<2x50xbf16> loc(#loc69)
        %392 = "ttir.multiply"(%390, %5, %391) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc69)
        %393 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc69)
        %394 = "ttir.reshape"(%392, %393) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc69)
        %395 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc71)
        %396 = "ttir.add"(%394, %4, %395) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc71)
        %397 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc72)
        %398 = "ttir.rsqrt"(%396, %397) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc72)
        %399 = ttir.empty() : tensor<2x50xbf16> loc(#loc73)
        %400 = "ttir.reshape"(%398, %399) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc73)
        %401 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc73)
        %402 = "ttir.reshape"(%400, %401) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc73)
        %403 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc73)
        %404 = "ttir.broadcast"(%402, %403) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc73)
        %405 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc73)
        %406 = "ttir.multiply"(%386, %404, %405) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc73)
        %407 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %408 = "ttir.reshape"(%arg134, %407) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %409 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %410 = "ttir.reshape"(%408, %409) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %411 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc73)
        %412 = "ttir.reshape"(%410, %411) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc73)
        %413 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc73)
        %414 = "ttir.broadcast"(%412, %413) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc73)
        %415 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc73)
        %416 = "ttir.multiply"(%406, %414, %415) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc73)
        %417 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %418 = "ttir.reshape"(%arg133, %417) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %419 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %420 = "ttir.reshape"(%418, %419) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %421 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc71)
        %422 = "ttir.reshape"(%420, %421) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc71)
        %423 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc71)
        %424 = "ttir.broadcast"(%422, %423) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc71)
        %425 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc71)
        %426 = "ttir.add"(%416, %424, %425) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc71)
        %427 = ttir.empty() : tensor<100x768xbf16> loc(#loc74)
        %428 = "ttir.reshape"(%426, %427) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc74)
        %429 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %430 = "ttir.reshape"(%arg161, %429) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %431 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %432 = "ttir.reshape"(%430, %431) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %433 = ttir.empty() : tensor<768x768xbf16> loc(#loc75)
        %434 = "ttir.permute"(%432, %433) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc75)
        %435 = "ttir.dot_general"(%428, %434) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc76)
        %436 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc74)
        %437 = "ttir.reshape"(%435, %436) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc74)
        %438 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %439 = "ttir.reshape"(%arg160, %438) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %440 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %441 = "ttir.reshape"(%439, %440) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %442 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc77)
        %443 = "ttir.reshape"(%441, %442) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc77)
        %444 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc77)
        %445 = "ttir.broadcast"(%443, %444) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc77)
        %446 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc77)
        %447 = "ttir.add"(%437, %445, %446) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc77)
        %448 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc78)
        %449 = "ttir.reshape"(%447, %448) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc78)
        %450 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc79)
        %451 = "ttir.permute"(%449, %450) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc79)
        %452 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc80)
        %453 = "ttir.reshape"(%451, %452) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc80)
        %454 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %455 = "ttir.reshape"(%arg159, %454) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %456 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %457 = "ttir.reshape"(%455, %456) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %458 = ttir.empty() : tensor<768x768xbf16> loc(#loc81)
        %459 = "ttir.permute"(%457, %458) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc81)
        %460 = "ttir.dot_general"(%428, %459) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc82)
        %461 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc83)
        %462 = "ttir.reshape"(%460, %461) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc83)
        %463 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %464 = "ttir.reshape"(%arg158, %463) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %465 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %466 = "ttir.reshape"(%464, %465) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %467 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc84)
        %468 = "ttir.reshape"(%466, %467) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc84)
        %469 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc84)
        %470 = "ttir.broadcast"(%468, %469) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc84)
        %471 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc84)
        %472 = "ttir.add"(%462, %470, %471) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc84)
        %473 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc85)
        %474 = "ttir.reshape"(%472, %473) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc85)
        %475 = ttir.empty() : tensor<2x12x64x50xbf16> loc(#loc86)
        %476 = "ttir.permute"(%474, %475) <{permutation = array<i64: 0, 2, 3, 1>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x64x50xbf16>) -> tensor<2x12x64x50xbf16> loc(#loc86)
        %477 = ttir.empty() : tensor<24x64x50xbf16> loc(#loc80)
        %478 = "ttir.reshape"(%476, %477) <{shape = [24 : i32, 64 : i32, 50 : i32]}> : (tensor<2x12x64x50xbf16>, tensor<24x64x50xbf16>) -> tensor<24x64x50xbf16> loc(#loc80)
        %479 = "ttir.dot_general"(%453, %478) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x64xbf16>, tensor<24x64x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc87)
        %480 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc80)
        %481 = "ttir.reshape"(%479, %480) <{shape = [2 : i32, 12 : i32, 50 : i32, 50 : i32]}> : (tensor<24x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc80)
        %482 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc88)
        %483 = "ttir.multiply"(%481, %3, %482) : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc88)
        %484 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc89)
        %485 = "ttir.typecast"(%483, %484) <{conservative_folding = false}> : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc89)
        %486 = ttir.empty() : tensor<2x12x50xf32> loc(#loc90)
        %487 = "ttir.max"(%485, %486) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc90)
        %488 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc90)
        %489 = "ttir.reshape"(%487, %488) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc90)
        %490 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc90)
        %491 = "ttir.broadcast"(%489, %490) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc90)
        %492 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc90)
        %493 = "ttir.subtract"(%485, %491, %492) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc90)
        %494 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc90)
        %495 = "ttir.exp"(%493, %494) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc90)
        %496 = ttir.empty() : tensor<2x12x50xf32> loc(#loc90)
        %497 = "ttir.sum"(%495, %496) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc90)
        %498 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc90)
        %499 = "ttir.reshape"(%497, %498) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc90)
        %500 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc90)
        %501 = "ttir.broadcast"(%499, %500) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc90)
        %502 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc90)
        %503 = "ttir.div"(%495, %501, %502) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc90)
        %504 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc91)
        %505 = "ttir.typecast"(%503, %504) <{conservative_folding = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc91)
        %506 = ttir.empty() : tensor<24x50x50xbf16> loc(#loc92)
        %507 = "ttir.reshape"(%505, %506) <{shape = [24 : i32, 50 : i32, 50 : i32]}> : (tensor<2x12x50x50xbf16>, tensor<24x50x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc92)
        %508 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %509 = "ttir.reshape"(%arg132, %508) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %510 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %511 = "ttir.reshape"(%509, %510) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %512 = ttir.empty() : tensor<768x768xbf16> loc(#loc93)
        %513 = "ttir.permute"(%511, %512) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc93)
        %514 = "ttir.dot_general"(%428, %513) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc94)
        %515 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc95)
        %516 = "ttir.reshape"(%514, %515) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc95)
        %517 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %518 = "ttir.reshape"(%arg131, %517) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %519 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %520 = "ttir.reshape"(%518, %519) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %521 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc96)
        %522 = "ttir.reshape"(%520, %521) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc96)
        %523 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc96)
        %524 = "ttir.broadcast"(%522, %523) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc96)
        %525 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc96)
        %526 = "ttir.add"(%516, %524, %525) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc96)
        %527 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc97)
        %528 = "ttir.reshape"(%526, %527) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc97)
        %529 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc98)
        %530 = "ttir.permute"(%528, %529) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc98)
        %531 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc92)
        %532 = "ttir.reshape"(%530, %531) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc92)
        %533 = "ttir.dot_general"(%507, %532) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x50xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc99)
        %534 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc92)
        %535 = "ttir.reshape"(%533, %534) <{shape = [2 : i32, 12 : i32, 50 : i32, 64 : i32]}> : (tensor<24x50x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc92)
        %536 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc100)
        %537 = "ttir.permute"(%535, %536) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x12x50x64xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc100)
        %538 = ttir.empty() : tensor<100x768xbf16> loc(#loc101)
        %539 = "ttir.reshape"(%537, %538) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x12x64xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc101)
        %540 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %541 = "ttir.reshape"(%arg130, %540) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %542 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %543 = "ttir.reshape"(%541, %542) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %544 = ttir.empty() : tensor<768x768xbf16> loc(#loc102)
        %545 = "ttir.permute"(%543, %544) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc102)
        %546 = "ttir.dot_general"(%539, %545) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc103)
        %547 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc101)
        %548 = "ttir.reshape"(%546, %547) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc101)
        %549 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %550 = "ttir.reshape"(%arg129, %549) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %551 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %552 = "ttir.reshape"(%550, %551) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %553 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc104)
        %554 = "ttir.reshape"(%552, %553) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc104)
        %555 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc104)
        %556 = "ttir.broadcast"(%554, %555) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc104)
        %557 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc104)
        %558 = "ttir.add"(%548, %556, %557) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc104)
        %559 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc105)
        %560 = "ttir.add"(%376, %558, %559) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc105)
        %561 = ttir.empty() : tensor<2x50xbf16> loc(#loc106)
        %562 = "ttir.sum"(%560, %561) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc106)
        %563 = ttir.empty() : tensor<2x50xbf16> loc(#loc106)
        %564 = "ttir.multiply"(%562, %5, %563) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc106)
        %565 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc107)
        %566 = "ttir.reshape"(%564, %565) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc107)
        %567 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc107)
        %568 = "ttir.broadcast"(%566, %567) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc107)
        %569 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc107)
        %570 = "ttir.subtract"(%560, %568, %569) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc107)
        %571 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc106)
        %572 = "ttir.multiply"(%570, %570, %571) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc106)
        %573 = ttir.empty() : tensor<2x50xbf16> loc(#loc106)
        %574 = "ttir.sum"(%572, %573) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc106)
        %575 = ttir.empty() : tensor<2x50xbf16> loc(#loc106)
        %576 = "ttir.multiply"(%574, %5, %575) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc106)
        %577 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc106)
        %578 = "ttir.reshape"(%576, %577) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc106)
        %579 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc108)
        %580 = "ttir.add"(%578, %4, %579) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc108)
        %581 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc109)
        %582 = "ttir.rsqrt"(%580, %581) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc109)
        %583 = ttir.empty() : tensor<2x50xbf16> loc(#loc110)
        %584 = "ttir.reshape"(%582, %583) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc110)
        %585 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc110)
        %586 = "ttir.reshape"(%584, %585) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc110)
        %587 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc110)
        %588 = "ttir.broadcast"(%586, %587) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc110)
        %589 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc110)
        %590 = "ttir.multiply"(%570, %588, %589) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc110)
        %591 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %592 = "ttir.reshape"(%arg128, %591) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %593 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %594 = "ttir.reshape"(%592, %593) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %595 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc110)
        %596 = "ttir.reshape"(%594, %595) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc110)
        %597 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc110)
        %598 = "ttir.broadcast"(%596, %597) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc110)
        %599 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc110)
        %600 = "ttir.multiply"(%590, %598, %599) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc110)
        %601 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %602 = "ttir.reshape"(%arg127, %601) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %603 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %604 = "ttir.reshape"(%602, %603) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %605 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc108)
        %606 = "ttir.reshape"(%604, %605) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc108)
        %607 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc108)
        %608 = "ttir.broadcast"(%606, %607) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc108)
        %609 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc108)
        %610 = "ttir.add"(%600, %608, %609) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc108)
        %611 = ttir.empty() : tensor<100x768xbf16> loc(#loc111)
        %612 = "ttir.reshape"(%610, %611) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc111)
        %613 = ttir.empty() : tensor<1x3072x768xbf16> loc(#loc2)
        %614 = "ttir.reshape"(%arg126, %613) <{shape = [1 : i32, 3072 : i32, 768 : i32]}> : (tensor<3072x768xbf16>, tensor<1x3072x768xbf16>) -> tensor<1x3072x768xbf16> loc(#loc2)
        %615 = ttir.empty() : tensor<3072x768xbf16> loc(#loc2)
        %616 = "ttir.reshape"(%614, %615) <{shape = [3072 : i32, 768 : i32]}> : (tensor<1x3072x768xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc2)
        %617 = ttir.empty() : tensor<768x3072xbf16> loc(#loc112)
        %618 = "ttir.permute"(%616, %617) <{permutation = array<i64: 1, 0>}> : (tensor<3072x768xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc112)
        %619 = "ttir.dot_general"(%612, %618) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc113)
        %620 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc111)
        %621 = "ttir.reshape"(%619, %620) <{shape = [2 : i32, 50 : i32, 3072 : i32]}> : (tensor<100x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc111)
        %622 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc2)
        %623 = "ttir.reshape"(%arg125, %622) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc2)
        %624 = ttir.empty() : tensor<3072xbf16> loc(#loc2)
        %625 = "ttir.reshape"(%623, %624) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc2)
        %626 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc114)
        %627 = "ttir.reshape"(%625, %626) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc114)
        %628 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc114)
        %629 = "ttir.broadcast"(%627, %628) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc114)
        %630 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc114)
        %631 = "ttir.add"(%621, %629, %630) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc114)
        %632 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc115)
        %633 = "ttir.multiply"(%631, %2, %632) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc115)
        %634 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc116)
        %635 = "ttir.sigmoid"(%633, %634) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc116)
        %636 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc115)
        %637 = "ttir.multiply"(%631, %635, %636) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc115)
        %638 = ttir.empty() : tensor<100x3072xbf16> loc(#loc117)
        %639 = "ttir.reshape"(%637, %638) <{shape = [100 : i32, 3072 : i32]}> : (tensor<2x50x3072xbf16>, tensor<100x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc117)
        %640 = ttir.empty() : tensor<1x768x3072xbf16> loc(#loc2)
        %641 = "ttir.reshape"(%arg124, %640) <{shape = [1 : i32, 768 : i32, 3072 : i32]}> : (tensor<768x3072xbf16>, tensor<1x768x3072xbf16>) -> tensor<1x768x3072xbf16> loc(#loc2)
        %642 = ttir.empty() : tensor<768x3072xbf16> loc(#loc2)
        %643 = "ttir.reshape"(%641, %642) <{shape = [768 : i32, 3072 : i32]}> : (tensor<1x768x3072xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc2)
        %644 = ttir.empty() : tensor<3072x768xbf16> loc(#loc118)
        %645 = "ttir.permute"(%643, %644) <{permutation = array<i64: 1, 0>}> : (tensor<768x3072xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc118)
        %646 = "ttir.dot_general"(%639, %645) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x3072xbf16>, tensor<3072x768xbf16>) -> tensor<100x768xbf16> loc(#loc119)
        %647 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc117)
        %648 = "ttir.reshape"(%646, %647) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc117)
        %649 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %650 = "ttir.reshape"(%arg123, %649) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %651 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %652 = "ttir.reshape"(%650, %651) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %653 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc120)
        %654 = "ttir.reshape"(%652, %653) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc120)
        %655 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc120)
        %656 = "ttir.broadcast"(%654, %655) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc120)
        %657 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc120)
        %658 = "ttir.add"(%648, %656, %657) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc120)
        %659 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc121)
        %660 = "ttir.add"(%560, %658, %659) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc121)
        %661 = ttir.empty() : tensor<2x50xbf16> loc(#loc122)
        %662 = "ttir.sum"(%660, %661) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc122)
        %663 = ttir.empty() : tensor<2x50xbf16> loc(#loc122)
        %664 = "ttir.multiply"(%662, %5, %663) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc122)
        %665 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc123)
        %666 = "ttir.reshape"(%664, %665) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc123)
        %667 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc123)
        %668 = "ttir.broadcast"(%666, %667) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc123)
        %669 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc123)
        %670 = "ttir.subtract"(%660, %668, %669) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc123)
        %671 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc122)
        %672 = "ttir.multiply"(%670, %670, %671) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc122)
        %673 = ttir.empty() : tensor<2x50xbf16> loc(#loc122)
        %674 = "ttir.sum"(%672, %673) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc122)
        %675 = ttir.empty() : tensor<2x50xbf16> loc(#loc122)
        %676 = "ttir.multiply"(%674, %5, %675) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc122)
        %677 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc122)
        %678 = "ttir.reshape"(%676, %677) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc122)
        %679 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc124)
        %680 = "ttir.add"(%678, %4, %679) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc124)
        %681 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc125)
        %682 = "ttir.rsqrt"(%680, %681) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc125)
        %683 = ttir.empty() : tensor<2x50xbf16> loc(#loc126)
        %684 = "ttir.reshape"(%682, %683) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc126)
        %685 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc126)
        %686 = "ttir.reshape"(%684, %685) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc126)
        %687 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc126)
        %688 = "ttir.broadcast"(%686, %687) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc126)
        %689 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc126)
        %690 = "ttir.multiply"(%670, %688, %689) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc126)
        %691 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %692 = "ttir.reshape"(%arg122, %691) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %693 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %694 = "ttir.reshape"(%692, %693) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %695 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc126)
        %696 = "ttir.reshape"(%694, %695) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc126)
        %697 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc126)
        %698 = "ttir.broadcast"(%696, %697) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc126)
        %699 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc126)
        %700 = "ttir.multiply"(%690, %698, %699) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc126)
        %701 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %702 = "ttir.reshape"(%arg121, %701) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %703 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %704 = "ttir.reshape"(%702, %703) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %705 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc124)
        %706 = "ttir.reshape"(%704, %705) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc124)
        %707 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc124)
        %708 = "ttir.broadcast"(%706, %707) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc124)
        %709 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc124)
        %710 = "ttir.add"(%700, %708, %709) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc124)
        %711 = ttir.empty() : tensor<100x768xbf16> loc(#loc127)
        %712 = "ttir.reshape"(%710, %711) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc127)
        %713 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %714 = "ttir.reshape"(%arg165, %713) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %715 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %716 = "ttir.reshape"(%714, %715) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %717 = ttir.empty() : tensor<768x768xbf16> loc(#loc128)
        %718 = "ttir.permute"(%716, %717) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc128)
        %719 = "ttir.dot_general"(%712, %718) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc129)
        %720 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc127)
        %721 = "ttir.reshape"(%719, %720) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc127)
        %722 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %723 = "ttir.reshape"(%arg164, %722) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %724 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %725 = "ttir.reshape"(%723, %724) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %726 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc130)
        %727 = "ttir.reshape"(%725, %726) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc130)
        %728 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc130)
        %729 = "ttir.broadcast"(%727, %728) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc130)
        %730 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc130)
        %731 = "ttir.add"(%721, %729, %730) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc130)
        %732 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc131)
        %733 = "ttir.reshape"(%731, %732) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc131)
        %734 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc132)
        %735 = "ttir.permute"(%733, %734) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc132)
        %736 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc133)
        %737 = "ttir.reshape"(%735, %736) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc133)
        %738 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %739 = "ttir.reshape"(%arg163, %738) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %740 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %741 = "ttir.reshape"(%739, %740) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %742 = ttir.empty() : tensor<768x768xbf16> loc(#loc134)
        %743 = "ttir.permute"(%741, %742) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc134)
        %744 = "ttir.dot_general"(%712, %743) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc135)
        %745 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc136)
        %746 = "ttir.reshape"(%744, %745) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc136)
        %747 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %748 = "ttir.reshape"(%arg162, %747) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %749 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %750 = "ttir.reshape"(%748, %749) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %751 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc137)
        %752 = "ttir.reshape"(%750, %751) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc137)
        %753 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc137)
        %754 = "ttir.broadcast"(%752, %753) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc137)
        %755 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc137)
        %756 = "ttir.add"(%746, %754, %755) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc137)
        %757 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc138)
        %758 = "ttir.reshape"(%756, %757) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc138)
        %759 = ttir.empty() : tensor<2x12x64x50xbf16> loc(#loc139)
        %760 = "ttir.permute"(%758, %759) <{permutation = array<i64: 0, 2, 3, 1>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x64x50xbf16>) -> tensor<2x12x64x50xbf16> loc(#loc139)
        %761 = ttir.empty() : tensor<24x64x50xbf16> loc(#loc133)
        %762 = "ttir.reshape"(%760, %761) <{shape = [24 : i32, 64 : i32, 50 : i32]}> : (tensor<2x12x64x50xbf16>, tensor<24x64x50xbf16>) -> tensor<24x64x50xbf16> loc(#loc133)
        %763 = "ttir.dot_general"(%737, %762) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x64xbf16>, tensor<24x64x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc140)
        %764 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc133)
        %765 = "ttir.reshape"(%763, %764) <{shape = [2 : i32, 12 : i32, 50 : i32, 50 : i32]}> : (tensor<24x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc133)
        %766 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc141)
        %767 = "ttir.multiply"(%765, %3, %766) : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc141)
        %768 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc142)
        %769 = "ttir.typecast"(%767, %768) <{conservative_folding = false}> : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc142)
        %770 = ttir.empty() : tensor<2x12x50xf32> loc(#loc143)
        %771 = "ttir.max"(%769, %770) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc143)
        %772 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc143)
        %773 = "ttir.reshape"(%771, %772) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc143)
        %774 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc143)
        %775 = "ttir.broadcast"(%773, %774) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc143)
        %776 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc143)
        %777 = "ttir.subtract"(%769, %775, %776) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc143)
        %778 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc143)
        %779 = "ttir.exp"(%777, %778) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc143)
        %780 = ttir.empty() : tensor<2x12x50xf32> loc(#loc143)
        %781 = "ttir.sum"(%779, %780) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc143)
        %782 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc143)
        %783 = "ttir.reshape"(%781, %782) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc143)
        %784 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc143)
        %785 = "ttir.broadcast"(%783, %784) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc143)
        %786 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc143)
        %787 = "ttir.div"(%779, %785, %786) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc143)
        %788 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc144)
        %789 = "ttir.typecast"(%787, %788) <{conservative_folding = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc144)
        %790 = ttir.empty() : tensor<24x50x50xbf16> loc(#loc145)
        %791 = "ttir.reshape"(%789, %790) <{shape = [24 : i32, 50 : i32, 50 : i32]}> : (tensor<2x12x50x50xbf16>, tensor<24x50x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc145)
        %792 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %793 = "ttir.reshape"(%arg120, %792) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %794 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %795 = "ttir.reshape"(%793, %794) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %796 = ttir.empty() : tensor<768x768xbf16> loc(#loc146)
        %797 = "ttir.permute"(%795, %796) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc146)
        %798 = "ttir.dot_general"(%712, %797) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc147)
        %799 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc148)
        %800 = "ttir.reshape"(%798, %799) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc148)
        %801 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %802 = "ttir.reshape"(%arg119, %801) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %803 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %804 = "ttir.reshape"(%802, %803) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %805 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc149)
        %806 = "ttir.reshape"(%804, %805) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc149)
        %807 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc149)
        %808 = "ttir.broadcast"(%806, %807) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc149)
        %809 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc149)
        %810 = "ttir.add"(%800, %808, %809) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc149)
        %811 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc150)
        %812 = "ttir.reshape"(%810, %811) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc150)
        %813 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc151)
        %814 = "ttir.permute"(%812, %813) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc151)
        %815 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc145)
        %816 = "ttir.reshape"(%814, %815) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc145)
        %817 = "ttir.dot_general"(%791, %816) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x50xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc152)
        %818 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc145)
        %819 = "ttir.reshape"(%817, %818) <{shape = [2 : i32, 12 : i32, 50 : i32, 64 : i32]}> : (tensor<24x50x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc145)
        %820 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc153)
        %821 = "ttir.permute"(%819, %820) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x12x50x64xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc153)
        %822 = ttir.empty() : tensor<100x768xbf16> loc(#loc154)
        %823 = "ttir.reshape"(%821, %822) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x12x64xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc154)
        %824 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %825 = "ttir.reshape"(%arg118, %824) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %826 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %827 = "ttir.reshape"(%825, %826) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %828 = ttir.empty() : tensor<768x768xbf16> loc(#loc155)
        %829 = "ttir.permute"(%827, %828) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc155)
        %830 = "ttir.dot_general"(%823, %829) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc156)
        %831 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc154)
        %832 = "ttir.reshape"(%830, %831) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc154)
        %833 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %834 = "ttir.reshape"(%arg117, %833) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %835 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %836 = "ttir.reshape"(%834, %835) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %837 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc157)
        %838 = "ttir.reshape"(%836, %837) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc157)
        %839 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc157)
        %840 = "ttir.broadcast"(%838, %839) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc157)
        %841 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc157)
        %842 = "ttir.add"(%832, %840, %841) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc157)
        %843 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc158)
        %844 = "ttir.add"(%660, %842, %843) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc158)
        %845 = ttir.empty() : tensor<2x50xbf16> loc(#loc159)
        %846 = "ttir.sum"(%844, %845) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc159)
        %847 = ttir.empty() : tensor<2x50xbf16> loc(#loc159)
        %848 = "ttir.multiply"(%846, %5, %847) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc159)
        %849 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc160)
        %850 = "ttir.reshape"(%848, %849) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc160)
        %851 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc160)
        %852 = "ttir.broadcast"(%850, %851) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc160)
        %853 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc160)
        %854 = "ttir.subtract"(%844, %852, %853) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc160)
        %855 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc159)
        %856 = "ttir.multiply"(%854, %854, %855) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc159)
        %857 = ttir.empty() : tensor<2x50xbf16> loc(#loc159)
        %858 = "ttir.sum"(%856, %857) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc159)
        %859 = ttir.empty() : tensor<2x50xbf16> loc(#loc159)
        %860 = "ttir.multiply"(%858, %5, %859) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc159)
        %861 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc159)
        %862 = "ttir.reshape"(%860, %861) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc159)
        %863 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc161)
        %864 = "ttir.add"(%862, %4, %863) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc161)
        %865 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc162)
        %866 = "ttir.rsqrt"(%864, %865) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc162)
        %867 = ttir.empty() : tensor<2x50xbf16> loc(#loc163)
        %868 = "ttir.reshape"(%866, %867) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc163)
        %869 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc163)
        %870 = "ttir.reshape"(%868, %869) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc163)
        %871 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc163)
        %872 = "ttir.broadcast"(%870, %871) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc163)
        %873 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc163)
        %874 = "ttir.multiply"(%854, %872, %873) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc163)
        %875 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %876 = "ttir.reshape"(%arg116, %875) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %877 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %878 = "ttir.reshape"(%876, %877) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %879 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc163)
        %880 = "ttir.reshape"(%878, %879) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc163)
        %881 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc163)
        %882 = "ttir.broadcast"(%880, %881) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc163)
        %883 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc163)
        %884 = "ttir.multiply"(%874, %882, %883) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc163)
        %885 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %886 = "ttir.reshape"(%arg115, %885) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %887 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %888 = "ttir.reshape"(%886, %887) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %889 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc161)
        %890 = "ttir.reshape"(%888, %889) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc161)
        %891 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc161)
        %892 = "ttir.broadcast"(%890, %891) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc161)
        %893 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc161)
        %894 = "ttir.add"(%884, %892, %893) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc161)
        %895 = ttir.empty() : tensor<100x768xbf16> loc(#loc164)
        %896 = "ttir.reshape"(%894, %895) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc164)
        %897 = ttir.empty() : tensor<1x3072x768xbf16> loc(#loc2)
        %898 = "ttir.reshape"(%arg114, %897) <{shape = [1 : i32, 3072 : i32, 768 : i32]}> : (tensor<3072x768xbf16>, tensor<1x3072x768xbf16>) -> tensor<1x3072x768xbf16> loc(#loc2)
        %899 = ttir.empty() : tensor<3072x768xbf16> loc(#loc2)
        %900 = "ttir.reshape"(%898, %899) <{shape = [3072 : i32, 768 : i32]}> : (tensor<1x3072x768xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc2)
        %901 = ttir.empty() : tensor<768x3072xbf16> loc(#loc165)
        %902 = "ttir.permute"(%900, %901) <{permutation = array<i64: 1, 0>}> : (tensor<3072x768xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc165)
        %903 = "ttir.dot_general"(%896, %902) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc166)
        %904 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc164)
        %905 = "ttir.reshape"(%903, %904) <{shape = [2 : i32, 50 : i32, 3072 : i32]}> : (tensor<100x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc164)
        %906 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc2)
        %907 = "ttir.reshape"(%arg113, %906) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc2)
        %908 = ttir.empty() : tensor<3072xbf16> loc(#loc2)
        %909 = "ttir.reshape"(%907, %908) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc2)
        %910 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc167)
        %911 = "ttir.reshape"(%909, %910) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc167)
        %912 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc167)
        %913 = "ttir.broadcast"(%911, %912) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc167)
        %914 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc167)
        %915 = "ttir.add"(%905, %913, %914) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc167)
        %916 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc168)
        %917 = "ttir.multiply"(%915, %2, %916) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc168)
        %918 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc169)
        %919 = "ttir.sigmoid"(%917, %918) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc169)
        %920 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc168)
        %921 = "ttir.multiply"(%915, %919, %920) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc168)
        %922 = ttir.empty() : tensor<100x3072xbf16> loc(#loc170)
        %923 = "ttir.reshape"(%921, %922) <{shape = [100 : i32, 3072 : i32]}> : (tensor<2x50x3072xbf16>, tensor<100x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc170)
        %924 = ttir.empty() : tensor<1x768x3072xbf16> loc(#loc2)
        %925 = "ttir.reshape"(%arg112, %924) <{shape = [1 : i32, 768 : i32, 3072 : i32]}> : (tensor<768x3072xbf16>, tensor<1x768x3072xbf16>) -> tensor<1x768x3072xbf16> loc(#loc2)
        %926 = ttir.empty() : tensor<768x3072xbf16> loc(#loc2)
        %927 = "ttir.reshape"(%925, %926) <{shape = [768 : i32, 3072 : i32]}> : (tensor<1x768x3072xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc2)
        %928 = ttir.empty() : tensor<3072x768xbf16> loc(#loc171)
        %929 = "ttir.permute"(%927, %928) <{permutation = array<i64: 1, 0>}> : (tensor<768x3072xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc171)
        %930 = "ttir.dot_general"(%923, %929) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x3072xbf16>, tensor<3072x768xbf16>) -> tensor<100x768xbf16> loc(#loc172)
        %931 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc170)
        %932 = "ttir.reshape"(%930, %931) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc170)
        %933 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %934 = "ttir.reshape"(%arg111, %933) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %935 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %936 = "ttir.reshape"(%934, %935) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %937 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc173)
        %938 = "ttir.reshape"(%936, %937) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc173)
        %939 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc173)
        %940 = "ttir.broadcast"(%938, %939) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc173)
        %941 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc173)
        %942 = "ttir.add"(%932, %940, %941) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc173)
        %943 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc174)
        %944 = "ttir.add"(%844, %942, %943) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc174)
        %945 = ttir.empty() : tensor<2x50xbf16> loc(#loc175)
        %946 = "ttir.sum"(%944, %945) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc175)
        %947 = ttir.empty() : tensor<2x50xbf16> loc(#loc175)
        %948 = "ttir.multiply"(%946, %5, %947) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc175)
        %949 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc176)
        %950 = "ttir.reshape"(%948, %949) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc176)
        %951 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc176)
        %952 = "ttir.broadcast"(%950, %951) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc176)
        %953 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc176)
        %954 = "ttir.subtract"(%944, %952, %953) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc176)
        %955 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc175)
        %956 = "ttir.multiply"(%954, %954, %955) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc175)
        %957 = ttir.empty() : tensor<2x50xbf16> loc(#loc175)
        %958 = "ttir.sum"(%956, %957) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc175)
        %959 = ttir.empty() : tensor<2x50xbf16> loc(#loc175)
        %960 = "ttir.multiply"(%958, %5, %959) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc175)
        %961 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc175)
        %962 = "ttir.reshape"(%960, %961) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc175)
        %963 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc177)
        %964 = "ttir.add"(%962, %4, %963) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc177)
        %965 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc178)
        %966 = "ttir.rsqrt"(%964, %965) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc178)
        %967 = ttir.empty() : tensor<2x50xbf16> loc(#loc179)
        %968 = "ttir.reshape"(%966, %967) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc179)
        %969 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc179)
        %970 = "ttir.reshape"(%968, %969) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc179)
        %971 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc179)
        %972 = "ttir.broadcast"(%970, %971) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc179)
        %973 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc179)
        %974 = "ttir.multiply"(%954, %972, %973) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc179)
        %975 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %976 = "ttir.reshape"(%arg110, %975) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %977 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %978 = "ttir.reshape"(%976, %977) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %979 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc179)
        %980 = "ttir.reshape"(%978, %979) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc179)
        %981 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc179)
        %982 = "ttir.broadcast"(%980, %981) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc179)
        %983 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc179)
        %984 = "ttir.multiply"(%974, %982, %983) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc179)
        %985 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %986 = "ttir.reshape"(%arg109, %985) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %987 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %988 = "ttir.reshape"(%986, %987) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %989 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc177)
        %990 = "ttir.reshape"(%988, %989) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc177)
        %991 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc177)
        %992 = "ttir.broadcast"(%990, %991) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc177)
        %993 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc177)
        %994 = "ttir.add"(%984, %992, %993) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc177)
        %995 = ttir.empty() : tensor<100x768xbf16> loc(#loc180)
        %996 = "ttir.reshape"(%994, %995) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc180)
        %997 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %998 = "ttir.reshape"(%arg169, %997) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %999 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %1000 = "ttir.reshape"(%998, %999) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %1001 = ttir.empty() : tensor<768x768xbf16> loc(#loc181)
        %1002 = "ttir.permute"(%1000, %1001) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc181)
        %1003 = "ttir.dot_general"(%996, %1002) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc182)
        %1004 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc180)
        %1005 = "ttir.reshape"(%1003, %1004) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc180)
        %1006 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1007 = "ttir.reshape"(%arg168, %1006) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1008 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1009 = "ttir.reshape"(%1007, %1008) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1010 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc183)
        %1011 = "ttir.reshape"(%1009, %1010) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc183)
        %1012 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc183)
        %1013 = "ttir.broadcast"(%1011, %1012) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc183)
        %1014 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc183)
        %1015 = "ttir.add"(%1005, %1013, %1014) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc183)
        %1016 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc184)
        %1017 = "ttir.reshape"(%1015, %1016) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc184)
        %1018 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc185)
        %1019 = "ttir.permute"(%1017, %1018) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc185)
        %1020 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc186)
        %1021 = "ttir.reshape"(%1019, %1020) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc186)
        %1022 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %1023 = "ttir.reshape"(%arg167, %1022) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %1024 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %1025 = "ttir.reshape"(%1023, %1024) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %1026 = ttir.empty() : tensor<768x768xbf16> loc(#loc187)
        %1027 = "ttir.permute"(%1025, %1026) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc187)
        %1028 = "ttir.dot_general"(%996, %1027) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc188)
        %1029 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc189)
        %1030 = "ttir.reshape"(%1028, %1029) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc189)
        %1031 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1032 = "ttir.reshape"(%arg166, %1031) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1033 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1034 = "ttir.reshape"(%1032, %1033) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1035 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc190)
        %1036 = "ttir.reshape"(%1034, %1035) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc190)
        %1037 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc190)
        %1038 = "ttir.broadcast"(%1036, %1037) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc190)
        %1039 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc190)
        %1040 = "ttir.add"(%1030, %1038, %1039) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc190)
        %1041 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc191)
        %1042 = "ttir.reshape"(%1040, %1041) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc191)
        %1043 = ttir.empty() : tensor<2x12x64x50xbf16> loc(#loc192)
        %1044 = "ttir.permute"(%1042, %1043) <{permutation = array<i64: 0, 2, 3, 1>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x64x50xbf16>) -> tensor<2x12x64x50xbf16> loc(#loc192)
        %1045 = ttir.empty() : tensor<24x64x50xbf16> loc(#loc186)
        %1046 = "ttir.reshape"(%1044, %1045) <{shape = [24 : i32, 64 : i32, 50 : i32]}> : (tensor<2x12x64x50xbf16>, tensor<24x64x50xbf16>) -> tensor<24x64x50xbf16> loc(#loc186)
        %1047 = "ttir.dot_general"(%1021, %1046) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x64xbf16>, tensor<24x64x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc193)
        %1048 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc186)
        %1049 = "ttir.reshape"(%1047, %1048) <{shape = [2 : i32, 12 : i32, 50 : i32, 50 : i32]}> : (tensor<24x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc186)
        %1050 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc194)
        %1051 = "ttir.multiply"(%1049, %3, %1050) : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc194)
        %1052 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc195)
        %1053 = "ttir.typecast"(%1051, %1052) <{conservative_folding = false}> : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc195)
        %1054 = ttir.empty() : tensor<2x12x50xf32> loc(#loc196)
        %1055 = "ttir.max"(%1053, %1054) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc196)
        %1056 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc196)
        %1057 = "ttir.reshape"(%1055, %1056) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc196)
        %1058 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc196)
        %1059 = "ttir.broadcast"(%1057, %1058) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc196)
        %1060 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc196)
        %1061 = "ttir.subtract"(%1053, %1059, %1060) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc196)
        %1062 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc196)
        %1063 = "ttir.exp"(%1061, %1062) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc196)
        %1064 = ttir.empty() : tensor<2x12x50xf32> loc(#loc196)
        %1065 = "ttir.sum"(%1063, %1064) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc196)
        %1066 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc196)
        %1067 = "ttir.reshape"(%1065, %1066) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc196)
        %1068 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc196)
        %1069 = "ttir.broadcast"(%1067, %1068) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc196)
        %1070 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc196)
        %1071 = "ttir.div"(%1063, %1069, %1070) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc196)
        %1072 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc197)
        %1073 = "ttir.typecast"(%1071, %1072) <{conservative_folding = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc197)
        %1074 = ttir.empty() : tensor<24x50x50xbf16> loc(#loc198)
        %1075 = "ttir.reshape"(%1073, %1074) <{shape = [24 : i32, 50 : i32, 50 : i32]}> : (tensor<2x12x50x50xbf16>, tensor<24x50x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc198)
        %1076 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %1077 = "ttir.reshape"(%arg108, %1076) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %1078 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %1079 = "ttir.reshape"(%1077, %1078) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %1080 = ttir.empty() : tensor<768x768xbf16> loc(#loc199)
        %1081 = "ttir.permute"(%1079, %1080) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc199)
        %1082 = "ttir.dot_general"(%996, %1081) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc200)
        %1083 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc201)
        %1084 = "ttir.reshape"(%1082, %1083) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc201)
        %1085 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1086 = "ttir.reshape"(%arg107, %1085) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1087 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1088 = "ttir.reshape"(%1086, %1087) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1089 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc202)
        %1090 = "ttir.reshape"(%1088, %1089) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc202)
        %1091 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc202)
        %1092 = "ttir.broadcast"(%1090, %1091) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc202)
        %1093 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc202)
        %1094 = "ttir.add"(%1084, %1092, %1093) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc202)
        %1095 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc203)
        %1096 = "ttir.reshape"(%1094, %1095) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc203)
        %1097 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc204)
        %1098 = "ttir.permute"(%1096, %1097) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc204)
        %1099 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc198)
        %1100 = "ttir.reshape"(%1098, %1099) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc198)
        %1101 = "ttir.dot_general"(%1075, %1100) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x50xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc205)
        %1102 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc198)
        %1103 = "ttir.reshape"(%1101, %1102) <{shape = [2 : i32, 12 : i32, 50 : i32, 64 : i32]}> : (tensor<24x50x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc198)
        %1104 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc206)
        %1105 = "ttir.permute"(%1103, %1104) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x12x50x64xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc206)
        %1106 = ttir.empty() : tensor<100x768xbf16> loc(#loc207)
        %1107 = "ttir.reshape"(%1105, %1106) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x12x64xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc207)
        %1108 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %1109 = "ttir.reshape"(%arg106, %1108) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %1110 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %1111 = "ttir.reshape"(%1109, %1110) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %1112 = ttir.empty() : tensor<768x768xbf16> loc(#loc208)
        %1113 = "ttir.permute"(%1111, %1112) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc208)
        %1114 = "ttir.dot_general"(%1107, %1113) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc209)
        %1115 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc207)
        %1116 = "ttir.reshape"(%1114, %1115) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc207)
        %1117 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1118 = "ttir.reshape"(%arg105, %1117) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1119 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1120 = "ttir.reshape"(%1118, %1119) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1121 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc210)
        %1122 = "ttir.reshape"(%1120, %1121) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc210)
        %1123 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc210)
        %1124 = "ttir.broadcast"(%1122, %1123) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc210)
        %1125 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc210)
        %1126 = "ttir.add"(%1116, %1124, %1125) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc210)
        %1127 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc211)
        %1128 = "ttir.add"(%944, %1126, %1127) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc211)
        %1129 = ttir.empty() : tensor<2x50xbf16> loc(#loc212)
        %1130 = "ttir.sum"(%1128, %1129) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc212)
        %1131 = ttir.empty() : tensor<2x50xbf16> loc(#loc212)
        %1132 = "ttir.multiply"(%1130, %5, %1131) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc212)
        %1133 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc213)
        %1134 = "ttir.reshape"(%1132, %1133) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc213)
        %1135 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc213)
        %1136 = "ttir.broadcast"(%1134, %1135) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc213)
        %1137 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc213)
        %1138 = "ttir.subtract"(%1128, %1136, %1137) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc213)
        %1139 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc212)
        %1140 = "ttir.multiply"(%1138, %1138, %1139) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc212)
        %1141 = ttir.empty() : tensor<2x50xbf16> loc(#loc212)
        %1142 = "ttir.sum"(%1140, %1141) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc212)
        %1143 = ttir.empty() : tensor<2x50xbf16> loc(#loc212)
        %1144 = "ttir.multiply"(%1142, %5, %1143) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc212)
        %1145 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc212)
        %1146 = "ttir.reshape"(%1144, %1145) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc212)
        %1147 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc214)
        %1148 = "ttir.add"(%1146, %4, %1147) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc214)
        %1149 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc215)
        %1150 = "ttir.rsqrt"(%1148, %1149) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc215)
        %1151 = ttir.empty() : tensor<2x50xbf16> loc(#loc216)
        %1152 = "ttir.reshape"(%1150, %1151) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc216)
        %1153 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc216)
        %1154 = "ttir.reshape"(%1152, %1153) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc216)
        %1155 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc216)
        %1156 = "ttir.broadcast"(%1154, %1155) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc216)
        %1157 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc216)
        %1158 = "ttir.multiply"(%1138, %1156, %1157) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc216)
        %1159 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1160 = "ttir.reshape"(%arg104, %1159) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1161 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1162 = "ttir.reshape"(%1160, %1161) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1163 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc216)
        %1164 = "ttir.reshape"(%1162, %1163) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc216)
        %1165 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc216)
        %1166 = "ttir.broadcast"(%1164, %1165) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc216)
        %1167 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc216)
        %1168 = "ttir.multiply"(%1158, %1166, %1167) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc216)
        %1169 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1170 = "ttir.reshape"(%arg103, %1169) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1171 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1172 = "ttir.reshape"(%1170, %1171) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1173 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc214)
        %1174 = "ttir.reshape"(%1172, %1173) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc214)
        %1175 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc214)
        %1176 = "ttir.broadcast"(%1174, %1175) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc214)
        %1177 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc214)
        %1178 = "ttir.add"(%1168, %1176, %1177) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc214)
        %1179 = ttir.empty() : tensor<100x768xbf16> loc(#loc217)
        %1180 = "ttir.reshape"(%1178, %1179) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc217)
        %1181 = ttir.empty() : tensor<1x3072x768xbf16> loc(#loc2)
        %1182 = "ttir.reshape"(%arg102, %1181) <{shape = [1 : i32, 3072 : i32, 768 : i32]}> : (tensor<3072x768xbf16>, tensor<1x3072x768xbf16>) -> tensor<1x3072x768xbf16> loc(#loc2)
        %1183 = ttir.empty() : tensor<3072x768xbf16> loc(#loc2)
        %1184 = "ttir.reshape"(%1182, %1183) <{shape = [3072 : i32, 768 : i32]}> : (tensor<1x3072x768xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc2)
        %1185 = ttir.empty() : tensor<768x3072xbf16> loc(#loc218)
        %1186 = "ttir.permute"(%1184, %1185) <{permutation = array<i64: 1, 0>}> : (tensor<3072x768xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc218)
        %1187 = "ttir.dot_general"(%1180, %1186) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc219)
        %1188 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc217)
        %1189 = "ttir.reshape"(%1187, %1188) <{shape = [2 : i32, 50 : i32, 3072 : i32]}> : (tensor<100x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc217)
        %1190 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc2)
        %1191 = "ttir.reshape"(%arg101, %1190) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc2)
        %1192 = ttir.empty() : tensor<3072xbf16> loc(#loc2)
        %1193 = "ttir.reshape"(%1191, %1192) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc2)
        %1194 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc220)
        %1195 = "ttir.reshape"(%1193, %1194) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc220)
        %1196 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc220)
        %1197 = "ttir.broadcast"(%1195, %1196) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc220)
        %1198 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc220)
        %1199 = "ttir.add"(%1189, %1197, %1198) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc220)
        %1200 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc221)
        %1201 = "ttir.multiply"(%1199, %2, %1200) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc221)
        %1202 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc222)
        %1203 = "ttir.sigmoid"(%1201, %1202) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc222)
        %1204 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc221)
        %1205 = "ttir.multiply"(%1199, %1203, %1204) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc221)
        %1206 = ttir.empty() : tensor<100x3072xbf16> loc(#loc223)
        %1207 = "ttir.reshape"(%1205, %1206) <{shape = [100 : i32, 3072 : i32]}> : (tensor<2x50x3072xbf16>, tensor<100x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc223)
        %1208 = ttir.empty() : tensor<1x768x3072xbf16> loc(#loc2)
        %1209 = "ttir.reshape"(%arg100, %1208) <{shape = [1 : i32, 768 : i32, 3072 : i32]}> : (tensor<768x3072xbf16>, tensor<1x768x3072xbf16>) -> tensor<1x768x3072xbf16> loc(#loc2)
        %1210 = ttir.empty() : tensor<768x3072xbf16> loc(#loc2)
        %1211 = "ttir.reshape"(%1209, %1210) <{shape = [768 : i32, 3072 : i32]}> : (tensor<1x768x3072xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc2)
        %1212 = ttir.empty() : tensor<3072x768xbf16> loc(#loc224)
        %1213 = "ttir.permute"(%1211, %1212) <{permutation = array<i64: 1, 0>}> : (tensor<768x3072xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc224)
        %1214 = "ttir.dot_general"(%1207, %1213) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x3072xbf16>, tensor<3072x768xbf16>) -> tensor<100x768xbf16> loc(#loc225)
        %1215 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc223)
        %1216 = "ttir.reshape"(%1214, %1215) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc223)
        %1217 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1218 = "ttir.reshape"(%arg99, %1217) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1219 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1220 = "ttir.reshape"(%1218, %1219) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1221 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc226)
        %1222 = "ttir.reshape"(%1220, %1221) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc226)
        %1223 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc226)
        %1224 = "ttir.broadcast"(%1222, %1223) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc226)
        %1225 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc226)
        %1226 = "ttir.add"(%1216, %1224, %1225) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc226)
        %1227 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc227)
        %1228 = "ttir.add"(%1128, %1226, %1227) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc227)
        %1229 = ttir.empty() : tensor<2x50xbf16> loc(#loc228)
        %1230 = "ttir.sum"(%1228, %1229) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc228)
        %1231 = ttir.empty() : tensor<2x50xbf16> loc(#loc228)
        %1232 = "ttir.multiply"(%1230, %5, %1231) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc228)
        %1233 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc229)
        %1234 = "ttir.reshape"(%1232, %1233) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc229)
        %1235 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc229)
        %1236 = "ttir.broadcast"(%1234, %1235) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc229)
        %1237 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc229)
        %1238 = "ttir.subtract"(%1228, %1236, %1237) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc229)
        %1239 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc228)
        %1240 = "ttir.multiply"(%1238, %1238, %1239) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc228)
        %1241 = ttir.empty() : tensor<2x50xbf16> loc(#loc228)
        %1242 = "ttir.sum"(%1240, %1241) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc228)
        %1243 = ttir.empty() : tensor<2x50xbf16> loc(#loc228)
        %1244 = "ttir.multiply"(%1242, %5, %1243) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc228)
        %1245 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc228)
        %1246 = "ttir.reshape"(%1244, %1245) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc228)
        %1247 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc230)
        %1248 = "ttir.add"(%1246, %4, %1247) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc230)
        %1249 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc231)
        %1250 = "ttir.rsqrt"(%1248, %1249) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc231)
        %1251 = ttir.empty() : tensor<2x50xbf16> loc(#loc232)
        %1252 = "ttir.reshape"(%1250, %1251) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc232)
        %1253 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc232)
        %1254 = "ttir.reshape"(%1252, %1253) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc232)
        %1255 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc232)
        %1256 = "ttir.broadcast"(%1254, %1255) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc232)
        %1257 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc232)
        %1258 = "ttir.multiply"(%1238, %1256, %1257) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc232)
        %1259 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1260 = "ttir.reshape"(%arg98, %1259) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1261 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1262 = "ttir.reshape"(%1260, %1261) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1263 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc232)
        %1264 = "ttir.reshape"(%1262, %1263) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc232)
        %1265 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc232)
        %1266 = "ttir.broadcast"(%1264, %1265) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc232)
        %1267 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc232)
        %1268 = "ttir.multiply"(%1258, %1266, %1267) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc232)
        %1269 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1270 = "ttir.reshape"(%arg97, %1269) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1271 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1272 = "ttir.reshape"(%1270, %1271) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1273 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc230)
        %1274 = "ttir.reshape"(%1272, %1273) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc230)
        %1275 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc230)
        %1276 = "ttir.broadcast"(%1274, %1275) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc230)
        %1277 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc230)
        %1278 = "ttir.add"(%1268, %1276, %1277) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc230)
        %1279 = ttir.empty() : tensor<100x768xbf16> loc(#loc233)
        %1280 = "ttir.reshape"(%1278, %1279) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc233)
        %1281 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %1282 = "ttir.reshape"(%arg173, %1281) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %1283 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %1284 = "ttir.reshape"(%1282, %1283) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %1285 = ttir.empty() : tensor<768x768xbf16> loc(#loc234)
        %1286 = "ttir.permute"(%1284, %1285) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc234)
        %1287 = "ttir.dot_general"(%1280, %1286) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc235)
        %1288 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc233)
        %1289 = "ttir.reshape"(%1287, %1288) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc233)
        %1290 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1291 = "ttir.reshape"(%arg172, %1290) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1292 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1293 = "ttir.reshape"(%1291, %1292) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1294 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc236)
        %1295 = "ttir.reshape"(%1293, %1294) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc236)
        %1296 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc236)
        %1297 = "ttir.broadcast"(%1295, %1296) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc236)
        %1298 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc236)
        %1299 = "ttir.add"(%1289, %1297, %1298) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc236)
        %1300 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc237)
        %1301 = "ttir.reshape"(%1299, %1300) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc237)
        %1302 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc238)
        %1303 = "ttir.permute"(%1301, %1302) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc238)
        %1304 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc239)
        %1305 = "ttir.reshape"(%1303, %1304) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc239)
        %1306 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %1307 = "ttir.reshape"(%arg171, %1306) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %1308 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %1309 = "ttir.reshape"(%1307, %1308) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %1310 = ttir.empty() : tensor<768x768xbf16> loc(#loc240)
        %1311 = "ttir.permute"(%1309, %1310) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc240)
        %1312 = "ttir.dot_general"(%1280, %1311) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc241)
        %1313 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc242)
        %1314 = "ttir.reshape"(%1312, %1313) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc242)
        %1315 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1316 = "ttir.reshape"(%arg170, %1315) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1317 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1318 = "ttir.reshape"(%1316, %1317) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1319 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc243)
        %1320 = "ttir.reshape"(%1318, %1319) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc243)
        %1321 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc243)
        %1322 = "ttir.broadcast"(%1320, %1321) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc243)
        %1323 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc243)
        %1324 = "ttir.add"(%1314, %1322, %1323) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc243)
        %1325 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc244)
        %1326 = "ttir.reshape"(%1324, %1325) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc244)
        %1327 = ttir.empty() : tensor<2x12x64x50xbf16> loc(#loc245)
        %1328 = "ttir.permute"(%1326, %1327) <{permutation = array<i64: 0, 2, 3, 1>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x64x50xbf16>) -> tensor<2x12x64x50xbf16> loc(#loc245)
        %1329 = ttir.empty() : tensor<24x64x50xbf16> loc(#loc239)
        %1330 = "ttir.reshape"(%1328, %1329) <{shape = [24 : i32, 64 : i32, 50 : i32]}> : (tensor<2x12x64x50xbf16>, tensor<24x64x50xbf16>) -> tensor<24x64x50xbf16> loc(#loc239)
        %1331 = "ttir.dot_general"(%1305, %1330) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x64xbf16>, tensor<24x64x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc246)
        %1332 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc239)
        %1333 = "ttir.reshape"(%1331, %1332) <{shape = [2 : i32, 12 : i32, 50 : i32, 50 : i32]}> : (tensor<24x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc239)
        %1334 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc247)
        %1335 = "ttir.multiply"(%1333, %3, %1334) : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc247)
        %1336 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc248)
        %1337 = "ttir.typecast"(%1335, %1336) <{conservative_folding = false}> : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc248)
        %1338 = ttir.empty() : tensor<2x12x50xf32> loc(#loc249)
        %1339 = "ttir.max"(%1337, %1338) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc249)
        %1340 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc249)
        %1341 = "ttir.reshape"(%1339, %1340) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc249)
        %1342 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc249)
        %1343 = "ttir.broadcast"(%1341, %1342) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc249)
        %1344 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc249)
        %1345 = "ttir.subtract"(%1337, %1343, %1344) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc249)
        %1346 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc249)
        %1347 = "ttir.exp"(%1345, %1346) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc249)
        %1348 = ttir.empty() : tensor<2x12x50xf32> loc(#loc249)
        %1349 = "ttir.sum"(%1347, %1348) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc249)
        %1350 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc249)
        %1351 = "ttir.reshape"(%1349, %1350) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc249)
        %1352 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc249)
        %1353 = "ttir.broadcast"(%1351, %1352) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc249)
        %1354 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc249)
        %1355 = "ttir.div"(%1347, %1353, %1354) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc249)
        %1356 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc250)
        %1357 = "ttir.typecast"(%1355, %1356) <{conservative_folding = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc250)
        %1358 = ttir.empty() : tensor<24x50x50xbf16> loc(#loc251)
        %1359 = "ttir.reshape"(%1357, %1358) <{shape = [24 : i32, 50 : i32, 50 : i32]}> : (tensor<2x12x50x50xbf16>, tensor<24x50x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc251)
        %1360 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %1361 = "ttir.reshape"(%arg96, %1360) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %1362 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %1363 = "ttir.reshape"(%1361, %1362) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %1364 = ttir.empty() : tensor<768x768xbf16> loc(#loc252)
        %1365 = "ttir.permute"(%1363, %1364) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc252)
        %1366 = "ttir.dot_general"(%1280, %1365) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc253)
        %1367 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc254)
        %1368 = "ttir.reshape"(%1366, %1367) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc254)
        %1369 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1370 = "ttir.reshape"(%arg95, %1369) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1371 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1372 = "ttir.reshape"(%1370, %1371) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1373 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc255)
        %1374 = "ttir.reshape"(%1372, %1373) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc255)
        %1375 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc255)
        %1376 = "ttir.broadcast"(%1374, %1375) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc255)
        %1377 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc255)
        %1378 = "ttir.add"(%1368, %1376, %1377) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc255)
        %1379 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc256)
        %1380 = "ttir.reshape"(%1378, %1379) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc256)
        %1381 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc257)
        %1382 = "ttir.permute"(%1380, %1381) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc257)
        %1383 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc251)
        %1384 = "ttir.reshape"(%1382, %1383) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc251)
        %1385 = "ttir.dot_general"(%1359, %1384) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x50xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc258)
        %1386 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc251)
        %1387 = "ttir.reshape"(%1385, %1386) <{shape = [2 : i32, 12 : i32, 50 : i32, 64 : i32]}> : (tensor<24x50x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc251)
        %1388 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc259)
        %1389 = "ttir.permute"(%1387, %1388) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x12x50x64xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc259)
        %1390 = ttir.empty() : tensor<100x768xbf16> loc(#loc260)
        %1391 = "ttir.reshape"(%1389, %1390) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x12x64xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc260)
        %1392 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %1393 = "ttir.reshape"(%arg94, %1392) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %1394 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %1395 = "ttir.reshape"(%1393, %1394) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %1396 = ttir.empty() : tensor<768x768xbf16> loc(#loc261)
        %1397 = "ttir.permute"(%1395, %1396) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc261)
        %1398 = "ttir.dot_general"(%1391, %1397) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc262)
        %1399 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc260)
        %1400 = "ttir.reshape"(%1398, %1399) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc260)
        %1401 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1402 = "ttir.reshape"(%arg93, %1401) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1403 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1404 = "ttir.reshape"(%1402, %1403) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1405 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc263)
        %1406 = "ttir.reshape"(%1404, %1405) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc263)
        %1407 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc263)
        %1408 = "ttir.broadcast"(%1406, %1407) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc263)
        %1409 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc263)
        %1410 = "ttir.add"(%1400, %1408, %1409) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc263)
        %1411 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc264)
        %1412 = "ttir.add"(%1228, %1410, %1411) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc264)
        %1413 = ttir.empty() : tensor<2x50xbf16> loc(#loc265)
        %1414 = "ttir.sum"(%1412, %1413) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc265)
        %1415 = ttir.empty() : tensor<2x50xbf16> loc(#loc265)
        %1416 = "ttir.multiply"(%1414, %5, %1415) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc265)
        %1417 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc266)
        %1418 = "ttir.reshape"(%1416, %1417) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc266)
        %1419 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc266)
        %1420 = "ttir.broadcast"(%1418, %1419) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc266)
        %1421 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc266)
        %1422 = "ttir.subtract"(%1412, %1420, %1421) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc266)
        %1423 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc265)
        %1424 = "ttir.multiply"(%1422, %1422, %1423) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc265)
        %1425 = ttir.empty() : tensor<2x50xbf16> loc(#loc265)
        %1426 = "ttir.sum"(%1424, %1425) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc265)
        %1427 = ttir.empty() : tensor<2x50xbf16> loc(#loc265)
        %1428 = "ttir.multiply"(%1426, %5, %1427) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc265)
        %1429 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc265)
        %1430 = "ttir.reshape"(%1428, %1429) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc265)
        %1431 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc267)
        %1432 = "ttir.add"(%1430, %4, %1431) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc267)
        %1433 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc268)
        %1434 = "ttir.rsqrt"(%1432, %1433) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc268)
        %1435 = ttir.empty() : tensor<2x50xbf16> loc(#loc269)
        %1436 = "ttir.reshape"(%1434, %1435) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc269)
        %1437 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc269)
        %1438 = "ttir.reshape"(%1436, %1437) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc269)
        %1439 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc269)
        %1440 = "ttir.broadcast"(%1438, %1439) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc269)
        %1441 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc269)
        %1442 = "ttir.multiply"(%1422, %1440, %1441) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc269)
        %1443 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1444 = "ttir.reshape"(%arg92, %1443) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1445 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1446 = "ttir.reshape"(%1444, %1445) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1447 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc269)
        %1448 = "ttir.reshape"(%1446, %1447) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc269)
        %1449 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc269)
        %1450 = "ttir.broadcast"(%1448, %1449) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc269)
        %1451 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc269)
        %1452 = "ttir.multiply"(%1442, %1450, %1451) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc269)
        %1453 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1454 = "ttir.reshape"(%arg91, %1453) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1455 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1456 = "ttir.reshape"(%1454, %1455) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1457 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc267)
        %1458 = "ttir.reshape"(%1456, %1457) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc267)
        %1459 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc267)
        %1460 = "ttir.broadcast"(%1458, %1459) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc267)
        %1461 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc267)
        %1462 = "ttir.add"(%1452, %1460, %1461) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc267)
        %1463 = ttir.empty() : tensor<100x768xbf16> loc(#loc270)
        %1464 = "ttir.reshape"(%1462, %1463) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc270)
        %1465 = ttir.empty() : tensor<1x3072x768xbf16> loc(#loc2)
        %1466 = "ttir.reshape"(%arg90, %1465) <{shape = [1 : i32, 3072 : i32, 768 : i32]}> : (tensor<3072x768xbf16>, tensor<1x3072x768xbf16>) -> tensor<1x3072x768xbf16> loc(#loc2)
        %1467 = ttir.empty() : tensor<3072x768xbf16> loc(#loc2)
        %1468 = "ttir.reshape"(%1466, %1467) <{shape = [3072 : i32, 768 : i32]}> : (tensor<1x3072x768xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc2)
        %1469 = ttir.empty() : tensor<768x3072xbf16> loc(#loc271)
        %1470 = "ttir.permute"(%1468, %1469) <{permutation = array<i64: 1, 0>}> : (tensor<3072x768xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc271)
        %1471 = "ttir.dot_general"(%1464, %1470) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc272)
        %1472 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc270)
        %1473 = "ttir.reshape"(%1471, %1472) <{shape = [2 : i32, 50 : i32, 3072 : i32]}> : (tensor<100x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc270)
        %1474 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc2)
        %1475 = "ttir.reshape"(%arg89, %1474) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc2)
        %1476 = ttir.empty() : tensor<3072xbf16> loc(#loc2)
        %1477 = "ttir.reshape"(%1475, %1476) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc2)
        %1478 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc273)
        %1479 = "ttir.reshape"(%1477, %1478) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc273)
        %1480 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc273)
        %1481 = "ttir.broadcast"(%1479, %1480) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc273)
        %1482 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc273)
        %1483 = "ttir.add"(%1473, %1481, %1482) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc273)
        %1484 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc274)
        %1485 = "ttir.multiply"(%1483, %2, %1484) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc274)
        %1486 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc275)
        %1487 = "ttir.sigmoid"(%1485, %1486) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc275)
        %1488 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc274)
        %1489 = "ttir.multiply"(%1483, %1487, %1488) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc274)
        %1490 = ttir.empty() : tensor<100x3072xbf16> loc(#loc276)
        %1491 = "ttir.reshape"(%1489, %1490) <{shape = [100 : i32, 3072 : i32]}> : (tensor<2x50x3072xbf16>, tensor<100x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc276)
        %1492 = ttir.empty() : tensor<1x768x3072xbf16> loc(#loc2)
        %1493 = "ttir.reshape"(%arg88, %1492) <{shape = [1 : i32, 768 : i32, 3072 : i32]}> : (tensor<768x3072xbf16>, tensor<1x768x3072xbf16>) -> tensor<1x768x3072xbf16> loc(#loc2)
        %1494 = ttir.empty() : tensor<768x3072xbf16> loc(#loc2)
        %1495 = "ttir.reshape"(%1493, %1494) <{shape = [768 : i32, 3072 : i32]}> : (tensor<1x768x3072xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc2)
        %1496 = ttir.empty() : tensor<3072x768xbf16> loc(#loc277)
        %1497 = "ttir.permute"(%1495, %1496) <{permutation = array<i64: 1, 0>}> : (tensor<768x3072xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc277)
        %1498 = "ttir.dot_general"(%1491, %1497) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x3072xbf16>, tensor<3072x768xbf16>) -> tensor<100x768xbf16> loc(#loc278)
        %1499 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc276)
        %1500 = "ttir.reshape"(%1498, %1499) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc276)
        %1501 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1502 = "ttir.reshape"(%arg87, %1501) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1503 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1504 = "ttir.reshape"(%1502, %1503) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1505 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc279)
        %1506 = "ttir.reshape"(%1504, %1505) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc279)
        %1507 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc279)
        %1508 = "ttir.broadcast"(%1506, %1507) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc279)
        %1509 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc279)
        %1510 = "ttir.add"(%1500, %1508, %1509) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc279)
        %1511 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc280)
        %1512 = "ttir.add"(%1412, %1510, %1511) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc280)
        %1513 = ttir.empty() : tensor<2x50xbf16> loc(#loc281)
        %1514 = "ttir.sum"(%1512, %1513) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc281)
        %1515 = ttir.empty() : tensor<2x50xbf16> loc(#loc281)
        %1516 = "ttir.multiply"(%1514, %5, %1515) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc281)
        %1517 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc282)
        %1518 = "ttir.reshape"(%1516, %1517) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc282)
        %1519 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc282)
        %1520 = "ttir.broadcast"(%1518, %1519) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc282)
        %1521 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc282)
        %1522 = "ttir.subtract"(%1512, %1520, %1521) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc282)
        %1523 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc281)
        %1524 = "ttir.multiply"(%1522, %1522, %1523) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc281)
        %1525 = ttir.empty() : tensor<2x50xbf16> loc(#loc281)
        %1526 = "ttir.sum"(%1524, %1525) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc281)
        %1527 = ttir.empty() : tensor<2x50xbf16> loc(#loc281)
        %1528 = "ttir.multiply"(%1526, %5, %1527) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc281)
        %1529 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc281)
        %1530 = "ttir.reshape"(%1528, %1529) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc281)
        %1531 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc283)
        %1532 = "ttir.add"(%1530, %4, %1531) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc283)
        %1533 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc284)
        %1534 = "ttir.rsqrt"(%1532, %1533) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc284)
        %1535 = ttir.empty() : tensor<2x50xbf16> loc(#loc285)
        %1536 = "ttir.reshape"(%1534, %1535) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc285)
        %1537 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc285)
        %1538 = "ttir.reshape"(%1536, %1537) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc285)
        %1539 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc285)
        %1540 = "ttir.broadcast"(%1538, %1539) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc285)
        %1541 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc285)
        %1542 = "ttir.multiply"(%1522, %1540, %1541) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc285)
        %1543 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1544 = "ttir.reshape"(%arg86, %1543) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1545 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1546 = "ttir.reshape"(%1544, %1545) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1547 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc285)
        %1548 = "ttir.reshape"(%1546, %1547) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc285)
        %1549 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc285)
        %1550 = "ttir.broadcast"(%1548, %1549) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc285)
        %1551 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc285)
        %1552 = "ttir.multiply"(%1542, %1550, %1551) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc285)
        %1553 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1554 = "ttir.reshape"(%arg85, %1553) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1555 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1556 = "ttir.reshape"(%1554, %1555) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1557 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc283)
        %1558 = "ttir.reshape"(%1556, %1557) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc283)
        %1559 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc283)
        %1560 = "ttir.broadcast"(%1558, %1559) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc283)
        %1561 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc283)
        %1562 = "ttir.add"(%1552, %1560, %1561) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc283)
        %1563 = ttir.empty() : tensor<100x768xbf16> loc(#loc286)
        %1564 = "ttir.reshape"(%1562, %1563) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc286)
        %1565 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %1566 = "ttir.reshape"(%arg177, %1565) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %1567 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %1568 = "ttir.reshape"(%1566, %1567) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %1569 = ttir.empty() : tensor<768x768xbf16> loc(#loc287)
        %1570 = "ttir.permute"(%1568, %1569) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc287)
        %1571 = "ttir.dot_general"(%1564, %1570) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc288)
        %1572 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc286)
        %1573 = "ttir.reshape"(%1571, %1572) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc286)
        %1574 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1575 = "ttir.reshape"(%arg176, %1574) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1576 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1577 = "ttir.reshape"(%1575, %1576) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1578 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc289)
        %1579 = "ttir.reshape"(%1577, %1578) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc289)
        %1580 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc289)
        %1581 = "ttir.broadcast"(%1579, %1580) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc289)
        %1582 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc289)
        %1583 = "ttir.add"(%1573, %1581, %1582) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc289)
        %1584 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc290)
        %1585 = "ttir.reshape"(%1583, %1584) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc290)
        %1586 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc291)
        %1587 = "ttir.permute"(%1585, %1586) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc291)
        %1588 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc292)
        %1589 = "ttir.reshape"(%1587, %1588) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc292)
        %1590 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %1591 = "ttir.reshape"(%arg175, %1590) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %1592 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %1593 = "ttir.reshape"(%1591, %1592) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %1594 = ttir.empty() : tensor<768x768xbf16> loc(#loc293)
        %1595 = "ttir.permute"(%1593, %1594) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc293)
        %1596 = "ttir.dot_general"(%1564, %1595) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc294)
        %1597 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc295)
        %1598 = "ttir.reshape"(%1596, %1597) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc295)
        %1599 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1600 = "ttir.reshape"(%arg174, %1599) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1601 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1602 = "ttir.reshape"(%1600, %1601) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1603 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc296)
        %1604 = "ttir.reshape"(%1602, %1603) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc296)
        %1605 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc296)
        %1606 = "ttir.broadcast"(%1604, %1605) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc296)
        %1607 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc296)
        %1608 = "ttir.add"(%1598, %1606, %1607) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc296)
        %1609 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc297)
        %1610 = "ttir.reshape"(%1608, %1609) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc297)
        %1611 = ttir.empty() : tensor<2x12x64x50xbf16> loc(#loc298)
        %1612 = "ttir.permute"(%1610, %1611) <{permutation = array<i64: 0, 2, 3, 1>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x64x50xbf16>) -> tensor<2x12x64x50xbf16> loc(#loc298)
        %1613 = ttir.empty() : tensor<24x64x50xbf16> loc(#loc292)
        %1614 = "ttir.reshape"(%1612, %1613) <{shape = [24 : i32, 64 : i32, 50 : i32]}> : (tensor<2x12x64x50xbf16>, tensor<24x64x50xbf16>) -> tensor<24x64x50xbf16> loc(#loc292)
        %1615 = "ttir.dot_general"(%1589, %1614) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x64xbf16>, tensor<24x64x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc299)
        %1616 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc292)
        %1617 = "ttir.reshape"(%1615, %1616) <{shape = [2 : i32, 12 : i32, 50 : i32, 50 : i32]}> : (tensor<24x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc292)
        %1618 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc300)
        %1619 = "ttir.multiply"(%1617, %3, %1618) : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc300)
        %1620 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc301)
        %1621 = "ttir.typecast"(%1619, %1620) <{conservative_folding = false}> : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc301)
        %1622 = ttir.empty() : tensor<2x12x50xf32> loc(#loc302)
        %1623 = "ttir.max"(%1621, %1622) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc302)
        %1624 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc302)
        %1625 = "ttir.reshape"(%1623, %1624) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc302)
        %1626 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc302)
        %1627 = "ttir.broadcast"(%1625, %1626) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc302)
        %1628 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc302)
        %1629 = "ttir.subtract"(%1621, %1627, %1628) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc302)
        %1630 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc302)
        %1631 = "ttir.exp"(%1629, %1630) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc302)
        %1632 = ttir.empty() : tensor<2x12x50xf32> loc(#loc302)
        %1633 = "ttir.sum"(%1631, %1632) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc302)
        %1634 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc302)
        %1635 = "ttir.reshape"(%1633, %1634) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc302)
        %1636 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc302)
        %1637 = "ttir.broadcast"(%1635, %1636) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc302)
        %1638 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc302)
        %1639 = "ttir.div"(%1631, %1637, %1638) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc302)
        %1640 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc303)
        %1641 = "ttir.typecast"(%1639, %1640) <{conservative_folding = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc303)
        %1642 = ttir.empty() : tensor<24x50x50xbf16> loc(#loc304)
        %1643 = "ttir.reshape"(%1641, %1642) <{shape = [24 : i32, 50 : i32, 50 : i32]}> : (tensor<2x12x50x50xbf16>, tensor<24x50x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc304)
        %1644 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %1645 = "ttir.reshape"(%arg84, %1644) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %1646 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %1647 = "ttir.reshape"(%1645, %1646) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %1648 = ttir.empty() : tensor<768x768xbf16> loc(#loc305)
        %1649 = "ttir.permute"(%1647, %1648) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc305)
        %1650 = "ttir.dot_general"(%1564, %1649) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc306)
        %1651 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc307)
        %1652 = "ttir.reshape"(%1650, %1651) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc307)
        %1653 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1654 = "ttir.reshape"(%arg83, %1653) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1655 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1656 = "ttir.reshape"(%1654, %1655) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1657 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc308)
        %1658 = "ttir.reshape"(%1656, %1657) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc308)
        %1659 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc308)
        %1660 = "ttir.broadcast"(%1658, %1659) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc308)
        %1661 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc308)
        %1662 = "ttir.add"(%1652, %1660, %1661) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc308)
        %1663 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc309)
        %1664 = "ttir.reshape"(%1662, %1663) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc309)
        %1665 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc310)
        %1666 = "ttir.permute"(%1664, %1665) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc310)
        %1667 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc304)
        %1668 = "ttir.reshape"(%1666, %1667) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc304)
        %1669 = "ttir.dot_general"(%1643, %1668) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x50xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc311)
        %1670 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc304)
        %1671 = "ttir.reshape"(%1669, %1670) <{shape = [2 : i32, 12 : i32, 50 : i32, 64 : i32]}> : (tensor<24x50x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc304)
        %1672 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc312)
        %1673 = "ttir.permute"(%1671, %1672) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x12x50x64xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc312)
        %1674 = ttir.empty() : tensor<100x768xbf16> loc(#loc313)
        %1675 = "ttir.reshape"(%1673, %1674) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x12x64xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc313)
        %1676 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %1677 = "ttir.reshape"(%arg82, %1676) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %1678 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %1679 = "ttir.reshape"(%1677, %1678) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %1680 = ttir.empty() : tensor<768x768xbf16> loc(#loc314)
        %1681 = "ttir.permute"(%1679, %1680) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc314)
        %1682 = "ttir.dot_general"(%1675, %1681) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc315)
        %1683 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc313)
        %1684 = "ttir.reshape"(%1682, %1683) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc313)
        %1685 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1686 = "ttir.reshape"(%arg81, %1685) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1687 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1688 = "ttir.reshape"(%1686, %1687) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1689 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc316)
        %1690 = "ttir.reshape"(%1688, %1689) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc316)
        %1691 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc316)
        %1692 = "ttir.broadcast"(%1690, %1691) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc316)
        %1693 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc316)
        %1694 = "ttir.add"(%1684, %1692, %1693) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc316)
        %1695 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc317)
        %1696 = "ttir.add"(%1512, %1694, %1695) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc317)
        %1697 = ttir.empty() : tensor<2x50xbf16> loc(#loc318)
        %1698 = "ttir.sum"(%1696, %1697) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc318)
        %1699 = ttir.empty() : tensor<2x50xbf16> loc(#loc318)
        %1700 = "ttir.multiply"(%1698, %5, %1699) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc318)
        %1701 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc319)
        %1702 = "ttir.reshape"(%1700, %1701) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc319)
        %1703 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc319)
        %1704 = "ttir.broadcast"(%1702, %1703) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc319)
        %1705 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc319)
        %1706 = "ttir.subtract"(%1696, %1704, %1705) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc319)
        %1707 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc318)
        %1708 = "ttir.multiply"(%1706, %1706, %1707) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc318)
        %1709 = ttir.empty() : tensor<2x50xbf16> loc(#loc318)
        %1710 = "ttir.sum"(%1708, %1709) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc318)
        %1711 = ttir.empty() : tensor<2x50xbf16> loc(#loc318)
        %1712 = "ttir.multiply"(%1710, %5, %1711) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc318)
        %1713 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc318)
        %1714 = "ttir.reshape"(%1712, %1713) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc318)
        %1715 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc320)
        %1716 = "ttir.add"(%1714, %4, %1715) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc320)
        %1717 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc321)
        %1718 = "ttir.rsqrt"(%1716, %1717) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc321)
        %1719 = ttir.empty() : tensor<2x50xbf16> loc(#loc322)
        %1720 = "ttir.reshape"(%1718, %1719) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc322)
        %1721 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc322)
        %1722 = "ttir.reshape"(%1720, %1721) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc322)
        %1723 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc322)
        %1724 = "ttir.broadcast"(%1722, %1723) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc322)
        %1725 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc322)
        %1726 = "ttir.multiply"(%1706, %1724, %1725) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc322)
        %1727 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1728 = "ttir.reshape"(%arg80, %1727) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1729 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1730 = "ttir.reshape"(%1728, %1729) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1731 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc322)
        %1732 = "ttir.reshape"(%1730, %1731) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc322)
        %1733 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc322)
        %1734 = "ttir.broadcast"(%1732, %1733) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc322)
        %1735 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc322)
        %1736 = "ttir.multiply"(%1726, %1734, %1735) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc322)
        %1737 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1738 = "ttir.reshape"(%arg79, %1737) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1739 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1740 = "ttir.reshape"(%1738, %1739) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1741 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc320)
        %1742 = "ttir.reshape"(%1740, %1741) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc320)
        %1743 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc320)
        %1744 = "ttir.broadcast"(%1742, %1743) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc320)
        %1745 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc320)
        %1746 = "ttir.add"(%1736, %1744, %1745) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc320)
        %1747 = ttir.empty() : tensor<100x768xbf16> loc(#loc323)
        %1748 = "ttir.reshape"(%1746, %1747) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc323)
        %1749 = ttir.empty() : tensor<1x3072x768xbf16> loc(#loc2)
        %1750 = "ttir.reshape"(%arg78, %1749) <{shape = [1 : i32, 3072 : i32, 768 : i32]}> : (tensor<3072x768xbf16>, tensor<1x3072x768xbf16>) -> tensor<1x3072x768xbf16> loc(#loc2)
        %1751 = ttir.empty() : tensor<3072x768xbf16> loc(#loc2)
        %1752 = "ttir.reshape"(%1750, %1751) <{shape = [3072 : i32, 768 : i32]}> : (tensor<1x3072x768xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc2)
        %1753 = ttir.empty() : tensor<768x3072xbf16> loc(#loc324)
        %1754 = "ttir.permute"(%1752, %1753) <{permutation = array<i64: 1, 0>}> : (tensor<3072x768xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc324)
        %1755 = "ttir.dot_general"(%1748, %1754) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc325)
        %1756 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc323)
        %1757 = "ttir.reshape"(%1755, %1756) <{shape = [2 : i32, 50 : i32, 3072 : i32]}> : (tensor<100x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc323)
        %1758 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc2)
        %1759 = "ttir.reshape"(%arg77, %1758) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc2)
        %1760 = ttir.empty() : tensor<3072xbf16> loc(#loc2)
        %1761 = "ttir.reshape"(%1759, %1760) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc2)
        %1762 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc326)
        %1763 = "ttir.reshape"(%1761, %1762) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc326)
        %1764 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc326)
        %1765 = "ttir.broadcast"(%1763, %1764) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc326)
        %1766 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc326)
        %1767 = "ttir.add"(%1757, %1765, %1766) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc326)
        %1768 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc327)
        %1769 = "ttir.multiply"(%1767, %2, %1768) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc327)
        %1770 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc328)
        %1771 = "ttir.sigmoid"(%1769, %1770) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc328)
        %1772 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc327)
        %1773 = "ttir.multiply"(%1767, %1771, %1772) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc327)
        %1774 = ttir.empty() : tensor<100x3072xbf16> loc(#loc329)
        %1775 = "ttir.reshape"(%1773, %1774) <{shape = [100 : i32, 3072 : i32]}> : (tensor<2x50x3072xbf16>, tensor<100x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc329)
        %1776 = ttir.empty() : tensor<1x768x3072xbf16> loc(#loc2)
        %1777 = "ttir.reshape"(%arg76, %1776) <{shape = [1 : i32, 768 : i32, 3072 : i32]}> : (tensor<768x3072xbf16>, tensor<1x768x3072xbf16>) -> tensor<1x768x3072xbf16> loc(#loc2)
        %1778 = ttir.empty() : tensor<768x3072xbf16> loc(#loc2)
        %1779 = "ttir.reshape"(%1777, %1778) <{shape = [768 : i32, 3072 : i32]}> : (tensor<1x768x3072xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc2)
        %1780 = ttir.empty() : tensor<3072x768xbf16> loc(#loc330)
        %1781 = "ttir.permute"(%1779, %1780) <{permutation = array<i64: 1, 0>}> : (tensor<768x3072xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc330)
        %1782 = "ttir.dot_general"(%1775, %1781) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x3072xbf16>, tensor<3072x768xbf16>) -> tensor<100x768xbf16> loc(#loc331)
        %1783 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc329)
        %1784 = "ttir.reshape"(%1782, %1783) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc329)
        %1785 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1786 = "ttir.reshape"(%arg75, %1785) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1787 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1788 = "ttir.reshape"(%1786, %1787) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1789 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc332)
        %1790 = "ttir.reshape"(%1788, %1789) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc332)
        %1791 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc332)
        %1792 = "ttir.broadcast"(%1790, %1791) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc332)
        %1793 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc332)
        %1794 = "ttir.add"(%1784, %1792, %1793) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc332)
        %1795 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc333)
        %1796 = "ttir.add"(%1696, %1794, %1795) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc333)
        %1797 = ttir.empty() : tensor<2x50xbf16> loc(#loc334)
        %1798 = "ttir.sum"(%1796, %1797) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc334)
        %1799 = ttir.empty() : tensor<2x50xbf16> loc(#loc334)
        %1800 = "ttir.multiply"(%1798, %5, %1799) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc334)
        %1801 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc335)
        %1802 = "ttir.reshape"(%1800, %1801) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc335)
        %1803 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc335)
        %1804 = "ttir.broadcast"(%1802, %1803) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc335)
        %1805 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc335)
        %1806 = "ttir.subtract"(%1796, %1804, %1805) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc335)
        %1807 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc334)
        %1808 = "ttir.multiply"(%1806, %1806, %1807) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc334)
        %1809 = ttir.empty() : tensor<2x50xbf16> loc(#loc334)
        %1810 = "ttir.sum"(%1808, %1809) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc334)
        %1811 = ttir.empty() : tensor<2x50xbf16> loc(#loc334)
        %1812 = "ttir.multiply"(%1810, %5, %1811) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc334)
        %1813 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc334)
        %1814 = "ttir.reshape"(%1812, %1813) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc334)
        %1815 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc336)
        %1816 = "ttir.add"(%1814, %4, %1815) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc336)
        %1817 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc337)
        %1818 = "ttir.rsqrt"(%1816, %1817) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc337)
        %1819 = ttir.empty() : tensor<2x50xbf16> loc(#loc338)
        %1820 = "ttir.reshape"(%1818, %1819) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc338)
        %1821 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc338)
        %1822 = "ttir.reshape"(%1820, %1821) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc338)
        %1823 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc338)
        %1824 = "ttir.broadcast"(%1822, %1823) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc338)
        %1825 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc338)
        %1826 = "ttir.multiply"(%1806, %1824, %1825) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc338)
        %1827 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1828 = "ttir.reshape"(%arg74, %1827) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1829 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1830 = "ttir.reshape"(%1828, %1829) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1831 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc338)
        %1832 = "ttir.reshape"(%1830, %1831) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc338)
        %1833 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc338)
        %1834 = "ttir.broadcast"(%1832, %1833) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc338)
        %1835 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc338)
        %1836 = "ttir.multiply"(%1826, %1834, %1835) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc338)
        %1837 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1838 = "ttir.reshape"(%arg73, %1837) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1839 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1840 = "ttir.reshape"(%1838, %1839) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1841 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc336)
        %1842 = "ttir.reshape"(%1840, %1841) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc336)
        %1843 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc336)
        %1844 = "ttir.broadcast"(%1842, %1843) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc336)
        %1845 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc336)
        %1846 = "ttir.add"(%1836, %1844, %1845) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc336)
        %1847 = ttir.empty() : tensor<100x768xbf16> loc(#loc339)
        %1848 = "ttir.reshape"(%1846, %1847) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc339)
        %1849 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %1850 = "ttir.reshape"(%arg181, %1849) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %1851 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %1852 = "ttir.reshape"(%1850, %1851) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %1853 = ttir.empty() : tensor<768x768xbf16> loc(#loc340)
        %1854 = "ttir.permute"(%1852, %1853) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc340)
        %1855 = "ttir.dot_general"(%1848, %1854) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc341)
        %1856 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc339)
        %1857 = "ttir.reshape"(%1855, %1856) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc339)
        %1858 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1859 = "ttir.reshape"(%arg180, %1858) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1860 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1861 = "ttir.reshape"(%1859, %1860) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1862 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc342)
        %1863 = "ttir.reshape"(%1861, %1862) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc342)
        %1864 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc342)
        %1865 = "ttir.broadcast"(%1863, %1864) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc342)
        %1866 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc342)
        %1867 = "ttir.add"(%1857, %1865, %1866) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc342)
        %1868 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc343)
        %1869 = "ttir.reshape"(%1867, %1868) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc343)
        %1870 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc344)
        %1871 = "ttir.permute"(%1869, %1870) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc344)
        %1872 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc345)
        %1873 = "ttir.reshape"(%1871, %1872) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc345)
        %1874 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %1875 = "ttir.reshape"(%arg179, %1874) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %1876 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %1877 = "ttir.reshape"(%1875, %1876) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %1878 = ttir.empty() : tensor<768x768xbf16> loc(#loc346)
        %1879 = "ttir.permute"(%1877, %1878) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc346)
        %1880 = "ttir.dot_general"(%1848, %1879) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc347)
        %1881 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc348)
        %1882 = "ttir.reshape"(%1880, %1881) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc348)
        %1883 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1884 = "ttir.reshape"(%arg178, %1883) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1885 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1886 = "ttir.reshape"(%1884, %1885) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1887 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc349)
        %1888 = "ttir.reshape"(%1886, %1887) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc349)
        %1889 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc349)
        %1890 = "ttir.broadcast"(%1888, %1889) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc349)
        %1891 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc349)
        %1892 = "ttir.add"(%1882, %1890, %1891) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc349)
        %1893 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc350)
        %1894 = "ttir.reshape"(%1892, %1893) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc350)
        %1895 = ttir.empty() : tensor<2x12x64x50xbf16> loc(#loc351)
        %1896 = "ttir.permute"(%1894, %1895) <{permutation = array<i64: 0, 2, 3, 1>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x64x50xbf16>) -> tensor<2x12x64x50xbf16> loc(#loc351)
        %1897 = ttir.empty() : tensor<24x64x50xbf16> loc(#loc345)
        %1898 = "ttir.reshape"(%1896, %1897) <{shape = [24 : i32, 64 : i32, 50 : i32]}> : (tensor<2x12x64x50xbf16>, tensor<24x64x50xbf16>) -> tensor<24x64x50xbf16> loc(#loc345)
        %1899 = "ttir.dot_general"(%1873, %1898) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x64xbf16>, tensor<24x64x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc352)
        %1900 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc345)
        %1901 = "ttir.reshape"(%1899, %1900) <{shape = [2 : i32, 12 : i32, 50 : i32, 50 : i32]}> : (tensor<24x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc345)
        %1902 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc353)
        %1903 = "ttir.multiply"(%1901, %3, %1902) : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc353)
        %1904 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc354)
        %1905 = "ttir.typecast"(%1903, %1904) <{conservative_folding = false}> : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc354)
        %1906 = ttir.empty() : tensor<2x12x50xf32> loc(#loc355)
        %1907 = "ttir.max"(%1905, %1906) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc355)
        %1908 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc355)
        %1909 = "ttir.reshape"(%1907, %1908) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc355)
        %1910 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc355)
        %1911 = "ttir.broadcast"(%1909, %1910) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc355)
        %1912 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc355)
        %1913 = "ttir.subtract"(%1905, %1911, %1912) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc355)
        %1914 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc355)
        %1915 = "ttir.exp"(%1913, %1914) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc355)
        %1916 = ttir.empty() : tensor<2x12x50xf32> loc(#loc355)
        %1917 = "ttir.sum"(%1915, %1916) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc355)
        %1918 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc355)
        %1919 = "ttir.reshape"(%1917, %1918) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc355)
        %1920 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc355)
        %1921 = "ttir.broadcast"(%1919, %1920) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc355)
        %1922 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc355)
        %1923 = "ttir.div"(%1915, %1921, %1922) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc355)
        %1924 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc356)
        %1925 = "ttir.typecast"(%1923, %1924) <{conservative_folding = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc356)
        %1926 = ttir.empty() : tensor<24x50x50xbf16> loc(#loc357)
        %1927 = "ttir.reshape"(%1925, %1926) <{shape = [24 : i32, 50 : i32, 50 : i32]}> : (tensor<2x12x50x50xbf16>, tensor<24x50x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc357)
        %1928 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %1929 = "ttir.reshape"(%arg72, %1928) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %1930 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %1931 = "ttir.reshape"(%1929, %1930) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %1932 = ttir.empty() : tensor<768x768xbf16> loc(#loc358)
        %1933 = "ttir.permute"(%1931, %1932) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc358)
        %1934 = "ttir.dot_general"(%1848, %1933) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc359)
        %1935 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc360)
        %1936 = "ttir.reshape"(%1934, %1935) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc360)
        %1937 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1938 = "ttir.reshape"(%arg71, %1937) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1939 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1940 = "ttir.reshape"(%1938, %1939) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1941 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc361)
        %1942 = "ttir.reshape"(%1940, %1941) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc361)
        %1943 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc361)
        %1944 = "ttir.broadcast"(%1942, %1943) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc361)
        %1945 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc361)
        %1946 = "ttir.add"(%1936, %1944, %1945) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc361)
        %1947 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc362)
        %1948 = "ttir.reshape"(%1946, %1947) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc362)
        %1949 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc363)
        %1950 = "ttir.permute"(%1948, %1949) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc363)
        %1951 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc357)
        %1952 = "ttir.reshape"(%1950, %1951) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc357)
        %1953 = "ttir.dot_general"(%1927, %1952) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x50xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc364)
        %1954 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc357)
        %1955 = "ttir.reshape"(%1953, %1954) <{shape = [2 : i32, 12 : i32, 50 : i32, 64 : i32]}> : (tensor<24x50x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc357)
        %1956 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc365)
        %1957 = "ttir.permute"(%1955, %1956) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x12x50x64xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc365)
        %1958 = ttir.empty() : tensor<100x768xbf16> loc(#loc366)
        %1959 = "ttir.reshape"(%1957, %1958) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x12x64xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc366)
        %1960 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %1961 = "ttir.reshape"(%arg70, %1960) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %1962 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %1963 = "ttir.reshape"(%1961, %1962) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %1964 = ttir.empty() : tensor<768x768xbf16> loc(#loc367)
        %1965 = "ttir.permute"(%1963, %1964) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc367)
        %1966 = "ttir.dot_general"(%1959, %1965) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc368)
        %1967 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc366)
        %1968 = "ttir.reshape"(%1966, %1967) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc366)
        %1969 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %1970 = "ttir.reshape"(%arg69, %1969) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %1971 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %1972 = "ttir.reshape"(%1970, %1971) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %1973 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc369)
        %1974 = "ttir.reshape"(%1972, %1973) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc369)
        %1975 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc369)
        %1976 = "ttir.broadcast"(%1974, %1975) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc369)
        %1977 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc369)
        %1978 = "ttir.add"(%1968, %1976, %1977) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc369)
        %1979 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc370)
        %1980 = "ttir.add"(%1796, %1978, %1979) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc370)
        %1981 = ttir.empty() : tensor<2x50xbf16> loc(#loc371)
        %1982 = "ttir.sum"(%1980, %1981) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc371)
        %1983 = ttir.empty() : tensor<2x50xbf16> loc(#loc371)
        %1984 = "ttir.multiply"(%1982, %5, %1983) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc371)
        %1985 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc372)
        %1986 = "ttir.reshape"(%1984, %1985) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc372)
        %1987 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc372)
        %1988 = "ttir.broadcast"(%1986, %1987) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc372)
        %1989 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc372)
        %1990 = "ttir.subtract"(%1980, %1988, %1989) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc372)
        %1991 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc371)
        %1992 = "ttir.multiply"(%1990, %1990, %1991) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc371)
        %1993 = ttir.empty() : tensor<2x50xbf16> loc(#loc371)
        %1994 = "ttir.sum"(%1992, %1993) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc371)
        %1995 = ttir.empty() : tensor<2x50xbf16> loc(#loc371)
        %1996 = "ttir.multiply"(%1994, %5, %1995) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc371)
        %1997 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc371)
        %1998 = "ttir.reshape"(%1996, %1997) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc371)
        %1999 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc373)
        %2000 = "ttir.add"(%1998, %4, %1999) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc373)
        %2001 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc374)
        %2002 = "ttir.rsqrt"(%2000, %2001) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc374)
        %2003 = ttir.empty() : tensor<2x50xbf16> loc(#loc375)
        %2004 = "ttir.reshape"(%2002, %2003) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc375)
        %2005 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc375)
        %2006 = "ttir.reshape"(%2004, %2005) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc375)
        %2007 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc375)
        %2008 = "ttir.broadcast"(%2006, %2007) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc375)
        %2009 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc375)
        %2010 = "ttir.multiply"(%1990, %2008, %2009) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc375)
        %2011 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2012 = "ttir.reshape"(%arg68, %2011) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2013 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2014 = "ttir.reshape"(%2012, %2013) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2015 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc375)
        %2016 = "ttir.reshape"(%2014, %2015) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc375)
        %2017 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc375)
        %2018 = "ttir.broadcast"(%2016, %2017) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc375)
        %2019 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc375)
        %2020 = "ttir.multiply"(%2010, %2018, %2019) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc375)
        %2021 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2022 = "ttir.reshape"(%arg67, %2021) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2023 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2024 = "ttir.reshape"(%2022, %2023) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2025 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc373)
        %2026 = "ttir.reshape"(%2024, %2025) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc373)
        %2027 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc373)
        %2028 = "ttir.broadcast"(%2026, %2027) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc373)
        %2029 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc373)
        %2030 = "ttir.add"(%2020, %2028, %2029) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc373)
        %2031 = ttir.empty() : tensor<100x768xbf16> loc(#loc376)
        %2032 = "ttir.reshape"(%2030, %2031) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc376)
        %2033 = ttir.empty() : tensor<1x3072x768xbf16> loc(#loc2)
        %2034 = "ttir.reshape"(%arg66, %2033) <{shape = [1 : i32, 3072 : i32, 768 : i32]}> : (tensor<3072x768xbf16>, tensor<1x3072x768xbf16>) -> tensor<1x3072x768xbf16> loc(#loc2)
        %2035 = ttir.empty() : tensor<3072x768xbf16> loc(#loc2)
        %2036 = "ttir.reshape"(%2034, %2035) <{shape = [3072 : i32, 768 : i32]}> : (tensor<1x3072x768xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc2)
        %2037 = ttir.empty() : tensor<768x3072xbf16> loc(#loc377)
        %2038 = "ttir.permute"(%2036, %2037) <{permutation = array<i64: 1, 0>}> : (tensor<3072x768xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc377)
        %2039 = "ttir.dot_general"(%2032, %2038) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc378)
        %2040 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc376)
        %2041 = "ttir.reshape"(%2039, %2040) <{shape = [2 : i32, 50 : i32, 3072 : i32]}> : (tensor<100x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc376)
        %2042 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc2)
        %2043 = "ttir.reshape"(%arg65, %2042) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc2)
        %2044 = ttir.empty() : tensor<3072xbf16> loc(#loc2)
        %2045 = "ttir.reshape"(%2043, %2044) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc2)
        %2046 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc379)
        %2047 = "ttir.reshape"(%2045, %2046) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc379)
        %2048 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc379)
        %2049 = "ttir.broadcast"(%2047, %2048) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc379)
        %2050 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc379)
        %2051 = "ttir.add"(%2041, %2049, %2050) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc379)
        %2052 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc380)
        %2053 = "ttir.multiply"(%2051, %2, %2052) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc380)
        %2054 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc381)
        %2055 = "ttir.sigmoid"(%2053, %2054) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc381)
        %2056 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc380)
        %2057 = "ttir.multiply"(%2051, %2055, %2056) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc380)
        %2058 = ttir.empty() : tensor<100x3072xbf16> loc(#loc382)
        %2059 = "ttir.reshape"(%2057, %2058) <{shape = [100 : i32, 3072 : i32]}> : (tensor<2x50x3072xbf16>, tensor<100x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc382)
        %2060 = ttir.empty() : tensor<1x768x3072xbf16> loc(#loc2)
        %2061 = "ttir.reshape"(%arg64, %2060) <{shape = [1 : i32, 768 : i32, 3072 : i32]}> : (tensor<768x3072xbf16>, tensor<1x768x3072xbf16>) -> tensor<1x768x3072xbf16> loc(#loc2)
        %2062 = ttir.empty() : tensor<768x3072xbf16> loc(#loc2)
        %2063 = "ttir.reshape"(%2061, %2062) <{shape = [768 : i32, 3072 : i32]}> : (tensor<1x768x3072xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc2)
        %2064 = ttir.empty() : tensor<3072x768xbf16> loc(#loc383)
        %2065 = "ttir.permute"(%2063, %2064) <{permutation = array<i64: 1, 0>}> : (tensor<768x3072xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc383)
        %2066 = "ttir.dot_general"(%2059, %2065) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x3072xbf16>, tensor<3072x768xbf16>) -> tensor<100x768xbf16> loc(#loc384)
        %2067 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc382)
        %2068 = "ttir.reshape"(%2066, %2067) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc382)
        %2069 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2070 = "ttir.reshape"(%arg63, %2069) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2071 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2072 = "ttir.reshape"(%2070, %2071) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2073 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc385)
        %2074 = "ttir.reshape"(%2072, %2073) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc385)
        %2075 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc385)
        %2076 = "ttir.broadcast"(%2074, %2075) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc385)
        %2077 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc385)
        %2078 = "ttir.add"(%2068, %2076, %2077) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc385)
        %2079 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc386)
        %2080 = "ttir.add"(%1980, %2078, %2079) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc386)
        %2081 = ttir.empty() : tensor<2x50xbf16> loc(#loc387)
        %2082 = "ttir.sum"(%2080, %2081) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc387)
        %2083 = ttir.empty() : tensor<2x50xbf16> loc(#loc387)
        %2084 = "ttir.multiply"(%2082, %5, %2083) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc387)
        %2085 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc388)
        %2086 = "ttir.reshape"(%2084, %2085) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc388)
        %2087 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc388)
        %2088 = "ttir.broadcast"(%2086, %2087) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc388)
        %2089 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc388)
        %2090 = "ttir.subtract"(%2080, %2088, %2089) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc388)
        %2091 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc387)
        %2092 = "ttir.multiply"(%2090, %2090, %2091) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc387)
        %2093 = ttir.empty() : tensor<2x50xbf16> loc(#loc387)
        %2094 = "ttir.sum"(%2092, %2093) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc387)
        %2095 = ttir.empty() : tensor<2x50xbf16> loc(#loc387)
        %2096 = "ttir.multiply"(%2094, %5, %2095) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc387)
        %2097 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc387)
        %2098 = "ttir.reshape"(%2096, %2097) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc387)
        %2099 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc389)
        %2100 = "ttir.add"(%2098, %4, %2099) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc389)
        %2101 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc390)
        %2102 = "ttir.rsqrt"(%2100, %2101) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc390)
        %2103 = ttir.empty() : tensor<2x50xbf16> loc(#loc391)
        %2104 = "ttir.reshape"(%2102, %2103) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc391)
        %2105 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc391)
        %2106 = "ttir.reshape"(%2104, %2105) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc391)
        %2107 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc391)
        %2108 = "ttir.broadcast"(%2106, %2107) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc391)
        %2109 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc391)
        %2110 = "ttir.multiply"(%2090, %2108, %2109) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc391)
        %2111 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2112 = "ttir.reshape"(%arg62, %2111) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2113 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2114 = "ttir.reshape"(%2112, %2113) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2115 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc391)
        %2116 = "ttir.reshape"(%2114, %2115) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc391)
        %2117 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc391)
        %2118 = "ttir.broadcast"(%2116, %2117) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc391)
        %2119 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc391)
        %2120 = "ttir.multiply"(%2110, %2118, %2119) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc391)
        %2121 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2122 = "ttir.reshape"(%arg61, %2121) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2123 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2124 = "ttir.reshape"(%2122, %2123) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2125 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc389)
        %2126 = "ttir.reshape"(%2124, %2125) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc389)
        %2127 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc389)
        %2128 = "ttir.broadcast"(%2126, %2127) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc389)
        %2129 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc389)
        %2130 = "ttir.add"(%2120, %2128, %2129) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc389)
        %2131 = ttir.empty() : tensor<100x768xbf16> loc(#loc392)
        %2132 = "ttir.reshape"(%2130, %2131) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc392)
        %2133 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %2134 = "ttir.reshape"(%arg185, %2133) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %2135 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %2136 = "ttir.reshape"(%2134, %2135) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %2137 = ttir.empty() : tensor<768x768xbf16> loc(#loc393)
        %2138 = "ttir.permute"(%2136, %2137) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc393)
        %2139 = "ttir.dot_general"(%2132, %2138) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc394)
        %2140 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc392)
        %2141 = "ttir.reshape"(%2139, %2140) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc392)
        %2142 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2143 = "ttir.reshape"(%arg184, %2142) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2144 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2145 = "ttir.reshape"(%2143, %2144) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2146 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc395)
        %2147 = "ttir.reshape"(%2145, %2146) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc395)
        %2148 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc395)
        %2149 = "ttir.broadcast"(%2147, %2148) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc395)
        %2150 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc395)
        %2151 = "ttir.add"(%2141, %2149, %2150) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc395)
        %2152 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc396)
        %2153 = "ttir.reshape"(%2151, %2152) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc396)
        %2154 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc397)
        %2155 = "ttir.permute"(%2153, %2154) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc397)
        %2156 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc398)
        %2157 = "ttir.reshape"(%2155, %2156) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc398)
        %2158 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %2159 = "ttir.reshape"(%arg183, %2158) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %2160 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %2161 = "ttir.reshape"(%2159, %2160) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %2162 = ttir.empty() : tensor<768x768xbf16> loc(#loc399)
        %2163 = "ttir.permute"(%2161, %2162) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc399)
        %2164 = "ttir.dot_general"(%2132, %2163) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc400)
        %2165 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc401)
        %2166 = "ttir.reshape"(%2164, %2165) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc401)
        %2167 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2168 = "ttir.reshape"(%arg182, %2167) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2169 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2170 = "ttir.reshape"(%2168, %2169) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2171 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc402)
        %2172 = "ttir.reshape"(%2170, %2171) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc402)
        %2173 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc402)
        %2174 = "ttir.broadcast"(%2172, %2173) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc402)
        %2175 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc402)
        %2176 = "ttir.add"(%2166, %2174, %2175) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc402)
        %2177 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc403)
        %2178 = "ttir.reshape"(%2176, %2177) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc403)
        %2179 = ttir.empty() : tensor<2x12x64x50xbf16> loc(#loc404)
        %2180 = "ttir.permute"(%2178, %2179) <{permutation = array<i64: 0, 2, 3, 1>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x64x50xbf16>) -> tensor<2x12x64x50xbf16> loc(#loc404)
        %2181 = ttir.empty() : tensor<24x64x50xbf16> loc(#loc398)
        %2182 = "ttir.reshape"(%2180, %2181) <{shape = [24 : i32, 64 : i32, 50 : i32]}> : (tensor<2x12x64x50xbf16>, tensor<24x64x50xbf16>) -> tensor<24x64x50xbf16> loc(#loc398)
        %2183 = "ttir.dot_general"(%2157, %2182) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x64xbf16>, tensor<24x64x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc405)
        %2184 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc398)
        %2185 = "ttir.reshape"(%2183, %2184) <{shape = [2 : i32, 12 : i32, 50 : i32, 50 : i32]}> : (tensor<24x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc398)
        %2186 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc406)
        %2187 = "ttir.multiply"(%2185, %3, %2186) : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc406)
        %2188 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc407)
        %2189 = "ttir.typecast"(%2187, %2188) <{conservative_folding = false}> : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc407)
        %2190 = ttir.empty() : tensor<2x12x50xf32> loc(#loc408)
        %2191 = "ttir.max"(%2189, %2190) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc408)
        %2192 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc408)
        %2193 = "ttir.reshape"(%2191, %2192) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc408)
        %2194 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc408)
        %2195 = "ttir.broadcast"(%2193, %2194) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc408)
        %2196 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc408)
        %2197 = "ttir.subtract"(%2189, %2195, %2196) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc408)
        %2198 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc408)
        %2199 = "ttir.exp"(%2197, %2198) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc408)
        %2200 = ttir.empty() : tensor<2x12x50xf32> loc(#loc408)
        %2201 = "ttir.sum"(%2199, %2200) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc408)
        %2202 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc408)
        %2203 = "ttir.reshape"(%2201, %2202) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc408)
        %2204 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc408)
        %2205 = "ttir.broadcast"(%2203, %2204) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc408)
        %2206 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc408)
        %2207 = "ttir.div"(%2199, %2205, %2206) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc408)
        %2208 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc409)
        %2209 = "ttir.typecast"(%2207, %2208) <{conservative_folding = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc409)
        %2210 = ttir.empty() : tensor<24x50x50xbf16> loc(#loc410)
        %2211 = "ttir.reshape"(%2209, %2210) <{shape = [24 : i32, 50 : i32, 50 : i32]}> : (tensor<2x12x50x50xbf16>, tensor<24x50x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc410)
        %2212 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %2213 = "ttir.reshape"(%arg60, %2212) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %2214 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %2215 = "ttir.reshape"(%2213, %2214) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %2216 = ttir.empty() : tensor<768x768xbf16> loc(#loc411)
        %2217 = "ttir.permute"(%2215, %2216) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc411)
        %2218 = "ttir.dot_general"(%2132, %2217) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc412)
        %2219 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc413)
        %2220 = "ttir.reshape"(%2218, %2219) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc413)
        %2221 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2222 = "ttir.reshape"(%arg59, %2221) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2223 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2224 = "ttir.reshape"(%2222, %2223) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2225 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc414)
        %2226 = "ttir.reshape"(%2224, %2225) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc414)
        %2227 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc414)
        %2228 = "ttir.broadcast"(%2226, %2227) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc414)
        %2229 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc414)
        %2230 = "ttir.add"(%2220, %2228, %2229) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc414)
        %2231 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc415)
        %2232 = "ttir.reshape"(%2230, %2231) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc415)
        %2233 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc416)
        %2234 = "ttir.permute"(%2232, %2233) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc416)
        %2235 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc410)
        %2236 = "ttir.reshape"(%2234, %2235) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc410)
        %2237 = "ttir.dot_general"(%2211, %2236) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x50xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc417)
        %2238 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc410)
        %2239 = "ttir.reshape"(%2237, %2238) <{shape = [2 : i32, 12 : i32, 50 : i32, 64 : i32]}> : (tensor<24x50x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc410)
        %2240 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc418)
        %2241 = "ttir.permute"(%2239, %2240) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x12x50x64xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc418)
        %2242 = ttir.empty() : tensor<100x768xbf16> loc(#loc419)
        %2243 = "ttir.reshape"(%2241, %2242) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x12x64xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc419)
        %2244 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %2245 = "ttir.reshape"(%arg58, %2244) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %2246 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %2247 = "ttir.reshape"(%2245, %2246) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %2248 = ttir.empty() : tensor<768x768xbf16> loc(#loc420)
        %2249 = "ttir.permute"(%2247, %2248) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc420)
        %2250 = "ttir.dot_general"(%2243, %2249) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc421)
        %2251 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc419)
        %2252 = "ttir.reshape"(%2250, %2251) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc419)
        %2253 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2254 = "ttir.reshape"(%arg57, %2253) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2255 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2256 = "ttir.reshape"(%2254, %2255) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2257 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc422)
        %2258 = "ttir.reshape"(%2256, %2257) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc422)
        %2259 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc422)
        %2260 = "ttir.broadcast"(%2258, %2259) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc422)
        %2261 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc422)
        %2262 = "ttir.add"(%2252, %2260, %2261) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc422)
        %2263 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc423)
        %2264 = "ttir.add"(%2080, %2262, %2263) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc423)
        %2265 = ttir.empty() : tensor<2x50xbf16> loc(#loc424)
        %2266 = "ttir.sum"(%2264, %2265) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc424)
        %2267 = ttir.empty() : tensor<2x50xbf16> loc(#loc424)
        %2268 = "ttir.multiply"(%2266, %5, %2267) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc424)
        %2269 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc425)
        %2270 = "ttir.reshape"(%2268, %2269) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc425)
        %2271 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc425)
        %2272 = "ttir.broadcast"(%2270, %2271) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc425)
        %2273 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc425)
        %2274 = "ttir.subtract"(%2264, %2272, %2273) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc425)
        %2275 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc424)
        %2276 = "ttir.multiply"(%2274, %2274, %2275) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc424)
        %2277 = ttir.empty() : tensor<2x50xbf16> loc(#loc424)
        %2278 = "ttir.sum"(%2276, %2277) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc424)
        %2279 = ttir.empty() : tensor<2x50xbf16> loc(#loc424)
        %2280 = "ttir.multiply"(%2278, %5, %2279) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc424)
        %2281 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc424)
        %2282 = "ttir.reshape"(%2280, %2281) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc424)
        %2283 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc426)
        %2284 = "ttir.add"(%2282, %4, %2283) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc426)
        %2285 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc427)
        %2286 = "ttir.rsqrt"(%2284, %2285) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc427)
        %2287 = ttir.empty() : tensor<2x50xbf16> loc(#loc428)
        %2288 = "ttir.reshape"(%2286, %2287) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc428)
        %2289 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc428)
        %2290 = "ttir.reshape"(%2288, %2289) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc428)
        %2291 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc428)
        %2292 = "ttir.broadcast"(%2290, %2291) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc428)
        %2293 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc428)
        %2294 = "ttir.multiply"(%2274, %2292, %2293) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc428)
        %2295 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2296 = "ttir.reshape"(%arg56, %2295) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2297 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2298 = "ttir.reshape"(%2296, %2297) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2299 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc428)
        %2300 = "ttir.reshape"(%2298, %2299) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc428)
        %2301 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc428)
        %2302 = "ttir.broadcast"(%2300, %2301) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc428)
        %2303 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc428)
        %2304 = "ttir.multiply"(%2294, %2302, %2303) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc428)
        %2305 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2306 = "ttir.reshape"(%arg55, %2305) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2307 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2308 = "ttir.reshape"(%2306, %2307) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2309 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc426)
        %2310 = "ttir.reshape"(%2308, %2309) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc426)
        %2311 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc426)
        %2312 = "ttir.broadcast"(%2310, %2311) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc426)
        %2313 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc426)
        %2314 = "ttir.add"(%2304, %2312, %2313) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc426)
        %2315 = ttir.empty() : tensor<100x768xbf16> loc(#loc429)
        %2316 = "ttir.reshape"(%2314, %2315) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc429)
        %2317 = ttir.empty() : tensor<1x3072x768xbf16> loc(#loc2)
        %2318 = "ttir.reshape"(%arg54, %2317) <{shape = [1 : i32, 3072 : i32, 768 : i32]}> : (tensor<3072x768xbf16>, tensor<1x3072x768xbf16>) -> tensor<1x3072x768xbf16> loc(#loc2)
        %2319 = ttir.empty() : tensor<3072x768xbf16> loc(#loc2)
        %2320 = "ttir.reshape"(%2318, %2319) <{shape = [3072 : i32, 768 : i32]}> : (tensor<1x3072x768xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc2)
        %2321 = ttir.empty() : tensor<768x3072xbf16> loc(#loc430)
        %2322 = "ttir.permute"(%2320, %2321) <{permutation = array<i64: 1, 0>}> : (tensor<3072x768xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc430)
        %2323 = "ttir.dot_general"(%2316, %2322) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc431)
        %2324 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc429)
        %2325 = "ttir.reshape"(%2323, %2324) <{shape = [2 : i32, 50 : i32, 3072 : i32]}> : (tensor<100x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc429)
        %2326 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc2)
        %2327 = "ttir.reshape"(%arg53, %2326) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc2)
        %2328 = ttir.empty() : tensor<3072xbf16> loc(#loc2)
        %2329 = "ttir.reshape"(%2327, %2328) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc2)
        %2330 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc432)
        %2331 = "ttir.reshape"(%2329, %2330) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc432)
        %2332 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc432)
        %2333 = "ttir.broadcast"(%2331, %2332) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc432)
        %2334 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc432)
        %2335 = "ttir.add"(%2325, %2333, %2334) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc432)
        %2336 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc433)
        %2337 = "ttir.multiply"(%2335, %2, %2336) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc433)
        %2338 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc434)
        %2339 = "ttir.sigmoid"(%2337, %2338) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc434)
        %2340 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc433)
        %2341 = "ttir.multiply"(%2335, %2339, %2340) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc433)
        %2342 = ttir.empty() : tensor<100x3072xbf16> loc(#loc435)
        %2343 = "ttir.reshape"(%2341, %2342) <{shape = [100 : i32, 3072 : i32]}> : (tensor<2x50x3072xbf16>, tensor<100x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc435)
        %2344 = ttir.empty() : tensor<1x768x3072xbf16> loc(#loc2)
        %2345 = "ttir.reshape"(%arg52, %2344) <{shape = [1 : i32, 768 : i32, 3072 : i32]}> : (tensor<768x3072xbf16>, tensor<1x768x3072xbf16>) -> tensor<1x768x3072xbf16> loc(#loc2)
        %2346 = ttir.empty() : tensor<768x3072xbf16> loc(#loc2)
        %2347 = "ttir.reshape"(%2345, %2346) <{shape = [768 : i32, 3072 : i32]}> : (tensor<1x768x3072xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc2)
        %2348 = ttir.empty() : tensor<3072x768xbf16> loc(#loc436)
        %2349 = "ttir.permute"(%2347, %2348) <{permutation = array<i64: 1, 0>}> : (tensor<768x3072xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc436)
        %2350 = "ttir.dot_general"(%2343, %2349) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x3072xbf16>, tensor<3072x768xbf16>) -> tensor<100x768xbf16> loc(#loc437)
        %2351 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc435)
        %2352 = "ttir.reshape"(%2350, %2351) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc435)
        %2353 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2354 = "ttir.reshape"(%arg51, %2353) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2355 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2356 = "ttir.reshape"(%2354, %2355) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2357 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc438)
        %2358 = "ttir.reshape"(%2356, %2357) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc438)
        %2359 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc438)
        %2360 = "ttir.broadcast"(%2358, %2359) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc438)
        %2361 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc438)
        %2362 = "ttir.add"(%2352, %2360, %2361) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc438)
        %2363 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc439)
        %2364 = "ttir.add"(%2264, %2362, %2363) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc439)
        %2365 = ttir.empty() : tensor<2x50xbf16> loc(#loc440)
        %2366 = "ttir.sum"(%2364, %2365) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc440)
        %2367 = ttir.empty() : tensor<2x50xbf16> loc(#loc440)
        %2368 = "ttir.multiply"(%2366, %5, %2367) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc440)
        %2369 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc441)
        %2370 = "ttir.reshape"(%2368, %2369) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc441)
        %2371 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc441)
        %2372 = "ttir.broadcast"(%2370, %2371) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc441)
        %2373 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc441)
        %2374 = "ttir.subtract"(%2364, %2372, %2373) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc441)
        %2375 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc440)
        %2376 = "ttir.multiply"(%2374, %2374, %2375) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc440)
        %2377 = ttir.empty() : tensor<2x50xbf16> loc(#loc440)
        %2378 = "ttir.sum"(%2376, %2377) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc440)
        %2379 = ttir.empty() : tensor<2x50xbf16> loc(#loc440)
        %2380 = "ttir.multiply"(%2378, %5, %2379) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc440)
        %2381 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc440)
        %2382 = "ttir.reshape"(%2380, %2381) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc440)
        %2383 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc442)
        %2384 = "ttir.add"(%2382, %4, %2383) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc442)
        %2385 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc443)
        %2386 = "ttir.rsqrt"(%2384, %2385) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc443)
        %2387 = ttir.empty() : tensor<2x50xbf16> loc(#loc444)
        %2388 = "ttir.reshape"(%2386, %2387) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc444)
        %2389 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc444)
        %2390 = "ttir.reshape"(%2388, %2389) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc444)
        %2391 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc444)
        %2392 = "ttir.broadcast"(%2390, %2391) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc444)
        %2393 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc444)
        %2394 = "ttir.multiply"(%2374, %2392, %2393) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc444)
        %2395 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2396 = "ttir.reshape"(%arg50, %2395) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2397 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2398 = "ttir.reshape"(%2396, %2397) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2399 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc444)
        %2400 = "ttir.reshape"(%2398, %2399) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc444)
        %2401 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc444)
        %2402 = "ttir.broadcast"(%2400, %2401) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc444)
        %2403 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc444)
        %2404 = "ttir.multiply"(%2394, %2402, %2403) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc444)
        %2405 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2406 = "ttir.reshape"(%arg49, %2405) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2407 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2408 = "ttir.reshape"(%2406, %2407) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2409 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc442)
        %2410 = "ttir.reshape"(%2408, %2409) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc442)
        %2411 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc442)
        %2412 = "ttir.broadcast"(%2410, %2411) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc442)
        %2413 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc442)
        %2414 = "ttir.add"(%2404, %2412, %2413) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc442)
        %2415 = ttir.empty() : tensor<100x768xbf16> loc(#loc445)
        %2416 = "ttir.reshape"(%2414, %2415) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc445)
        %2417 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %2418 = "ttir.reshape"(%arg189, %2417) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %2419 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %2420 = "ttir.reshape"(%2418, %2419) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %2421 = ttir.empty() : tensor<768x768xbf16> loc(#loc446)
        %2422 = "ttir.permute"(%2420, %2421) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc446)
        %2423 = "ttir.dot_general"(%2416, %2422) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc447)
        %2424 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc445)
        %2425 = "ttir.reshape"(%2423, %2424) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc445)
        %2426 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2427 = "ttir.reshape"(%arg188, %2426) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2428 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2429 = "ttir.reshape"(%2427, %2428) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2430 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc448)
        %2431 = "ttir.reshape"(%2429, %2430) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc448)
        %2432 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc448)
        %2433 = "ttir.broadcast"(%2431, %2432) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc448)
        %2434 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc448)
        %2435 = "ttir.add"(%2425, %2433, %2434) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc448)
        %2436 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc449)
        %2437 = "ttir.reshape"(%2435, %2436) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc449)
        %2438 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc450)
        %2439 = "ttir.permute"(%2437, %2438) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc450)
        %2440 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc451)
        %2441 = "ttir.reshape"(%2439, %2440) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc451)
        %2442 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %2443 = "ttir.reshape"(%arg187, %2442) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %2444 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %2445 = "ttir.reshape"(%2443, %2444) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %2446 = ttir.empty() : tensor<768x768xbf16> loc(#loc452)
        %2447 = "ttir.permute"(%2445, %2446) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc452)
        %2448 = "ttir.dot_general"(%2416, %2447) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc453)
        %2449 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc454)
        %2450 = "ttir.reshape"(%2448, %2449) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc454)
        %2451 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2452 = "ttir.reshape"(%arg186, %2451) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2453 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2454 = "ttir.reshape"(%2452, %2453) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2455 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc455)
        %2456 = "ttir.reshape"(%2454, %2455) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc455)
        %2457 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc455)
        %2458 = "ttir.broadcast"(%2456, %2457) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc455)
        %2459 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc455)
        %2460 = "ttir.add"(%2450, %2458, %2459) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc455)
        %2461 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc456)
        %2462 = "ttir.reshape"(%2460, %2461) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc456)
        %2463 = ttir.empty() : tensor<2x12x64x50xbf16> loc(#loc457)
        %2464 = "ttir.permute"(%2462, %2463) <{permutation = array<i64: 0, 2, 3, 1>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x64x50xbf16>) -> tensor<2x12x64x50xbf16> loc(#loc457)
        %2465 = ttir.empty() : tensor<24x64x50xbf16> loc(#loc451)
        %2466 = "ttir.reshape"(%2464, %2465) <{shape = [24 : i32, 64 : i32, 50 : i32]}> : (tensor<2x12x64x50xbf16>, tensor<24x64x50xbf16>) -> tensor<24x64x50xbf16> loc(#loc451)
        %2467 = "ttir.dot_general"(%2441, %2466) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x64xbf16>, tensor<24x64x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc458)
        %2468 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc451)
        %2469 = "ttir.reshape"(%2467, %2468) <{shape = [2 : i32, 12 : i32, 50 : i32, 50 : i32]}> : (tensor<24x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc451)
        %2470 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc459)
        %2471 = "ttir.multiply"(%2469, %3, %2470) : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc459)
        %2472 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc460)
        %2473 = "ttir.typecast"(%2471, %2472) <{conservative_folding = false}> : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc460)
        %2474 = ttir.empty() : tensor<2x12x50xf32> loc(#loc461)
        %2475 = "ttir.max"(%2473, %2474) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc461)
        %2476 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc461)
        %2477 = "ttir.reshape"(%2475, %2476) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc461)
        %2478 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc461)
        %2479 = "ttir.broadcast"(%2477, %2478) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc461)
        %2480 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc461)
        %2481 = "ttir.subtract"(%2473, %2479, %2480) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc461)
        %2482 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc461)
        %2483 = "ttir.exp"(%2481, %2482) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc461)
        %2484 = ttir.empty() : tensor<2x12x50xf32> loc(#loc461)
        %2485 = "ttir.sum"(%2483, %2484) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc461)
        %2486 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc461)
        %2487 = "ttir.reshape"(%2485, %2486) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc461)
        %2488 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc461)
        %2489 = "ttir.broadcast"(%2487, %2488) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc461)
        %2490 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc461)
        %2491 = "ttir.div"(%2483, %2489, %2490) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc461)
        %2492 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc462)
        %2493 = "ttir.typecast"(%2491, %2492) <{conservative_folding = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc462)
        %2494 = ttir.empty() : tensor<24x50x50xbf16> loc(#loc463)
        %2495 = "ttir.reshape"(%2493, %2494) <{shape = [24 : i32, 50 : i32, 50 : i32]}> : (tensor<2x12x50x50xbf16>, tensor<24x50x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc463)
        %2496 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %2497 = "ttir.reshape"(%arg48, %2496) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %2498 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %2499 = "ttir.reshape"(%2497, %2498) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %2500 = ttir.empty() : tensor<768x768xbf16> loc(#loc464)
        %2501 = "ttir.permute"(%2499, %2500) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc464)
        %2502 = "ttir.dot_general"(%2416, %2501) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc465)
        %2503 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc466)
        %2504 = "ttir.reshape"(%2502, %2503) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc466)
        %2505 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2506 = "ttir.reshape"(%arg47, %2505) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2507 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2508 = "ttir.reshape"(%2506, %2507) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2509 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc467)
        %2510 = "ttir.reshape"(%2508, %2509) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc467)
        %2511 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc467)
        %2512 = "ttir.broadcast"(%2510, %2511) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc467)
        %2513 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc467)
        %2514 = "ttir.add"(%2504, %2512, %2513) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc467)
        %2515 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc468)
        %2516 = "ttir.reshape"(%2514, %2515) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc468)
        %2517 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc469)
        %2518 = "ttir.permute"(%2516, %2517) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc469)
        %2519 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc463)
        %2520 = "ttir.reshape"(%2518, %2519) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc463)
        %2521 = "ttir.dot_general"(%2495, %2520) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x50xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc470)
        %2522 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc463)
        %2523 = "ttir.reshape"(%2521, %2522) <{shape = [2 : i32, 12 : i32, 50 : i32, 64 : i32]}> : (tensor<24x50x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc463)
        %2524 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc471)
        %2525 = "ttir.permute"(%2523, %2524) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x12x50x64xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc471)
        %2526 = ttir.empty() : tensor<100x768xbf16> loc(#loc472)
        %2527 = "ttir.reshape"(%2525, %2526) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x12x64xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc472)
        %2528 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %2529 = "ttir.reshape"(%arg46, %2528) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %2530 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %2531 = "ttir.reshape"(%2529, %2530) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %2532 = ttir.empty() : tensor<768x768xbf16> loc(#loc473)
        %2533 = "ttir.permute"(%2531, %2532) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc473)
        %2534 = "ttir.dot_general"(%2527, %2533) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc474)
        %2535 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc472)
        %2536 = "ttir.reshape"(%2534, %2535) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc472)
        %2537 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2538 = "ttir.reshape"(%arg45, %2537) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2539 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2540 = "ttir.reshape"(%2538, %2539) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2541 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc475)
        %2542 = "ttir.reshape"(%2540, %2541) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc475)
        %2543 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc475)
        %2544 = "ttir.broadcast"(%2542, %2543) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc475)
        %2545 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc475)
        %2546 = "ttir.add"(%2536, %2544, %2545) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc475)
        %2547 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc476)
        %2548 = "ttir.add"(%2364, %2546, %2547) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc476)
        %2549 = ttir.empty() : tensor<2x50xbf16> loc(#loc477)
        %2550 = "ttir.sum"(%2548, %2549) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc477)
        %2551 = ttir.empty() : tensor<2x50xbf16> loc(#loc477)
        %2552 = "ttir.multiply"(%2550, %5, %2551) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc477)
        %2553 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc478)
        %2554 = "ttir.reshape"(%2552, %2553) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc478)
        %2555 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc478)
        %2556 = "ttir.broadcast"(%2554, %2555) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc478)
        %2557 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc478)
        %2558 = "ttir.subtract"(%2548, %2556, %2557) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc478)
        %2559 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc477)
        %2560 = "ttir.multiply"(%2558, %2558, %2559) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc477)
        %2561 = ttir.empty() : tensor<2x50xbf16> loc(#loc477)
        %2562 = "ttir.sum"(%2560, %2561) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc477)
        %2563 = ttir.empty() : tensor<2x50xbf16> loc(#loc477)
        %2564 = "ttir.multiply"(%2562, %5, %2563) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc477)
        %2565 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc477)
        %2566 = "ttir.reshape"(%2564, %2565) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc477)
        %2567 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc479)
        %2568 = "ttir.add"(%2566, %4, %2567) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc479)
        %2569 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc480)
        %2570 = "ttir.rsqrt"(%2568, %2569) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc480)
        %2571 = ttir.empty() : tensor<2x50xbf16> loc(#loc481)
        %2572 = "ttir.reshape"(%2570, %2571) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc481)
        %2573 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc481)
        %2574 = "ttir.reshape"(%2572, %2573) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc481)
        %2575 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc481)
        %2576 = "ttir.broadcast"(%2574, %2575) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc481)
        %2577 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc481)
        %2578 = "ttir.multiply"(%2558, %2576, %2577) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc481)
        %2579 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2580 = "ttir.reshape"(%arg44, %2579) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2581 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2582 = "ttir.reshape"(%2580, %2581) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2583 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc481)
        %2584 = "ttir.reshape"(%2582, %2583) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc481)
        %2585 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc481)
        %2586 = "ttir.broadcast"(%2584, %2585) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc481)
        %2587 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc481)
        %2588 = "ttir.multiply"(%2578, %2586, %2587) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc481)
        %2589 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2590 = "ttir.reshape"(%arg43, %2589) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2591 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2592 = "ttir.reshape"(%2590, %2591) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2593 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc479)
        %2594 = "ttir.reshape"(%2592, %2593) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc479)
        %2595 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc479)
        %2596 = "ttir.broadcast"(%2594, %2595) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc479)
        %2597 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc479)
        %2598 = "ttir.add"(%2588, %2596, %2597) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc479)
        %2599 = ttir.empty() : tensor<100x768xbf16> loc(#loc482)
        %2600 = "ttir.reshape"(%2598, %2599) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc482)
        %2601 = ttir.empty() : tensor<1x3072x768xbf16> loc(#loc2)
        %2602 = "ttir.reshape"(%arg42, %2601) <{shape = [1 : i32, 3072 : i32, 768 : i32]}> : (tensor<3072x768xbf16>, tensor<1x3072x768xbf16>) -> tensor<1x3072x768xbf16> loc(#loc2)
        %2603 = ttir.empty() : tensor<3072x768xbf16> loc(#loc2)
        %2604 = "ttir.reshape"(%2602, %2603) <{shape = [3072 : i32, 768 : i32]}> : (tensor<1x3072x768xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc2)
        %2605 = ttir.empty() : tensor<768x3072xbf16> loc(#loc483)
        %2606 = "ttir.permute"(%2604, %2605) <{permutation = array<i64: 1, 0>}> : (tensor<3072x768xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc483)
        %2607 = "ttir.dot_general"(%2600, %2606) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc484)
        %2608 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc482)
        %2609 = "ttir.reshape"(%2607, %2608) <{shape = [2 : i32, 50 : i32, 3072 : i32]}> : (tensor<100x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc482)
        %2610 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc2)
        %2611 = "ttir.reshape"(%arg41, %2610) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc2)
        %2612 = ttir.empty() : tensor<3072xbf16> loc(#loc2)
        %2613 = "ttir.reshape"(%2611, %2612) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc2)
        %2614 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc485)
        %2615 = "ttir.reshape"(%2613, %2614) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc485)
        %2616 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc485)
        %2617 = "ttir.broadcast"(%2615, %2616) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc485)
        %2618 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc485)
        %2619 = "ttir.add"(%2609, %2617, %2618) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc485)
        %2620 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc486)
        %2621 = "ttir.multiply"(%2619, %2, %2620) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc486)
        %2622 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc487)
        %2623 = "ttir.sigmoid"(%2621, %2622) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc487)
        %2624 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc486)
        %2625 = "ttir.multiply"(%2619, %2623, %2624) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc486)
        %2626 = ttir.empty() : tensor<100x3072xbf16> loc(#loc488)
        %2627 = "ttir.reshape"(%2625, %2626) <{shape = [100 : i32, 3072 : i32]}> : (tensor<2x50x3072xbf16>, tensor<100x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc488)
        %2628 = ttir.empty() : tensor<1x768x3072xbf16> loc(#loc2)
        %2629 = "ttir.reshape"(%arg40, %2628) <{shape = [1 : i32, 768 : i32, 3072 : i32]}> : (tensor<768x3072xbf16>, tensor<1x768x3072xbf16>) -> tensor<1x768x3072xbf16> loc(#loc2)
        %2630 = ttir.empty() : tensor<768x3072xbf16> loc(#loc2)
        %2631 = "ttir.reshape"(%2629, %2630) <{shape = [768 : i32, 3072 : i32]}> : (tensor<1x768x3072xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc2)
        %2632 = ttir.empty() : tensor<3072x768xbf16> loc(#loc489)
        %2633 = "ttir.permute"(%2631, %2632) <{permutation = array<i64: 1, 0>}> : (tensor<768x3072xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc489)
        %2634 = "ttir.dot_general"(%2627, %2633) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x3072xbf16>, tensor<3072x768xbf16>) -> tensor<100x768xbf16> loc(#loc490)
        %2635 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc488)
        %2636 = "ttir.reshape"(%2634, %2635) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc488)
        %2637 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2638 = "ttir.reshape"(%arg39, %2637) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2639 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2640 = "ttir.reshape"(%2638, %2639) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2641 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc491)
        %2642 = "ttir.reshape"(%2640, %2641) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc491)
        %2643 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc491)
        %2644 = "ttir.broadcast"(%2642, %2643) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc491)
        %2645 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc491)
        %2646 = "ttir.add"(%2636, %2644, %2645) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc491)
        %2647 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc492)
        %2648 = "ttir.add"(%2548, %2646, %2647) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc492)
        %2649 = ttir.empty() : tensor<2x50xbf16> loc(#loc493)
        %2650 = "ttir.sum"(%2648, %2649) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc493)
        %2651 = ttir.empty() : tensor<2x50xbf16> loc(#loc493)
        %2652 = "ttir.multiply"(%2650, %5, %2651) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc493)
        %2653 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc494)
        %2654 = "ttir.reshape"(%2652, %2653) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc494)
        %2655 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc494)
        %2656 = "ttir.broadcast"(%2654, %2655) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc494)
        %2657 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc494)
        %2658 = "ttir.subtract"(%2648, %2656, %2657) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc494)
        %2659 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc493)
        %2660 = "ttir.multiply"(%2658, %2658, %2659) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc493)
        %2661 = ttir.empty() : tensor<2x50xbf16> loc(#loc493)
        %2662 = "ttir.sum"(%2660, %2661) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc493)
        %2663 = ttir.empty() : tensor<2x50xbf16> loc(#loc493)
        %2664 = "ttir.multiply"(%2662, %5, %2663) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc493)
        %2665 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc493)
        %2666 = "ttir.reshape"(%2664, %2665) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc493)
        %2667 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc495)
        %2668 = "ttir.add"(%2666, %4, %2667) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc495)
        %2669 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc496)
        %2670 = "ttir.rsqrt"(%2668, %2669) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc496)
        %2671 = ttir.empty() : tensor<2x50xbf16> loc(#loc497)
        %2672 = "ttir.reshape"(%2670, %2671) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc497)
        %2673 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc497)
        %2674 = "ttir.reshape"(%2672, %2673) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc497)
        %2675 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc497)
        %2676 = "ttir.broadcast"(%2674, %2675) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc497)
        %2677 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc497)
        %2678 = "ttir.multiply"(%2658, %2676, %2677) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc497)
        %2679 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2680 = "ttir.reshape"(%arg38, %2679) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2681 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2682 = "ttir.reshape"(%2680, %2681) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2683 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc497)
        %2684 = "ttir.reshape"(%2682, %2683) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc497)
        %2685 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc497)
        %2686 = "ttir.broadcast"(%2684, %2685) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc497)
        %2687 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc497)
        %2688 = "ttir.multiply"(%2678, %2686, %2687) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc497)
        %2689 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2690 = "ttir.reshape"(%arg37, %2689) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2691 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2692 = "ttir.reshape"(%2690, %2691) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2693 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc495)
        %2694 = "ttir.reshape"(%2692, %2693) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc495)
        %2695 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc495)
        %2696 = "ttir.broadcast"(%2694, %2695) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc495)
        %2697 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc495)
        %2698 = "ttir.add"(%2688, %2696, %2697) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc495)
        %2699 = ttir.empty() : tensor<100x768xbf16> loc(#loc498)
        %2700 = "ttir.reshape"(%2698, %2699) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc498)
        %2701 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %2702 = "ttir.reshape"(%arg193, %2701) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %2703 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %2704 = "ttir.reshape"(%2702, %2703) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %2705 = ttir.empty() : tensor<768x768xbf16> loc(#loc499)
        %2706 = "ttir.permute"(%2704, %2705) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc499)
        %2707 = "ttir.dot_general"(%2700, %2706) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc500)
        %2708 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc498)
        %2709 = "ttir.reshape"(%2707, %2708) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc498)
        %2710 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2711 = "ttir.reshape"(%arg192, %2710) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2712 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2713 = "ttir.reshape"(%2711, %2712) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2714 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc501)
        %2715 = "ttir.reshape"(%2713, %2714) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc501)
        %2716 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc501)
        %2717 = "ttir.broadcast"(%2715, %2716) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc501)
        %2718 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc501)
        %2719 = "ttir.add"(%2709, %2717, %2718) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc501)
        %2720 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc502)
        %2721 = "ttir.reshape"(%2719, %2720) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc502)
        %2722 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc503)
        %2723 = "ttir.permute"(%2721, %2722) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc503)
        %2724 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc504)
        %2725 = "ttir.reshape"(%2723, %2724) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc504)
        %2726 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %2727 = "ttir.reshape"(%arg191, %2726) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %2728 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %2729 = "ttir.reshape"(%2727, %2728) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %2730 = ttir.empty() : tensor<768x768xbf16> loc(#loc505)
        %2731 = "ttir.permute"(%2729, %2730) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc505)
        %2732 = "ttir.dot_general"(%2700, %2731) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc506)
        %2733 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc507)
        %2734 = "ttir.reshape"(%2732, %2733) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc507)
        %2735 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2736 = "ttir.reshape"(%arg190, %2735) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2737 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2738 = "ttir.reshape"(%2736, %2737) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2739 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc508)
        %2740 = "ttir.reshape"(%2738, %2739) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc508)
        %2741 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc508)
        %2742 = "ttir.broadcast"(%2740, %2741) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc508)
        %2743 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc508)
        %2744 = "ttir.add"(%2734, %2742, %2743) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc508)
        %2745 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc509)
        %2746 = "ttir.reshape"(%2744, %2745) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc509)
        %2747 = ttir.empty() : tensor<2x12x64x50xbf16> loc(#loc510)
        %2748 = "ttir.permute"(%2746, %2747) <{permutation = array<i64: 0, 2, 3, 1>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x64x50xbf16>) -> tensor<2x12x64x50xbf16> loc(#loc510)
        %2749 = ttir.empty() : tensor<24x64x50xbf16> loc(#loc504)
        %2750 = "ttir.reshape"(%2748, %2749) <{shape = [24 : i32, 64 : i32, 50 : i32]}> : (tensor<2x12x64x50xbf16>, tensor<24x64x50xbf16>) -> tensor<24x64x50xbf16> loc(#loc504)
        %2751 = "ttir.dot_general"(%2725, %2750) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x64xbf16>, tensor<24x64x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc511)
        %2752 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc504)
        %2753 = "ttir.reshape"(%2751, %2752) <{shape = [2 : i32, 12 : i32, 50 : i32, 50 : i32]}> : (tensor<24x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc504)
        %2754 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc512)
        %2755 = "ttir.multiply"(%2753, %3, %2754) : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc512)
        %2756 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc513)
        %2757 = "ttir.typecast"(%2755, %2756) <{conservative_folding = false}> : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc513)
        %2758 = ttir.empty() : tensor<2x12x50xf32> loc(#loc514)
        %2759 = "ttir.max"(%2757, %2758) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc514)
        %2760 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc514)
        %2761 = "ttir.reshape"(%2759, %2760) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc514)
        %2762 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc514)
        %2763 = "ttir.broadcast"(%2761, %2762) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc514)
        %2764 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc514)
        %2765 = "ttir.subtract"(%2757, %2763, %2764) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc514)
        %2766 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc514)
        %2767 = "ttir.exp"(%2765, %2766) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc514)
        %2768 = ttir.empty() : tensor<2x12x50xf32> loc(#loc514)
        %2769 = "ttir.sum"(%2767, %2768) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc514)
        %2770 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc514)
        %2771 = "ttir.reshape"(%2769, %2770) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc514)
        %2772 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc514)
        %2773 = "ttir.broadcast"(%2771, %2772) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc514)
        %2774 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc514)
        %2775 = "ttir.div"(%2767, %2773, %2774) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc514)
        %2776 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc515)
        %2777 = "ttir.typecast"(%2775, %2776) <{conservative_folding = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc515)
        %2778 = ttir.empty() : tensor<24x50x50xbf16> loc(#loc516)
        %2779 = "ttir.reshape"(%2777, %2778) <{shape = [24 : i32, 50 : i32, 50 : i32]}> : (tensor<2x12x50x50xbf16>, tensor<24x50x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc516)
        %2780 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %2781 = "ttir.reshape"(%arg36, %2780) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %2782 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %2783 = "ttir.reshape"(%2781, %2782) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %2784 = ttir.empty() : tensor<768x768xbf16> loc(#loc517)
        %2785 = "ttir.permute"(%2783, %2784) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc517)
        %2786 = "ttir.dot_general"(%2700, %2785) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc518)
        %2787 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc519)
        %2788 = "ttir.reshape"(%2786, %2787) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc519)
        %2789 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2790 = "ttir.reshape"(%arg35, %2789) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2791 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2792 = "ttir.reshape"(%2790, %2791) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2793 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc520)
        %2794 = "ttir.reshape"(%2792, %2793) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc520)
        %2795 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc520)
        %2796 = "ttir.broadcast"(%2794, %2795) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc520)
        %2797 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc520)
        %2798 = "ttir.add"(%2788, %2796, %2797) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc520)
        %2799 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc521)
        %2800 = "ttir.reshape"(%2798, %2799) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc521)
        %2801 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc522)
        %2802 = "ttir.permute"(%2800, %2801) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc522)
        %2803 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc516)
        %2804 = "ttir.reshape"(%2802, %2803) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc516)
        %2805 = "ttir.dot_general"(%2779, %2804) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x50xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc523)
        %2806 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc516)
        %2807 = "ttir.reshape"(%2805, %2806) <{shape = [2 : i32, 12 : i32, 50 : i32, 64 : i32]}> : (tensor<24x50x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc516)
        %2808 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc524)
        %2809 = "ttir.permute"(%2807, %2808) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x12x50x64xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc524)
        %2810 = ttir.empty() : tensor<100x768xbf16> loc(#loc525)
        %2811 = "ttir.reshape"(%2809, %2810) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x12x64xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc525)
        %2812 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %2813 = "ttir.reshape"(%arg34, %2812) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %2814 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %2815 = "ttir.reshape"(%2813, %2814) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %2816 = ttir.empty() : tensor<768x768xbf16> loc(#loc526)
        %2817 = "ttir.permute"(%2815, %2816) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc526)
        %2818 = "ttir.dot_general"(%2811, %2817) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc527)
        %2819 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc525)
        %2820 = "ttir.reshape"(%2818, %2819) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc525)
        %2821 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2822 = "ttir.reshape"(%arg33, %2821) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2823 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2824 = "ttir.reshape"(%2822, %2823) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2825 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc528)
        %2826 = "ttir.reshape"(%2824, %2825) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc528)
        %2827 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc528)
        %2828 = "ttir.broadcast"(%2826, %2827) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc528)
        %2829 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc528)
        %2830 = "ttir.add"(%2820, %2828, %2829) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc528)
        %2831 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc529)
        %2832 = "ttir.add"(%2648, %2830, %2831) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc529)
        %2833 = ttir.empty() : tensor<2x50xbf16> loc(#loc530)
        %2834 = "ttir.sum"(%2832, %2833) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc530)
        %2835 = ttir.empty() : tensor<2x50xbf16> loc(#loc530)
        %2836 = "ttir.multiply"(%2834, %5, %2835) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc530)
        %2837 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc531)
        %2838 = "ttir.reshape"(%2836, %2837) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc531)
        %2839 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc531)
        %2840 = "ttir.broadcast"(%2838, %2839) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc531)
        %2841 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc531)
        %2842 = "ttir.subtract"(%2832, %2840, %2841) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc531)
        %2843 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc530)
        %2844 = "ttir.multiply"(%2842, %2842, %2843) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc530)
        %2845 = ttir.empty() : tensor<2x50xbf16> loc(#loc530)
        %2846 = "ttir.sum"(%2844, %2845) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc530)
        %2847 = ttir.empty() : tensor<2x50xbf16> loc(#loc530)
        %2848 = "ttir.multiply"(%2846, %5, %2847) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc530)
        %2849 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc530)
        %2850 = "ttir.reshape"(%2848, %2849) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc530)
        %2851 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc532)
        %2852 = "ttir.add"(%2850, %4, %2851) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc532)
        %2853 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc533)
        %2854 = "ttir.rsqrt"(%2852, %2853) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc533)
        %2855 = ttir.empty() : tensor<2x50xbf16> loc(#loc534)
        %2856 = "ttir.reshape"(%2854, %2855) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc534)
        %2857 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc534)
        %2858 = "ttir.reshape"(%2856, %2857) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc534)
        %2859 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc534)
        %2860 = "ttir.broadcast"(%2858, %2859) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc534)
        %2861 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc534)
        %2862 = "ttir.multiply"(%2842, %2860, %2861) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc534)
        %2863 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2864 = "ttir.reshape"(%arg32, %2863) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2865 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2866 = "ttir.reshape"(%2864, %2865) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2867 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc534)
        %2868 = "ttir.reshape"(%2866, %2867) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc534)
        %2869 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc534)
        %2870 = "ttir.broadcast"(%2868, %2869) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc534)
        %2871 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc534)
        %2872 = "ttir.multiply"(%2862, %2870, %2871) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc534)
        %2873 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2874 = "ttir.reshape"(%arg31, %2873) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2875 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2876 = "ttir.reshape"(%2874, %2875) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2877 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc532)
        %2878 = "ttir.reshape"(%2876, %2877) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc532)
        %2879 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc532)
        %2880 = "ttir.broadcast"(%2878, %2879) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc532)
        %2881 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc532)
        %2882 = "ttir.add"(%2872, %2880, %2881) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc532)
        %2883 = ttir.empty() : tensor<100x768xbf16> loc(#loc535)
        %2884 = "ttir.reshape"(%2882, %2883) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc535)
        %2885 = ttir.empty() : tensor<1x3072x768xbf16> loc(#loc2)
        %2886 = "ttir.reshape"(%arg30, %2885) <{shape = [1 : i32, 3072 : i32, 768 : i32]}> : (tensor<3072x768xbf16>, tensor<1x3072x768xbf16>) -> tensor<1x3072x768xbf16> loc(#loc2)
        %2887 = ttir.empty() : tensor<3072x768xbf16> loc(#loc2)
        %2888 = "ttir.reshape"(%2886, %2887) <{shape = [3072 : i32, 768 : i32]}> : (tensor<1x3072x768xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc2)
        %2889 = ttir.empty() : tensor<768x3072xbf16> loc(#loc536)
        %2890 = "ttir.permute"(%2888, %2889) <{permutation = array<i64: 1, 0>}> : (tensor<3072x768xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc536)
        %2891 = "ttir.dot_general"(%2884, %2890) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc537)
        %2892 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc535)
        %2893 = "ttir.reshape"(%2891, %2892) <{shape = [2 : i32, 50 : i32, 3072 : i32]}> : (tensor<100x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc535)
        %2894 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc2)
        %2895 = "ttir.reshape"(%arg29, %2894) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc2)
        %2896 = ttir.empty() : tensor<3072xbf16> loc(#loc2)
        %2897 = "ttir.reshape"(%2895, %2896) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc2)
        %2898 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc538)
        %2899 = "ttir.reshape"(%2897, %2898) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc538)
        %2900 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc538)
        %2901 = "ttir.broadcast"(%2899, %2900) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc538)
        %2902 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc538)
        %2903 = "ttir.add"(%2893, %2901, %2902) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc538)
        %2904 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc539)
        %2905 = "ttir.multiply"(%2903, %2, %2904) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc539)
        %2906 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc540)
        %2907 = "ttir.sigmoid"(%2905, %2906) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc540)
        %2908 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc539)
        %2909 = "ttir.multiply"(%2903, %2907, %2908) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc539)
        %2910 = ttir.empty() : tensor<100x3072xbf16> loc(#loc541)
        %2911 = "ttir.reshape"(%2909, %2910) <{shape = [100 : i32, 3072 : i32]}> : (tensor<2x50x3072xbf16>, tensor<100x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc541)
        %2912 = ttir.empty() : tensor<1x768x3072xbf16> loc(#loc2)
        %2913 = "ttir.reshape"(%arg28, %2912) <{shape = [1 : i32, 768 : i32, 3072 : i32]}> : (tensor<768x3072xbf16>, tensor<1x768x3072xbf16>) -> tensor<1x768x3072xbf16> loc(#loc2)
        %2914 = ttir.empty() : tensor<768x3072xbf16> loc(#loc2)
        %2915 = "ttir.reshape"(%2913, %2914) <{shape = [768 : i32, 3072 : i32]}> : (tensor<1x768x3072xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc2)
        %2916 = ttir.empty() : tensor<3072x768xbf16> loc(#loc542)
        %2917 = "ttir.permute"(%2915, %2916) <{permutation = array<i64: 1, 0>}> : (tensor<768x3072xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc542)
        %2918 = "ttir.dot_general"(%2911, %2917) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x3072xbf16>, tensor<3072x768xbf16>) -> tensor<100x768xbf16> loc(#loc543)
        %2919 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc541)
        %2920 = "ttir.reshape"(%2918, %2919) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc541)
        %2921 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2922 = "ttir.reshape"(%arg27, %2921) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2923 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2924 = "ttir.reshape"(%2922, %2923) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2925 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc544)
        %2926 = "ttir.reshape"(%2924, %2925) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc544)
        %2927 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc544)
        %2928 = "ttir.broadcast"(%2926, %2927) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc544)
        %2929 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc544)
        %2930 = "ttir.add"(%2920, %2928, %2929) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc544)
        %2931 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc545)
        %2932 = "ttir.add"(%2832, %2930, %2931) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc545)
        %2933 = ttir.empty() : tensor<2x50xbf16> loc(#loc546)
        %2934 = "ttir.sum"(%2932, %2933) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc546)
        %2935 = ttir.empty() : tensor<2x50xbf16> loc(#loc546)
        %2936 = "ttir.multiply"(%2934, %5, %2935) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc546)
        %2937 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc547)
        %2938 = "ttir.reshape"(%2936, %2937) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc547)
        %2939 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc547)
        %2940 = "ttir.broadcast"(%2938, %2939) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc547)
        %2941 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc547)
        %2942 = "ttir.subtract"(%2932, %2940, %2941) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc547)
        %2943 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc546)
        %2944 = "ttir.multiply"(%2942, %2942, %2943) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc546)
        %2945 = ttir.empty() : tensor<2x50xbf16> loc(#loc546)
        %2946 = "ttir.sum"(%2944, %2945) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc546)
        %2947 = ttir.empty() : tensor<2x50xbf16> loc(#loc546)
        %2948 = "ttir.multiply"(%2946, %5, %2947) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc546)
        %2949 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc546)
        %2950 = "ttir.reshape"(%2948, %2949) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc546)
        %2951 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc548)
        %2952 = "ttir.add"(%2950, %4, %2951) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc548)
        %2953 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc549)
        %2954 = "ttir.rsqrt"(%2952, %2953) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc549)
        %2955 = ttir.empty() : tensor<2x50xbf16> loc(#loc550)
        %2956 = "ttir.reshape"(%2954, %2955) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc550)
        %2957 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc550)
        %2958 = "ttir.reshape"(%2956, %2957) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc550)
        %2959 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc550)
        %2960 = "ttir.broadcast"(%2958, %2959) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc550)
        %2961 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc550)
        %2962 = "ttir.multiply"(%2942, %2960, %2961) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc550)
        %2963 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2964 = "ttir.reshape"(%arg26, %2963) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2965 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2966 = "ttir.reshape"(%2964, %2965) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2967 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc550)
        %2968 = "ttir.reshape"(%2966, %2967) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc550)
        %2969 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc550)
        %2970 = "ttir.broadcast"(%2968, %2969) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc550)
        %2971 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc550)
        %2972 = "ttir.multiply"(%2962, %2970, %2971) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc550)
        %2973 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2974 = "ttir.reshape"(%arg25, %2973) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2975 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2976 = "ttir.reshape"(%2974, %2975) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2977 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc548)
        %2978 = "ttir.reshape"(%2976, %2977) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc548)
        %2979 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc548)
        %2980 = "ttir.broadcast"(%2978, %2979) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc548)
        %2981 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc548)
        %2982 = "ttir.add"(%2972, %2980, %2981) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc548)
        %2983 = ttir.empty() : tensor<100x768xbf16> loc(#loc551)
        %2984 = "ttir.reshape"(%2982, %2983) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc551)
        %2985 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %2986 = "ttir.reshape"(%arg197, %2985) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %2987 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %2988 = "ttir.reshape"(%2986, %2987) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %2989 = ttir.empty() : tensor<768x768xbf16> loc(#loc552)
        %2990 = "ttir.permute"(%2988, %2989) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc552)
        %2991 = "ttir.dot_general"(%2984, %2990) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc553)
        %2992 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc551)
        %2993 = "ttir.reshape"(%2991, %2992) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc551)
        %2994 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %2995 = "ttir.reshape"(%arg196, %2994) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %2996 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %2997 = "ttir.reshape"(%2995, %2996) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %2998 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc554)
        %2999 = "ttir.reshape"(%2997, %2998) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc554)
        %3000 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc554)
        %3001 = "ttir.broadcast"(%2999, %3000) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc554)
        %3002 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc554)
        %3003 = "ttir.add"(%2993, %3001, %3002) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc554)
        %3004 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc555)
        %3005 = "ttir.reshape"(%3003, %3004) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc555)
        %3006 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc556)
        %3007 = "ttir.permute"(%3005, %3006) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc556)
        %3008 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc557)
        %3009 = "ttir.reshape"(%3007, %3008) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc557)
        %3010 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %3011 = "ttir.reshape"(%arg195, %3010) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %3012 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %3013 = "ttir.reshape"(%3011, %3012) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %3014 = ttir.empty() : tensor<768x768xbf16> loc(#loc558)
        %3015 = "ttir.permute"(%3013, %3014) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc558)
        %3016 = "ttir.dot_general"(%2984, %3015) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc559)
        %3017 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc560)
        %3018 = "ttir.reshape"(%3016, %3017) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc560)
        %3019 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %3020 = "ttir.reshape"(%arg194, %3019) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %3021 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %3022 = "ttir.reshape"(%3020, %3021) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %3023 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc561)
        %3024 = "ttir.reshape"(%3022, %3023) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc561)
        %3025 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc561)
        %3026 = "ttir.broadcast"(%3024, %3025) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc561)
        %3027 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc561)
        %3028 = "ttir.add"(%3018, %3026, %3027) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc561)
        %3029 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc562)
        %3030 = "ttir.reshape"(%3028, %3029) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc562)
        %3031 = ttir.empty() : tensor<2x12x64x50xbf16> loc(#loc563)
        %3032 = "ttir.permute"(%3030, %3031) <{permutation = array<i64: 0, 2, 3, 1>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x64x50xbf16>) -> tensor<2x12x64x50xbf16> loc(#loc563)
        %3033 = ttir.empty() : tensor<24x64x50xbf16> loc(#loc557)
        %3034 = "ttir.reshape"(%3032, %3033) <{shape = [24 : i32, 64 : i32, 50 : i32]}> : (tensor<2x12x64x50xbf16>, tensor<24x64x50xbf16>) -> tensor<24x64x50xbf16> loc(#loc557)
        %3035 = "ttir.dot_general"(%3009, %3034) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x64xbf16>, tensor<24x64x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc564)
        %3036 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc557)
        %3037 = "ttir.reshape"(%3035, %3036) <{shape = [2 : i32, 12 : i32, 50 : i32, 50 : i32]}> : (tensor<24x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc557)
        %3038 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc565)
        %3039 = "ttir.multiply"(%3037, %3, %3038) : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc565)
        %3040 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc566)
        %3041 = "ttir.typecast"(%3039, %3040) <{conservative_folding = false}> : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc566)
        %3042 = ttir.empty() : tensor<2x12x50xf32> loc(#loc567)
        %3043 = "ttir.max"(%3041, %3042) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc567)
        %3044 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc567)
        %3045 = "ttir.reshape"(%3043, %3044) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc567)
        %3046 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc567)
        %3047 = "ttir.broadcast"(%3045, %3046) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc567)
        %3048 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc567)
        %3049 = "ttir.subtract"(%3041, %3047, %3048) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc567)
        %3050 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc567)
        %3051 = "ttir.exp"(%3049, %3050) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc567)
        %3052 = ttir.empty() : tensor<2x12x50xf32> loc(#loc567)
        %3053 = "ttir.sum"(%3051, %3052) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc567)
        %3054 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc567)
        %3055 = "ttir.reshape"(%3053, %3054) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc567)
        %3056 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc567)
        %3057 = "ttir.broadcast"(%3055, %3056) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc567)
        %3058 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc567)
        %3059 = "ttir.div"(%3051, %3057, %3058) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc567)
        %3060 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc568)
        %3061 = "ttir.typecast"(%3059, %3060) <{conservative_folding = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc568)
        %3062 = ttir.empty() : tensor<24x50x50xbf16> loc(#loc569)
        %3063 = "ttir.reshape"(%3061, %3062) <{shape = [24 : i32, 50 : i32, 50 : i32]}> : (tensor<2x12x50x50xbf16>, tensor<24x50x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc569)
        %3064 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %3065 = "ttir.reshape"(%arg24, %3064) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %3066 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %3067 = "ttir.reshape"(%3065, %3066) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %3068 = ttir.empty() : tensor<768x768xbf16> loc(#loc570)
        %3069 = "ttir.permute"(%3067, %3068) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc570)
        %3070 = "ttir.dot_general"(%2984, %3069) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc571)
        %3071 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc572)
        %3072 = "ttir.reshape"(%3070, %3071) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc572)
        %3073 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %3074 = "ttir.reshape"(%arg23, %3073) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %3075 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %3076 = "ttir.reshape"(%3074, %3075) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %3077 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc573)
        %3078 = "ttir.reshape"(%3076, %3077) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc573)
        %3079 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc573)
        %3080 = "ttir.broadcast"(%3078, %3079) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc573)
        %3081 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc573)
        %3082 = "ttir.add"(%3072, %3080, %3081) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc573)
        %3083 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc574)
        %3084 = "ttir.reshape"(%3082, %3083) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc574)
        %3085 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc575)
        %3086 = "ttir.permute"(%3084, %3085) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc575)
        %3087 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc569)
        %3088 = "ttir.reshape"(%3086, %3087) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc569)
        %3089 = "ttir.dot_general"(%3063, %3088) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x50xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc576)
        %3090 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc569)
        %3091 = "ttir.reshape"(%3089, %3090) <{shape = [2 : i32, 12 : i32, 50 : i32, 64 : i32]}> : (tensor<24x50x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc569)
        %3092 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc577)
        %3093 = "ttir.permute"(%3091, %3092) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x12x50x64xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc577)
        %3094 = ttir.empty() : tensor<100x768xbf16> loc(#loc578)
        %3095 = "ttir.reshape"(%3093, %3094) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x12x64xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc578)
        %3096 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %3097 = "ttir.reshape"(%arg22, %3096) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %3098 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %3099 = "ttir.reshape"(%3097, %3098) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %3100 = ttir.empty() : tensor<768x768xbf16> loc(#loc579)
        %3101 = "ttir.permute"(%3099, %3100) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc579)
        %3102 = "ttir.dot_general"(%3095, %3101) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc580)
        %3103 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc578)
        %3104 = "ttir.reshape"(%3102, %3103) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc578)
        %3105 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %3106 = "ttir.reshape"(%arg21, %3105) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %3107 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %3108 = "ttir.reshape"(%3106, %3107) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %3109 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc581)
        %3110 = "ttir.reshape"(%3108, %3109) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc581)
        %3111 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc581)
        %3112 = "ttir.broadcast"(%3110, %3111) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc581)
        %3113 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc581)
        %3114 = "ttir.add"(%3104, %3112, %3113) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc581)
        %3115 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc582)
        %3116 = "ttir.add"(%2932, %3114, %3115) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc582)
        %3117 = ttir.empty() : tensor<2x50xbf16> loc(#loc583)
        %3118 = "ttir.sum"(%3116, %3117) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc583)
        %3119 = ttir.empty() : tensor<2x50xbf16> loc(#loc583)
        %3120 = "ttir.multiply"(%3118, %5, %3119) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc583)
        %3121 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc584)
        %3122 = "ttir.reshape"(%3120, %3121) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc584)
        %3123 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc584)
        %3124 = "ttir.broadcast"(%3122, %3123) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc584)
        %3125 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc584)
        %3126 = "ttir.subtract"(%3116, %3124, %3125) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc584)
        %3127 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc583)
        %3128 = "ttir.multiply"(%3126, %3126, %3127) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc583)
        %3129 = ttir.empty() : tensor<2x50xbf16> loc(#loc583)
        %3130 = "ttir.sum"(%3128, %3129) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc583)
        %3131 = ttir.empty() : tensor<2x50xbf16> loc(#loc583)
        %3132 = "ttir.multiply"(%3130, %5, %3131) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc583)
        %3133 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc583)
        %3134 = "ttir.reshape"(%3132, %3133) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc583)
        %3135 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc585)
        %3136 = "ttir.add"(%3134, %4, %3135) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc585)
        %3137 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc586)
        %3138 = "ttir.rsqrt"(%3136, %3137) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc586)
        %3139 = ttir.empty() : tensor<2x50xbf16> loc(#loc587)
        %3140 = "ttir.reshape"(%3138, %3139) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc587)
        %3141 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc587)
        %3142 = "ttir.reshape"(%3140, %3141) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc587)
        %3143 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc587)
        %3144 = "ttir.broadcast"(%3142, %3143) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc587)
        %3145 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc587)
        %3146 = "ttir.multiply"(%3126, %3144, %3145) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc587)
        %3147 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %3148 = "ttir.reshape"(%arg20, %3147) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %3149 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %3150 = "ttir.reshape"(%3148, %3149) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %3151 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc587)
        %3152 = "ttir.reshape"(%3150, %3151) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc587)
        %3153 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc587)
        %3154 = "ttir.broadcast"(%3152, %3153) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc587)
        %3155 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc587)
        %3156 = "ttir.multiply"(%3146, %3154, %3155) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc587)
        %3157 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %3158 = "ttir.reshape"(%arg19, %3157) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %3159 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %3160 = "ttir.reshape"(%3158, %3159) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %3161 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc585)
        %3162 = "ttir.reshape"(%3160, %3161) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc585)
        %3163 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc585)
        %3164 = "ttir.broadcast"(%3162, %3163) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc585)
        %3165 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc585)
        %3166 = "ttir.add"(%3156, %3164, %3165) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc585)
        %3167 = ttir.empty() : tensor<100x768xbf16> loc(#loc588)
        %3168 = "ttir.reshape"(%3166, %3167) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc588)
        %3169 = ttir.empty() : tensor<1x3072x768xbf16> loc(#loc2)
        %3170 = "ttir.reshape"(%arg18, %3169) <{shape = [1 : i32, 3072 : i32, 768 : i32]}> : (tensor<3072x768xbf16>, tensor<1x3072x768xbf16>) -> tensor<1x3072x768xbf16> loc(#loc2)
        %3171 = ttir.empty() : tensor<3072x768xbf16> loc(#loc2)
        %3172 = "ttir.reshape"(%3170, %3171) <{shape = [3072 : i32, 768 : i32]}> : (tensor<1x3072x768xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc2)
        %3173 = ttir.empty() : tensor<768x3072xbf16> loc(#loc589)
        %3174 = "ttir.permute"(%3172, %3173) <{permutation = array<i64: 1, 0>}> : (tensor<3072x768xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc589)
        %3175 = "ttir.dot_general"(%3168, %3174) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc590)
        %3176 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc588)
        %3177 = "ttir.reshape"(%3175, %3176) <{shape = [2 : i32, 50 : i32, 3072 : i32]}> : (tensor<100x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc588)
        %3178 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc2)
        %3179 = "ttir.reshape"(%arg17, %3178) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc2)
        %3180 = ttir.empty() : tensor<3072xbf16> loc(#loc2)
        %3181 = "ttir.reshape"(%3179, %3180) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc2)
        %3182 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc591)
        %3183 = "ttir.reshape"(%3181, %3182) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc591)
        %3184 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc591)
        %3185 = "ttir.broadcast"(%3183, %3184) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc591)
        %3186 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc591)
        %3187 = "ttir.add"(%3177, %3185, %3186) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc591)
        %3188 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc592)
        %3189 = "ttir.multiply"(%3187, %2, %3188) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc592)
        %3190 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc593)
        %3191 = "ttir.sigmoid"(%3189, %3190) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc593)
        %3192 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc592)
        %3193 = "ttir.multiply"(%3187, %3191, %3192) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc592)
        %3194 = ttir.empty() : tensor<100x3072xbf16> loc(#loc594)
        %3195 = "ttir.reshape"(%3193, %3194) <{shape = [100 : i32, 3072 : i32]}> : (tensor<2x50x3072xbf16>, tensor<100x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc594)
        %3196 = ttir.empty() : tensor<1x768x3072xbf16> loc(#loc2)
        %3197 = "ttir.reshape"(%arg16, %3196) <{shape = [1 : i32, 768 : i32, 3072 : i32]}> : (tensor<768x3072xbf16>, tensor<1x768x3072xbf16>) -> tensor<1x768x3072xbf16> loc(#loc2)
        %3198 = ttir.empty() : tensor<768x3072xbf16> loc(#loc2)
        %3199 = "ttir.reshape"(%3197, %3198) <{shape = [768 : i32, 3072 : i32]}> : (tensor<1x768x3072xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc2)
        %3200 = ttir.empty() : tensor<3072x768xbf16> loc(#loc595)
        %3201 = "ttir.permute"(%3199, %3200) <{permutation = array<i64: 1, 0>}> : (tensor<768x3072xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc595)
        %3202 = "ttir.dot_general"(%3195, %3201) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x3072xbf16>, tensor<3072x768xbf16>) -> tensor<100x768xbf16> loc(#loc596)
        %3203 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc594)
        %3204 = "ttir.reshape"(%3202, %3203) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc594)
        %3205 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %3206 = "ttir.reshape"(%arg15, %3205) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %3207 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %3208 = "ttir.reshape"(%3206, %3207) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %3209 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc597)
        %3210 = "ttir.reshape"(%3208, %3209) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc597)
        %3211 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc597)
        %3212 = "ttir.broadcast"(%3210, %3211) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc597)
        %3213 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc597)
        %3214 = "ttir.add"(%3204, %3212, %3213) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc597)
        %3215 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc598)
        %3216 = "ttir.add"(%3116, %3214, %3215) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc598)
        %3217 = ttir.empty() : tensor<2x50xbf16> loc(#loc599)
        %3218 = "ttir.sum"(%3216, %3217) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc599)
        %3219 = ttir.empty() : tensor<2x50xbf16> loc(#loc599)
        %3220 = "ttir.multiply"(%3218, %5, %3219) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc599)
        %3221 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc600)
        %3222 = "ttir.reshape"(%3220, %3221) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc600)
        %3223 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc600)
        %3224 = "ttir.broadcast"(%3222, %3223) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc600)
        %3225 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc600)
        %3226 = "ttir.subtract"(%3216, %3224, %3225) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc600)
        %3227 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc599)
        %3228 = "ttir.multiply"(%3226, %3226, %3227) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc599)
        %3229 = ttir.empty() : tensor<2x50xbf16> loc(#loc599)
        %3230 = "ttir.sum"(%3228, %3229) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc599)
        %3231 = ttir.empty() : tensor<2x50xbf16> loc(#loc599)
        %3232 = "ttir.multiply"(%3230, %5, %3231) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc599)
        %3233 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc599)
        %3234 = "ttir.reshape"(%3232, %3233) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc599)
        %3235 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc601)
        %3236 = "ttir.add"(%3234, %4, %3235) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc601)
        %3237 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc602)
        %3238 = "ttir.rsqrt"(%3236, %3237) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc602)
        %3239 = ttir.empty() : tensor<2x50xbf16> loc(#loc603)
        %3240 = "ttir.reshape"(%3238, %3239) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc603)
        %3241 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc603)
        %3242 = "ttir.reshape"(%3240, %3241) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc603)
        %3243 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc603)
        %3244 = "ttir.broadcast"(%3242, %3243) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc603)
        %3245 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc603)
        %3246 = "ttir.multiply"(%3226, %3244, %3245) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc603)
        %3247 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %3248 = "ttir.reshape"(%arg14, %3247) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %3249 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %3250 = "ttir.reshape"(%3248, %3249) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %3251 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc603)
        %3252 = "ttir.reshape"(%3250, %3251) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc603)
        %3253 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc603)
        %3254 = "ttir.broadcast"(%3252, %3253) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc603)
        %3255 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc603)
        %3256 = "ttir.multiply"(%3246, %3254, %3255) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc603)
        %3257 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %3258 = "ttir.reshape"(%arg13, %3257) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %3259 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %3260 = "ttir.reshape"(%3258, %3259) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %3261 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc601)
        %3262 = "ttir.reshape"(%3260, %3261) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc601)
        %3263 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc601)
        %3264 = "ttir.broadcast"(%3262, %3263) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc601)
        %3265 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc601)
        %3266 = "ttir.add"(%3256, %3264, %3265) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc601)
        %3267 = ttir.empty() : tensor<100x768xbf16> loc(#loc604)
        %3268 = "ttir.reshape"(%3266, %3267) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc604)
        %3269 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %3270 = "ttir.reshape"(%arg201, %3269) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %3271 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %3272 = "ttir.reshape"(%3270, %3271) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %3273 = ttir.empty() : tensor<768x768xbf16> loc(#loc605)
        %3274 = "ttir.permute"(%3272, %3273) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc605)
        %3275 = "ttir.dot_general"(%3268, %3274) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc606)
        %3276 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc604)
        %3277 = "ttir.reshape"(%3275, %3276) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc604)
        %3278 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %3279 = "ttir.reshape"(%arg200, %3278) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %3280 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %3281 = "ttir.reshape"(%3279, %3280) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %3282 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc607)
        %3283 = "ttir.reshape"(%3281, %3282) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc607)
        %3284 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc607)
        %3285 = "ttir.broadcast"(%3283, %3284) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc607)
        %3286 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc607)
        %3287 = "ttir.add"(%3277, %3285, %3286) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc607)
        %3288 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc608)
        %3289 = "ttir.reshape"(%3287, %3288) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc608)
        %3290 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc609)
        %3291 = "ttir.permute"(%3289, %3290) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc609)
        %3292 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc610)
        %3293 = "ttir.reshape"(%3291, %3292) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc610)
        %3294 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %3295 = "ttir.reshape"(%arg199, %3294) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %3296 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %3297 = "ttir.reshape"(%3295, %3296) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %3298 = ttir.empty() : tensor<768x768xbf16> loc(#loc611)
        %3299 = "ttir.permute"(%3297, %3298) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc611)
        %3300 = "ttir.dot_general"(%3268, %3299) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc612)
        %3301 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc613)
        %3302 = "ttir.reshape"(%3300, %3301) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc613)
        %3303 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %3304 = "ttir.reshape"(%arg198, %3303) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %3305 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %3306 = "ttir.reshape"(%3304, %3305) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %3307 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc614)
        %3308 = "ttir.reshape"(%3306, %3307) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc614)
        %3309 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc614)
        %3310 = "ttir.broadcast"(%3308, %3309) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc614)
        %3311 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc614)
        %3312 = "ttir.add"(%3302, %3310, %3311) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc614)
        %3313 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc615)
        %3314 = "ttir.reshape"(%3312, %3313) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc615)
        %3315 = ttir.empty() : tensor<2x12x64x50xbf16> loc(#loc616)
        %3316 = "ttir.permute"(%3314, %3315) <{permutation = array<i64: 0, 2, 3, 1>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x64x50xbf16>) -> tensor<2x12x64x50xbf16> loc(#loc616)
        %3317 = ttir.empty() : tensor<24x64x50xbf16> loc(#loc610)
        %3318 = "ttir.reshape"(%3316, %3317) <{shape = [24 : i32, 64 : i32, 50 : i32]}> : (tensor<2x12x64x50xbf16>, tensor<24x64x50xbf16>) -> tensor<24x64x50xbf16> loc(#loc610)
        %3319 = "ttir.dot_general"(%3293, %3318) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x64xbf16>, tensor<24x64x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc617)
        %3320 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc610)
        %3321 = "ttir.reshape"(%3319, %3320) <{shape = [2 : i32, 12 : i32, 50 : i32, 50 : i32]}> : (tensor<24x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc610)
        %3322 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc618)
        %3323 = "ttir.multiply"(%3321, %3, %3322) : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc618)
        %3324 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc619)
        %3325 = "ttir.typecast"(%3323, %3324) <{conservative_folding = false}> : (tensor<2x12x50x50xbf16>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc619)
        %3326 = ttir.empty() : tensor<2x12x50xf32> loc(#loc620)
        %3327 = "ttir.max"(%3325, %3326) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc620)
        %3328 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc620)
        %3329 = "ttir.reshape"(%3327, %3328) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc620)
        %3330 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc620)
        %3331 = "ttir.broadcast"(%3329, %3330) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc620)
        %3332 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc620)
        %3333 = "ttir.subtract"(%3325, %3331, %3332) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc620)
        %3334 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc620)
        %3335 = "ttir.exp"(%3333, %3334) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc620)
        %3336 = ttir.empty() : tensor<2x12x50xf32> loc(#loc620)
        %3337 = "ttir.sum"(%3335, %3336) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50xf32>) -> tensor<2x12x50xf32> loc(#loc620)
        %3338 = ttir.empty() : tensor<2x12x50x1xf32> loc(#loc620)
        %3339 = "ttir.reshape"(%3337, %3338) <{shape = [2 : i32, 12 : i32, 50 : i32, 1 : i32]}> : (tensor<2x12x50xf32>, tensor<2x12x50x1xf32>) -> tensor<2x12x50x1xf32> loc(#loc620)
        %3340 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc620)
        %3341 = "ttir.broadcast"(%3339, %3340) <{broadcast_dimensions = array<i64: 1, 1, 1, 50>}> : (tensor<2x12x50x1xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc620)
        %3342 = ttir.empty() : tensor<2x12x50x50xf32> loc(#loc620)
        %3343 = "ttir.div"(%3335, %3341, %3342) : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>, tensor<2x12x50x50xf32>) -> tensor<2x12x50x50xf32> loc(#loc620)
        %3344 = ttir.empty() : tensor<2x12x50x50xbf16> loc(#loc621)
        %3345 = "ttir.typecast"(%3343, %3344) <{conservative_folding = false}> : (tensor<2x12x50x50xf32>, tensor<2x12x50x50xbf16>) -> tensor<2x12x50x50xbf16> loc(#loc621)
        %3346 = ttir.empty() : tensor<24x50x50xbf16> loc(#loc622)
        %3347 = "ttir.reshape"(%3345, %3346) <{shape = [24 : i32, 50 : i32, 50 : i32]}> : (tensor<2x12x50x50xbf16>, tensor<24x50x50xbf16>) -> tensor<24x50x50xbf16> loc(#loc622)
        %3348 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %3349 = "ttir.reshape"(%arg12, %3348) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %3350 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %3351 = "ttir.reshape"(%3349, %3350) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %3352 = ttir.empty() : tensor<768x768xbf16> loc(#loc623)
        %3353 = "ttir.permute"(%3351, %3352) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc623)
        %3354 = "ttir.dot_general"(%3268, %3353) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc624)
        %3355 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc625)
        %3356 = "ttir.reshape"(%3354, %3355) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc625)
        %3357 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %3358 = "ttir.reshape"(%arg11, %3357) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %3359 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %3360 = "ttir.reshape"(%3358, %3359) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %3361 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc626)
        %3362 = "ttir.reshape"(%3360, %3361) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc626)
        %3363 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc626)
        %3364 = "ttir.broadcast"(%3362, %3363) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc626)
        %3365 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc626)
        %3366 = "ttir.add"(%3356, %3364, %3365) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc626)
        %3367 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc627)
        %3368 = "ttir.reshape"(%3366, %3367) <{shape = [2 : i32, 50 : i32, 12 : i32, 64 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc627)
        %3369 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc628)
        %3370 = "ttir.permute"(%3368, %3369) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x50x12x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc628)
        %3371 = ttir.empty() : tensor<24x50x64xbf16> loc(#loc622)
        %3372 = "ttir.reshape"(%3370, %3371) <{shape = [24 : i32, 50 : i32, 64 : i32]}> : (tensor<2x12x50x64xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc622)
        %3373 = "ttir.dot_general"(%3347, %3372) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x50x50xbf16>, tensor<24x50x64xbf16>) -> tensor<24x50x64xbf16> loc(#loc629)
        %3374 = ttir.empty() : tensor<2x12x50x64xbf16> loc(#loc622)
        %3375 = "ttir.reshape"(%3373, %3374) <{shape = [2 : i32, 12 : i32, 50 : i32, 64 : i32]}> : (tensor<24x50x64xbf16>, tensor<2x12x50x64xbf16>) -> tensor<2x12x50x64xbf16> loc(#loc622)
        %3376 = ttir.empty() : tensor<2x50x12x64xbf16> loc(#loc630)
        %3377 = "ttir.permute"(%3375, %3376) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<2x12x50x64xbf16>, tensor<2x50x12x64xbf16>) -> tensor<2x50x12x64xbf16> loc(#loc630)
        %3378 = ttir.empty() : tensor<100x768xbf16> loc(#loc631)
        %3379 = "ttir.reshape"(%3377, %3378) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x12x64xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc631)
        %3380 = ttir.empty() : tensor<1x768x768xbf16> loc(#loc2)
        %3381 = "ttir.reshape"(%arg10, %3380) <{shape = [1 : i32, 768 : i32, 768 : i32]}> : (tensor<768x768xbf16>, tensor<1x768x768xbf16>) -> tensor<1x768x768xbf16> loc(#loc2)
        %3382 = ttir.empty() : tensor<768x768xbf16> loc(#loc2)
        %3383 = "ttir.reshape"(%3381, %3382) <{shape = [768 : i32, 768 : i32]}> : (tensor<1x768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc2)
        %3384 = ttir.empty() : tensor<768x768xbf16> loc(#loc632)
        %3385 = "ttir.permute"(%3383, %3384) <{permutation = array<i64: 1, 0>}> : (tensor<768x768xbf16>, tensor<768x768xbf16>) -> tensor<768x768xbf16> loc(#loc632)
        %3386 = "ttir.dot_general"(%3379, %3385) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x768xbf16>) -> tensor<100x768xbf16> loc(#loc633)
        %3387 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc631)
        %3388 = "ttir.reshape"(%3386, %3387) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc631)
        %3389 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %3390 = "ttir.reshape"(%arg9, %3389) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %3391 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %3392 = "ttir.reshape"(%3390, %3391) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %3393 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc634)
        %3394 = "ttir.reshape"(%3392, %3393) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc634)
        %3395 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc634)
        %3396 = "ttir.broadcast"(%3394, %3395) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc634)
        %3397 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc634)
        %3398 = "ttir.add"(%3388, %3396, %3397) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc634)
        %3399 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc635)
        %3400 = "ttir.add"(%3216, %3398, %3399) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc635)
        %3401 = ttir.empty() : tensor<2x50xbf16> loc(#loc636)
        %3402 = "ttir.sum"(%3400, %3401) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc636)
        %3403 = ttir.empty() : tensor<2x50xbf16> loc(#loc636)
        %3404 = "ttir.multiply"(%3402, %5, %3403) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc636)
        %3405 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc637)
        %3406 = "ttir.reshape"(%3404, %3405) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc637)
        %3407 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc637)
        %3408 = "ttir.broadcast"(%3406, %3407) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc637)
        %3409 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc637)
        %3410 = "ttir.subtract"(%3400, %3408, %3409) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc637)
        %3411 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc636)
        %3412 = "ttir.multiply"(%3410, %3410, %3411) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc636)
        %3413 = ttir.empty() : tensor<2x50xbf16> loc(#loc636)
        %3414 = "ttir.sum"(%3412, %3413) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<2x50x768xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc636)
        %3415 = ttir.empty() : tensor<2x50xbf16> loc(#loc636)
        %3416 = "ttir.multiply"(%3414, %5, %3415) : (tensor<2x50xbf16>, tensor<2x50xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc636)
        %3417 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc636)
        %3418 = "ttir.reshape"(%3416, %3417) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc636)
        %3419 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc638)
        %3420 = "ttir.add"(%3418, %4, %3419) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc638)
        %3421 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc639)
        %3422 = "ttir.rsqrt"(%3420, %3421) : (tensor<2x50x1xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc639)
        %3423 = ttir.empty() : tensor<2x50xbf16> loc(#loc640)
        %3424 = "ttir.reshape"(%3422, %3423) <{shape = [2 : i32, 50 : i32]}> : (tensor<2x50x1xbf16>, tensor<2x50xbf16>) -> tensor<2x50xbf16> loc(#loc640)
        %3425 = ttir.empty() : tensor<2x50x1xbf16> loc(#loc640)
        %3426 = "ttir.reshape"(%3424, %3425) <{shape = [2 : i32, 50 : i32, 1 : i32]}> : (tensor<2x50xbf16>, tensor<2x50x1xbf16>) -> tensor<2x50x1xbf16> loc(#loc640)
        %3427 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc640)
        %3428 = "ttir.broadcast"(%3426, %3427) <{broadcast_dimensions = array<i64: 1, 1, 768>}> : (tensor<2x50x1xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc640)
        %3429 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc640)
        %3430 = "ttir.multiply"(%3410, %3428, %3429) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc640)
        %3431 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %3432 = "ttir.reshape"(%arg8, %3431) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %3433 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %3434 = "ttir.reshape"(%3432, %3433) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %3435 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc640)
        %3436 = "ttir.reshape"(%3434, %3435) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc640)
        %3437 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc640)
        %3438 = "ttir.broadcast"(%3436, %3437) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc640)
        %3439 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc640)
        %3440 = "ttir.multiply"(%3430, %3438, %3439) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc640)
        %3441 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %3442 = "ttir.reshape"(%arg7, %3441) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %3443 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %3444 = "ttir.reshape"(%3442, %3443) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %3445 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc638)
        %3446 = "ttir.reshape"(%3444, %3445) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc638)
        %3447 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc638)
        %3448 = "ttir.broadcast"(%3446, %3447) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc638)
        %3449 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc638)
        %3450 = "ttir.add"(%3440, %3448, %3449) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc638)
        %3451 = ttir.empty() : tensor<100x768xbf16> loc(#loc641)
        %3452 = "ttir.reshape"(%3450, %3451) <{shape = [100 : i32, 768 : i32]}> : (tensor<2x50x768xbf16>, tensor<100x768xbf16>) -> tensor<100x768xbf16> loc(#loc641)
        %3453 = ttir.empty() : tensor<1x3072x768xbf16> loc(#loc2)
        %3454 = "ttir.reshape"(%arg6, %3453) <{shape = [1 : i32, 3072 : i32, 768 : i32]}> : (tensor<3072x768xbf16>, tensor<1x3072x768xbf16>) -> tensor<1x3072x768xbf16> loc(#loc2)
        %3455 = ttir.empty() : tensor<3072x768xbf16> loc(#loc2)
        %3456 = "ttir.reshape"(%3454, %3455) <{shape = [3072 : i32, 768 : i32]}> : (tensor<1x3072x768xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc2)
        %3457 = ttir.empty() : tensor<768x3072xbf16> loc(#loc642)
        %3458 = "ttir.permute"(%3456, %3457) <{permutation = array<i64: 1, 0>}> : (tensor<3072x768xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc642)
        %3459 = "ttir.dot_general"(%3452, %3458) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x768xbf16>, tensor<768x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc643)
        %3460 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc641)
        %3461 = "ttir.reshape"(%3459, %3460) <{shape = [2 : i32, 50 : i32, 3072 : i32]}> : (tensor<100x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc641)
        %3462 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc2)
        %3463 = "ttir.reshape"(%arg5, %3462) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc2)
        %3464 = ttir.empty() : tensor<3072xbf16> loc(#loc2)
        %3465 = "ttir.reshape"(%3463, %3464) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc2)
        %3466 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc644)
        %3467 = "ttir.reshape"(%3465, %3466) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc644)
        %3468 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc644)
        %3469 = "ttir.broadcast"(%3467, %3468) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc644)
        %3470 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc644)
        %3471 = "ttir.add"(%3461, %3469, %3470) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc644)
        %3472 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc645)
        %3473 = "ttir.multiply"(%3471, %2, %3472) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc645)
        %3474 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc646)
        %3475 = "ttir.sigmoid"(%3473, %3474) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc646)
        %3476 = ttir.empty() : tensor<2x50x3072xbf16> loc(#loc645)
        %3477 = "ttir.multiply"(%3471, %3475, %3476) : (tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>, tensor<2x50x3072xbf16>) -> tensor<2x50x3072xbf16> loc(#loc645)
        %3478 = ttir.empty() : tensor<100x3072xbf16> loc(#loc647)
        %3479 = "ttir.reshape"(%3477, %3478) <{shape = [100 : i32, 3072 : i32]}> : (tensor<2x50x3072xbf16>, tensor<100x3072xbf16>) -> tensor<100x3072xbf16> loc(#loc647)
        %3480 = ttir.empty() : tensor<1x768x3072xbf16> loc(#loc2)
        %3481 = "ttir.reshape"(%arg4, %3480) <{shape = [1 : i32, 768 : i32, 3072 : i32]}> : (tensor<768x3072xbf16>, tensor<1x768x3072xbf16>) -> tensor<1x768x3072xbf16> loc(#loc2)
        %3482 = ttir.empty() : tensor<768x3072xbf16> loc(#loc2)
        %3483 = "ttir.reshape"(%3481, %3482) <{shape = [768 : i32, 3072 : i32]}> : (tensor<1x768x3072xbf16>, tensor<768x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc2)
        %3484 = ttir.empty() : tensor<3072x768xbf16> loc(#loc648)
        %3485 = "ttir.permute"(%3483, %3484) <{permutation = array<i64: 1, 0>}> : (tensor<768x3072xbf16>, tensor<3072x768xbf16>) -> tensor<3072x768xbf16> loc(#loc648)
        %3486 = "ttir.dot_general"(%3479, %3485) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<100x3072xbf16>, tensor<3072x768xbf16>) -> tensor<100x768xbf16> loc(#loc649)
        %3487 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc647)
        %3488 = "ttir.reshape"(%3486, %3487) <{shape = [2 : i32, 50 : i32, 768 : i32]}> : (tensor<100x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc647)
        %3489 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %3490 = "ttir.reshape"(%arg3, %3489) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %3491 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %3492 = "ttir.reshape"(%3490, %3491) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %3493 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc650)
        %3494 = "ttir.reshape"(%3492, %3493) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc650)
        %3495 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc650)
        %3496 = "ttir.broadcast"(%3494, %3495) <{broadcast_dimensions = array<i64: 2, 50, 1>}> : (tensor<1x1x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc650)
        %3497 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc650)
        %3498 = "ttir.add"(%3488, %3496, %3497) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc650)
        %3499 = ttir.empty() : tensor<2x50x768xbf16> loc(#loc651)
        %3500 = "ttir.add"(%3400, %3498, %3499) : (tensor<2x50x768xbf16>, tensor<2x50x768xbf16>, tensor<2x50x768xbf16>) -> tensor<2x50x768xbf16> loc(#loc651)
        %3501 = ttir.empty() : tensor<2x1x768xbf16> loc(#loc652)
        %3502 = "ttir.slice_static"(%3500, %3501) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [2 : i32, 1 : i32, 768 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<2x50x768xbf16>, tensor<2x1x768xbf16>) -> tensor<2x1x768xbf16> loc(#loc652)
        %3503 = ttir.empty() : tensor<2x768xbf16> loc(#loc653)
        %3504 = "ttir.reshape"(%3502, %3503) <{shape = [2 : i32, 768 : i32]}> : (tensor<2x1x768xbf16>, tensor<2x768xbf16>) -> tensor<2x768xbf16> loc(#loc653)
        %3505 = ttir.empty() : tensor<2xbf16> loc(#loc654)
        %3506 = "ttir.sum"(%3504, %3505) <{dim_arg = [1 : i32], keep_dim = false}> : (tensor<2x768xbf16>, tensor<2xbf16>) -> tensor<2xbf16> loc(#loc654)
        %3507 = ttir.empty() : tensor<2xbf16> loc(#loc654)
        %3508 = "ttir.multiply"(%3506, %1, %3507) : (tensor<2xbf16>, tensor<2xbf16>, tensor<2xbf16>) -> tensor<2xbf16> loc(#loc654)
        %3509 = ttir.empty() : tensor<2x1xbf16> loc(#loc655)
        %3510 = "ttir.reshape"(%3508, %3509) <{shape = [2 : i32, 1 : i32]}> : (tensor<2xbf16>, tensor<2x1xbf16>) -> tensor<2x1xbf16> loc(#loc655)
        %3511 = ttir.empty() : tensor<2x768xbf16> loc(#loc655)
        %3512 = "ttir.broadcast"(%3510, %3511) <{broadcast_dimensions = array<i64: 1, 768>}> : (tensor<2x1xbf16>, tensor<2x768xbf16>) -> tensor<2x768xbf16> loc(#loc655)
        %3513 = ttir.empty() : tensor<2x768xbf16> loc(#loc655)
        %3514 = "ttir.subtract"(%3504, %3512, %3513) : (tensor<2x768xbf16>, tensor<2x768xbf16>, tensor<2x768xbf16>) -> tensor<2x768xbf16> loc(#loc655)
        %3515 = ttir.empty() : tensor<2x768xbf16> loc(#loc654)
        %3516 = "ttir.multiply"(%3514, %3514, %3515) : (tensor<2x768xbf16>, tensor<2x768xbf16>, tensor<2x768xbf16>) -> tensor<2x768xbf16> loc(#loc654)
        %3517 = ttir.empty() : tensor<2xbf16> loc(#loc654)
        %3518 = "ttir.sum"(%3516, %3517) <{dim_arg = [1 : i32], keep_dim = false}> : (tensor<2x768xbf16>, tensor<2xbf16>) -> tensor<2xbf16> loc(#loc654)
        %3519 = ttir.empty() : tensor<2xbf16> loc(#loc654)
        %3520 = "ttir.multiply"(%3518, %1, %3519) : (tensor<2xbf16>, tensor<2xbf16>, tensor<2xbf16>) -> tensor<2xbf16> loc(#loc654)
        %3521 = ttir.empty() : tensor<2x1xbf16> loc(#loc654)
        %3522 = "ttir.reshape"(%3520, %3521) <{shape = [2 : i32, 1 : i32]}> : (tensor<2xbf16>, tensor<2x1xbf16>) -> tensor<2x1xbf16> loc(#loc654)
        %3523 = ttir.empty() : tensor<2x1xbf16> loc(#loc656)
        %3524 = "ttir.add"(%3522, %0, %3523) : (tensor<2x1xbf16>, tensor<2x1xbf16>, tensor<2x1xbf16>) -> tensor<2x1xbf16> loc(#loc656)
        %3525 = ttir.empty() : tensor<2x1xbf16> loc(#loc657)
        %3526 = "ttir.rsqrt"(%3524, %3525) : (tensor<2x1xbf16>, tensor<2x1xbf16>) -> tensor<2x1xbf16> loc(#loc657)
        %3527 = ttir.empty() : tensor<2xbf16> loc(#loc658)
        %3528 = "ttir.reshape"(%3526, %3527) <{shape = [2 : i32]}> : (tensor<2x1xbf16>, tensor<2xbf16>) -> tensor<2xbf16> loc(#loc658)
        %3529 = ttir.empty() : tensor<2x1xbf16> loc(#loc658)
        %3530 = "ttir.reshape"(%3528, %3529) <{shape = [2 : i32, 1 : i32]}> : (tensor<2xbf16>, tensor<2x1xbf16>) -> tensor<2x1xbf16> loc(#loc658)
        %3531 = ttir.empty() : tensor<2x768xbf16> loc(#loc658)
        %3532 = "ttir.broadcast"(%3530, %3531) <{broadcast_dimensions = array<i64: 1, 768>}> : (tensor<2x1xbf16>, tensor<2x768xbf16>) -> tensor<2x768xbf16> loc(#loc658)
        %3533 = ttir.empty() : tensor<2x768xbf16> loc(#loc658)
        %3534 = "ttir.multiply"(%3514, %3532, %3533) : (tensor<2x768xbf16>, tensor<2x768xbf16>, tensor<2x768xbf16>) -> tensor<2x768xbf16> loc(#loc658)
        %3535 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %3536 = "ttir.reshape"(%arg2, %3535) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %3537 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %3538 = "ttir.reshape"(%3536, %3537) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %3539 = ttir.empty() : tensor<1x768xbf16> loc(#loc658)
        %3540 = "ttir.reshape"(%3538, %3539) <{shape = [1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x768xbf16>) -> tensor<1x768xbf16> loc(#loc658)
        %3541 = ttir.empty() : tensor<2x768xbf16> loc(#loc658)
        %3542 = "ttir.broadcast"(%3540, %3541) <{broadcast_dimensions = array<i64: 2, 1>}> : (tensor<1x768xbf16>, tensor<2x768xbf16>) -> tensor<2x768xbf16> loc(#loc658)
        %3543 = ttir.empty() : tensor<2x768xbf16> loc(#loc658)
        %3544 = "ttir.multiply"(%3534, %3542, %3543) : (tensor<2x768xbf16>, tensor<2x768xbf16>, tensor<2x768xbf16>) -> tensor<2x768xbf16> loc(#loc658)
        %3545 = ttir.empty() : tensor<1x1x768xbf16> loc(#loc2)
        %3546 = "ttir.reshape"(%arg1, %3545) <{shape = [1 : i32, 1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x1x768xbf16>) -> tensor<1x1x768xbf16> loc(#loc2)
        %3547 = ttir.empty() : tensor<768xbf16> loc(#loc2)
        %3548 = "ttir.reshape"(%3546, %3547) <{shape = [768 : i32]}> : (tensor<1x1x768xbf16>, tensor<768xbf16>) -> tensor<768xbf16> loc(#loc2)
        %3549 = ttir.empty() : tensor<1x768xbf16> loc(#loc656)
        %3550 = "ttir.reshape"(%3548, %3549) <{shape = [1 : i32, 768 : i32]}> : (tensor<768xbf16>, tensor<1x768xbf16>) -> tensor<1x768xbf16> loc(#loc656)
        %3551 = ttir.empty() : tensor<2x768xbf16> loc(#loc656)
        %3552 = "ttir.broadcast"(%3550, %3551) <{broadcast_dimensions = array<i64: 2, 1>}> : (tensor<1x768xbf16>, tensor<2x768xbf16>) -> tensor<2x768xbf16> loc(#loc656)
        %3553 = ttir.empty() : tensor<2x768xbf16> loc(#loc656)
        %3554 = "ttir.add"(%3544, %3552, %3553) : (tensor<2x768xbf16>, tensor<2x768xbf16>, tensor<2x768xbf16>) -> tensor<2x768xbf16> loc(#loc656)
        %3555 = ttir.empty() : tensor<1x512x768xbf16> loc(#loc2)
        %3556 = "ttir.reshape"(%arg0, %3555) <{shape = [1 : i32, 512 : i32, 768 : i32]}> : (tensor<512x768xbf16>, tensor<1x512x768xbf16>) -> tensor<1x512x768xbf16> loc(#loc2)
        %3557 = ttir.empty() : tensor<512x768xbf16> loc(#loc2)
        %3558 = "ttir.reshape"(%3556, %3557) <{shape = [512 : i32, 768 : i32]}> : (tensor<1x512x768xbf16>, tensor<512x768xbf16>) -> tensor<512x768xbf16> loc(#loc2)
        %3559 = ttir.empty() : tensor<768x512xbf16> loc(#loc659)
        %3560 = "ttir.permute"(%3558, %3559) <{permutation = array<i64: 1, 0>}> : (tensor<512x768xbf16>, tensor<768x512xbf16>) -> tensor<768x512xbf16> loc(#loc659)
        %3561 = "ttir.dot_general"(%3554, %3560) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<2x768xbf16>, tensor<768x512xbf16>) -> tensor<2x512xbf16> loc(#loc660)
        return %3561, %3500 : tensor<2x512xbf16>, tensor<2x50x768xbf16> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("unknown|unknown|-1|unknownaten__view")
#loc3 = loc("CLIPVisionTransformer[vision_model]|CLIPVisionEmbeddings[vision_model.embeddings]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:217|forward|227|aten__expand")
#loc4 = loc("CLIPVisionTransformer[vision_model]|CLIPVisionEmbeddings[vision_model.embeddings]|Conv2d[vision_model.embeddings.patch_embedding]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:217|forward|224|aten__convolution_overrideable")
#loc5 = loc("CLIPVisionTransformer[vision_model]|CLIPVisionEmbeddings[vision_model.embeddings]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:217|forward|225|aten__view")
#loc6 = loc("CLIPVisionTransformer[vision_model]|CLIPVisionEmbeddings[vision_model.embeddings]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:217|forward|225|aten__permute")
#loc7 = loc("CLIPVisionTransformer[vision_model]|CLIPVisionEmbeddings[vision_model.embeddings]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:217|forward|228|aten__cat")
#loc8 = loc("CLIPVisionTransformer[vision_model]|CLIPVisionEmbeddings[vision_model.embeddings]|Embedding[vision_model.embeddings.position_embedding]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:217|forward|232|aten__view")
#loc9 = loc("CLIPVisionTransformer[vision_model]|CLIPVisionEmbeddings[vision_model.embeddings]|Embedding[vision_model.embeddings.position_embedding]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:217|forward|232|aten__index_select")
#loc10 = loc("CLIPVisionTransformer[vision_model]|CLIPVisionEmbeddings[vision_model.embeddings]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:217|forward|232|aten__add")
#loc11 = loc("CLIPVisionTransformer[vision_model]|LayerNorm[vision_model.pre_layrnorm]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:767|forward|783|aten__var_mean")
#loc12 = loc("CLIPVisionTransformer[vision_model]|LayerNorm[vision_model.pre_layrnorm]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:767|forward|783|aten__sub")
#loc13 = loc("CLIPVisionTransformer[vision_model]|LayerNorm[vision_model.pre_layrnorm]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:767|forward|783|aten__add")
#loc14 = loc("CLIPVisionTransformer[vision_model]|LayerNorm[vision_model.pre_layrnorm]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:767|forward|783|aten__rsqrt")
#loc15 = loc("CLIPVisionTransformer[vision_model]|LayerNorm[vision_model.pre_layrnorm]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:767|forward|783|aten__mul")
#loc16 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|LayerNorm[vision_model.encoder.layers[0].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__var_mean")
#loc17 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|LayerNorm[vision_model.encoder.layers[0].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__sub")
#loc18 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|LayerNorm[vision_model.encoder.layers[0].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__add")
#loc19 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|LayerNorm[vision_model.encoder.layers[0].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__rsqrt")
#loc20 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|LayerNorm[vision_model.encoder.layers[0].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__mul")
#loc21 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|Linear[vision_model.encoder.layers[0].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__view")
#loc22 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|Linear[vision_model.encoder.layers[0].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__permute")
#loc23 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|Linear[vision_model.encoder.layers[0].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__mm")
#loc24 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|Linear[vision_model.encoder.layers[0].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__add")
#loc25 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__view")
#loc26 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__permute")
#loc27 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__view")
#loc28 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|Linear[vision_model.encoder.layers[0].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__permute")
#loc29 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|Linear[vision_model.encoder.layers[0].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__mm")
#loc30 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|Linear[vision_model.encoder.layers[0].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__view")
#loc31 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|Linear[vision_model.encoder.layers[0].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__add")
#loc32 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|339|aten__view")
#loc33 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__permute")
#loc34 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__matmul")
#loc35 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__mul")
#loc36 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|xla__cast")
#loc37 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|aten__softmax")
#loc38 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|291|xla__cast")
#loc39 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__view")
#loc40 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|Linear[vision_model.encoder.layers[0].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__permute")
#loc41 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|Linear[vision_model.encoder.layers[0].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__mm")
#loc42 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|Linear[vision_model.encoder.layers[0].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__view")
#loc43 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|Linear[vision_model.encoder.layers[0].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__add")
#loc44 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__view")
#loc45 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__permute")
#loc46 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__matmul")
#loc47 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|294|aten__permute")
#loc48 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|Linear[vision_model.encoder.layers[0].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__view")
#loc49 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|Linear[vision_model.encoder.layers[0].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__permute")
#loc50 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|Linear[vision_model.encoder.layers[0].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__mm")
#loc51 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPAttention[vision_model.encoder.layers[0].self_attn]|Linear[vision_model.encoder.layers[0].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__add")
#loc52 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|431|aten__add")
#loc53 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|LayerNorm[vision_model.encoder.layers[0].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__var_mean")
#loc54 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|LayerNorm[vision_model.encoder.layers[0].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__sub")
#loc55 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|LayerNorm[vision_model.encoder.layers[0].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__add")
#loc56 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|LayerNorm[vision_model.encoder.layers[0].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__rsqrt")
#loc57 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|LayerNorm[vision_model.encoder.layers[0].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__mul")
#loc58 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPMLP[vision_model.encoder.layers[0].mlp]|Linear[vision_model.encoder.layers[0].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__view")
#loc59 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPMLP[vision_model.encoder.layers[0].mlp]|Linear[vision_model.encoder.layers[0].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__permute")
#loc60 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPMLP[vision_model.encoder.layers[0].mlp]|Linear[vision_model.encoder.layers[0].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__mm")
#loc61 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPMLP[vision_model.encoder.layers[0].mlp]|Linear[vision_model.encoder.layers[0].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__add")
#loc62 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPMLP[vision_model.encoder.layers[0].mlp]|QuickGELUActivation[vision_model.encoder.layers[0].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__mul")
#loc63 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPMLP[vision_model.encoder.layers[0].mlp]|QuickGELUActivation[vision_model.encoder.layers[0].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__sigmoid")
#loc64 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPMLP[vision_model.encoder.layers[0].mlp]|Linear[vision_model.encoder.layers[0].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__view")
#loc65 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPMLP[vision_model.encoder.layers[0].mlp]|Linear[vision_model.encoder.layers[0].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__permute")
#loc66 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPMLP[vision_model.encoder.layers[0].mlp]|Linear[vision_model.encoder.layers[0].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__mm")
#loc67 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|CLIPMLP[vision_model.encoder.layers[0].mlp]|Linear[vision_model.encoder.layers[0].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__add")
#loc68 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[0]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|436|aten__add")
#loc69 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|LayerNorm[vision_model.encoder.layers[1].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__var_mean")
#loc70 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|LayerNorm[vision_model.encoder.layers[1].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__sub")
#loc71 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|LayerNorm[vision_model.encoder.layers[1].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__add")
#loc72 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|LayerNorm[vision_model.encoder.layers[1].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__rsqrt")
#loc73 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|LayerNorm[vision_model.encoder.layers[1].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__mul")
#loc74 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|Linear[vision_model.encoder.layers[1].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__view")
#loc75 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|Linear[vision_model.encoder.layers[1].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__permute")
#loc76 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|Linear[vision_model.encoder.layers[1].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__mm")
#loc77 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|Linear[vision_model.encoder.layers[1].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__add")
#loc78 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__view")
#loc79 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__permute")
#loc80 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__view")
#loc81 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|Linear[vision_model.encoder.layers[1].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__permute")
#loc82 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|Linear[vision_model.encoder.layers[1].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__mm")
#loc83 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|Linear[vision_model.encoder.layers[1].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__view")
#loc84 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|Linear[vision_model.encoder.layers[1].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__add")
#loc85 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|339|aten__view")
#loc86 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__permute")
#loc87 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__matmul")
#loc88 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__mul")
#loc89 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|xla__cast")
#loc90 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|aten__softmax")
#loc91 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|291|xla__cast")
#loc92 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__view")
#loc93 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|Linear[vision_model.encoder.layers[1].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__permute")
#loc94 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|Linear[vision_model.encoder.layers[1].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__mm")
#loc95 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|Linear[vision_model.encoder.layers[1].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__view")
#loc96 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|Linear[vision_model.encoder.layers[1].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__add")
#loc97 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__view")
#loc98 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__permute")
#loc99 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__matmul")
#loc100 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|294|aten__permute")
#loc101 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|Linear[vision_model.encoder.layers[1].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__view")
#loc102 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|Linear[vision_model.encoder.layers[1].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__permute")
#loc103 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|Linear[vision_model.encoder.layers[1].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__mm")
#loc104 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPAttention[vision_model.encoder.layers[1].self_attn]|Linear[vision_model.encoder.layers[1].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__add")
#loc105 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|431|aten__add")
#loc106 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|LayerNorm[vision_model.encoder.layers[1].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__var_mean")
#loc107 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|LayerNorm[vision_model.encoder.layers[1].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__sub")
#loc108 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|LayerNorm[vision_model.encoder.layers[1].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__add")
#loc109 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|LayerNorm[vision_model.encoder.layers[1].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__rsqrt")
#loc110 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|LayerNorm[vision_model.encoder.layers[1].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__mul")
#loc111 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPMLP[vision_model.encoder.layers[1].mlp]|Linear[vision_model.encoder.layers[1].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__view")
#loc112 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPMLP[vision_model.encoder.layers[1].mlp]|Linear[vision_model.encoder.layers[1].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__permute")
#loc113 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPMLP[vision_model.encoder.layers[1].mlp]|Linear[vision_model.encoder.layers[1].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__mm")
#loc114 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPMLP[vision_model.encoder.layers[1].mlp]|Linear[vision_model.encoder.layers[1].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__add")
#loc115 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPMLP[vision_model.encoder.layers[1].mlp]|QuickGELUActivation[vision_model.encoder.layers[1].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__mul")
#loc116 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPMLP[vision_model.encoder.layers[1].mlp]|QuickGELUActivation[vision_model.encoder.layers[1].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__sigmoid")
#loc117 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPMLP[vision_model.encoder.layers[1].mlp]|Linear[vision_model.encoder.layers[1].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__view")
#loc118 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPMLP[vision_model.encoder.layers[1].mlp]|Linear[vision_model.encoder.layers[1].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__permute")
#loc119 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPMLP[vision_model.encoder.layers[1].mlp]|Linear[vision_model.encoder.layers[1].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__mm")
#loc120 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|CLIPMLP[vision_model.encoder.layers[1].mlp]|Linear[vision_model.encoder.layers[1].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__add")
#loc121 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[1]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|436|aten__add")
#loc122 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|LayerNorm[vision_model.encoder.layers[2].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__var_mean")
#loc123 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|LayerNorm[vision_model.encoder.layers[2].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__sub")
#loc124 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|LayerNorm[vision_model.encoder.layers[2].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__add")
#loc125 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|LayerNorm[vision_model.encoder.layers[2].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__rsqrt")
#loc126 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|LayerNorm[vision_model.encoder.layers[2].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__mul")
#loc127 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|Linear[vision_model.encoder.layers[2].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__view")
#loc128 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|Linear[vision_model.encoder.layers[2].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__permute")
#loc129 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|Linear[vision_model.encoder.layers[2].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__mm")
#loc130 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|Linear[vision_model.encoder.layers[2].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__add")
#loc131 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__view")
#loc132 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__permute")
#loc133 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__view")
#loc134 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|Linear[vision_model.encoder.layers[2].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__permute")
#loc135 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|Linear[vision_model.encoder.layers[2].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__mm")
#loc136 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|Linear[vision_model.encoder.layers[2].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__view")
#loc137 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|Linear[vision_model.encoder.layers[2].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__add")
#loc138 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|339|aten__view")
#loc139 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__permute")
#loc140 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__matmul")
#loc141 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__mul")
#loc142 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|xla__cast")
#loc143 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|aten__softmax")
#loc144 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|291|xla__cast")
#loc145 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__view")
#loc146 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|Linear[vision_model.encoder.layers[2].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__permute")
#loc147 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|Linear[vision_model.encoder.layers[2].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__mm")
#loc148 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|Linear[vision_model.encoder.layers[2].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__view")
#loc149 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|Linear[vision_model.encoder.layers[2].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__add")
#loc150 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__view")
#loc151 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__permute")
#loc152 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__matmul")
#loc153 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|294|aten__permute")
#loc154 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|Linear[vision_model.encoder.layers[2].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__view")
#loc155 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|Linear[vision_model.encoder.layers[2].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__permute")
#loc156 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|Linear[vision_model.encoder.layers[2].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__mm")
#loc157 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPAttention[vision_model.encoder.layers[2].self_attn]|Linear[vision_model.encoder.layers[2].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__add")
#loc158 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|431|aten__add")
#loc159 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|LayerNorm[vision_model.encoder.layers[2].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__var_mean")
#loc160 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|LayerNorm[vision_model.encoder.layers[2].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__sub")
#loc161 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|LayerNorm[vision_model.encoder.layers[2].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__add")
#loc162 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|LayerNorm[vision_model.encoder.layers[2].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__rsqrt")
#loc163 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|LayerNorm[vision_model.encoder.layers[2].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__mul")
#loc164 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPMLP[vision_model.encoder.layers[2].mlp]|Linear[vision_model.encoder.layers[2].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__view")
#loc165 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPMLP[vision_model.encoder.layers[2].mlp]|Linear[vision_model.encoder.layers[2].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__permute")
#loc166 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPMLP[vision_model.encoder.layers[2].mlp]|Linear[vision_model.encoder.layers[2].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__mm")
#loc167 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPMLP[vision_model.encoder.layers[2].mlp]|Linear[vision_model.encoder.layers[2].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__add")
#loc168 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPMLP[vision_model.encoder.layers[2].mlp]|QuickGELUActivation[vision_model.encoder.layers[2].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__mul")
#loc169 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPMLP[vision_model.encoder.layers[2].mlp]|QuickGELUActivation[vision_model.encoder.layers[2].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__sigmoid")
#loc170 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPMLP[vision_model.encoder.layers[2].mlp]|Linear[vision_model.encoder.layers[2].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__view")
#loc171 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPMLP[vision_model.encoder.layers[2].mlp]|Linear[vision_model.encoder.layers[2].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__permute")
#loc172 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPMLP[vision_model.encoder.layers[2].mlp]|Linear[vision_model.encoder.layers[2].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__mm")
#loc173 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|CLIPMLP[vision_model.encoder.layers[2].mlp]|Linear[vision_model.encoder.layers[2].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__add")
#loc174 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[2]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|436|aten__add")
#loc175 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|LayerNorm[vision_model.encoder.layers[3].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__var_mean")
#loc176 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|LayerNorm[vision_model.encoder.layers[3].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__sub")
#loc177 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|LayerNorm[vision_model.encoder.layers[3].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__add")
#loc178 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|LayerNorm[vision_model.encoder.layers[3].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__rsqrt")
#loc179 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|LayerNorm[vision_model.encoder.layers[3].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__mul")
#loc180 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|Linear[vision_model.encoder.layers[3].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__view")
#loc181 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|Linear[vision_model.encoder.layers[3].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__permute")
#loc182 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|Linear[vision_model.encoder.layers[3].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__mm")
#loc183 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|Linear[vision_model.encoder.layers[3].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__add")
#loc184 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__view")
#loc185 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__permute")
#loc186 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__view")
#loc187 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|Linear[vision_model.encoder.layers[3].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__permute")
#loc188 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|Linear[vision_model.encoder.layers[3].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__mm")
#loc189 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|Linear[vision_model.encoder.layers[3].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__view")
#loc190 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|Linear[vision_model.encoder.layers[3].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__add")
#loc191 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|339|aten__view")
#loc192 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__permute")
#loc193 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__matmul")
#loc194 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__mul")
#loc195 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|xla__cast")
#loc196 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|aten__softmax")
#loc197 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|291|xla__cast")
#loc198 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__view")
#loc199 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|Linear[vision_model.encoder.layers[3].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__permute")
#loc200 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|Linear[vision_model.encoder.layers[3].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__mm")
#loc201 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|Linear[vision_model.encoder.layers[3].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__view")
#loc202 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|Linear[vision_model.encoder.layers[3].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__add")
#loc203 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__view")
#loc204 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__permute")
#loc205 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__matmul")
#loc206 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|294|aten__permute")
#loc207 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|Linear[vision_model.encoder.layers[3].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__view")
#loc208 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|Linear[vision_model.encoder.layers[3].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__permute")
#loc209 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|Linear[vision_model.encoder.layers[3].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__mm")
#loc210 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPAttention[vision_model.encoder.layers[3].self_attn]|Linear[vision_model.encoder.layers[3].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__add")
#loc211 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|431|aten__add")
#loc212 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|LayerNorm[vision_model.encoder.layers[3].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__var_mean")
#loc213 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|LayerNorm[vision_model.encoder.layers[3].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__sub")
#loc214 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|LayerNorm[vision_model.encoder.layers[3].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__add")
#loc215 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|LayerNorm[vision_model.encoder.layers[3].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__rsqrt")
#loc216 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|LayerNorm[vision_model.encoder.layers[3].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__mul")
#loc217 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPMLP[vision_model.encoder.layers[3].mlp]|Linear[vision_model.encoder.layers[3].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__view")
#loc218 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPMLP[vision_model.encoder.layers[3].mlp]|Linear[vision_model.encoder.layers[3].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__permute")
#loc219 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPMLP[vision_model.encoder.layers[3].mlp]|Linear[vision_model.encoder.layers[3].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__mm")
#loc220 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPMLP[vision_model.encoder.layers[3].mlp]|Linear[vision_model.encoder.layers[3].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__add")
#loc221 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPMLP[vision_model.encoder.layers[3].mlp]|QuickGELUActivation[vision_model.encoder.layers[3].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__mul")
#loc222 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPMLP[vision_model.encoder.layers[3].mlp]|QuickGELUActivation[vision_model.encoder.layers[3].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__sigmoid")
#loc223 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPMLP[vision_model.encoder.layers[3].mlp]|Linear[vision_model.encoder.layers[3].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__view")
#loc224 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPMLP[vision_model.encoder.layers[3].mlp]|Linear[vision_model.encoder.layers[3].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__permute")
#loc225 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPMLP[vision_model.encoder.layers[3].mlp]|Linear[vision_model.encoder.layers[3].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__mm")
#loc226 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|CLIPMLP[vision_model.encoder.layers[3].mlp]|Linear[vision_model.encoder.layers[3].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__add")
#loc227 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[3]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|436|aten__add")
#loc228 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|LayerNorm[vision_model.encoder.layers[4].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__var_mean")
#loc229 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|LayerNorm[vision_model.encoder.layers[4].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__sub")
#loc230 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|LayerNorm[vision_model.encoder.layers[4].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__add")
#loc231 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|LayerNorm[vision_model.encoder.layers[4].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__rsqrt")
#loc232 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|LayerNorm[vision_model.encoder.layers[4].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__mul")
#loc233 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|Linear[vision_model.encoder.layers[4].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__view")
#loc234 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|Linear[vision_model.encoder.layers[4].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__permute")
#loc235 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|Linear[vision_model.encoder.layers[4].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__mm")
#loc236 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|Linear[vision_model.encoder.layers[4].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__add")
#loc237 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__view")
#loc238 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__permute")
#loc239 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__view")
#loc240 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|Linear[vision_model.encoder.layers[4].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__permute")
#loc241 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|Linear[vision_model.encoder.layers[4].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__mm")
#loc242 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|Linear[vision_model.encoder.layers[4].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__view")
#loc243 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|Linear[vision_model.encoder.layers[4].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__add")
#loc244 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|339|aten__view")
#loc245 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__permute")
#loc246 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__matmul")
#loc247 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__mul")
#loc248 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|xla__cast")
#loc249 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|aten__softmax")
#loc250 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|291|xla__cast")
#loc251 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__view")
#loc252 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|Linear[vision_model.encoder.layers[4].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__permute")
#loc253 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|Linear[vision_model.encoder.layers[4].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__mm")
#loc254 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|Linear[vision_model.encoder.layers[4].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__view")
#loc255 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|Linear[vision_model.encoder.layers[4].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__add")
#loc256 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__view")
#loc257 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__permute")
#loc258 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__matmul")
#loc259 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|294|aten__permute")
#loc260 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|Linear[vision_model.encoder.layers[4].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__view")
#loc261 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|Linear[vision_model.encoder.layers[4].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__permute")
#loc262 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|Linear[vision_model.encoder.layers[4].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__mm")
#loc263 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPAttention[vision_model.encoder.layers[4].self_attn]|Linear[vision_model.encoder.layers[4].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__add")
#loc264 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|431|aten__add")
#loc265 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|LayerNorm[vision_model.encoder.layers[4].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__var_mean")
#loc266 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|LayerNorm[vision_model.encoder.layers[4].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__sub")
#loc267 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|LayerNorm[vision_model.encoder.layers[4].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__add")
#loc268 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|LayerNorm[vision_model.encoder.layers[4].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__rsqrt")
#loc269 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|LayerNorm[vision_model.encoder.layers[4].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__mul")
#loc270 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPMLP[vision_model.encoder.layers[4].mlp]|Linear[vision_model.encoder.layers[4].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__view")
#loc271 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPMLP[vision_model.encoder.layers[4].mlp]|Linear[vision_model.encoder.layers[4].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__permute")
#loc272 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPMLP[vision_model.encoder.layers[4].mlp]|Linear[vision_model.encoder.layers[4].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__mm")
#loc273 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPMLP[vision_model.encoder.layers[4].mlp]|Linear[vision_model.encoder.layers[4].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__add")
#loc274 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPMLP[vision_model.encoder.layers[4].mlp]|QuickGELUActivation[vision_model.encoder.layers[4].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__mul")
#loc275 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPMLP[vision_model.encoder.layers[4].mlp]|QuickGELUActivation[vision_model.encoder.layers[4].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__sigmoid")
#loc276 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPMLP[vision_model.encoder.layers[4].mlp]|Linear[vision_model.encoder.layers[4].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__view")
#loc277 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPMLP[vision_model.encoder.layers[4].mlp]|Linear[vision_model.encoder.layers[4].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__permute")
#loc278 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPMLP[vision_model.encoder.layers[4].mlp]|Linear[vision_model.encoder.layers[4].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__mm")
#loc279 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|CLIPMLP[vision_model.encoder.layers[4].mlp]|Linear[vision_model.encoder.layers[4].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__add")
#loc280 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[4]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|436|aten__add")
#loc281 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|LayerNorm[vision_model.encoder.layers[5].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__var_mean")
#loc282 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|LayerNorm[vision_model.encoder.layers[5].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__sub")
#loc283 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|LayerNorm[vision_model.encoder.layers[5].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__add")
#loc284 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|LayerNorm[vision_model.encoder.layers[5].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__rsqrt")
#loc285 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|LayerNorm[vision_model.encoder.layers[5].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__mul")
#loc286 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|Linear[vision_model.encoder.layers[5].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__view")
#loc287 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|Linear[vision_model.encoder.layers[5].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__permute")
#loc288 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|Linear[vision_model.encoder.layers[5].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__mm")
#loc289 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|Linear[vision_model.encoder.layers[5].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__add")
#loc290 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__view")
#loc291 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__permute")
#loc292 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__view")
#loc293 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|Linear[vision_model.encoder.layers[5].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__permute")
#loc294 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|Linear[vision_model.encoder.layers[5].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__mm")
#loc295 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|Linear[vision_model.encoder.layers[5].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__view")
#loc296 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|Linear[vision_model.encoder.layers[5].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__add")
#loc297 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|339|aten__view")
#loc298 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__permute")
#loc299 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__matmul")
#loc300 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__mul")
#loc301 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|xla__cast")
#loc302 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|aten__softmax")
#loc303 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|291|xla__cast")
#loc304 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__view")
#loc305 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|Linear[vision_model.encoder.layers[5].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__permute")
#loc306 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|Linear[vision_model.encoder.layers[5].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__mm")
#loc307 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|Linear[vision_model.encoder.layers[5].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__view")
#loc308 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|Linear[vision_model.encoder.layers[5].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__add")
#loc309 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__view")
#loc310 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__permute")
#loc311 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__matmul")
#loc312 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|294|aten__permute")
#loc313 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|Linear[vision_model.encoder.layers[5].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__view")
#loc314 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|Linear[vision_model.encoder.layers[5].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__permute")
#loc315 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|Linear[vision_model.encoder.layers[5].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__mm")
#loc316 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPAttention[vision_model.encoder.layers[5].self_attn]|Linear[vision_model.encoder.layers[5].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__add")
#loc317 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|431|aten__add")
#loc318 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|LayerNorm[vision_model.encoder.layers[5].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__var_mean")
#loc319 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|LayerNorm[vision_model.encoder.layers[5].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__sub")
#loc320 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|LayerNorm[vision_model.encoder.layers[5].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__add")
#loc321 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|LayerNorm[vision_model.encoder.layers[5].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__rsqrt")
#loc322 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|LayerNorm[vision_model.encoder.layers[5].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__mul")
#loc323 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPMLP[vision_model.encoder.layers[5].mlp]|Linear[vision_model.encoder.layers[5].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__view")
#loc324 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPMLP[vision_model.encoder.layers[5].mlp]|Linear[vision_model.encoder.layers[5].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__permute")
#loc325 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPMLP[vision_model.encoder.layers[5].mlp]|Linear[vision_model.encoder.layers[5].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__mm")
#loc326 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPMLP[vision_model.encoder.layers[5].mlp]|Linear[vision_model.encoder.layers[5].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__add")
#loc327 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPMLP[vision_model.encoder.layers[5].mlp]|QuickGELUActivation[vision_model.encoder.layers[5].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__mul")
#loc328 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPMLP[vision_model.encoder.layers[5].mlp]|QuickGELUActivation[vision_model.encoder.layers[5].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__sigmoid")
#loc329 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPMLP[vision_model.encoder.layers[5].mlp]|Linear[vision_model.encoder.layers[5].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__view")
#loc330 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPMLP[vision_model.encoder.layers[5].mlp]|Linear[vision_model.encoder.layers[5].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__permute")
#loc331 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPMLP[vision_model.encoder.layers[5].mlp]|Linear[vision_model.encoder.layers[5].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__mm")
#loc332 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|CLIPMLP[vision_model.encoder.layers[5].mlp]|Linear[vision_model.encoder.layers[5].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__add")
#loc333 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[5]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|436|aten__add")
#loc334 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|LayerNorm[vision_model.encoder.layers[6].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__var_mean")
#loc335 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|LayerNorm[vision_model.encoder.layers[6].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__sub")
#loc336 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|LayerNorm[vision_model.encoder.layers[6].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__add")
#loc337 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|LayerNorm[vision_model.encoder.layers[6].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__rsqrt")
#loc338 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|LayerNorm[vision_model.encoder.layers[6].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__mul")
#loc339 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|Linear[vision_model.encoder.layers[6].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__view")
#loc340 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|Linear[vision_model.encoder.layers[6].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__permute")
#loc341 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|Linear[vision_model.encoder.layers[6].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__mm")
#loc342 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|Linear[vision_model.encoder.layers[6].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__add")
#loc343 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__view")
#loc344 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__permute")
#loc345 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__view")
#loc346 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|Linear[vision_model.encoder.layers[6].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__permute")
#loc347 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|Linear[vision_model.encoder.layers[6].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__mm")
#loc348 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|Linear[vision_model.encoder.layers[6].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__view")
#loc349 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|Linear[vision_model.encoder.layers[6].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__add")
#loc350 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|339|aten__view")
#loc351 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__permute")
#loc352 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__matmul")
#loc353 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__mul")
#loc354 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|xla__cast")
#loc355 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|aten__softmax")
#loc356 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|291|xla__cast")
#loc357 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__view")
#loc358 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|Linear[vision_model.encoder.layers[6].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__permute")
#loc359 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|Linear[vision_model.encoder.layers[6].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__mm")
#loc360 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|Linear[vision_model.encoder.layers[6].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__view")
#loc361 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|Linear[vision_model.encoder.layers[6].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__add")
#loc362 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__view")
#loc363 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__permute")
#loc364 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__matmul")
#loc365 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|294|aten__permute")
#loc366 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|Linear[vision_model.encoder.layers[6].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__view")
#loc367 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|Linear[vision_model.encoder.layers[6].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__permute")
#loc368 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|Linear[vision_model.encoder.layers[6].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__mm")
#loc369 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPAttention[vision_model.encoder.layers[6].self_attn]|Linear[vision_model.encoder.layers[6].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__add")
#loc370 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|431|aten__add")
#loc371 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|LayerNorm[vision_model.encoder.layers[6].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__var_mean")
#loc372 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|LayerNorm[vision_model.encoder.layers[6].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__sub")
#loc373 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|LayerNorm[vision_model.encoder.layers[6].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__add")
#loc374 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|LayerNorm[vision_model.encoder.layers[6].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__rsqrt")
#loc375 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|LayerNorm[vision_model.encoder.layers[6].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__mul")
#loc376 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPMLP[vision_model.encoder.layers[6].mlp]|Linear[vision_model.encoder.layers[6].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__view")
#loc377 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPMLP[vision_model.encoder.layers[6].mlp]|Linear[vision_model.encoder.layers[6].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__permute")
#loc378 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPMLP[vision_model.encoder.layers[6].mlp]|Linear[vision_model.encoder.layers[6].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__mm")
#loc379 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPMLP[vision_model.encoder.layers[6].mlp]|Linear[vision_model.encoder.layers[6].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__add")
#loc380 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPMLP[vision_model.encoder.layers[6].mlp]|QuickGELUActivation[vision_model.encoder.layers[6].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__mul")
#loc381 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPMLP[vision_model.encoder.layers[6].mlp]|QuickGELUActivation[vision_model.encoder.layers[6].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__sigmoid")
#loc382 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPMLP[vision_model.encoder.layers[6].mlp]|Linear[vision_model.encoder.layers[6].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__view")
#loc383 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPMLP[vision_model.encoder.layers[6].mlp]|Linear[vision_model.encoder.layers[6].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__permute")
#loc384 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPMLP[vision_model.encoder.layers[6].mlp]|Linear[vision_model.encoder.layers[6].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__mm")
#loc385 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|CLIPMLP[vision_model.encoder.layers[6].mlp]|Linear[vision_model.encoder.layers[6].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__add")
#loc386 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[6]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|436|aten__add")
#loc387 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|LayerNorm[vision_model.encoder.layers[7].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__var_mean")
#loc388 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|LayerNorm[vision_model.encoder.layers[7].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__sub")
#loc389 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|LayerNorm[vision_model.encoder.layers[7].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__add")
#loc390 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|LayerNorm[vision_model.encoder.layers[7].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__rsqrt")
#loc391 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|LayerNorm[vision_model.encoder.layers[7].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__mul")
#loc392 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|Linear[vision_model.encoder.layers[7].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__view")
#loc393 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|Linear[vision_model.encoder.layers[7].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__permute")
#loc394 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|Linear[vision_model.encoder.layers[7].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__mm")
#loc395 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|Linear[vision_model.encoder.layers[7].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__add")
#loc396 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__view")
#loc397 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__permute")
#loc398 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__view")
#loc399 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|Linear[vision_model.encoder.layers[7].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__permute")
#loc400 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|Linear[vision_model.encoder.layers[7].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__mm")
#loc401 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|Linear[vision_model.encoder.layers[7].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__view")
#loc402 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|Linear[vision_model.encoder.layers[7].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__add")
#loc403 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|339|aten__view")
#loc404 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__permute")
#loc405 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__matmul")
#loc406 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__mul")
#loc407 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|xla__cast")
#loc408 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|aten__softmax")
#loc409 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|291|xla__cast")
#loc410 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__view")
#loc411 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|Linear[vision_model.encoder.layers[7].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__permute")
#loc412 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|Linear[vision_model.encoder.layers[7].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__mm")
#loc413 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|Linear[vision_model.encoder.layers[7].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__view")
#loc414 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|Linear[vision_model.encoder.layers[7].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__add")
#loc415 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__view")
#loc416 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__permute")
#loc417 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__matmul")
#loc418 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|294|aten__permute")
#loc419 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|Linear[vision_model.encoder.layers[7].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__view")
#loc420 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|Linear[vision_model.encoder.layers[7].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__permute")
#loc421 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|Linear[vision_model.encoder.layers[7].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__mm")
#loc422 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPAttention[vision_model.encoder.layers[7].self_attn]|Linear[vision_model.encoder.layers[7].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__add")
#loc423 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|431|aten__add")
#loc424 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|LayerNorm[vision_model.encoder.layers[7].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__var_mean")
#loc425 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|LayerNorm[vision_model.encoder.layers[7].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__sub")
#loc426 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|LayerNorm[vision_model.encoder.layers[7].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__add")
#loc427 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|LayerNorm[vision_model.encoder.layers[7].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__rsqrt")
#loc428 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|LayerNorm[vision_model.encoder.layers[7].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__mul")
#loc429 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPMLP[vision_model.encoder.layers[7].mlp]|Linear[vision_model.encoder.layers[7].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__view")
#loc430 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPMLP[vision_model.encoder.layers[7].mlp]|Linear[vision_model.encoder.layers[7].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__permute")
#loc431 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPMLP[vision_model.encoder.layers[7].mlp]|Linear[vision_model.encoder.layers[7].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__mm")
#loc432 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPMLP[vision_model.encoder.layers[7].mlp]|Linear[vision_model.encoder.layers[7].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__add")
#loc433 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPMLP[vision_model.encoder.layers[7].mlp]|QuickGELUActivation[vision_model.encoder.layers[7].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__mul")
#loc434 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPMLP[vision_model.encoder.layers[7].mlp]|QuickGELUActivation[vision_model.encoder.layers[7].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__sigmoid")
#loc435 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPMLP[vision_model.encoder.layers[7].mlp]|Linear[vision_model.encoder.layers[7].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__view")
#loc436 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPMLP[vision_model.encoder.layers[7].mlp]|Linear[vision_model.encoder.layers[7].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__permute")
#loc437 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPMLP[vision_model.encoder.layers[7].mlp]|Linear[vision_model.encoder.layers[7].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__mm")
#loc438 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|CLIPMLP[vision_model.encoder.layers[7].mlp]|Linear[vision_model.encoder.layers[7].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__add")
#loc439 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[7]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|436|aten__add")
#loc440 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|LayerNorm[vision_model.encoder.layers[8].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__var_mean")
#loc441 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|LayerNorm[vision_model.encoder.layers[8].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__sub")
#loc442 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|LayerNorm[vision_model.encoder.layers[8].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__add")
#loc443 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|LayerNorm[vision_model.encoder.layers[8].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__rsqrt")
#loc444 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|LayerNorm[vision_model.encoder.layers[8].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__mul")
#loc445 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|Linear[vision_model.encoder.layers[8].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__view")
#loc446 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|Linear[vision_model.encoder.layers[8].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__permute")
#loc447 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|Linear[vision_model.encoder.layers[8].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__mm")
#loc448 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|Linear[vision_model.encoder.layers[8].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__add")
#loc449 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__view")
#loc450 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__permute")
#loc451 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__view")
#loc452 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|Linear[vision_model.encoder.layers[8].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__permute")
#loc453 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|Linear[vision_model.encoder.layers[8].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__mm")
#loc454 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|Linear[vision_model.encoder.layers[8].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__view")
#loc455 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|Linear[vision_model.encoder.layers[8].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__add")
#loc456 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|339|aten__view")
#loc457 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__permute")
#loc458 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__matmul")
#loc459 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__mul")
#loc460 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|xla__cast")
#loc461 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|aten__softmax")
#loc462 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|291|xla__cast")
#loc463 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__view")
#loc464 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|Linear[vision_model.encoder.layers[8].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__permute")
#loc465 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|Linear[vision_model.encoder.layers[8].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__mm")
#loc466 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|Linear[vision_model.encoder.layers[8].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__view")
#loc467 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|Linear[vision_model.encoder.layers[8].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__add")
#loc468 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__view")
#loc469 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__permute")
#loc470 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__matmul")
#loc471 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|294|aten__permute")
#loc472 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|Linear[vision_model.encoder.layers[8].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__view")
#loc473 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|Linear[vision_model.encoder.layers[8].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__permute")
#loc474 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|Linear[vision_model.encoder.layers[8].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__mm")
#loc475 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPAttention[vision_model.encoder.layers[8].self_attn]|Linear[vision_model.encoder.layers[8].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__add")
#loc476 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|431|aten__add")
#loc477 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|LayerNorm[vision_model.encoder.layers[8].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__var_mean")
#loc478 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|LayerNorm[vision_model.encoder.layers[8].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__sub")
#loc479 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|LayerNorm[vision_model.encoder.layers[8].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__add")
#loc480 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|LayerNorm[vision_model.encoder.layers[8].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__rsqrt")
#loc481 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|LayerNorm[vision_model.encoder.layers[8].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__mul")
#loc482 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPMLP[vision_model.encoder.layers[8].mlp]|Linear[vision_model.encoder.layers[8].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__view")
#loc483 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPMLP[vision_model.encoder.layers[8].mlp]|Linear[vision_model.encoder.layers[8].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__permute")
#loc484 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPMLP[vision_model.encoder.layers[8].mlp]|Linear[vision_model.encoder.layers[8].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__mm")
#loc485 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPMLP[vision_model.encoder.layers[8].mlp]|Linear[vision_model.encoder.layers[8].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__add")
#loc486 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPMLP[vision_model.encoder.layers[8].mlp]|QuickGELUActivation[vision_model.encoder.layers[8].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__mul")
#loc487 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPMLP[vision_model.encoder.layers[8].mlp]|QuickGELUActivation[vision_model.encoder.layers[8].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__sigmoid")
#loc488 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPMLP[vision_model.encoder.layers[8].mlp]|Linear[vision_model.encoder.layers[8].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__view")
#loc489 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPMLP[vision_model.encoder.layers[8].mlp]|Linear[vision_model.encoder.layers[8].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__permute")
#loc490 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPMLP[vision_model.encoder.layers[8].mlp]|Linear[vision_model.encoder.layers[8].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__mm")
#loc491 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|CLIPMLP[vision_model.encoder.layers[8].mlp]|Linear[vision_model.encoder.layers[8].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__add")
#loc492 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[8]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|436|aten__add")
#loc493 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|LayerNorm[vision_model.encoder.layers[9].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__var_mean")
#loc494 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|LayerNorm[vision_model.encoder.layers[9].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__sub")
#loc495 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|LayerNorm[vision_model.encoder.layers[9].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__add")
#loc496 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|LayerNorm[vision_model.encoder.layers[9].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__rsqrt")
#loc497 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|LayerNorm[vision_model.encoder.layers[9].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__mul")
#loc498 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|Linear[vision_model.encoder.layers[9].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__view")
#loc499 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|Linear[vision_model.encoder.layers[9].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__permute")
#loc500 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|Linear[vision_model.encoder.layers[9].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__mm")
#loc501 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|Linear[vision_model.encoder.layers[9].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__add")
#loc502 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__view")
#loc503 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__permute")
#loc504 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__view")
#loc505 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|Linear[vision_model.encoder.layers[9].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__permute")
#loc506 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|Linear[vision_model.encoder.layers[9].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__mm")
#loc507 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|Linear[vision_model.encoder.layers[9].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__view")
#loc508 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|Linear[vision_model.encoder.layers[9].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__add")
#loc509 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|339|aten__view")
#loc510 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__permute")
#loc511 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__matmul")
#loc512 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__mul")
#loc513 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|xla__cast")
#loc514 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|aten__softmax")
#loc515 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|291|xla__cast")
#loc516 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__view")
#loc517 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|Linear[vision_model.encoder.layers[9].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__permute")
#loc518 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|Linear[vision_model.encoder.layers[9].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__mm")
#loc519 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|Linear[vision_model.encoder.layers[9].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__view")
#loc520 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|Linear[vision_model.encoder.layers[9].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__add")
#loc521 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__view")
#loc522 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__permute")
#loc523 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__matmul")
#loc524 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|294|aten__permute")
#loc525 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|Linear[vision_model.encoder.layers[9].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__view")
#loc526 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|Linear[vision_model.encoder.layers[9].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__permute")
#loc527 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|Linear[vision_model.encoder.layers[9].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__mm")
#loc528 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPAttention[vision_model.encoder.layers[9].self_attn]|Linear[vision_model.encoder.layers[9].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__add")
#loc529 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|431|aten__add")
#loc530 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|LayerNorm[vision_model.encoder.layers[9].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__var_mean")
#loc531 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|LayerNorm[vision_model.encoder.layers[9].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__sub")
#loc532 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|LayerNorm[vision_model.encoder.layers[9].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__add")
#loc533 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|LayerNorm[vision_model.encoder.layers[9].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__rsqrt")
#loc534 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|LayerNorm[vision_model.encoder.layers[9].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__mul")
#loc535 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPMLP[vision_model.encoder.layers[9].mlp]|Linear[vision_model.encoder.layers[9].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__view")
#loc536 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPMLP[vision_model.encoder.layers[9].mlp]|Linear[vision_model.encoder.layers[9].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__permute")
#loc537 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPMLP[vision_model.encoder.layers[9].mlp]|Linear[vision_model.encoder.layers[9].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__mm")
#loc538 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPMLP[vision_model.encoder.layers[9].mlp]|Linear[vision_model.encoder.layers[9].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__add")
#loc539 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPMLP[vision_model.encoder.layers[9].mlp]|QuickGELUActivation[vision_model.encoder.layers[9].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__mul")
#loc540 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPMLP[vision_model.encoder.layers[9].mlp]|QuickGELUActivation[vision_model.encoder.layers[9].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__sigmoid")
#loc541 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPMLP[vision_model.encoder.layers[9].mlp]|Linear[vision_model.encoder.layers[9].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__view")
#loc542 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPMLP[vision_model.encoder.layers[9].mlp]|Linear[vision_model.encoder.layers[9].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__permute")
#loc543 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPMLP[vision_model.encoder.layers[9].mlp]|Linear[vision_model.encoder.layers[9].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__mm")
#loc544 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|CLIPMLP[vision_model.encoder.layers[9].mlp]|Linear[vision_model.encoder.layers[9].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__add")
#loc545 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[9]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|436|aten__add")
#loc546 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|LayerNorm[vision_model.encoder.layers[10].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__var_mean")
#loc547 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|LayerNorm[vision_model.encoder.layers[10].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__sub")
#loc548 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|LayerNorm[vision_model.encoder.layers[10].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__add")
#loc549 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|LayerNorm[vision_model.encoder.layers[10].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__rsqrt")
#loc550 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|LayerNorm[vision_model.encoder.layers[10].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__mul")
#loc551 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|Linear[vision_model.encoder.layers[10].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__view")
#loc552 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|Linear[vision_model.encoder.layers[10].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__permute")
#loc553 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|Linear[vision_model.encoder.layers[10].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__mm")
#loc554 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|Linear[vision_model.encoder.layers[10].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__add")
#loc555 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__view")
#loc556 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__permute")
#loc557 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__view")
#loc558 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|Linear[vision_model.encoder.layers[10].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__permute")
#loc559 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|Linear[vision_model.encoder.layers[10].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__mm")
#loc560 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|Linear[vision_model.encoder.layers[10].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__view")
#loc561 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|Linear[vision_model.encoder.layers[10].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__add")
#loc562 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|339|aten__view")
#loc563 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__permute")
#loc564 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__matmul")
#loc565 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__mul")
#loc566 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|xla__cast")
#loc567 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|aten__softmax")
#loc568 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|291|xla__cast")
#loc569 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__view")
#loc570 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|Linear[vision_model.encoder.layers[10].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__permute")
#loc571 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|Linear[vision_model.encoder.layers[10].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__mm")
#loc572 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|Linear[vision_model.encoder.layers[10].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__view")
#loc573 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|Linear[vision_model.encoder.layers[10].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__add")
#loc574 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__view")
#loc575 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__permute")
#loc576 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__matmul")
#loc577 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|294|aten__permute")
#loc578 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|Linear[vision_model.encoder.layers[10].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__view")
#loc579 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|Linear[vision_model.encoder.layers[10].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__permute")
#loc580 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|Linear[vision_model.encoder.layers[10].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__mm")
#loc581 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPAttention[vision_model.encoder.layers[10].self_attn]|Linear[vision_model.encoder.layers[10].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__add")
#loc582 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|431|aten__add")
#loc583 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|LayerNorm[vision_model.encoder.layers[10].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__var_mean")
#loc584 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|LayerNorm[vision_model.encoder.layers[10].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__sub")
#loc585 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|LayerNorm[vision_model.encoder.layers[10].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__add")
#loc586 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|LayerNorm[vision_model.encoder.layers[10].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__rsqrt")
#loc587 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|LayerNorm[vision_model.encoder.layers[10].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__mul")
#loc588 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPMLP[vision_model.encoder.layers[10].mlp]|Linear[vision_model.encoder.layers[10].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__view")
#loc589 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPMLP[vision_model.encoder.layers[10].mlp]|Linear[vision_model.encoder.layers[10].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__permute")
#loc590 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPMLP[vision_model.encoder.layers[10].mlp]|Linear[vision_model.encoder.layers[10].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__mm")
#loc591 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPMLP[vision_model.encoder.layers[10].mlp]|Linear[vision_model.encoder.layers[10].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__add")
#loc592 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPMLP[vision_model.encoder.layers[10].mlp]|QuickGELUActivation[vision_model.encoder.layers[10].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__mul")
#loc593 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPMLP[vision_model.encoder.layers[10].mlp]|QuickGELUActivation[vision_model.encoder.layers[10].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__sigmoid")
#loc594 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPMLP[vision_model.encoder.layers[10].mlp]|Linear[vision_model.encoder.layers[10].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__view")
#loc595 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPMLP[vision_model.encoder.layers[10].mlp]|Linear[vision_model.encoder.layers[10].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__permute")
#loc596 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPMLP[vision_model.encoder.layers[10].mlp]|Linear[vision_model.encoder.layers[10].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__mm")
#loc597 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|CLIPMLP[vision_model.encoder.layers[10].mlp]|Linear[vision_model.encoder.layers[10].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__add")
#loc598 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[10]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|436|aten__add")
#loc599 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|LayerNorm[vision_model.encoder.layers[11].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__var_mean")
#loc600 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|LayerNorm[vision_model.encoder.layers[11].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__sub")
#loc601 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|LayerNorm[vision_model.encoder.layers[11].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__add")
#loc602 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|LayerNorm[vision_model.encoder.layers[11].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__rsqrt")
#loc603 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|LayerNorm[vision_model.encoder.layers[11].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|424|aten__mul")
#loc604 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|Linear[vision_model.encoder.layers[11].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__view")
#loc605 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|Linear[vision_model.encoder.layers[11].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__permute")
#loc606 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|Linear[vision_model.encoder.layers[11].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__mm")
#loc607 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|Linear[vision_model.encoder.layers[11].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|334|aten__add")
#loc608 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__view")
#loc609 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|338|aten__permute")
#loc610 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__view")
#loc611 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|Linear[vision_model.encoder.layers[11].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__permute")
#loc612 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|Linear[vision_model.encoder.layers[11].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__mm")
#loc613 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|Linear[vision_model.encoder.layers[11].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__view")
#loc614 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|Linear[vision_model.encoder.layers[11].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|335|aten__add")
#loc615 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|339|aten__view")
#loc616 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__permute")
#loc617 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__matmul")
#loc618 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|287|aten__mul")
#loc619 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|xla__cast")
#loc620 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|290|aten__softmax")
#loc621 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|291|xla__cast")
#loc622 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__view")
#loc623 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|Linear[vision_model.encoder.layers[11].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__permute")
#loc624 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|Linear[vision_model.encoder.layers[11].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__mm")
#loc625 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|Linear[vision_model.encoder.layers[11].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__view")
#loc626 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|Linear[vision_model.encoder.layers[11].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|336|aten__add")
#loc627 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__view")
#loc628 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|340|aten__permute")
#loc629 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|293|aten__matmul")
#loc630 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:276|eager_attention_forward|294|aten__permute")
#loc631 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|Linear[vision_model.encoder.layers[11].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__view")
#loc632 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|Linear[vision_model.encoder.layers[11].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__permute")
#loc633 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|Linear[vision_model.encoder.layers[11].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__mm")
#loc634 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPAttention[vision_model.encoder.layers[11].self_attn]|Linear[vision_model.encoder.layers[11].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:323|forward|374|aten__add")
#loc635 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|431|aten__add")
#loc636 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|LayerNorm[vision_model.encoder.layers[11].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__var_mean")
#loc637 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|LayerNorm[vision_model.encoder.layers[11].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__sub")
#loc638 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|LayerNorm[vision_model.encoder.layers[11].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__add")
#loc639 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|LayerNorm[vision_model.encoder.layers[11].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__rsqrt")
#loc640 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|LayerNorm[vision_model.encoder.layers[11].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|434|aten__mul")
#loc641 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPMLP[vision_model.encoder.layers[11].mlp]|Linear[vision_model.encoder.layers[11].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__view")
#loc642 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPMLP[vision_model.encoder.layers[11].mlp]|Linear[vision_model.encoder.layers[11].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__permute")
#loc643 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPMLP[vision_model.encoder.layers[11].mlp]|Linear[vision_model.encoder.layers[11].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__mm")
#loc644 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPMLP[vision_model.encoder.layers[11].mlp]|Linear[vision_model.encoder.layers[11].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|390|aten__add")
#loc645 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPMLP[vision_model.encoder.layers[11].mlp]|QuickGELUActivation[vision_model.encoder.layers[11].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__mul")
#loc646 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPMLP[vision_model.encoder.layers[11].mlp]|QuickGELUActivation[vision_model.encoder.layers[11].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/activations.py:86|forward|87|aten__sigmoid")
#loc647 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPMLP[vision_model.encoder.layers[11].mlp]|Linear[vision_model.encoder.layers[11].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__view")
#loc648 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPMLP[vision_model.encoder.layers[11].mlp]|Linear[vision_model.encoder.layers[11].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__permute")
#loc649 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPMLP[vision_model.encoder.layers[11].mlp]|Linear[vision_model.encoder.layers[11].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__mm")
#loc650 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|CLIPMLP[vision_model.encoder.layers[11].mlp]|Linear[vision_model.encoder.layers[11].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:389|forward|392|aten__add")
#loc651 = loc("CLIPVisionTransformer[vision_model]|CLIPEncoder[vision_model.encoder]|CLIPEncoderLayer[vision_model.encoder.layers[11]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:405|forward|436|aten__add")
#loc652 = loc("CLIPVisionTransformer[vision_model]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:767|forward|792|xla__generic_slice")
#loc653 = loc("CLIPVisionTransformer[vision_model]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:767|forward|792|aten__view")
#loc654 = loc("CLIPVisionTransformer[vision_model]|LayerNorm[vision_model.post_layernorm]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:767|forward|793|aten__var_mean")
#loc655 = loc("CLIPVisionTransformer[vision_model]|LayerNorm[vision_model.post_layernorm]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:767|forward|793|aten__sub")
#loc656 = loc("CLIPVisionTransformer[vision_model]|LayerNorm[vision_model.post_layernorm]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:767|forward|793|aten__add")
#loc657 = loc("CLIPVisionTransformer[vision_model]|LayerNorm[vision_model.post_layernorm]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:767|forward|793|aten__rsqrt")
#loc658 = loc("CLIPVisionTransformer[vision_model]|LayerNorm[vision_model.post_layernorm]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:767|forward|793|aten__mul")
#loc659 = loc("Linear[visual_projection]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:1169|forward|1203|aten__permute")
#loc660 = loc("Linear[visual_projection]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:1169|forward|1203|aten__mm")
