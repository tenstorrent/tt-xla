#dram = #ttnn.buffer_type<dram>
#loc = loc(unknown)
#loc7 = loc("-1|unknown|unknown|-1|unknownxla__device_data")
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 9x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 103552, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073051456, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0], [1 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x40x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x5120xbf16, #system_memory>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 288 + d1, d2), <1x1>, memref<9x160x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x5120xbf16, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x160x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x160x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1280xbf16, #system_memory>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 288 + d1, d2), <1x1>, memref<9x120x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1280xbf16, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x40x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout10 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 288 + d1, d2), <1x1>, memref<9x40x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout11 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1280x1280xbf16, #system_memory>>
#ttnn_layout12 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<120x40x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout13 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1280x1280xbf16, #dram>, <interleaved>>
#ttnn_layout14 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<40x40x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout15 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2048xbf16, #system_memory>>
#ttnn_layout16 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x64x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout17 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2048xbf16, #dram>, <interleaved>>
#ttnn_layout18 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x64x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout19 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x40x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout20 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 640 + d1 * 32 + d2, d3), <1x1>, memref<20x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout21 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 640 + d1 * 32 + d2, d3), <1x1>, memref<20x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout22 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 32 + d2, d3), <1x1>, memref<16x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout23 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 42 + d1 * 14 + d2, d3), <1x1>, memref<53760x14xbf16, #system_memory>>
#ttnn_layout24 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 608 + d1 * 608 + d2, d3), <1x1>, memref<19x40x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout25 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x257xsi32, #system_memory>>
#ttnn_layout26 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<257x1280xbf16, #system_memory>>
#ttnn_layout27 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 1280 + d1, d2), <1x1>, memref<40x9x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout28 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x257xsi32, #dram>, <interleaved>>
#ttnn_layout29 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x9x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout30 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x9x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout31 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x257xui32, #dram>, <interleaved>>
#ttnn_layout32 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<257x1280xbf16, #dram>, <interleaved>>
#ttnn_layout33 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 1280 + d1, d2), <1x1>, memref<40x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout34 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<64x40x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout35 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<40x160x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout36 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<160x40x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout37 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 672 + d1 * 224 + d2, d3), <1x1>, memref<672x224xbf16, #dram>, <interleaved>>
#ttnn_layout38 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 672 + d1 * 224 + d2, d3), <1x1>, memref<21x7x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout39 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 50176 + d1 * 224 + d2, d3), <1x1>, memref<1568x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout40 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 50176 + d1 * 50176 + d2, d3), <1x1>, memref<1568x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout41 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 256 + d2, d3), <1x1>, memref<8x40x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout42 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 32 + d2, d3), <1x1>, memref<16x40x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout43 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 40960 + d1 * 32 + d2, d3), <1x1>, memref<1280x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout44 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 1280 + d1, d2), <1x1>, memref<40x8x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout45 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<9x40x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout46 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<9x120x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout47 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8224 + d1 * 32 + d2, d3), <1x1>, memref<257x3x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout48 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4608 + d1 * 288 + d2, d3), <1x1>, memref<144x3x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout49 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<9x160x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout50 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<9x40x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout51 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8736 + d1 * 32 + d2, d3), <1x1>, memref<273x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout52 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1280 + d1 * 64 + d2, d3), <1x1>, memref<40x9x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout53 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 5760 + d1 * 288 + d2, d3), <1x1>, memref<180x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout54 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 5760 + d1 * 288 + d2, d3), <1x1>, memref<180x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout55 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x160x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout56 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x40x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout57 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 32 + d2, d3), <1x1>, memref<16x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout58 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x64x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
module @SyncTensorsGraph.13945 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x1>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.13945 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x1>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<9x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x1, chipIds = [0]> loc(#loc)
      func.func private @main_const_eval_0() -> tensor<1x16x1280xbf16, #ttnn_layout> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc1)
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 1.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<1x16x1280>}> : (!ttnn.device) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc)
        return %1 : tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_1(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc2)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc2)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc2)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc2)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_2(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc3)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc3)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc3)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc3)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc4)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc4)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc4)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc4)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc5)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc5)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc5)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc5)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc5)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc5)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc5)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc5)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_3(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc6)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc6)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc6)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc6)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_4(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_5(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc8)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc8)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc8)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc8)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_6(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc9)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc9)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc9)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc9)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_7(%arg0: tensor<2048xbf16, #ttnn_layout15> loc(unknown)) -> tensor<1x16x2048xbf16, #ttnn_layout16> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<2048xbf16, #ttnn_layout15>, !ttnn.device) -> tensor<2048xbf16, #ttnn_layout17> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<2048xbf16, #ttnn_layout17>) -> tensor<2048xbf16, #ttnn_layout18> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<2048xbf16, #ttnn_layout17>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 2048 : i32]}> : (tensor<2048xbf16, #ttnn_layout18>) -> tensor<1x1x2048xbf16, #ttnn_layout16> loc(#loc10)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<2048xbf16, #ttnn_layout18>) -> () loc(#loc10)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x16x1>}> : (tensor<1x1x2048xbf16, #ttnn_layout16>) -> tensor<1x16x2048xbf16, #ttnn_layout16> loc(#loc10)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x2048xbf16, #ttnn_layout16>) -> () loc(#loc10)
        return %4 : tensor<1x16x2048xbf16, #ttnn_layout16> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_8(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc11)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc11)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc11)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc11)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_9(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc12)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc12)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc12)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc12)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_10(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_11(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc13)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc13)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc13)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc13)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_12(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc14)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc14)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc14)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc14)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_13(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_14(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc15)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc15)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc15)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc15)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_15(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc16)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc16)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc16)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc16)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_16(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc17)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc17)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc17)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc17)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_17(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc18)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc18)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc18)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc18)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc19)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc19)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc19)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc19)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc20)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc20)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc20)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc20)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc20)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc20)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc20)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc20)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_18(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc21)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc21)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc21)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc21)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc22)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc22)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc22)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc22)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc23)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc23)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc23)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc23)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc23)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc23)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc23)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc23)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_19(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc24)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc24)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc24)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc24)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_20(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc25)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc25)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc25)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc25)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_21(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc26)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc26)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc26)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc26)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_22(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc27)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc27)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc27)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc27)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_23(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc28)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc28)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc28)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc28)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_24(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_25(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc29)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc29)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc29)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc29)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_26(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_27(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_28(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc30)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc30)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc30)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc30)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_29(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc31)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc31)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc31)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc31)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_30(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_31(%arg0: tensor<1x16x1280xbf16, #ttnn_layout> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg3: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> (tensor<16x1280xbf16, #ttnn_layout19>, tensor<1x20x16x64xbf16, #ttnn_layout20>) attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc1)
        %1 = "ttnn.to_device"(%arg3, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 0.353553385 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<1x20x16x64>}> : (!ttnn.device) -> tensor<1x20x16x64xf32, #ttnn_layout21> loc(#loc)
        %8 = "ttnn.layer_norm"(%arg0, %4, %6) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x16x1280xbf16, #ttnn_layout>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc32)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc32)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc32)
        %9 = "ttnn.reshape"(%8) <{shape = [16 : i32, 1280 : i32]}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc33)
        %10 = "ttnn.matmul"(%9, %2) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<16x1280xbf16, #ttnn_layout19>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc34)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc34)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc34)
        %11 = "ttnn.reshape"(%10) <{shape = [1 : i32, 16 : i32, 20 : i32, 64 : i32]}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> tensor<1x16x20x64xbf16, #ttnn_layout22> loc(#loc35)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc35)
        %12 = "ttnn.permute"(%11) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x20x64xbf16, #ttnn_layout22>) -> tensor<1x20x16x64xbf16, #ttnn_layout20> loc(#loc36)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x16x20x64xbf16, #ttnn_layout22>) -> () loc(#loc36)
        %13 = "ttnn.typecast"(%12) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x20x16x64xbf16, #ttnn_layout20>) -> tensor<1x20x16x64xf32, #ttnn_layout21> loc(#loc37)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x20x16x64xbf16, #ttnn_layout20>) -> () loc(#loc37)
        %14 = "ttnn.multiply"(%13, %7) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x20x16x64xf32, #ttnn_layout21>, tensor<1x20x16x64xf32, #ttnn_layout21>) -> tensor<1x20x16x64xf32, #ttnn_layout21> loc(#loc38)
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<1x20x16x64xf32, #ttnn_layout21>) -> () loc(#loc38)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x20x16x64xf32, #ttnn_layout21>) -> () loc(#loc38)
        %15 = "ttnn.reshape"(%8) <{shape = [16 : i32, 1280 : i32]}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc39)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc39)
        %16 = "ttnn.typecast"(%14) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x20x16x64xf32, #ttnn_layout21>) -> tensor<1x20x16x64xbf16, #ttnn_layout20> loc(#loc)
        "ttnn.deallocate"(%14) <{force = false}> : (tensor<1x20x16x64xf32, #ttnn_layout21>) -> () loc(#loc)
        return %15, %16 : tensor<16x1280xbf16, #ttnn_layout19>, tensor<1x20x16x64xbf16, #ttnn_layout20> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_32(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc40)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc40)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc40)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc40)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_33(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc41)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc41)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc41)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc41)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc42)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc42)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc42)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc42)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc43)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc43)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc43)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc43)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc43)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc43)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc43)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc43)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_34(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc44)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc44)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc44)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc44)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_35(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_36(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc45)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc45)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc45)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc45)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_37(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_38(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_39(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc46)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc46)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc46)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc46)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_40(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc47)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc47)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc47)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc47)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_41(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc48)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc48)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc48)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc48)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc49)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc49)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc49)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc49)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc50)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc50)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc50)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc50)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc50)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc50)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc50)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc50)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_42(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc51)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc51)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc51)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc51)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc52)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc52)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc52)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc52)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc53)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc53)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc53)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc53)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc53)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc53)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc53)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc53)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_43(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc54)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc54)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc54)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc54)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_44(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc55)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc55)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc55)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc55)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc56)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc56)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc56)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc56)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc57)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc57)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc57)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc57)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc57)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc57)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc57)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc57)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_45(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc58)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc58)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc58)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc58)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_46(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc59)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc59)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc59)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc59)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc60)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc60)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc60)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc60)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc61)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc61)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc61)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc61)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc61)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc61)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc61)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc61)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_47(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc62)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc62)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc62)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc62)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_48(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc63)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc63)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc63)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc63)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc64)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc64)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc64)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc64)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc65)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc65)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc65)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc65)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc65)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc65)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc65)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc65)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_49(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc66)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc66)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc66)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc66)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_50(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_51(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc67)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc67)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc67)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc67)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc68)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc68)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc68)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc68)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc69)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc69)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc69)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc69)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc69)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc69)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc69)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc69)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_52(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc70)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc70)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc70)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc70)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_53(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc71)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc71)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc71)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc71)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_54(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc72)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc72)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc72)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc72)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_55(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc73)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc73)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc73)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc73)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_56(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc74)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc74)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc74)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc74)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_57(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc75)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc75)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc75)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc75)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_58(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc76)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc76)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc76)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc76)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc77)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc77)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc77)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc77)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc78)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc78)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc78)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc78)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc78)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc78)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc78)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc78)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_59(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc79)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc79)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc79)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc79)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc80)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc80)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc80)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc80)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc81)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc81)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc81)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc81)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc81)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc81)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc81)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc81)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_60(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc82)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc82)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc82)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc82)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc83)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc83)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc83)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc83)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc84)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc84)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc84)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc84)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc84)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc84)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc84)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc84)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_61(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc85)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc85)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc85)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc85)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc86)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc86)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc86)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc86)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc87)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc87)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc87)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc87)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc87)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc87)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc87)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc87)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_62(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_63(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc88)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc88)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc88)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc88)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc89)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc89)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc89)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc89)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc90)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc90)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc90)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc90)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc90)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc90)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc90)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc90)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_64(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc91)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc91)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc91)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc91)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_65(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc92)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc92)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc92)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc92)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_66(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_67(%arg0: tensor<1280x3x14x14xbf16, #ttnn_layout23> {ttir.conv2d_weight} loc(unknown)) -> tensor<1x1x588x1280xbf16, #ttnn_layout24> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc1)
        %1 = "ttnn.prepare_conv2d_weights"(%arg0, %0) <{batch_size = 1 : i32, compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, conv2d_config = #ttnn.conv2d_config<weights_dtype = bf16, deallocate_activation = true, act_block_h_override = 0, enable_kernel_stride_folding = false, config_tensors_in_dram = true>, conv2d_slice_config = #ttnn.conv2d_slice_config<l1_full, 0>, dilation = array<i32: 1, 1>, groups = 1 : i32, has_bias = false, in_channels = 3 : i32, input_dtype = #ttcore.supportedDataTypes<bf16>, input_height = 224 : i32, input_memory_config = #ttnn.memory_config<#dram, <interleaved>>, input_tensor_layout = #ttnn.layout<tile>, input_width = 224 : i32, kernel_size = array<i32: 14, 14>, out_channels = 1280 : i32, output_dtype = #ttcore.supportedDataTypes<bf16>, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 14, 14>, weights_format = "OIHW"}> : (tensor<1280x3x14x14xbf16, #ttnn_layout23>, !ttnn.device) -> tensor<1x1x588x1280xbf16, #ttnn_layout24> loc(#loc568)
        return %1 : tensor<1x1x588x1280xbf16, #ttnn_layout24> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_68(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_69(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc94)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc94)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc94)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc94)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_70(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc95)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc95)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc95)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc95)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_71(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_72(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc96)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc96)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc96)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc96)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc97)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc97)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc97)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc97)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc98)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc98)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc98)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc98)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc98)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc98)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc98)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc98)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_73(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc99)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc99)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc99)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc99)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc100)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc100)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc100)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc100)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc101)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc101)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc101)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc101)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc101)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc101)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc101)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc101)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_74(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc102)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc102)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc102)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc102)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_75(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc103)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc103)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc103)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc103)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_76(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_77(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_78(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc104)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc104)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc104)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc104)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc105)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc105)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc105)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc105)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc106)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc106)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc106)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc106)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc106)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc106)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc106)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc106)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_79(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc107)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc107)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc107)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc107)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_80(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc108)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc108)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc108)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc108)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_81(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc109)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc109)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc109)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc109)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc110)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc110)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc110)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc110)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc111)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc111)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc111)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc111)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc111)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc111)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc111)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc111)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_82(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc112)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc112)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc112)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc112)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_83(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc113)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc113)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc113)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc113)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_84(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc114)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc114)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc114)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc114)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_85(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc115)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc115)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc115)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc115)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc116)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc116)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc116)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc116)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc117)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc117)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc117)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc117)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc117)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc117)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc117)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc117)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_86(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc118)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc118)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc118)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc118)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_87(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_88(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_89(%arg0: tensor<1x257xsi32, #ttnn_layout25> loc(unknown), %arg1: tensor<257x1280xbf16, #ttnn_layout26> loc(unknown)) -> tensor<1x1280x257xbf16, #ttnn_layout27> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x257xsi32, #ttnn_layout25>, !ttnn.device) -> tensor<1x257xsi32, #ttnn_layout28> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1x257xsi32, #ttnn_layout28>) -> tensor<1x257xsi32, #ttnn_layout29> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x257xsi32, #ttnn_layout28>) -> () loc(#loc)
        %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x257xsi32, #ttnn_layout29>) -> tensor<1x257xui32, #ttnn_layout30> loc(#loc119)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x257xsi32, #ttnn_layout29>) -> () loc(#loc119)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<row_major>}> : (tensor<1x257xui32, #ttnn_layout30>) -> tensor<1x257xui32, #ttnn_layout31> loc(#loc569)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x257xui32, #ttnn_layout30>) -> () loc(#loc569)
        %5 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<257x1280xbf16, #ttnn_layout26>, !ttnn.device) -> tensor<257x1280xbf16, #ttnn_layout32> loc(#loc569)
        %6 = "ttnn.embedding"(%4, %5) : (tensor<1x257xui32, #ttnn_layout31>, tensor<257x1280xbf16, #ttnn_layout32>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc119)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout32>) -> () loc(#loc119)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1x257xui32, #ttnn_layout31>) -> () loc(#loc119)
        %7 = "ttnn.permute"(%6) <{permutation = array<i64: 0, 2, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x1280x257xbf16, #ttnn_layout27> loc(#loc120)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc120)
        return %7 : tensor<1x1280x257xbf16, #ttnn_layout27> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_90(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_91(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc121)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc121)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc121)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc121)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc122)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc122)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc122)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc122)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc123)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc123)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc123)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc123)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc123)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc123)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc123)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc123)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_92(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc124)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc124)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc124)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc124)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_93(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc125)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc125)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc125)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc125)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_94(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc126)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc126)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc126)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc126)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_95(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc127)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc127)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc127)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc127)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_96(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc128)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc128)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc128)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc128)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_97(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_98(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc129)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc129)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc129)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc129)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_99(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc130)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc130)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc130)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc130)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_100(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc131)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc131)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc131)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc131)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc132)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc132)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc132)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc132)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc133)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc133)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc133)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc133)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc133)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc133)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc133)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc133)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_101(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc134)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc134)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc134)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc134)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_102(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc135)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc135)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc135)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc135)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc136)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc136)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc136)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc136)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc137)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc137)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc137)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc137)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc137)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc137)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc137)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc137)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_103(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_104(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc138)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc138)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc138)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc138)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_105(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc139)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc139)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc139)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc139)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_106(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc140)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc140)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc140)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc140)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_107(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc141)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc141)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc141)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc141)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_108(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc142)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc142)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc142)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc142)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_109(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc143)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc143)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc143)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc143)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_110(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc144)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc144)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc144)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc144)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_111(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc145)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc145)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc145)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc145)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_112(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc146)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc146)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc146)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc146)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc147)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc147)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc147)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc147)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc148)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc148)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc148)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc148)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc148)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc148)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc148)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc148)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_113(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_114(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc149)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc149)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc149)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc149)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_115(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc150)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc150)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc150)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc150)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_116(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc151)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc151)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc151)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc151)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_117(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc152)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc152)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc152)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc152)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc153)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc153)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc153)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc153)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc154)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc154)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc154)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc154)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc154)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc154)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc154)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc154)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_118(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc155)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc155)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc155)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc155)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_119(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc156)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc156)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc156)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc156)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc157)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc157)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc157)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc157)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc158)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc158)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc158)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc158)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc158)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc158)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc158)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc158)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_120(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_121(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc159)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc159)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc159)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc159)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_122(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc160)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc160)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc160)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc160)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_123(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc161)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc161)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc161)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc161)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_124(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc162)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc162)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc162)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc162)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_125(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc163)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc163)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc163)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc163)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_126(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc164)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc164)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc164)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc164)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_127(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc165)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc165)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc165)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc165)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_128(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_129(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_130(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc166)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc166)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc166)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc166)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_131(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc167)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc167)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc167)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc167)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_132(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc168)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc168)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc168)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc168)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc169)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc169)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc169)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc169)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc170)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc170)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc170)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc170)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc170)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc170)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc170)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc170)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_133(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc171)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc171)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc171)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc171)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_134(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc172)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc172)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc172)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc172)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc173)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc173)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc173)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc173)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc174)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc174)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc174)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc174)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc174)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc174)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc174)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc174)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_135(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc175)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc175)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc175)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc175)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc176)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc176)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc176)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc176)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc177)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc177)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc177)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc177)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc177)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc177)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc177)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc177)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_136(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc178)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc178)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc178)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc178)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_137(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc179)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc179)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc179)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc179)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc180)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc180)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc180)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc180)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc181)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc181)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc181)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc181)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc181)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc181)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc181)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc181)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_138(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc182)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc182)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc182)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc182)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_139(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_140(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc183)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc183)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc183)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc183)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_141(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc184)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc184)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc184)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc184)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_142(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc185)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc185)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc185)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc185)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_143(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x1280x1xbf16, #ttnn_layout33> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc186)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc186)
        %4 = "ttnn.permute"(%3) <{permutation = array<i64: 0, 2, 1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x1280x1xbf16, #ttnn_layout33> loc(#loc120)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc120)
        return %4 : tensor<1x1280x1xbf16, #ttnn_layout33> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_144(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc187)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc187)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc187)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc187)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_145(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc188)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc188)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc188)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc188)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_146(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc189)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc189)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc189)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc189)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_147(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc190)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc190)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc190)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc190)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_148(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc191)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc191)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc191)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc191)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_149(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_150(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc192)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc192)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc192)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc192)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_151(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc193)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc193)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc193)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc193)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_152(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc194)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc194)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc194)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc194)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_153(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_154(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc195)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc195)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc195)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc195)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_155(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc196)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc196)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc196)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc196)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_156(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc197)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc197)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc197)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc197)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_157(%arg0: tensor<5120xbf16, #ttnn_layout1> loc(unknown)) -> tensor<1x257x5120xbf16, #ttnn_layout2> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<5120xbf16, #ttnn_layout1>, !ttnn.device) -> tensor<5120xbf16, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<5120xbf16, #ttnn_layout3>) -> tensor<5120xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<5120xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 5120 : i32]}> : (tensor<5120xbf16, #ttnn_layout4>) -> tensor<1x1x5120xbf16, #ttnn_layout5> loc(#loc198)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<5120xbf16, #ttnn_layout4>) -> () loc(#loc198)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc198)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x5120xbf16, #ttnn_layout5>) -> () loc(#loc198)
        return %4 : tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_158(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_159(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg1: tensor<1280xbf16, #ttnn_layout6> loc(unknown), %arg2: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x3840xbf16, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc199)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc199)
        %8 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc199)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc199)
        %9 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc200)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc200)
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc200)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc200)
        %11 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc201)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc201)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc201)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc201)
        %13 = "ttnn.concat"(%8, %10, %12) <{dim = 2 : si32}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc201)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc201)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc201)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc201)
        return %13 : tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_160(%arg0: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg1: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown), %arg2: tensor<1280x1280xbf16, #ttnn_layout11> loc(unknown)) -> tensor<3840x1280xbf16, #ttnn_layout12> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg2, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %3 = "ttnn.to_device"(%arg1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %5 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280x1280xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<1280x1280xbf16, #ttnn_layout13> loc(#loc)
        %6 = "ttnn.to_layout"(%5) <{layout = #ttnn.layout<tile>}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> tensor<1280x1280xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout13>) -> () loc(#loc)
        %7 = "ttnn.concat"(%2, %4, %6) <{dim = 0 : si32}> : (tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc7)
        return %7 : tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_161(%arg0: tensor<1280xbf16, #ttnn_layout6> loc(unknown)) -> tensor<1x257x1280xbf16, #ttnn_layout10> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1280xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<1280xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1280xbf16, #ttnn_layout8>) -> tensor<1280xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1280xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1280 : i32]}> : (tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x1x1280xbf16, #ttnn_layout> loc(#loc202)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc202)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<1x257x1>}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc202)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1280xbf16, #ttnn_layout>) -> () loc(#loc202)
        return %4 : tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func @main(%arg0: tensor<2048xbf16, #ttnn_layout18> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<2048xbf16>>, ttir.name = "l__self___resampler_norm_out_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg1: tensor<2048xbf16, #ttnn_layout18> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<2048xbf16>>, ttir.name = "l__self___resampler_norm_out_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg2: tensor<2048xbf16, #ttnn_layout15> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<2048xbf16>>, ttir.name = "l__self___resampler_proj_out_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg3: tensor<2048x1280xbf16, #ttnn_layout34> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<2048x1280xbf16>>, ttir.name = "l__self___resampler_proj_out_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg4: tensor<1x16x1280xbf16, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1x16x1280xbf16>>, ttir.name = "l__self___resampler_latents"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg5: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___resampler_layers_0_attn_to_out_0_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg6: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___resampler_layers_0_attn_to_v_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg7: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_0_ln1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg8: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_0_ln1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg9: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_0_ln0_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg10: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_0_ln0_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg11: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_proj_in_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg12: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___resampler_proj_in_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg13: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_30_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg14: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_30_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg15: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_30_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg16: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_30_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg17: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_30_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg18: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_30_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg19: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_30_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg20: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_30_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg21: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_30_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg22: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_30_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg23: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_30_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg24: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_30_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg25: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_29_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg26: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_29_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg27: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_29_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg28: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_29_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg29: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_29_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg30: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_29_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg31: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_29_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg32: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_29_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg33: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_29_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg34: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_29_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg35: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_29_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg36: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_29_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg37: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_28_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg38: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_28_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg39: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_28_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg40: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_28_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg41: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_28_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg42: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_28_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg43: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_28_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg44: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_28_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg45: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_28_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg46: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_28_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg47: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_28_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg48: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_28_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg49: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_27_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg50: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_27_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg51: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_27_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg52: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_27_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg53: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_27_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg54: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_27_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg55: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_27_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg56: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_27_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg57: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_27_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg58: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_27_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg59: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_27_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg60: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_27_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg61: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_26_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg62: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_26_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg63: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_26_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg64: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_26_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg65: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_26_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg66: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_26_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg67: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_26_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg68: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_26_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg69: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_26_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg70: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_26_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg71: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_26_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg72: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_26_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg73: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_25_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg74: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_25_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg75: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_25_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg76: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_25_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg77: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_25_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg78: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_25_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg79: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_25_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg80: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_25_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg81: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_25_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg82: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_25_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg83: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_25_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg84: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_25_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg85: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_24_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg86: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_24_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg87: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_24_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg88: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_24_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg89: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_24_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg90: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_24_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg91: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_24_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg92: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_24_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg93: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_24_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg94: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_24_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg95: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_24_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg96: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_24_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg97: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_23_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg98: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_23_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg99: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_23_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg100: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_23_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg101: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_23_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg102: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_23_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg103: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_23_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg104: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_23_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg105: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_23_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg106: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_23_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg107: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_23_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg108: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_23_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg109: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_22_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg110: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_22_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg111: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_22_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg112: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_22_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg113: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_22_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg114: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_22_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg115: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_22_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg116: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_22_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg117: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_22_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg118: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_22_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg119: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_22_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg120: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_22_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg121: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_21_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg122: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_21_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg123: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_21_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg124: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_21_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg125: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_21_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg126: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_21_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg127: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_21_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg128: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_21_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg129: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_21_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg130: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_21_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg131: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_21_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg132: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_21_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg133: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_20_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg134: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_20_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg135: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_20_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg136: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_20_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg137: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_20_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg138: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_20_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg139: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_20_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg140: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_20_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg141: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_20_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg142: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_20_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg143: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_20_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg144: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_20_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg145: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_19_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg146: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_19_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg147: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_19_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg148: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_19_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg149: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_19_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg150: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_19_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg151: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_19_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg152: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_19_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg153: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_19_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg154: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_19_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg155: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_19_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg156: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_19_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg157: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_18_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg158: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_18_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg159: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_18_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg160: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_18_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg161: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_18_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg162: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_18_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg163: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_18_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg164: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_18_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg165: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_18_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg166: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_18_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg167: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_18_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg168: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_18_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg169: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_17_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg170: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_17_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg171: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_17_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg172: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_17_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg173: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_17_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg174: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_17_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg175: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_17_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg176: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_17_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg177: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_17_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg178: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_17_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg179: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_17_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg180: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_17_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg181: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_16_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg182: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_16_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg183: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_16_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg184: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_16_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg185: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_16_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg186: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_16_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg187: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_16_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg188: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_16_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg189: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_16_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg190: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_16_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg191: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_16_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg192: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_16_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg193: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_15_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg194: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_15_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg195: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_15_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg196: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_15_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg197: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_15_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg198: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_15_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg199: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_15_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg200: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_15_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg201: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_15_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg202: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_15_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg203: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_15_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg204: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_15_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg205: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_14_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg206: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_14_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg207: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_14_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg208: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_14_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg209: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_14_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg210: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_14_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg211: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_14_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg212: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_14_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg213: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_14_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg214: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_14_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg215: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_14_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg216: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_14_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg217: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_13_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg218: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_13_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg219: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_13_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg220: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_13_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg221: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_13_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg222: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_13_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg223: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_13_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg224: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_13_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg225: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_13_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg226: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_13_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg227: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_13_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg228: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_13_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg229: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_12_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg230: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_12_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg231: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_12_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg232: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_12_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg233: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_12_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg234: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_12_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg235: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_12_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg236: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_12_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg237: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_12_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg238: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_12_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg239: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_12_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg240: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_12_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg241: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_11_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg242: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_11_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg243: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_11_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg244: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_11_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg245: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_11_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg246: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_11_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg247: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_11_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg248: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_11_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg249: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_11_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg250: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_11_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg251: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_11_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg252: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_11_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg253: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_10_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg254: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_10_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg255: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_10_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg256: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_10_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg257: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_10_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg258: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_10_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg259: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_10_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg260: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_10_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg261: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_10_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg262: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_10_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg263: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_10_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg264: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_10_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg265: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_9_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg266: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_9_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg267: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_9_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg268: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_9_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg269: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_9_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg270: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_9_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg271: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_9_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg272: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_9_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg273: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_9_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg274: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_9_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg275: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_9_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg276: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_9_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg277: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_8_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg278: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_8_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg279: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_8_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg280: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_8_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg281: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_8_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg282: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_8_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg283: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_8_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg284: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_8_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg285: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_8_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg286: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_8_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg287: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_8_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg288: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_8_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg289: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_7_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg290: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_7_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg291: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_7_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg292: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_7_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg293: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_7_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg294: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_7_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg295: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_7_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg296: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_7_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg297: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_7_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg298: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_7_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg299: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_7_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg300: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_7_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg301: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_6_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg302: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_6_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg303: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_6_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg304: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_6_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg305: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_6_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg306: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_6_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg307: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_6_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg308: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_6_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg309: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_6_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg310: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_6_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg311: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_6_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg312: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_6_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg313: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_5_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg314: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_5_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg315: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_5_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg316: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_5_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg317: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_5_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg318: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_5_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg319: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_5_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg320: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_5_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg321: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_5_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg322: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_5_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg323: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_5_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg324: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_5_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg325: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_4_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg326: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_4_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg327: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_4_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg328: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_4_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg329: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_4_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg330: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_4_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg331: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_4_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg332: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_4_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg333: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_4_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg334: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_4_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg335: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_4_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg336: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_4_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg337: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_3_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg338: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_3_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg339: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_3_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg340: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_3_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg341: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_3_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg342: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_3_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg343: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_3_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg344: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_3_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg345: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_3_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg346: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_3_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg347: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_3_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg348: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_3_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg349: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_2_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg350: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_2_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg351: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_2_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg352: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_2_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg353: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_2_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg354: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_2_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg355: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_2_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg356: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_2_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg357: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_2_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg358: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_2_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg359: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_2_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg360: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_2_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg361: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_1_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg362: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_1_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg363: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_1_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg364: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_1_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg365: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_1_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg366: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_1_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg367: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_1_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg368: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_1_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg369: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_1_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg370: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_1_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg371: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_1_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg372: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_1_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg373: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_0_mlp_fc2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg374: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_0_mlp_fc2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg375: tensor<5120xbf16, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_0_mlp_fc1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg376: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_0_mlp_fc1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg377: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_0_layer_norm2_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg378: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_0_layer_norm2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg379: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_0_self_attn_out_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg380: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_0_self_attn_out_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg381: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_0_self_attn_v_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg382: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_0_self_attn_v_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg383: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_0_layer_norm1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg384: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_0_layer_norm1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg385: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_pre_layrnorm_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg386: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_pre_layrnorm_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg387: tensor<1x257xsi32, #ttnn_layout25> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1x257xi64>>, ttir.name = "l__self___image_encoder_vision_model_embeddings_position_ids"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg388: tensor<257x1280xbf16, #ttnn_layout26> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<257x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_embeddings_position_embedding_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg389: tensor<1280x3x14x14xbf16, #ttnn_layout23> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x3x14x14xbf16>>, ttir.conv2d_weight, ttir.name = "l__self___image_encoder_vision_model_embeddings_patch_embedding_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg390: tensor<1x3x224x224xbf16, #ttnn_layout37> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1x3x224x224xbf16>>, ttir.name = "args_0"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg391: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_embeddings_class_embedding"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg392: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_0_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg393: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_0_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg394: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_0_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg395: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_0_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg396: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_1_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg397: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_1_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg398: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_1_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg399: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_1_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg400: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_2_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg401: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_2_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg402: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_2_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg403: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_2_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg404: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_3_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg405: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_3_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg406: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_3_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg407: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_3_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg408: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_4_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg409: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_4_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg410: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_4_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg411: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_4_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg412: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_5_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg413: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_5_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg414: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_5_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg415: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_5_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg416: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_6_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg417: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_6_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg418: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_6_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg419: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_6_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg420: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_7_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg421: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_7_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg422: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_7_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg423: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_7_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg424: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_8_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg425: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_8_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg426: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_8_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg427: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_8_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg428: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_9_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg429: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_9_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg430: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_9_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg431: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_9_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg432: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_10_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg433: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_10_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg434: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_10_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg435: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_10_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg436: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_11_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg437: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_11_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg438: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_11_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg439: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_11_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg440: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_12_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg441: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_12_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg442: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_12_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg443: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_12_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg444: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_13_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg445: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_13_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg446: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_13_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg447: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_13_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg448: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_14_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg449: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_14_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg450: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_14_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg451: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_14_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg452: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_15_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg453: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_15_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg454: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_15_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg455: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_15_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg456: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_16_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg457: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_16_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg458: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_16_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg459: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_16_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg460: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_17_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg461: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_17_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg462: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_17_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg463: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_17_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg464: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_18_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg465: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_18_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg466: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_18_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg467: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_18_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg468: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_19_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg469: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_19_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg470: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_19_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg471: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_19_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg472: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_20_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg473: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_20_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg474: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_20_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg475: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_20_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg476: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_21_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg477: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_21_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg478: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_21_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg479: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_21_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg480: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_22_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg481: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_22_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg482: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_22_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg483: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_22_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg484: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_23_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg485: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_23_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg486: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_23_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg487: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_23_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg488: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_24_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg489: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_24_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg490: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_24_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg491: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_24_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg492: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_25_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg493: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_25_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg494: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_25_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg495: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_25_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg496: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_26_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg497: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_26_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg498: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_26_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg499: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_26_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg500: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_27_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg501: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_27_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg502: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_27_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg503: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_27_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg504: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_28_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg505: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_28_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg506: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_28_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg507: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_28_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg508: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_29_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg509: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_29_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg510: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_29_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg511: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_29_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg512: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_30_self_attn_k_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg513: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_30_self_attn_k_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg514: tensor<1280xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_30_self_attn_q_proj_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg515: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___image_encoder_vision_model_encoder_layers_30_self_attn_q_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg516: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___resampler_layers_0_attn_to_k_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg517: tensor<1280x1280xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___resampler_layers_0_attn_to_q_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg518: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "getattr_l__self___resampler_layers_0_ff___1___net_2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg519: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "getattr_l__self___resampler_layers_0_ff___1___net_0_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg520: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_0_ff_0_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg521: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_0_ff_0_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg522: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___resampler_layers_1_attn_to_out_0_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg523: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___resampler_layers_1_attn_to_v_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg524: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_1_ln1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg525: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_1_ln1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg526: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_1_ln0_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg527: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_1_ln0_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg528: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___resampler_layers_1_attn_to_k_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg529: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___resampler_layers_1_attn_to_q_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg530: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "getattr_l__self___resampler_layers_1_ff___1___net_2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg531: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "getattr_l__self___resampler_layers_1_ff___1___net_0_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg532: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_1_ff_0_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg533: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_1_ff_0_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg534: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___resampler_layers_2_attn_to_out_0_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg535: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___resampler_layers_2_attn_to_v_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg536: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_2_ln1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg537: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_2_ln1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg538: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_2_ln0_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg539: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_2_ln0_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg540: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___resampler_layers_2_attn_to_k_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg541: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___resampler_layers_2_attn_to_q_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg542: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "getattr_l__self___resampler_layers_2_ff___1___net_2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg543: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "getattr_l__self___resampler_layers_2_ff___1___net_0_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg544: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_2_ff_0_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg545: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_2_ff_0_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg546: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___resampler_layers_3_attn_to_out_0_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg547: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___resampler_layers_3_attn_to_v_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg548: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_3_ln1_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg549: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_3_ln1_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg550: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_3_ln0_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg551: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_3_ln0_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg552: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___resampler_layers_3_attn_to_k_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg553: tensor<1280x1280xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x1280xbf16>>, ttir.name = "l__self___resampler_layers_3_attn_to_q_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg554: tensor<1280x5120xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280x5120xbf16>>, ttir.name = "getattr_l__self___resampler_layers_3_ff___1___net_2_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg555: tensor<5120x1280xbf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<5120x1280xbf16>>, ttir.name = "getattr_l__self___resampler_layers_3_ff___1___net_0_proj_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg556: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_3_ff_0_bias"} loc("-1|unknown|unknown|-1|unknownxla__device_data"), %arg557: tensor<1280xbf16, #ttnn_layout9> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1280xbf16>>, ttir.name = "l__self___resampler_layers_3_ff_0_weight"} loc("-1|unknown|unknown|-1|unknownxla__device_data")) -> (tensor<1x16x2048xbf16, #ttnn_layout16> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<1x16x2048xbf16>>}) attributes {tt.function_type = "forward_device"} {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc)
        %1 = ttcore.load_cached(@main_const_eval_1, [%arg99]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg99) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %2 = ttcore.load_cached(@main_const_eval_2, [%arg225, %arg444, %arg446]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg446) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg444) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg225) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %3 = ttcore.load_cached(@main_const_eval_3, [%arg265]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg265) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %4 = ttcore.load_cached(@main_const_eval_4, [%arg46, %arg505, %arg507]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg507) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg505) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg46) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %5 = ttcore.load_cached(@main_const_eval_5, [%arg111]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg111) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %6 = ttcore.load_cached(@main_const_eval_6, [%arg231]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg231) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %7 = ttcore.load_cached(@main_const_eval_7, [%arg2]) : (tensor<2048xbf16, #ttnn_layout15>) -> tensor<1x16x2048xbf16, #ttnn_layout16> loc(#loc)
        "ttnn.deallocate"(%arg2) <{force = false}> : (tensor<2048xbf16, #ttnn_layout15>) -> () loc(#loc)
        %8 = ttcore.load_cached(@main_const_eval_8, [%arg175]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg175) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %9 = ttcore.load_cached(@main_const_eval_9, [%arg55]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg55) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %10 = ttcore.load_cached(@main_const_eval_10, [%arg70, %arg497, %arg499]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg499) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg497) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg70) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %11 = ttcore.load_cached(@main_const_eval_11, [%arg337]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg337) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %12 = ttcore.load_cached(@main_const_eval_12, [%arg211]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg211) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %13 = ttcore.load_cached(@main_const_eval_13, [%arg154, %arg469, %arg471]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg471) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg469) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg154) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %14 = ttcore.load_cached(@main_const_eval_14, [%arg363]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg363) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %15 = ttcore.load_cached(@main_const_eval_15, [%arg39]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg39) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %16 = ttcore.load_cached(@main_const_eval_16, [%arg229]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg229) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %17 = ttcore.load_cached(@main_const_eval_17, [%arg45, %arg504, %arg506]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg506) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg504) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg45) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %18 = ttcore.load_cached(@main_const_eval_18, [%arg177, %arg460, %arg462]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg462) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg460) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg177) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %19 = ttcore.load_cached(@main_const_eval_19, [%arg205]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg205) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %20 = ttcore.load_cached(@main_const_eval_20, [%arg169]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg169) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %21 = ttcore.load_cached(@main_const_eval_21, [%arg127]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg127) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %22 = ttcore.load_cached(@main_const_eval_22, [%arg361]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg361) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %23 = ttcore.load_cached(@main_const_eval_23, [%arg97]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg97) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %24 = ttcore.load_cached(@main_const_eval_24, [%arg202, %arg453, %arg455]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg455) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg453) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg202) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %25 = ttcore.load_cached(@main_const_eval_25, [%arg279]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg279) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %26 = ttcore.load_cached(@main_const_eval_26, [%arg358, %arg401, %arg403]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg403) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg401) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg358) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %27 = ttcore.load_cached(@main_const_eval_27, [%arg346, %arg405, %arg407]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg407) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg405) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg346) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %28 = ttcore.load_cached(@main_const_eval_28, [%arg291]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg291) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %29 = ttcore.load_cached(@main_const_eval_29, [%arg145]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg145) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %30 = ttcore.load_cached(@main_const_eval_30, [%arg286, %arg425, %arg427]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg427) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg425) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg286) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %31:2 = ttcore.load_cached(@main_const_eval_31, [%arg4, %arg7, %arg8, %arg517]) : (tensor<1x16x1280xbf16, #ttnn_layout>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280x1280xbf16, #ttnn_layout11>) -> (tensor<16x1280xbf16, #ttnn_layout19>, tensor<1x20x16x64xbf16, #ttnn_layout20>) loc(#loc)
        "ttnn.deallocate"(%arg517) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg8) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg7) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %32 = ttcore.load_cached(@main_const_eval_32, [%arg79]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg79) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %33 = ttcore.load_cached(@main_const_eval_33, [%arg105, %arg484, %arg486]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg486) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg484) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg105) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %34 = ttcore.load_cached(@main_const_eval_34, [%arg115]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg115) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %35 = ttcore.load_cached(@main_const_eval_35, [%arg178, %arg461, %arg463]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg463) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg461) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg178) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %36 = ttcore.load_cached(@main_const_eval_36, [%arg25]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg25) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %37 = ttcore.load_cached(@main_const_eval_37, [%arg106, %arg485, %arg487]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg487) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg485) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg106) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %38 = ttcore.load_cached(@main_const_eval_38, [%arg130, %arg477, %arg479]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg479) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg477) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg130) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %39 = ttcore.load_cached(@main_const_eval_39, [%arg27]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg27) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %40 = ttcore.load_cached(@main_const_eval_40, [%arg73]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg73) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %41 = ttcore.load_cached(@main_const_eval_41, [%arg285, %arg424, %arg426]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg426) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg424) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg285) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %42 = ttcore.load_cached(@main_const_eval_42, [%arg57, %arg500, %arg502]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg502) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg500) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg57) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %43 = ttcore.load_cached(@main_const_eval_43, [%arg375]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg375) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %44 = ttcore.load_cached(@main_const_eval_44, [%arg333, %arg408, %arg410]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg410) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg408) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg333) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %45 = ttcore.load_cached(@main_const_eval_45, [%arg147]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg147) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %46 = ttcore.load_cached(@main_const_eval_46, [%arg33, %arg508, %arg510]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg510) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg508) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg33) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %47 = ttcore.load_cached(@main_const_eval_47, [%arg307]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg307) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %48 = ttcore.load_cached(@main_const_eval_48, [%arg381, %arg392, %arg394]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg394) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg392) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg381) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %49 = ttcore.load_cached(@main_const_eval_49, [%arg19]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg19) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %50 = ttcore.load_cached(@main_const_eval_50, [%arg298, %arg421, %arg423]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg423) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg421) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg298) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %51 = ttcore.load_cached(@main_const_eval_51, [%arg153, %arg468, %arg470]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg470) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg468) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg153) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %52 = ttcore.load_cached(@main_const_eval_52, [%arg103]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg103) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %53 = ttcore.load_cached(@main_const_eval_53, [%arg151]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg151) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %54 = ttcore.load_cached(@main_const_eval_54, [%arg303]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg303) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %55 = ttcore.load_cached(@main_const_eval_55, [%arg13]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg13) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %56 = ttcore.load_cached(@main_const_eval_56, [%arg367]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg367) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %57 = ttcore.load_cached(@main_const_eval_57, [%arg37]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg37) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %58 = ttcore.load_cached(@main_const_eval_58, [%arg117, %arg480, %arg482]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg482) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg480) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg117) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %59 = ttcore.load_cached(@main_const_eval_59, [%arg81, %arg492, %arg494]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg494) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg492) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg81) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %60 = ttcore.load_cached(@main_const_eval_60, [%arg93, %arg488, %arg490]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg490) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg488) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg93) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %61 = ttcore.load_cached(@main_const_eval_61, [%arg141, %arg472, %arg474]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg474) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg472) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg141) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %62 = ttcore.load_cached(@main_const_eval_62, [%arg82, %arg493, %arg495]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg495) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg493) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg82) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %63 = ttcore.load_cached(@main_const_eval_63, [%arg369, %arg396, %arg398]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg398) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg396) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg369) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %64 = ttcore.load_cached(@main_const_eval_64, [%arg187]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg187) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %65 = ttcore.load_cached(@main_const_eval_65, [%arg259]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg259) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %66 = ttcore.load_cached(@main_const_eval_66, [%arg142, %arg473, %arg475]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg475) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg473) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg142) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %67 = ttcore.load_cached(@main_const_eval_67, [%arg389]) : (tensor<1280x3x14x14xbf16, #ttnn_layout23>) -> tensor<1x1x588x1280xbf16, #ttnn_layout24> loc(#loc)
        "ttnn.deallocate"(%arg389) <{force = false}> : (tensor<1280x3x14x14xbf16, #ttnn_layout23>) -> () loc(#loc)
        %68 = ttcore.load_cached(@main_const_eval_68, [%arg250, %arg437, %arg439]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg439) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg437) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg250) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %69 = ttcore.load_cached(@main_const_eval_69, [%arg235]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg235) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %70 = ttcore.load_cached(@main_const_eval_70, [%arg319]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg319) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %71 = ttcore.load_cached(@main_const_eval_71, [%arg382, %arg393, %arg395]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg395) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg393) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg382) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %72 = ttcore.load_cached(@main_const_eval_72, [%arg261, %arg432, %arg434]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg434) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg432) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg261) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %73 = ttcore.load_cached(@main_const_eval_73, [%arg201, %arg452, %arg454]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg454) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg452) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg201) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %74 = ttcore.load_cached(@main_const_eval_74, [%arg373]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg373) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %75 = ttcore.load_cached(@main_const_eval_75, [%arg283]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg283) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %76 = ttcore.load_cached(@main_const_eval_76, [%arg34, %arg509, %arg511]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg511) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg509) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg34) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %77 = ttcore.load_cached(@main_const_eval_77, [%arg94, %arg489, %arg491]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg491) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg489) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg94) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %78 = ttcore.load_cached(@main_const_eval_78, [%arg69, %arg496, %arg498]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg498) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg496) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg69) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %79 = ttcore.load_cached(@main_const_eval_79, [%arg139]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg139) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %80 = ttcore.load_cached(@main_const_eval_80, [%arg31]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg31) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %81 = ttcore.load_cached(@main_const_eval_81, [%arg357, %arg400, %arg402]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg402) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg400) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg357) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %82 = ttcore.load_cached(@main_const_eval_82, [%arg351]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg351) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %83 = ttcore.load_cached(@main_const_eval_83, [%arg133]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg133) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %84 = ttcore.load_cached(@main_const_eval_84, [%arg193]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg193) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %85 = ttcore.load_cached(@main_const_eval_85, [%arg297, %arg420, %arg422]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg422) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg420) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg297) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %86 = ttcore.load_cached(@main_const_eval_86, [%arg253]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg253) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %87 = ttcore.load_cached(@main_const_eval_87, [%arg214, %arg449, %arg451]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg451) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg449) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg214) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %88 = ttcore.load_cached(@main_const_eval_88, [%arg238, %arg441, %arg443]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg443) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg441) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg238) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %89 = ttcore.load_cached(@main_const_eval_89, [%arg387, %arg388]) : (tensor<1x257xsi32, #ttnn_layout25>, tensor<257x1280xbf16, #ttnn_layout26>) -> tensor<1x1280x257xbf16, #ttnn_layout27> loc(#loc)
        "ttnn.deallocate"(%arg388) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout26>) -> () loc(#loc)
        "ttnn.deallocate"(%arg387) <{force = false}> : (tensor<1x257xsi32, #ttnn_layout25>) -> () loc(#loc)
        %90 = ttcore.load_cached(@main_const_eval_90, [%arg190, %arg457, %arg459]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg459) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg457) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg190) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %91 = ttcore.load_cached(@main_const_eval_91, [%arg345, %arg404, %arg406]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg406) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg404) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg345) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %92 = ttcore.load_cached(@main_const_eval_92, [%arg315]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg315) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %93 = ttcore.load_cached(@main_const_eval_93, [%arg219]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg219) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %94 = ttcore.load_cached(@main_const_eval_94, [%arg277]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg277) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %95 = ttcore.load_cached(@main_const_eval_95, [%arg159]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg159) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %96 = ttcore.load_cached(@main_const_eval_96, [%arg255]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg255) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %97 = ttcore.load_cached(@main_const_eval_97, [%arg322, %arg413, %arg415]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg415) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg413) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg322) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %98 = ttcore.load_cached(@main_const_eval_98, [%arg331]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg331) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %99 = ttcore.load_cached(@main_const_eval_99, [%arg63]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg63) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %100 = ttcore.load_cached(@main_const_eval_100, [%arg309, %arg416, %arg418]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg418) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg416) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg309) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %101 = ttcore.load_cached(@main_const_eval_101, [%arg163]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg163) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %102 = ttcore.load_cached(@main_const_eval_102, [%arg213, %arg448, %arg450]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg450) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg448) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg213) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %103 = ttcore.load_cached(@main_const_eval_103, [%arg226, %arg445, %arg447]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg447) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg445) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg226) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %104 = ttcore.load_cached(@main_const_eval_104, [%arg301]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg301) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %105 = ttcore.load_cached(@main_const_eval_105, [%arg181]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg181) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %106 = ttcore.load_cached(@main_const_eval_106, [%arg67]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg67) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %107 = ttcore.load_cached(@main_const_eval_107, [%arg313]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg313) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %108 = ttcore.load_cached(@main_const_eval_108, [%arg135]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg135) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %109 = ttcore.load_cached(@main_const_eval_109, [%arg171]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg171) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %110 = ttcore.load_cached(@main_const_eval_110, [%arg217]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg217) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %111 = ttcore.load_cached(@main_const_eval_111, [%arg123]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg123) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %112 = ttcore.load_cached(@main_const_eval_112, [%arg129, %arg476, %arg478]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg478) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg476) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg129) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %113 = ttcore.load_cached(@main_const_eval_113, [%arg166, %arg465, %arg467]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg467) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg465) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg166) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %114 = ttcore.load_cached(@main_const_eval_114, [%arg271]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg271) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %115 = ttcore.load_cached(@main_const_eval_115, [%arg199]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg199) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %116 = ttcore.load_cached(@main_const_eval_116, [%arg51]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg51) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %117 = ttcore.load_cached(@main_const_eval_117, [%arg249, %arg436, %arg438]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg438) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg436) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg249) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %118 = ttcore.load_cached(@main_const_eval_118, [%arg75]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg75) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %119 = ttcore.load_cached(@main_const_eval_119, [%arg189, %arg456, %arg458]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg458) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg456) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg189) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %120 = ttcore.load_cached(@main_const_eval_120, [%arg274, %arg429, %arg431]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg431) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg429) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg274) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %121 = ttcore.load_cached(@main_const_eval_121, [%arg295]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg295) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %122 = ttcore.load_cached(@main_const_eval_122, [%arg43]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg43) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %123 = ttcore.load_cached(@main_const_eval_123, [%arg355]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg355) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %124 = ttcore.load_cached(@main_const_eval_124, [%arg61]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg61) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %125 = ttcore.load_cached(@main_const_eval_125, [%arg379]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg379) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %126 = ttcore.load_cached(@main_const_eval_126, [%arg109]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg109) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %127 = ttcore.load_cached(@main_const_eval_127, [%arg223]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg223) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %128 = ttcore.load_cached(@main_const_eval_128, [%arg334, %arg409, %arg411]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg411) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg409) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg334) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %129 = ttcore.load_cached(@main_const_eval_129, [%arg310, %arg417, %arg419]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg419) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg417) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg310) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %130 = ttcore.load_cached(@main_const_eval_130, [%arg49]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg49) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %131 = ttcore.load_cached(@main_const_eval_131, [%arg183]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg183) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %132 = ttcore.load_cached(@main_const_eval_132, [%arg21, %arg512, %arg514]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg514) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg512) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg21) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %133 = ttcore.load_cached(@main_const_eval_133, [%arg343]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg343) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %134 = ttcore.load_cached(@main_const_eval_134, [%arg273, %arg428, %arg430]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg430) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg428) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg273) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %135 = ttcore.load_cached(@main_const_eval_135, [%arg165, %arg464, %arg466]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg466) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg464) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg165) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %136 = ttcore.load_cached(@main_const_eval_136, [%arg15]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg15) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %137 = ttcore.load_cached(@main_const_eval_137, [%arg237, %arg440, %arg442]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg442) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg440) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg237) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %138 = ttcore.load_cached(@main_const_eval_138, [%arg11]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg11) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %139 = ttcore.load_cached(@main_const_eval_139, [%arg22, %arg513, %arg515]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg515) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg513) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg22) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %140 = ttcore.load_cached(@main_const_eval_140, [%arg87]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg87) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %141 = ttcore.load_cached(@main_const_eval_141, [%arg247]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg247) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %142 = ttcore.load_cached(@main_const_eval_142, [%arg207]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg207) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %143 = ttcore.load_cached(@main_const_eval_143, [%arg391]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x1280x1xbf16, #ttnn_layout33> loc(#loc)
        "ttnn.deallocate"(%arg391) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %144 = ttcore.load_cached(@main_const_eval_144, [%arg91]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg91) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %145 = ttcore.load_cached(@main_const_eval_145, [%arg85]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg85) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %146 = ttcore.load_cached(@main_const_eval_146, [%arg339]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg339) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %147 = ttcore.load_cached(@main_const_eval_147, [%arg349]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg349) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %148 = ttcore.load_cached(@main_const_eval_148, [%arg157]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg157) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %149 = ttcore.load_cached(@main_const_eval_149, [%arg118, %arg481, %arg483]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg483) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg481) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg118) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %150 = ttcore.load_cached(@main_const_eval_150, [%arg325]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg325) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %151 = ttcore.load_cached(@main_const_eval_151, [%arg327]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg327) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %152 = ttcore.load_cached(@main_const_eval_152, [%arg241]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg241) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %153 = ttcore.load_cached(@main_const_eval_153, [%arg262, %arg433, %arg435]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg435) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg433) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg262) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %154 = ttcore.load_cached(@main_const_eval_154, [%arg289]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg289) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %155 = ttcore.load_cached(@main_const_eval_155, [%arg195]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg195) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %156 = ttcore.load_cached(@main_const_eval_156, [%arg267]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg267) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %157 = ttcore.load_cached(@main_const_eval_157, [%arg243]) : (tensor<5120xbf16, #ttnn_layout1>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc)
        "ttnn.deallocate"(%arg243) <{force = false}> : (tensor<5120xbf16, #ttnn_layout1>) -> () loc(#loc)
        %158 = ttcore.load_cached(@main_const_eval_158, [%arg370, %arg397, %arg399]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg399) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg397) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg370) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %159 = ttcore.load_cached(@main_const_eval_159, [%arg321, %arg412, %arg414]) : (tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>, tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg414) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg412) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        "ttnn.deallocate"(%arg321) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %160 = ttcore.load_cached(@main_const_eval_160, [%arg58, %arg501, %arg503]) : (tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>, tensor<1280x1280xbf16, #ttnn_layout11>) -> tensor<3840x1280xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg503) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg501) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        "ttnn.deallocate"(%arg58) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout11>) -> () loc(#loc)
        %161 = ttcore.load_cached(@main_const_eval_161, [%arg121]) : (tensor<1280xbf16, #ttnn_layout6>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg121) <{force = false}> : (tensor<1280xbf16, #ttnn_layout6>) -> () loc(#loc)
        %162 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device loc(#loc1)
        %163 = "ttnn.to_layout"(%arg390) <{layout = #ttnn.layout<tile>}> : (tensor<1x3x224x224xbf16, #ttnn_layout37>) -> tensor<1x3x224x224xbf16, #ttnn_layout38> loc(#loc1)
        "ttnn.deallocate"(%arg390) <{force = false}> : (tensor<1x3x224x224xbf16, #ttnn_layout37>) -> () loc(#loc1)
        %164 = "ttnn.permute"(%163) <{permutation = array<i64: 0, 2, 3, 1>}> : (tensor<1x3x224x224xbf16, #ttnn_layout38>) -> tensor<1x224x224x3xbf16, #ttnn_layout39> loc(#loc93)
        "ttnn.deallocate"(%163) <{force = false}> : (tensor<1x3x224x224xbf16, #ttnn_layout38>) -> () loc(#loc93)
        %165 = "ttnn.reshape"(%164) <{shape = [1 : i32, 1 : i32, 50176 : i32, 3 : i32]}> : (tensor<1x224x224x3xbf16, #ttnn_layout39>) -> tensor<1x1x50176x3xbf16, #ttnn_layout40> loc(#loc570)
        "ttnn.deallocate"(%164) <{force = false}> : (tensor<1x224x224x3xbf16, #ttnn_layout39>) -> () loc(#loc570)
        %166 = "ttnn.conv2d"(%165, %67, %162) <{batch_size = 1 : i32, compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, conv2d_config = #ttnn.conv2d_config<weights_dtype = bf16, deallocate_activation = true, act_block_h_override = 0, enable_kernel_stride_folding = false, config_tensors_in_dram = true>, conv2d_slice_config = #ttnn.conv2d_slice_config<l1_full, 0>, dilation = array<i32: 1, 1>, dtype = #ttcore.supportedDataTypes<bf16>, groups = 1 : i32, in_channels = 3 : i32, input_height = 224 : i32, input_width = 224 : i32, kernel_size = array<i32: 14, 14>, out_channels = 1280 : i32, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 14, 14>}> : (tensor<1x1x50176x3xbf16, #ttnn_layout40>, tensor<1x1x588x1280xbf16, #ttnn_layout24>, !ttnn.device) -> tensor<1x1x256x1280xbf16, #ttnn_layout41> loc(#loc93)
        "ttnn.deallocate"(%165) <{force = false}> : (tensor<1x1x50176x3xbf16, #ttnn_layout40>) -> () loc(#loc93)
        "ttnn.deallocate"(%67) <{force = false}> : (tensor<1x1x588x1280xbf16, #ttnn_layout24>) -> () loc(#loc93)
        %167 = "ttnn.reshape"(%166) <{shape = [1 : i32, 16 : i32, 16 : i32, 1280 : i32]}> : (tensor<1x1x256x1280xbf16, #ttnn_layout41>) -> tensor<1x16x16x1280xbf16, #ttnn_layout42> loc(#loc570)
        "ttnn.deallocate"(%166) <{force = false}> : (tensor<1x1x256x1280xbf16, #ttnn_layout41>) -> () loc(#loc570)
        %168 = "ttnn.permute"(%167) <{permutation = array<i64: 0, 3, 1, 2>}> : (tensor<1x16x16x1280xbf16, #ttnn_layout42>) -> tensor<1x1280x16x16xbf16, #ttnn_layout43> loc(#loc93)
        "ttnn.deallocate"(%167) <{force = false}> : (tensor<1x16x16x1280xbf16, #ttnn_layout42>) -> () loc(#loc93)
        %169 = "ttnn.reshape"(%168) <{shape = [1 : i32, 1280 : i32, 256 : i32]}> : (tensor<1x1280x16x16xbf16, #ttnn_layout43>) -> tensor<1x1280x256xbf16, #ttnn_layout44> loc(#loc203)
        "ttnn.deallocate"(%168) <{force = false}> : (tensor<1x1280x16x16xbf16, #ttnn_layout43>) -> () loc(#loc203)
        %170 = "ttnn.concat"(%143, %169) <{dim = 2 : si32}> : (tensor<1x1280x1xbf16, #ttnn_layout33>, tensor<1x1280x256xbf16, #ttnn_layout44>) -> tensor<1x1280x257xbf16, #ttnn_layout27> loc(#loc120)
        "ttnn.deallocate"(%169) <{force = false}> : (tensor<1x1280x256xbf16, #ttnn_layout44>) -> () loc(#loc120)
        "ttnn.deallocate"(%143) <{force = false}> : (tensor<1x1280x1xbf16, #ttnn_layout33>) -> () loc(#loc120)
        %171 = "ttnn.add"(%170, %89) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1280x257xbf16, #ttnn_layout27>, tensor<1x1280x257xbf16, #ttnn_layout27>) -> tensor<1x1280x257xbf16, #ttnn_layout27> loc(#loc204)
        "ttnn.deallocate"(%170) <{force = false}> : (tensor<1x1280x257xbf16, #ttnn_layout27>) -> () loc(#loc204)
        "ttnn.deallocate"(%89) <{force = false}> : (tensor<1x1280x257xbf16, #ttnn_layout27>) -> () loc(#loc204)
        %172 = "ttnn.permute"(%171) <{permutation = array<i64: 0, 2, 1>}> : (tensor<1x1280x257xbf16, #ttnn_layout27>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc204)
        "ttnn.deallocate"(%171) <{force = false}> : (tensor<1x1280x257xbf16, #ttnn_layout27>) -> () loc(#loc204)
        %173 = "ttnn.layer_norm"(%172, %arg386, %arg385) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc205)
        "ttnn.deallocate"(%172) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc205)
        "ttnn.deallocate"(%arg386) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc205)
        "ttnn.deallocate"(%arg385) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc205)
        %174 = "ttnn.layer_norm"(%173, %arg384, %arg383) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc206)
        "ttnn.deallocate"(%arg384) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc206)
        "ttnn.deallocate"(%arg383) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc206)
        %175 = "ttnn.reshape"(%174) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc207)
        "ttnn.deallocate"(%174) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc207)
        %176 = "ttnn.matmul"(%175, %71) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc571)
        "ttnn.deallocate"(%175) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc571)
        "ttnn.deallocate"(%71) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc571)
        %177 = "ttnn.add"(%176, %48) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc572)
        "ttnn.deallocate"(%176) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc572)
        "ttnn.deallocate"(%48) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc572)
        %178 = "ttnn.slice_static"(%177) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc573)
        %179 = "ttnn.slice_static"(%177) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc574)
        %180 = "ttnn.slice_static"(%177) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc575)
        "ttnn.deallocate"(%177) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc575)
        %181 = "ttnn.reshape"(%178) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc576)
        "ttnn.deallocate"(%178) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc576)
        %182 = "ttnn.reshape"(%179) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc577)
        "ttnn.deallocate"(%179) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc577)
        %183 = "ttnn.reshape"(%180) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc578)
        "ttnn.deallocate"(%180) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc578)
        %184 = "ttnn.permute"(%181) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc579)
        "ttnn.deallocate"(%181) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc579)
        %185 = "ttnn.permute"(%182) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc580)
        "ttnn.deallocate"(%182) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc580)
        %186 = "ttnn.permute"(%183) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc581)
        "ttnn.deallocate"(%183) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc581)
        %187 = "ttnn.pad"(%184) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc208)
        "ttnn.deallocate"(%184) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc208)
        %188 = "ttnn.pad"(%185) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc208)
        "ttnn.deallocate"(%185) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc208)
        %189 = "ttnn.pad"(%186) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc208)
        "ttnn.deallocate"(%186) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc208)
        %190 = "ttnn.scaled_dot_product_attention"(%187, %188, %189) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc208)
        "ttnn.deallocate"(%189) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc208)
        "ttnn.deallocate"(%188) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc208)
        "ttnn.deallocate"(%187) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc208)
        %191 = "ttnn.slice_static"(%190) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc208)
        "ttnn.deallocate"(%190) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc208)
        %192 = "ttnn.permute"(%191) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc582)
        "ttnn.deallocate"(%191) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc582)
        %193 = "ttnn.reshape"(%192) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc209)
        "ttnn.deallocate"(%192) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc209)
        %194 = "ttnn.matmul"(%193, %arg380) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc583)
        "ttnn.deallocate"(%193) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc583)
        "ttnn.deallocate"(%arg380) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc583)
        %195 = "ttnn.add"(%194, %125) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc584)
        "ttnn.deallocate"(%194) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc584)
        "ttnn.deallocate"(%125) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc584)
        %196 = "ttnn.add"(%173, %195) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc210)
        "ttnn.deallocate"(%195) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc210)
        "ttnn.deallocate"(%173) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc210)
        %197 = "ttnn.layer_norm"(%196, %arg378, %arg377) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc211)
        "ttnn.deallocate"(%arg378) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc211)
        "ttnn.deallocate"(%arg377) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc211)
        %198 = "ttnn.reshape"(%197) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc212)
        "ttnn.deallocate"(%197) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc212)
        %199 = "ttnn.matmul"(%198, %arg376) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc585)
        "ttnn.deallocate"(%198) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc585)
        "ttnn.deallocate"(%arg376) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc585)
        %200 = "ttnn.add"(%199, %43) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc586)
        "ttnn.deallocate"(%199) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc586)
        "ttnn.deallocate"(%43) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc586)
        %201 = "ttnn.gelu"(%200) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc587)
        "ttnn.deallocate"(%200) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc587)
        %202 = "ttnn.reshape"(%201) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc213)
        "ttnn.deallocate"(%201) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc213)
        %203 = "ttnn.matmul"(%202, %arg374) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc588)
        "ttnn.deallocate"(%202) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc588)
        "ttnn.deallocate"(%arg374) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc588)
        %204 = "ttnn.add"(%203, %74) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc589)
        "ttnn.deallocate"(%203) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc589)
        "ttnn.deallocate"(%74) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc589)
        %205 = "ttnn.add"(%196, %204) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc214)
        "ttnn.deallocate"(%204) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc214)
        "ttnn.deallocate"(%196) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc214)
        %206 = "ttnn.layer_norm"(%205, %arg372, %arg371) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc215)
        "ttnn.deallocate"(%arg372) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc215)
        "ttnn.deallocate"(%arg371) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc215)
        %207 = "ttnn.reshape"(%206) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc216)
        "ttnn.deallocate"(%206) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc216)
        %208 = "ttnn.matmul"(%207, %158) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc590)
        "ttnn.deallocate"(%207) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc590)
        "ttnn.deallocate"(%158) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc590)
        %209 = "ttnn.add"(%208, %63) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc591)
        "ttnn.deallocate"(%208) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc591)
        "ttnn.deallocate"(%63) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc591)
        %210 = "ttnn.slice_static"(%209) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc592)
        %211 = "ttnn.slice_static"(%209) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc593)
        %212 = "ttnn.slice_static"(%209) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc594)
        "ttnn.deallocate"(%209) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc594)
        %213 = "ttnn.reshape"(%210) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc595)
        "ttnn.deallocate"(%210) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc595)
        %214 = "ttnn.reshape"(%211) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc596)
        "ttnn.deallocate"(%211) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc596)
        %215 = "ttnn.reshape"(%212) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc597)
        "ttnn.deallocate"(%212) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc597)
        %216 = "ttnn.permute"(%213) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc598)
        "ttnn.deallocate"(%213) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc598)
        %217 = "ttnn.permute"(%214) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc599)
        "ttnn.deallocate"(%214) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc599)
        %218 = "ttnn.permute"(%215) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc600)
        "ttnn.deallocate"(%215) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc600)
        %219 = "ttnn.pad"(%216) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc217)
        "ttnn.deallocate"(%216) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc217)
        %220 = "ttnn.pad"(%217) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc217)
        "ttnn.deallocate"(%217) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc217)
        %221 = "ttnn.pad"(%218) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc217)
        "ttnn.deallocate"(%218) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc217)
        %222 = "ttnn.scaled_dot_product_attention"(%219, %220, %221) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc217)
        "ttnn.deallocate"(%221) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc217)
        "ttnn.deallocate"(%220) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc217)
        "ttnn.deallocate"(%219) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc217)
        %223 = "ttnn.slice_static"(%222) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc217)
        "ttnn.deallocate"(%222) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc217)
        %224 = "ttnn.permute"(%223) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc601)
        "ttnn.deallocate"(%223) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc601)
        %225 = "ttnn.reshape"(%224) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc218)
        "ttnn.deallocate"(%224) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc218)
        %226 = "ttnn.matmul"(%225, %arg368) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc602)
        "ttnn.deallocate"(%225) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc602)
        "ttnn.deallocate"(%arg368) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc602)
        %227 = "ttnn.add"(%226, %56) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc603)
        "ttnn.deallocate"(%226) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc603)
        "ttnn.deallocate"(%56) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc603)
        %228 = "ttnn.add"(%205, %227) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc219)
        "ttnn.deallocate"(%227) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc219)
        "ttnn.deallocate"(%205) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc219)
        %229 = "ttnn.layer_norm"(%228, %arg366, %arg365) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc220)
        "ttnn.deallocate"(%arg366) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc220)
        "ttnn.deallocate"(%arg365) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc220)
        %230 = "ttnn.reshape"(%229) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc221)
        "ttnn.deallocate"(%229) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc221)
        %231 = "ttnn.matmul"(%230, %arg364) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc604)
        "ttnn.deallocate"(%230) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc604)
        "ttnn.deallocate"(%arg364) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc604)
        %232 = "ttnn.add"(%231, %14) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc605)
        "ttnn.deallocate"(%231) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc605)
        "ttnn.deallocate"(%14) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc605)
        %233 = "ttnn.gelu"(%232) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc606)
        "ttnn.deallocate"(%232) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc606)
        %234 = "ttnn.reshape"(%233) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc222)
        "ttnn.deallocate"(%233) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc222)
        %235 = "ttnn.matmul"(%234, %arg362) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc607)
        "ttnn.deallocate"(%234) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc607)
        "ttnn.deallocate"(%arg362) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc607)
        %236 = "ttnn.add"(%235, %22) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc608)
        "ttnn.deallocate"(%235) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc608)
        "ttnn.deallocate"(%22) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc608)
        %237 = "ttnn.add"(%228, %236) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc223)
        "ttnn.deallocate"(%236) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc223)
        "ttnn.deallocate"(%228) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc223)
        %238 = "ttnn.layer_norm"(%237, %arg360, %arg359) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc224)
        "ttnn.deallocate"(%arg360) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc224)
        "ttnn.deallocate"(%arg359) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc224)
        %239 = "ttnn.reshape"(%238) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc225)
        "ttnn.deallocate"(%238) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc225)
        %240 = "ttnn.matmul"(%239, %26) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc609)
        "ttnn.deallocate"(%239) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc609)
        "ttnn.deallocate"(%26) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc609)
        %241 = "ttnn.add"(%240, %81) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc610)
        "ttnn.deallocate"(%240) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc610)
        "ttnn.deallocate"(%81) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc610)
        %242 = "ttnn.slice_static"(%241) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc611)
        %243 = "ttnn.slice_static"(%241) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc612)
        %244 = "ttnn.slice_static"(%241) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc613)
        "ttnn.deallocate"(%241) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc613)
        %245 = "ttnn.reshape"(%242) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc614)
        "ttnn.deallocate"(%242) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc614)
        %246 = "ttnn.reshape"(%243) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc615)
        "ttnn.deallocate"(%243) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc615)
        %247 = "ttnn.reshape"(%244) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc616)
        "ttnn.deallocate"(%244) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc616)
        %248 = "ttnn.permute"(%245) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc617)
        "ttnn.deallocate"(%245) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc617)
        %249 = "ttnn.permute"(%246) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc618)
        "ttnn.deallocate"(%246) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc618)
        %250 = "ttnn.permute"(%247) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc619)
        "ttnn.deallocate"(%247) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc619)
        %251 = "ttnn.pad"(%248) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc226)
        "ttnn.deallocate"(%248) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc226)
        %252 = "ttnn.pad"(%249) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc226)
        "ttnn.deallocate"(%249) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc226)
        %253 = "ttnn.pad"(%250) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc226)
        "ttnn.deallocate"(%250) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc226)
        %254 = "ttnn.scaled_dot_product_attention"(%251, %252, %253) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc226)
        "ttnn.deallocate"(%253) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc226)
        "ttnn.deallocate"(%252) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc226)
        "ttnn.deallocate"(%251) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc226)
        %255 = "ttnn.slice_static"(%254) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc226)
        "ttnn.deallocate"(%254) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc226)
        %256 = "ttnn.permute"(%255) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc620)
        "ttnn.deallocate"(%255) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc620)
        %257 = "ttnn.reshape"(%256) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc227)
        "ttnn.deallocate"(%256) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc227)
        %258 = "ttnn.matmul"(%257, %arg356) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc621)
        "ttnn.deallocate"(%257) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc621)
        "ttnn.deallocate"(%arg356) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc621)
        %259 = "ttnn.add"(%258, %123) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc622)
        "ttnn.deallocate"(%258) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc622)
        "ttnn.deallocate"(%123) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc622)
        %260 = "ttnn.add"(%237, %259) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc228)
        "ttnn.deallocate"(%259) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc228)
        "ttnn.deallocate"(%237) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc228)
        %261 = "ttnn.layer_norm"(%260, %arg354, %arg353) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc229)
        "ttnn.deallocate"(%arg354) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc229)
        "ttnn.deallocate"(%arg353) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc229)
        %262 = "ttnn.reshape"(%261) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc230)
        "ttnn.deallocate"(%261) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc230)
        %263 = "ttnn.matmul"(%262, %arg352) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc623)
        "ttnn.deallocate"(%262) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc623)
        "ttnn.deallocate"(%arg352) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc623)
        %264 = "ttnn.add"(%263, %82) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc624)
        "ttnn.deallocate"(%263) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc624)
        "ttnn.deallocate"(%82) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc624)
        %265 = "ttnn.gelu"(%264) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc625)
        "ttnn.deallocate"(%264) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc625)
        %266 = "ttnn.reshape"(%265) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc231)
        "ttnn.deallocate"(%265) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc231)
        %267 = "ttnn.matmul"(%266, %arg350) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc626)
        "ttnn.deallocate"(%266) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc626)
        "ttnn.deallocate"(%arg350) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc626)
        %268 = "ttnn.add"(%267, %147) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc627)
        "ttnn.deallocate"(%267) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc627)
        "ttnn.deallocate"(%147) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc627)
        %269 = "ttnn.add"(%260, %268) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc232)
        "ttnn.deallocate"(%268) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc232)
        "ttnn.deallocate"(%260) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc232)
        %270 = "ttnn.layer_norm"(%269, %arg348, %arg347) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc233)
        "ttnn.deallocate"(%arg348) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc233)
        "ttnn.deallocate"(%arg347) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc233)
        %271 = "ttnn.reshape"(%270) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc234)
        "ttnn.deallocate"(%270) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc234)
        %272 = "ttnn.matmul"(%271, %27) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc628)
        "ttnn.deallocate"(%271) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc628)
        "ttnn.deallocate"(%27) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc628)
        %273 = "ttnn.add"(%272, %91) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc629)
        "ttnn.deallocate"(%272) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc629)
        "ttnn.deallocate"(%91) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc629)
        %274 = "ttnn.slice_static"(%273) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc630)
        %275 = "ttnn.slice_static"(%273) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc631)
        %276 = "ttnn.slice_static"(%273) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc632)
        "ttnn.deallocate"(%273) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc632)
        %277 = "ttnn.reshape"(%274) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc633)
        "ttnn.deallocate"(%274) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc633)
        %278 = "ttnn.reshape"(%275) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc634)
        "ttnn.deallocate"(%275) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc634)
        %279 = "ttnn.reshape"(%276) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc635)
        "ttnn.deallocate"(%276) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc635)
        %280 = "ttnn.permute"(%277) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc636)
        "ttnn.deallocate"(%277) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc636)
        %281 = "ttnn.permute"(%278) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc637)
        "ttnn.deallocate"(%278) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc637)
        %282 = "ttnn.permute"(%279) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc638)
        "ttnn.deallocate"(%279) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc638)
        %283 = "ttnn.pad"(%280) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc235)
        "ttnn.deallocate"(%280) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc235)
        %284 = "ttnn.pad"(%281) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc235)
        "ttnn.deallocate"(%281) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc235)
        %285 = "ttnn.pad"(%282) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc235)
        "ttnn.deallocate"(%282) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc235)
        %286 = "ttnn.scaled_dot_product_attention"(%283, %284, %285) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc235)
        "ttnn.deallocate"(%285) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc235)
        "ttnn.deallocate"(%284) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc235)
        "ttnn.deallocate"(%283) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc235)
        %287 = "ttnn.slice_static"(%286) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc235)
        "ttnn.deallocate"(%286) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc235)
        %288 = "ttnn.permute"(%287) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc639)
        "ttnn.deallocate"(%287) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc639)
        %289 = "ttnn.reshape"(%288) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc236)
        "ttnn.deallocate"(%288) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc236)
        %290 = "ttnn.matmul"(%289, %arg344) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc640)
        "ttnn.deallocate"(%289) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc640)
        "ttnn.deallocate"(%arg344) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc640)
        %291 = "ttnn.add"(%290, %133) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc641)
        "ttnn.deallocate"(%290) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc641)
        "ttnn.deallocate"(%133) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc641)
        %292 = "ttnn.add"(%269, %291) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc237)
        "ttnn.deallocate"(%291) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc237)
        "ttnn.deallocate"(%269) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc237)
        %293 = "ttnn.layer_norm"(%292, %arg342, %arg341) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc238)
        "ttnn.deallocate"(%arg342) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc238)
        "ttnn.deallocate"(%arg341) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc238)
        %294 = "ttnn.reshape"(%293) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc239)
        "ttnn.deallocate"(%293) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc239)
        %295 = "ttnn.matmul"(%294, %arg340) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc642)
        "ttnn.deallocate"(%294) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc642)
        "ttnn.deallocate"(%arg340) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc642)
        %296 = "ttnn.add"(%295, %146) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc643)
        "ttnn.deallocate"(%295) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc643)
        "ttnn.deallocate"(%146) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc643)
        %297 = "ttnn.gelu"(%296) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc644)
        "ttnn.deallocate"(%296) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc644)
        %298 = "ttnn.reshape"(%297) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc240)
        "ttnn.deallocate"(%297) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc240)
        %299 = "ttnn.matmul"(%298, %arg338) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc645)
        "ttnn.deallocate"(%298) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc645)
        "ttnn.deallocate"(%arg338) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc645)
        %300 = "ttnn.add"(%299, %11) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc646)
        "ttnn.deallocate"(%299) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc646)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc646)
        %301 = "ttnn.add"(%292, %300) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc241)
        "ttnn.deallocate"(%300) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc241)
        "ttnn.deallocate"(%292) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc241)
        %302 = "ttnn.layer_norm"(%301, %arg336, %arg335) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc242)
        "ttnn.deallocate"(%arg336) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc242)
        "ttnn.deallocate"(%arg335) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc242)
        %303 = "ttnn.reshape"(%302) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc243)
        "ttnn.deallocate"(%302) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc243)
        %304 = "ttnn.matmul"(%303, %128) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc647)
        "ttnn.deallocate"(%303) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc647)
        "ttnn.deallocate"(%128) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc647)
        %305 = "ttnn.add"(%304, %44) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc648)
        "ttnn.deallocate"(%304) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc648)
        "ttnn.deallocate"(%44) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc648)
        %306 = "ttnn.slice_static"(%305) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc649)
        %307 = "ttnn.slice_static"(%305) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc650)
        %308 = "ttnn.slice_static"(%305) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc651)
        "ttnn.deallocate"(%305) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc651)
        %309 = "ttnn.reshape"(%306) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc652)
        "ttnn.deallocate"(%306) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc652)
        %310 = "ttnn.reshape"(%307) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc653)
        "ttnn.deallocate"(%307) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc653)
        %311 = "ttnn.reshape"(%308) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc654)
        "ttnn.deallocate"(%308) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc654)
        %312 = "ttnn.permute"(%309) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc655)
        "ttnn.deallocate"(%309) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc655)
        %313 = "ttnn.permute"(%310) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc656)
        "ttnn.deallocate"(%310) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc656)
        %314 = "ttnn.permute"(%311) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc657)
        "ttnn.deallocate"(%311) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc657)
        %315 = "ttnn.pad"(%312) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc244)
        "ttnn.deallocate"(%312) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc244)
        %316 = "ttnn.pad"(%313) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc244)
        "ttnn.deallocate"(%313) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc244)
        %317 = "ttnn.pad"(%314) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc244)
        "ttnn.deallocate"(%314) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc244)
        %318 = "ttnn.scaled_dot_product_attention"(%315, %316, %317) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc244)
        "ttnn.deallocate"(%317) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc244)
        "ttnn.deallocate"(%316) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc244)
        "ttnn.deallocate"(%315) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc244)
        %319 = "ttnn.slice_static"(%318) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc244)
        "ttnn.deallocate"(%318) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc244)
        %320 = "ttnn.permute"(%319) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc658)
        "ttnn.deallocate"(%319) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc658)
        %321 = "ttnn.reshape"(%320) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc245)
        "ttnn.deallocate"(%320) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc245)
        %322 = "ttnn.matmul"(%321, %arg332) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc659)
        "ttnn.deallocate"(%321) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc659)
        "ttnn.deallocate"(%arg332) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc659)
        %323 = "ttnn.add"(%322, %98) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc660)
        "ttnn.deallocate"(%322) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc660)
        "ttnn.deallocate"(%98) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc660)
        %324 = "ttnn.add"(%301, %323) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc246)
        "ttnn.deallocate"(%323) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc246)
        "ttnn.deallocate"(%301) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc246)
        %325 = "ttnn.layer_norm"(%324, %arg330, %arg329) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc247)
        "ttnn.deallocate"(%arg330) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc247)
        "ttnn.deallocate"(%arg329) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc247)
        %326 = "ttnn.reshape"(%325) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc248)
        "ttnn.deallocate"(%325) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc248)
        %327 = "ttnn.matmul"(%326, %arg328) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc661)
        "ttnn.deallocate"(%326) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc661)
        "ttnn.deallocate"(%arg328) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc661)
        %328 = "ttnn.add"(%327, %151) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc662)
        "ttnn.deallocate"(%327) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc662)
        "ttnn.deallocate"(%151) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc662)
        %329 = "ttnn.gelu"(%328) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc663)
        "ttnn.deallocate"(%328) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc663)
        %330 = "ttnn.reshape"(%329) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc249)
        "ttnn.deallocate"(%329) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc249)
        %331 = "ttnn.matmul"(%330, %arg326) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc664)
        "ttnn.deallocate"(%330) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc664)
        "ttnn.deallocate"(%arg326) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc664)
        %332 = "ttnn.add"(%331, %150) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc665)
        "ttnn.deallocate"(%331) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc665)
        "ttnn.deallocate"(%150) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc665)
        %333 = "ttnn.add"(%324, %332) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc250)
        "ttnn.deallocate"(%332) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc250)
        "ttnn.deallocate"(%324) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc250)
        %334 = "ttnn.layer_norm"(%333, %arg324, %arg323) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc251)
        "ttnn.deallocate"(%arg324) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc251)
        "ttnn.deallocate"(%arg323) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc251)
        %335 = "ttnn.reshape"(%334) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc252)
        "ttnn.deallocate"(%334) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc252)
        %336 = "ttnn.matmul"(%335, %97) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc666)
        "ttnn.deallocate"(%335) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc666)
        "ttnn.deallocate"(%97) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc666)
        %337 = "ttnn.add"(%336, %159) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc667)
        "ttnn.deallocate"(%336) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc667)
        "ttnn.deallocate"(%159) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc667)
        %338 = "ttnn.slice_static"(%337) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc668)
        %339 = "ttnn.slice_static"(%337) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc669)
        %340 = "ttnn.slice_static"(%337) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc670)
        "ttnn.deallocate"(%337) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc670)
        %341 = "ttnn.reshape"(%338) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc671)
        "ttnn.deallocate"(%338) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc671)
        %342 = "ttnn.reshape"(%339) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc672)
        "ttnn.deallocate"(%339) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc672)
        %343 = "ttnn.reshape"(%340) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc673)
        "ttnn.deallocate"(%340) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc673)
        %344 = "ttnn.permute"(%341) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc674)
        "ttnn.deallocate"(%341) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc674)
        %345 = "ttnn.permute"(%342) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc675)
        "ttnn.deallocate"(%342) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc675)
        %346 = "ttnn.permute"(%343) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc676)
        "ttnn.deallocate"(%343) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc676)
        %347 = "ttnn.pad"(%344) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc253)
        "ttnn.deallocate"(%344) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc253)
        %348 = "ttnn.pad"(%345) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc253)
        "ttnn.deallocate"(%345) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc253)
        %349 = "ttnn.pad"(%346) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc253)
        "ttnn.deallocate"(%346) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc253)
        %350 = "ttnn.scaled_dot_product_attention"(%347, %348, %349) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc253)
        "ttnn.deallocate"(%349) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc253)
        "ttnn.deallocate"(%348) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc253)
        "ttnn.deallocate"(%347) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc253)
        %351 = "ttnn.slice_static"(%350) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc253)
        "ttnn.deallocate"(%350) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc253)
        %352 = "ttnn.permute"(%351) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc677)
        "ttnn.deallocate"(%351) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc677)
        %353 = "ttnn.reshape"(%352) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc254)
        "ttnn.deallocate"(%352) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc254)
        %354 = "ttnn.matmul"(%353, %arg320) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc678)
        "ttnn.deallocate"(%353) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc678)
        "ttnn.deallocate"(%arg320) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc678)
        %355 = "ttnn.add"(%354, %70) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc679)
        "ttnn.deallocate"(%354) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc679)
        "ttnn.deallocate"(%70) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc679)
        %356 = "ttnn.add"(%333, %355) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc255)
        "ttnn.deallocate"(%355) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc255)
        "ttnn.deallocate"(%333) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc255)
        %357 = "ttnn.layer_norm"(%356, %arg318, %arg317) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc256)
        "ttnn.deallocate"(%arg318) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc256)
        "ttnn.deallocate"(%arg317) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc256)
        %358 = "ttnn.reshape"(%357) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc257)
        "ttnn.deallocate"(%357) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc257)
        %359 = "ttnn.matmul"(%358, %arg316) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc680)
        "ttnn.deallocate"(%358) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc680)
        "ttnn.deallocate"(%arg316) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc680)
        %360 = "ttnn.add"(%359, %92) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc681)
        "ttnn.deallocate"(%359) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc681)
        "ttnn.deallocate"(%92) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc681)
        %361 = "ttnn.gelu"(%360) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc682)
        "ttnn.deallocate"(%360) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc682)
        %362 = "ttnn.reshape"(%361) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc258)
        "ttnn.deallocate"(%361) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc258)
        %363 = "ttnn.matmul"(%362, %arg314) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc683)
        "ttnn.deallocate"(%362) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc683)
        "ttnn.deallocate"(%arg314) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc683)
        %364 = "ttnn.add"(%363, %107) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc684)
        "ttnn.deallocate"(%363) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc684)
        "ttnn.deallocate"(%107) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc684)
        %365 = "ttnn.add"(%356, %364) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc259)
        "ttnn.deallocate"(%364) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc259)
        "ttnn.deallocate"(%356) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc259)
        %366 = "ttnn.layer_norm"(%365, %arg312, %arg311) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc260)
        "ttnn.deallocate"(%arg312) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc260)
        "ttnn.deallocate"(%arg311) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc260)
        %367 = "ttnn.reshape"(%366) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc261)
        "ttnn.deallocate"(%366) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc261)
        %368 = "ttnn.matmul"(%367, %129) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc685)
        "ttnn.deallocate"(%367) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc685)
        "ttnn.deallocate"(%129) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc685)
        %369 = "ttnn.add"(%368, %100) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc686)
        "ttnn.deallocate"(%368) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc686)
        "ttnn.deallocate"(%100) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc686)
        %370 = "ttnn.slice_static"(%369) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc687)
        %371 = "ttnn.slice_static"(%369) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc688)
        %372 = "ttnn.slice_static"(%369) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc689)
        "ttnn.deallocate"(%369) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc689)
        %373 = "ttnn.reshape"(%370) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc690)
        "ttnn.deallocate"(%370) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc690)
        %374 = "ttnn.reshape"(%371) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc691)
        "ttnn.deallocate"(%371) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc691)
        %375 = "ttnn.reshape"(%372) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc692)
        "ttnn.deallocate"(%372) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc692)
        %376 = "ttnn.permute"(%373) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc693)
        "ttnn.deallocate"(%373) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc693)
        %377 = "ttnn.permute"(%374) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc694)
        "ttnn.deallocate"(%374) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc694)
        %378 = "ttnn.permute"(%375) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc695)
        "ttnn.deallocate"(%375) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc695)
        %379 = "ttnn.pad"(%376) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc262)
        "ttnn.deallocate"(%376) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc262)
        %380 = "ttnn.pad"(%377) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc262)
        "ttnn.deallocate"(%377) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc262)
        %381 = "ttnn.pad"(%378) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc262)
        "ttnn.deallocate"(%378) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc262)
        %382 = "ttnn.scaled_dot_product_attention"(%379, %380, %381) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc262)
        "ttnn.deallocate"(%381) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc262)
        "ttnn.deallocate"(%380) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc262)
        "ttnn.deallocate"(%379) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc262)
        %383 = "ttnn.slice_static"(%382) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc262)
        "ttnn.deallocate"(%382) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc262)
        %384 = "ttnn.permute"(%383) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc696)
        "ttnn.deallocate"(%383) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc696)
        %385 = "ttnn.reshape"(%384) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc263)
        "ttnn.deallocate"(%384) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc263)
        %386 = "ttnn.matmul"(%385, %arg308) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc697)
        "ttnn.deallocate"(%385) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc697)
        "ttnn.deallocate"(%arg308) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc697)
        %387 = "ttnn.add"(%386, %47) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc698)
        "ttnn.deallocate"(%386) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc698)
        "ttnn.deallocate"(%47) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc698)
        %388 = "ttnn.add"(%365, %387) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc264)
        "ttnn.deallocate"(%387) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc264)
        "ttnn.deallocate"(%365) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc264)
        %389 = "ttnn.layer_norm"(%388, %arg306, %arg305) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc265)
        "ttnn.deallocate"(%arg306) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc265)
        "ttnn.deallocate"(%arg305) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc265)
        %390 = "ttnn.reshape"(%389) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc266)
        "ttnn.deallocate"(%389) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc266)
        %391 = "ttnn.matmul"(%390, %arg304) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc699)
        "ttnn.deallocate"(%390) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc699)
        "ttnn.deallocate"(%arg304) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc699)
        %392 = "ttnn.add"(%391, %54) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc700)
        "ttnn.deallocate"(%391) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc700)
        "ttnn.deallocate"(%54) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc700)
        %393 = "ttnn.gelu"(%392) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc701)
        "ttnn.deallocate"(%392) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc701)
        %394 = "ttnn.reshape"(%393) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc267)
        "ttnn.deallocate"(%393) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc267)
        %395 = "ttnn.matmul"(%394, %arg302) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc702)
        "ttnn.deallocate"(%394) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc702)
        "ttnn.deallocate"(%arg302) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc702)
        %396 = "ttnn.add"(%395, %104) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc703)
        "ttnn.deallocate"(%395) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc703)
        "ttnn.deallocate"(%104) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc703)
        %397 = "ttnn.add"(%388, %396) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc268)
        "ttnn.deallocate"(%396) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc268)
        "ttnn.deallocate"(%388) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc268)
        %398 = "ttnn.layer_norm"(%397, %arg300, %arg299) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc269)
        "ttnn.deallocate"(%arg300) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc269)
        "ttnn.deallocate"(%arg299) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc269)
        %399 = "ttnn.reshape"(%398) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc270)
        "ttnn.deallocate"(%398) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc270)
        %400 = "ttnn.matmul"(%399, %50) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc704)
        "ttnn.deallocate"(%399) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc704)
        "ttnn.deallocate"(%50) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc704)
        %401 = "ttnn.add"(%400, %85) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc705)
        "ttnn.deallocate"(%400) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc705)
        "ttnn.deallocate"(%85) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc705)
        %402 = "ttnn.slice_static"(%401) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc706)
        %403 = "ttnn.slice_static"(%401) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc707)
        %404 = "ttnn.slice_static"(%401) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc708)
        "ttnn.deallocate"(%401) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc708)
        %405 = "ttnn.reshape"(%402) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc709)
        "ttnn.deallocate"(%402) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc709)
        %406 = "ttnn.reshape"(%403) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc710)
        "ttnn.deallocate"(%403) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc710)
        %407 = "ttnn.reshape"(%404) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc711)
        "ttnn.deallocate"(%404) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc711)
        %408 = "ttnn.permute"(%405) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc712)
        "ttnn.deallocate"(%405) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc712)
        %409 = "ttnn.permute"(%406) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc713)
        "ttnn.deallocate"(%406) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc713)
        %410 = "ttnn.permute"(%407) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc714)
        "ttnn.deallocate"(%407) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc714)
        %411 = "ttnn.pad"(%408) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc271)
        "ttnn.deallocate"(%408) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc271)
        %412 = "ttnn.pad"(%409) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc271)
        "ttnn.deallocate"(%409) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc271)
        %413 = "ttnn.pad"(%410) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc271)
        "ttnn.deallocate"(%410) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc271)
        %414 = "ttnn.scaled_dot_product_attention"(%411, %412, %413) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc271)
        "ttnn.deallocate"(%413) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc271)
        "ttnn.deallocate"(%412) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc271)
        "ttnn.deallocate"(%411) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc271)
        %415 = "ttnn.slice_static"(%414) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc271)
        "ttnn.deallocate"(%414) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc271)
        %416 = "ttnn.permute"(%415) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc715)
        "ttnn.deallocate"(%415) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc715)
        %417 = "ttnn.reshape"(%416) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc272)
        "ttnn.deallocate"(%416) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc272)
        %418 = "ttnn.matmul"(%417, %arg296) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc716)
        "ttnn.deallocate"(%417) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc716)
        "ttnn.deallocate"(%arg296) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc716)
        %419 = "ttnn.add"(%418, %121) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc717)
        "ttnn.deallocate"(%418) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc717)
        "ttnn.deallocate"(%121) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc717)
        %420 = "ttnn.add"(%397, %419) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc273)
        "ttnn.deallocate"(%419) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc273)
        "ttnn.deallocate"(%397) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc273)
        %421 = "ttnn.layer_norm"(%420, %arg294, %arg293) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc274)
        "ttnn.deallocate"(%arg294) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc274)
        "ttnn.deallocate"(%arg293) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc274)
        %422 = "ttnn.reshape"(%421) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc275)
        "ttnn.deallocate"(%421) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc275)
        %423 = "ttnn.matmul"(%422, %arg292) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc718)
        "ttnn.deallocate"(%422) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc718)
        "ttnn.deallocate"(%arg292) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc718)
        %424 = "ttnn.add"(%423, %28) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc719)
        "ttnn.deallocate"(%423) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc719)
        "ttnn.deallocate"(%28) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc719)
        %425 = "ttnn.gelu"(%424) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc720)
        "ttnn.deallocate"(%424) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc720)
        %426 = "ttnn.reshape"(%425) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc276)
        "ttnn.deallocate"(%425) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc276)
        %427 = "ttnn.matmul"(%426, %arg290) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc721)
        "ttnn.deallocate"(%426) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc721)
        "ttnn.deallocate"(%arg290) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc721)
        %428 = "ttnn.add"(%427, %154) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc722)
        "ttnn.deallocate"(%427) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc722)
        "ttnn.deallocate"(%154) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc722)
        %429 = "ttnn.add"(%420, %428) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc277)
        "ttnn.deallocate"(%428) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc277)
        "ttnn.deallocate"(%420) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc277)
        %430 = "ttnn.layer_norm"(%429, %arg288, %arg287) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc278)
        "ttnn.deallocate"(%arg288) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc278)
        "ttnn.deallocate"(%arg287) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc278)
        %431 = "ttnn.reshape"(%430) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc279)
        "ttnn.deallocate"(%430) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc279)
        %432 = "ttnn.matmul"(%431, %30) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc723)
        "ttnn.deallocate"(%431) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc723)
        "ttnn.deallocate"(%30) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc723)
        %433 = "ttnn.add"(%432, %41) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc724)
        "ttnn.deallocate"(%432) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc724)
        "ttnn.deallocate"(%41) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc724)
        %434 = "ttnn.slice_static"(%433) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc725)
        %435 = "ttnn.slice_static"(%433) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc726)
        %436 = "ttnn.slice_static"(%433) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc727)
        "ttnn.deallocate"(%433) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc727)
        %437 = "ttnn.reshape"(%434) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc728)
        "ttnn.deallocate"(%434) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc728)
        %438 = "ttnn.reshape"(%435) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc729)
        "ttnn.deallocate"(%435) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc729)
        %439 = "ttnn.reshape"(%436) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc730)
        "ttnn.deallocate"(%436) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc730)
        %440 = "ttnn.permute"(%437) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc731)
        "ttnn.deallocate"(%437) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc731)
        %441 = "ttnn.permute"(%438) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc732)
        "ttnn.deallocate"(%438) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc732)
        %442 = "ttnn.permute"(%439) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc733)
        "ttnn.deallocate"(%439) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc733)
        %443 = "ttnn.pad"(%440) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc280)
        "ttnn.deallocate"(%440) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc280)
        %444 = "ttnn.pad"(%441) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc280)
        "ttnn.deallocate"(%441) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc280)
        %445 = "ttnn.pad"(%442) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc280)
        "ttnn.deallocate"(%442) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc280)
        %446 = "ttnn.scaled_dot_product_attention"(%443, %444, %445) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc280)
        "ttnn.deallocate"(%445) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc280)
        "ttnn.deallocate"(%444) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc280)
        "ttnn.deallocate"(%443) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc280)
        %447 = "ttnn.slice_static"(%446) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc280)
        "ttnn.deallocate"(%446) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc280)
        %448 = "ttnn.permute"(%447) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc734)
        "ttnn.deallocate"(%447) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc734)
        %449 = "ttnn.reshape"(%448) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc281)
        "ttnn.deallocate"(%448) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc281)
        %450 = "ttnn.matmul"(%449, %arg284) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc735)
        "ttnn.deallocate"(%449) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc735)
        "ttnn.deallocate"(%arg284) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc735)
        %451 = "ttnn.add"(%450, %75) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc736)
        "ttnn.deallocate"(%450) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc736)
        "ttnn.deallocate"(%75) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc736)
        %452 = "ttnn.add"(%429, %451) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc282)
        "ttnn.deallocate"(%451) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc282)
        "ttnn.deallocate"(%429) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc282)
        %453 = "ttnn.layer_norm"(%452, %arg282, %arg281) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc283)
        "ttnn.deallocate"(%arg282) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc283)
        "ttnn.deallocate"(%arg281) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc283)
        %454 = "ttnn.reshape"(%453) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc284)
        "ttnn.deallocate"(%453) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc284)
        %455 = "ttnn.matmul"(%454, %arg280) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc737)
        "ttnn.deallocate"(%454) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc737)
        "ttnn.deallocate"(%arg280) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc737)
        %456 = "ttnn.add"(%455, %25) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc738)
        "ttnn.deallocate"(%455) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc738)
        "ttnn.deallocate"(%25) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc738)
        %457 = "ttnn.gelu"(%456) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc739)
        "ttnn.deallocate"(%456) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc739)
        %458 = "ttnn.reshape"(%457) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc285)
        "ttnn.deallocate"(%457) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc285)
        %459 = "ttnn.matmul"(%458, %arg278) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc740)
        "ttnn.deallocate"(%458) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc740)
        "ttnn.deallocate"(%arg278) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc740)
        %460 = "ttnn.add"(%459, %94) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc741)
        "ttnn.deallocate"(%459) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc741)
        "ttnn.deallocate"(%94) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc741)
        %461 = "ttnn.add"(%452, %460) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc286)
        "ttnn.deallocate"(%460) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc286)
        "ttnn.deallocate"(%452) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc286)
        %462 = "ttnn.layer_norm"(%461, %arg276, %arg275) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc287)
        "ttnn.deallocate"(%arg276) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc287)
        "ttnn.deallocate"(%arg275) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc287)
        %463 = "ttnn.reshape"(%462) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc288)
        "ttnn.deallocate"(%462) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc288)
        %464 = "ttnn.matmul"(%463, %120) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc742)
        "ttnn.deallocate"(%463) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc742)
        "ttnn.deallocate"(%120) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc742)
        %465 = "ttnn.add"(%464, %134) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc743)
        "ttnn.deallocate"(%464) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc743)
        "ttnn.deallocate"(%134) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc743)
        %466 = "ttnn.slice_static"(%465) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc744)
        %467 = "ttnn.slice_static"(%465) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc745)
        %468 = "ttnn.slice_static"(%465) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc746)
        "ttnn.deallocate"(%465) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc746)
        %469 = "ttnn.reshape"(%466) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc747)
        "ttnn.deallocate"(%466) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc747)
        %470 = "ttnn.reshape"(%467) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc748)
        "ttnn.deallocate"(%467) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc748)
        %471 = "ttnn.reshape"(%468) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc749)
        "ttnn.deallocate"(%468) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc749)
        %472 = "ttnn.permute"(%469) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc750)
        "ttnn.deallocate"(%469) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc750)
        %473 = "ttnn.permute"(%470) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc751)
        "ttnn.deallocate"(%470) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc751)
        %474 = "ttnn.permute"(%471) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc752)
        "ttnn.deallocate"(%471) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc752)
        %475 = "ttnn.pad"(%472) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc289)
        "ttnn.deallocate"(%472) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc289)
        %476 = "ttnn.pad"(%473) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc289)
        "ttnn.deallocate"(%473) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc289)
        %477 = "ttnn.pad"(%474) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc289)
        "ttnn.deallocate"(%474) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc289)
        %478 = "ttnn.scaled_dot_product_attention"(%475, %476, %477) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc289)
        "ttnn.deallocate"(%477) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc289)
        "ttnn.deallocate"(%476) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc289)
        "ttnn.deallocate"(%475) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc289)
        %479 = "ttnn.slice_static"(%478) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc289)
        "ttnn.deallocate"(%478) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc289)
        %480 = "ttnn.permute"(%479) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc753)
        "ttnn.deallocate"(%479) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc753)
        %481 = "ttnn.reshape"(%480) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc290)
        "ttnn.deallocate"(%480) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc290)
        %482 = "ttnn.matmul"(%481, %arg272) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc754)
        "ttnn.deallocate"(%481) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc754)
        "ttnn.deallocate"(%arg272) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc754)
        %483 = "ttnn.add"(%482, %114) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc755)
        "ttnn.deallocate"(%482) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc755)
        "ttnn.deallocate"(%114) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc755)
        %484 = "ttnn.add"(%461, %483) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc291)
        "ttnn.deallocate"(%483) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc291)
        "ttnn.deallocate"(%461) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc291)
        %485 = "ttnn.layer_norm"(%484, %arg270, %arg269) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc292)
        "ttnn.deallocate"(%arg270) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc292)
        "ttnn.deallocate"(%arg269) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc292)
        %486 = "ttnn.reshape"(%485) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc293)
        "ttnn.deallocate"(%485) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc293)
        %487 = "ttnn.matmul"(%486, %arg268) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc756)
        "ttnn.deallocate"(%486) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc756)
        "ttnn.deallocate"(%arg268) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc756)
        %488 = "ttnn.add"(%487, %156) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc757)
        "ttnn.deallocate"(%487) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc757)
        "ttnn.deallocate"(%156) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc757)
        %489 = "ttnn.gelu"(%488) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc758)
        "ttnn.deallocate"(%488) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc758)
        %490 = "ttnn.reshape"(%489) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc294)
        "ttnn.deallocate"(%489) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc294)
        %491 = "ttnn.matmul"(%490, %arg266) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc759)
        "ttnn.deallocate"(%490) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc759)
        "ttnn.deallocate"(%arg266) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc759)
        %492 = "ttnn.add"(%491, %3) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc760)
        "ttnn.deallocate"(%491) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc760)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc760)
        %493 = "ttnn.add"(%484, %492) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc295)
        "ttnn.deallocate"(%492) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc295)
        "ttnn.deallocate"(%484) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc295)
        %494 = "ttnn.layer_norm"(%493, %arg264, %arg263) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc296)
        "ttnn.deallocate"(%arg264) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc296)
        "ttnn.deallocate"(%arg263) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc296)
        %495 = "ttnn.reshape"(%494) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc297)
        "ttnn.deallocate"(%494) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc297)
        %496 = "ttnn.matmul"(%495, %153) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc761)
        "ttnn.deallocate"(%495) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc761)
        "ttnn.deallocate"(%153) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc761)
        %497 = "ttnn.add"(%496, %72) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc762)
        "ttnn.deallocate"(%496) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc762)
        "ttnn.deallocate"(%72) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc762)
        %498 = "ttnn.slice_static"(%497) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc763)
        %499 = "ttnn.slice_static"(%497) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc764)
        %500 = "ttnn.slice_static"(%497) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc765)
        "ttnn.deallocate"(%497) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc765)
        %501 = "ttnn.reshape"(%498) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc766)
        "ttnn.deallocate"(%498) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc766)
        %502 = "ttnn.reshape"(%499) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc767)
        "ttnn.deallocate"(%499) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc767)
        %503 = "ttnn.reshape"(%500) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc768)
        "ttnn.deallocate"(%500) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc768)
        %504 = "ttnn.permute"(%501) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc769)
        "ttnn.deallocate"(%501) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc769)
        %505 = "ttnn.permute"(%502) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc770)
        "ttnn.deallocate"(%502) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc770)
        %506 = "ttnn.permute"(%503) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc771)
        "ttnn.deallocate"(%503) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc771)
        %507 = "ttnn.pad"(%504) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc298)
        "ttnn.deallocate"(%504) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc298)
        %508 = "ttnn.pad"(%505) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc298)
        "ttnn.deallocate"(%505) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc298)
        %509 = "ttnn.pad"(%506) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc298)
        "ttnn.deallocate"(%506) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc298)
        %510 = "ttnn.scaled_dot_product_attention"(%507, %508, %509) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc298)
        "ttnn.deallocate"(%509) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc298)
        "ttnn.deallocate"(%508) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc298)
        "ttnn.deallocate"(%507) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc298)
        %511 = "ttnn.slice_static"(%510) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc298)
        "ttnn.deallocate"(%510) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc298)
        %512 = "ttnn.permute"(%511) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc772)
        "ttnn.deallocate"(%511) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc772)
        %513 = "ttnn.reshape"(%512) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc299)
        "ttnn.deallocate"(%512) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc299)
        %514 = "ttnn.matmul"(%513, %arg260) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc773)
        "ttnn.deallocate"(%513) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc773)
        "ttnn.deallocate"(%arg260) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc773)
        %515 = "ttnn.add"(%514, %65) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc774)
        "ttnn.deallocate"(%514) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc774)
        "ttnn.deallocate"(%65) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc774)
        %516 = "ttnn.add"(%493, %515) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc300)
        "ttnn.deallocate"(%515) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc300)
        "ttnn.deallocate"(%493) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc300)
        %517 = "ttnn.layer_norm"(%516, %arg258, %arg257) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc301)
        "ttnn.deallocate"(%arg258) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc301)
        "ttnn.deallocate"(%arg257) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc301)
        %518 = "ttnn.reshape"(%517) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc302)
        "ttnn.deallocate"(%517) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc302)
        %519 = "ttnn.matmul"(%518, %arg256) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc775)
        "ttnn.deallocate"(%518) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc775)
        "ttnn.deallocate"(%arg256) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc775)
        %520 = "ttnn.add"(%519, %96) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc776)
        "ttnn.deallocate"(%519) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc776)
        "ttnn.deallocate"(%96) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc776)
        %521 = "ttnn.gelu"(%520) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc777)
        "ttnn.deallocate"(%520) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc777)
        %522 = "ttnn.reshape"(%521) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc303)
        "ttnn.deallocate"(%521) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc303)
        %523 = "ttnn.matmul"(%522, %arg254) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc778)
        "ttnn.deallocate"(%522) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc778)
        "ttnn.deallocate"(%arg254) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc778)
        %524 = "ttnn.add"(%523, %86) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc779)
        "ttnn.deallocate"(%523) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc779)
        "ttnn.deallocate"(%86) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc779)
        %525 = "ttnn.add"(%516, %524) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc304)
        "ttnn.deallocate"(%524) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc304)
        "ttnn.deallocate"(%516) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc304)
        %526 = "ttnn.layer_norm"(%525, %arg252, %arg251) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc305)
        "ttnn.deallocate"(%arg252) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc305)
        "ttnn.deallocate"(%arg251) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc305)
        %527 = "ttnn.reshape"(%526) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc306)
        "ttnn.deallocate"(%526) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc306)
        %528 = "ttnn.matmul"(%527, %68) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc780)
        "ttnn.deallocate"(%527) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc780)
        "ttnn.deallocate"(%68) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc780)
        %529 = "ttnn.add"(%528, %117) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc781)
        "ttnn.deallocate"(%528) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc781)
        "ttnn.deallocate"(%117) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc781)
        %530 = "ttnn.slice_static"(%529) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc782)
        %531 = "ttnn.slice_static"(%529) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc783)
        %532 = "ttnn.slice_static"(%529) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc784)
        "ttnn.deallocate"(%529) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc784)
        %533 = "ttnn.reshape"(%530) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc785)
        "ttnn.deallocate"(%530) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc785)
        %534 = "ttnn.reshape"(%531) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc786)
        "ttnn.deallocate"(%531) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc786)
        %535 = "ttnn.reshape"(%532) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc787)
        "ttnn.deallocate"(%532) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc787)
        %536 = "ttnn.permute"(%533) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc788)
        "ttnn.deallocate"(%533) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc788)
        %537 = "ttnn.permute"(%534) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc789)
        "ttnn.deallocate"(%534) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc789)
        %538 = "ttnn.permute"(%535) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc790)
        "ttnn.deallocate"(%535) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc790)
        %539 = "ttnn.pad"(%536) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc307)
        "ttnn.deallocate"(%536) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc307)
        %540 = "ttnn.pad"(%537) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc307)
        "ttnn.deallocate"(%537) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc307)
        %541 = "ttnn.pad"(%538) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc307)
        "ttnn.deallocate"(%538) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc307)
        %542 = "ttnn.scaled_dot_product_attention"(%539, %540, %541) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc307)
        "ttnn.deallocate"(%541) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc307)
        "ttnn.deallocate"(%540) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc307)
        "ttnn.deallocate"(%539) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc307)
        %543 = "ttnn.slice_static"(%542) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc307)
        "ttnn.deallocate"(%542) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc307)
        %544 = "ttnn.permute"(%543) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc791)
        "ttnn.deallocate"(%543) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc791)
        %545 = "ttnn.reshape"(%544) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc308)
        "ttnn.deallocate"(%544) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc308)
        %546 = "ttnn.matmul"(%545, %arg248) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc792)
        "ttnn.deallocate"(%545) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc792)
        "ttnn.deallocate"(%arg248) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc792)
        %547 = "ttnn.add"(%546, %141) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc793)
        "ttnn.deallocate"(%546) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc793)
        "ttnn.deallocate"(%141) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc793)
        %548 = "ttnn.add"(%525, %547) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc309)
        "ttnn.deallocate"(%547) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc309)
        "ttnn.deallocate"(%525) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc309)
        %549 = "ttnn.layer_norm"(%548, %arg246, %arg245) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc310)
        "ttnn.deallocate"(%arg246) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc310)
        "ttnn.deallocate"(%arg245) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc310)
        %550 = "ttnn.reshape"(%549) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc311)
        "ttnn.deallocate"(%549) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc311)
        %551 = "ttnn.matmul"(%550, %arg244) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc794)
        "ttnn.deallocate"(%550) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc794)
        "ttnn.deallocate"(%arg244) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc794)
        %552 = "ttnn.add"(%551, %157) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc795)
        "ttnn.deallocate"(%551) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc795)
        "ttnn.deallocate"(%157) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc795)
        %553 = "ttnn.gelu"(%552) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc796)
        "ttnn.deallocate"(%552) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc796)
        %554 = "ttnn.reshape"(%553) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc312)
        "ttnn.deallocate"(%553) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc312)
        %555 = "ttnn.matmul"(%554, %arg242) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc797)
        "ttnn.deallocate"(%554) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc797)
        "ttnn.deallocate"(%arg242) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc797)
        %556 = "ttnn.add"(%555, %152) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc798)
        "ttnn.deallocate"(%555) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc798)
        "ttnn.deallocate"(%152) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc798)
        %557 = "ttnn.add"(%548, %556) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc313)
        "ttnn.deallocate"(%556) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc313)
        "ttnn.deallocate"(%548) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc313)
        %558 = "ttnn.layer_norm"(%557, %arg240, %arg239) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc314)
        "ttnn.deallocate"(%arg240) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc314)
        "ttnn.deallocate"(%arg239) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc314)
        %559 = "ttnn.reshape"(%558) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc315)
        "ttnn.deallocate"(%558) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc315)
        %560 = "ttnn.matmul"(%559, %88) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc799)
        "ttnn.deallocate"(%559) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc799)
        "ttnn.deallocate"(%88) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc799)
        %561 = "ttnn.add"(%560, %137) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc800)
        "ttnn.deallocate"(%560) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc800)
        "ttnn.deallocate"(%137) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc800)
        %562 = "ttnn.slice_static"(%561) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc801)
        %563 = "ttnn.slice_static"(%561) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc802)
        %564 = "ttnn.slice_static"(%561) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc803)
        "ttnn.deallocate"(%561) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc803)
        %565 = "ttnn.reshape"(%562) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc804)
        "ttnn.deallocate"(%562) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc804)
        %566 = "ttnn.reshape"(%563) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc805)
        "ttnn.deallocate"(%563) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc805)
        %567 = "ttnn.reshape"(%564) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc806)
        "ttnn.deallocate"(%564) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc806)
        %568 = "ttnn.permute"(%565) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc807)
        "ttnn.deallocate"(%565) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc807)
        %569 = "ttnn.permute"(%566) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc808)
        "ttnn.deallocate"(%566) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc808)
        %570 = "ttnn.permute"(%567) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc809)
        "ttnn.deallocate"(%567) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc809)
        %571 = "ttnn.pad"(%568) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc316)
        "ttnn.deallocate"(%568) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc316)
        %572 = "ttnn.pad"(%569) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc316)
        "ttnn.deallocate"(%569) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc316)
        %573 = "ttnn.pad"(%570) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc316)
        "ttnn.deallocate"(%570) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc316)
        %574 = "ttnn.scaled_dot_product_attention"(%571, %572, %573) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc316)
        "ttnn.deallocate"(%573) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc316)
        "ttnn.deallocate"(%572) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc316)
        "ttnn.deallocate"(%571) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc316)
        %575 = "ttnn.slice_static"(%574) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc316)
        "ttnn.deallocate"(%574) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc316)
        %576 = "ttnn.permute"(%575) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc810)
        "ttnn.deallocate"(%575) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc810)
        %577 = "ttnn.reshape"(%576) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc317)
        "ttnn.deallocate"(%576) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc317)
        %578 = "ttnn.matmul"(%577, %arg236) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc811)
        "ttnn.deallocate"(%577) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc811)
        "ttnn.deallocate"(%arg236) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc811)
        %579 = "ttnn.add"(%578, %69) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc812)
        "ttnn.deallocate"(%578) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc812)
        "ttnn.deallocate"(%69) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc812)
        %580 = "ttnn.add"(%557, %579) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc318)
        "ttnn.deallocate"(%579) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc318)
        "ttnn.deallocate"(%557) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc318)
        %581 = "ttnn.layer_norm"(%580, %arg234, %arg233) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc319)
        "ttnn.deallocate"(%arg234) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc319)
        "ttnn.deallocate"(%arg233) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc319)
        %582 = "ttnn.reshape"(%581) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc320)
        "ttnn.deallocate"(%581) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc320)
        %583 = "ttnn.matmul"(%582, %arg232) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc813)
        "ttnn.deallocate"(%582) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc813)
        "ttnn.deallocate"(%arg232) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc813)
        %584 = "ttnn.add"(%583, %6) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc814)
        "ttnn.deallocate"(%583) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc814)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc814)
        %585 = "ttnn.gelu"(%584) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc815)
        "ttnn.deallocate"(%584) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc815)
        %586 = "ttnn.reshape"(%585) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc321)
        "ttnn.deallocate"(%585) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc321)
        %587 = "ttnn.matmul"(%586, %arg230) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc816)
        "ttnn.deallocate"(%586) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc816)
        "ttnn.deallocate"(%arg230) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc816)
        %588 = "ttnn.add"(%587, %16) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc817)
        "ttnn.deallocate"(%587) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc817)
        "ttnn.deallocate"(%16) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc817)
        %589 = "ttnn.add"(%580, %588) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc322)
        "ttnn.deallocate"(%588) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc322)
        "ttnn.deallocate"(%580) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc322)
        %590 = "ttnn.layer_norm"(%589, %arg228, %arg227) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc323)
        "ttnn.deallocate"(%arg228) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc323)
        "ttnn.deallocate"(%arg227) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc323)
        %591 = "ttnn.reshape"(%590) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc324)
        "ttnn.deallocate"(%590) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc324)
        %592 = "ttnn.matmul"(%591, %103) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc818)
        "ttnn.deallocate"(%591) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc818)
        "ttnn.deallocate"(%103) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc818)
        %593 = "ttnn.add"(%592, %2) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc819)
        "ttnn.deallocate"(%592) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc819)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc819)
        %594 = "ttnn.slice_static"(%593) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc820)
        %595 = "ttnn.slice_static"(%593) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc821)
        %596 = "ttnn.slice_static"(%593) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc822)
        "ttnn.deallocate"(%593) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc822)
        %597 = "ttnn.reshape"(%594) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc823)
        "ttnn.deallocate"(%594) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc823)
        %598 = "ttnn.reshape"(%595) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc824)
        "ttnn.deallocate"(%595) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc824)
        %599 = "ttnn.reshape"(%596) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc825)
        "ttnn.deallocate"(%596) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc825)
        %600 = "ttnn.permute"(%597) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc826)
        "ttnn.deallocate"(%597) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc826)
        %601 = "ttnn.permute"(%598) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc827)
        "ttnn.deallocate"(%598) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc827)
        %602 = "ttnn.permute"(%599) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc828)
        "ttnn.deallocate"(%599) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc828)
        %603 = "ttnn.pad"(%600) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc325)
        "ttnn.deallocate"(%600) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc325)
        %604 = "ttnn.pad"(%601) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc325)
        "ttnn.deallocate"(%601) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc325)
        %605 = "ttnn.pad"(%602) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc325)
        "ttnn.deallocate"(%602) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc325)
        %606 = "ttnn.scaled_dot_product_attention"(%603, %604, %605) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc325)
        "ttnn.deallocate"(%605) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc325)
        "ttnn.deallocate"(%604) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc325)
        "ttnn.deallocate"(%603) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc325)
        %607 = "ttnn.slice_static"(%606) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc325)
        "ttnn.deallocate"(%606) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc325)
        %608 = "ttnn.permute"(%607) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc829)
        "ttnn.deallocate"(%607) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc829)
        %609 = "ttnn.reshape"(%608) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc326)
        "ttnn.deallocate"(%608) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc326)
        %610 = "ttnn.matmul"(%609, %arg224) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc830)
        "ttnn.deallocate"(%609) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc830)
        "ttnn.deallocate"(%arg224) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc830)
        %611 = "ttnn.add"(%610, %127) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc831)
        "ttnn.deallocate"(%610) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc831)
        "ttnn.deallocate"(%127) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc831)
        %612 = "ttnn.add"(%589, %611) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc327)
        "ttnn.deallocate"(%611) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc327)
        "ttnn.deallocate"(%589) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc327)
        %613 = "ttnn.layer_norm"(%612, %arg222, %arg221) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc328)
        "ttnn.deallocate"(%arg222) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc328)
        "ttnn.deallocate"(%arg221) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc328)
        %614 = "ttnn.reshape"(%613) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc329)
        "ttnn.deallocate"(%613) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc329)
        %615 = "ttnn.matmul"(%614, %arg220) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc832)
        "ttnn.deallocate"(%614) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc832)
        "ttnn.deallocate"(%arg220) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc832)
        %616 = "ttnn.add"(%615, %93) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc833)
        "ttnn.deallocate"(%615) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc833)
        "ttnn.deallocate"(%93) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc833)
        %617 = "ttnn.gelu"(%616) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc834)
        "ttnn.deallocate"(%616) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc834)
        %618 = "ttnn.reshape"(%617) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc330)
        "ttnn.deallocate"(%617) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc330)
        %619 = "ttnn.matmul"(%618, %arg218) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc835)
        "ttnn.deallocate"(%618) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc835)
        "ttnn.deallocate"(%arg218) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc835)
        %620 = "ttnn.add"(%619, %110) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc836)
        "ttnn.deallocate"(%619) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc836)
        "ttnn.deallocate"(%110) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc836)
        %621 = "ttnn.add"(%612, %620) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc331)
        "ttnn.deallocate"(%620) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc331)
        "ttnn.deallocate"(%612) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc331)
        %622 = "ttnn.layer_norm"(%621, %arg216, %arg215) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc332)
        "ttnn.deallocate"(%arg216) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc332)
        "ttnn.deallocate"(%arg215) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc332)
        %623 = "ttnn.reshape"(%622) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc333)
        "ttnn.deallocate"(%622) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc333)
        %624 = "ttnn.matmul"(%623, %87) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc837)
        "ttnn.deallocate"(%623) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc837)
        "ttnn.deallocate"(%87) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc837)
        %625 = "ttnn.add"(%624, %102) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc838)
        "ttnn.deallocate"(%624) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc838)
        "ttnn.deallocate"(%102) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc838)
        %626 = "ttnn.slice_static"(%625) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc839)
        %627 = "ttnn.slice_static"(%625) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc840)
        %628 = "ttnn.slice_static"(%625) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc841)
        "ttnn.deallocate"(%625) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc841)
        %629 = "ttnn.reshape"(%626) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc842)
        "ttnn.deallocate"(%626) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc842)
        %630 = "ttnn.reshape"(%627) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc843)
        "ttnn.deallocate"(%627) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc843)
        %631 = "ttnn.reshape"(%628) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc844)
        "ttnn.deallocate"(%628) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc844)
        %632 = "ttnn.permute"(%629) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc845)
        "ttnn.deallocate"(%629) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc845)
        %633 = "ttnn.permute"(%630) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc846)
        "ttnn.deallocate"(%630) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc846)
        %634 = "ttnn.permute"(%631) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc847)
        "ttnn.deallocate"(%631) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc847)
        %635 = "ttnn.pad"(%632) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc334)
        "ttnn.deallocate"(%632) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc334)
        %636 = "ttnn.pad"(%633) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc334)
        "ttnn.deallocate"(%633) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc334)
        %637 = "ttnn.pad"(%634) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc334)
        "ttnn.deallocate"(%634) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc334)
        %638 = "ttnn.scaled_dot_product_attention"(%635, %636, %637) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc334)
        "ttnn.deallocate"(%637) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc334)
        "ttnn.deallocate"(%636) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc334)
        "ttnn.deallocate"(%635) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc334)
        %639 = "ttnn.slice_static"(%638) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc334)
        "ttnn.deallocate"(%638) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc334)
        %640 = "ttnn.permute"(%639) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc848)
        "ttnn.deallocate"(%639) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc848)
        %641 = "ttnn.reshape"(%640) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc335)
        "ttnn.deallocate"(%640) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc335)
        %642 = "ttnn.matmul"(%641, %arg212) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc849)
        "ttnn.deallocate"(%641) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc849)
        "ttnn.deallocate"(%arg212) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc849)
        %643 = "ttnn.add"(%642, %12) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc850)
        "ttnn.deallocate"(%642) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc850)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc850)
        %644 = "ttnn.add"(%621, %643) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc336)
        "ttnn.deallocate"(%643) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc336)
        "ttnn.deallocate"(%621) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc336)
        %645 = "ttnn.layer_norm"(%644, %arg210, %arg209) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc337)
        "ttnn.deallocate"(%arg210) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc337)
        "ttnn.deallocate"(%arg209) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc337)
        %646 = "ttnn.reshape"(%645) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc338)
        "ttnn.deallocate"(%645) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc338)
        %647 = "ttnn.matmul"(%646, %arg208) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc851)
        "ttnn.deallocate"(%646) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc851)
        "ttnn.deallocate"(%arg208) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc851)
        %648 = "ttnn.add"(%647, %142) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc852)
        "ttnn.deallocate"(%647) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc852)
        "ttnn.deallocate"(%142) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc852)
        %649 = "ttnn.gelu"(%648) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc853)
        "ttnn.deallocate"(%648) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc853)
        %650 = "ttnn.reshape"(%649) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc339)
        "ttnn.deallocate"(%649) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc339)
        %651 = "ttnn.matmul"(%650, %arg206) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc854)
        "ttnn.deallocate"(%650) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc854)
        "ttnn.deallocate"(%arg206) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc854)
        %652 = "ttnn.add"(%651, %19) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc855)
        "ttnn.deallocate"(%651) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc855)
        "ttnn.deallocate"(%19) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc855)
        %653 = "ttnn.add"(%644, %652) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc340)
        "ttnn.deallocate"(%652) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc340)
        "ttnn.deallocate"(%644) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc340)
        %654 = "ttnn.layer_norm"(%653, %arg204, %arg203) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc341)
        "ttnn.deallocate"(%arg204) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc341)
        "ttnn.deallocate"(%arg203) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc341)
        %655 = "ttnn.reshape"(%654) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc342)
        "ttnn.deallocate"(%654) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc342)
        %656 = "ttnn.matmul"(%655, %24) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc856)
        "ttnn.deallocate"(%655) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc856)
        "ttnn.deallocate"(%24) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc856)
        %657 = "ttnn.add"(%656, %73) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc857)
        "ttnn.deallocate"(%656) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc857)
        "ttnn.deallocate"(%73) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc857)
        %658 = "ttnn.slice_static"(%657) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc858)
        %659 = "ttnn.slice_static"(%657) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc859)
        %660 = "ttnn.slice_static"(%657) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc860)
        "ttnn.deallocate"(%657) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc860)
        %661 = "ttnn.reshape"(%658) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc861)
        "ttnn.deallocate"(%658) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc861)
        %662 = "ttnn.reshape"(%659) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc862)
        "ttnn.deallocate"(%659) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc862)
        %663 = "ttnn.reshape"(%660) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc863)
        "ttnn.deallocate"(%660) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc863)
        %664 = "ttnn.permute"(%661) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc864)
        "ttnn.deallocate"(%661) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc864)
        %665 = "ttnn.permute"(%662) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc865)
        "ttnn.deallocate"(%662) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc865)
        %666 = "ttnn.permute"(%663) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc866)
        "ttnn.deallocate"(%663) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc866)
        %667 = "ttnn.pad"(%664) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc343)
        "ttnn.deallocate"(%664) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc343)
        %668 = "ttnn.pad"(%665) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc343)
        "ttnn.deallocate"(%665) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc343)
        %669 = "ttnn.pad"(%666) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc343)
        "ttnn.deallocate"(%666) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc343)
        %670 = "ttnn.scaled_dot_product_attention"(%667, %668, %669) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc343)
        "ttnn.deallocate"(%669) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc343)
        "ttnn.deallocate"(%668) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc343)
        "ttnn.deallocate"(%667) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc343)
        %671 = "ttnn.slice_static"(%670) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc343)
        "ttnn.deallocate"(%670) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc343)
        %672 = "ttnn.permute"(%671) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc867)
        "ttnn.deallocate"(%671) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc867)
        %673 = "ttnn.reshape"(%672) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc344)
        "ttnn.deallocate"(%672) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc344)
        %674 = "ttnn.matmul"(%673, %arg200) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc868)
        "ttnn.deallocate"(%673) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc868)
        "ttnn.deallocate"(%arg200) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc868)
        %675 = "ttnn.add"(%674, %115) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc869)
        "ttnn.deallocate"(%674) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc869)
        "ttnn.deallocate"(%115) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc869)
        %676 = "ttnn.add"(%653, %675) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc345)
        "ttnn.deallocate"(%675) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc345)
        "ttnn.deallocate"(%653) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc345)
        %677 = "ttnn.layer_norm"(%676, %arg198, %arg197) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc346)
        "ttnn.deallocate"(%arg198) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc346)
        "ttnn.deallocate"(%arg197) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc346)
        %678 = "ttnn.reshape"(%677) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc347)
        "ttnn.deallocate"(%677) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc347)
        %679 = "ttnn.matmul"(%678, %arg196) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc870)
        "ttnn.deallocate"(%678) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc870)
        "ttnn.deallocate"(%arg196) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc870)
        %680 = "ttnn.add"(%679, %155) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc871)
        "ttnn.deallocate"(%679) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc871)
        "ttnn.deallocate"(%155) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc871)
        %681 = "ttnn.gelu"(%680) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc872)
        "ttnn.deallocate"(%680) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc872)
        %682 = "ttnn.reshape"(%681) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc348)
        "ttnn.deallocate"(%681) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc348)
        %683 = "ttnn.matmul"(%682, %arg194) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc873)
        "ttnn.deallocate"(%682) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc873)
        "ttnn.deallocate"(%arg194) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc873)
        %684 = "ttnn.add"(%683, %84) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc874)
        "ttnn.deallocate"(%683) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc874)
        "ttnn.deallocate"(%84) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc874)
        %685 = "ttnn.add"(%676, %684) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc349)
        "ttnn.deallocate"(%684) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc349)
        "ttnn.deallocate"(%676) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc349)
        %686 = "ttnn.layer_norm"(%685, %arg192, %arg191) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc350)
        "ttnn.deallocate"(%arg192) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc350)
        "ttnn.deallocate"(%arg191) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc350)
        %687 = "ttnn.reshape"(%686) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc351)
        "ttnn.deallocate"(%686) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc351)
        %688 = "ttnn.matmul"(%687, %90) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc875)
        "ttnn.deallocate"(%687) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc875)
        "ttnn.deallocate"(%90) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc875)
        %689 = "ttnn.add"(%688, %119) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc876)
        "ttnn.deallocate"(%688) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc876)
        "ttnn.deallocate"(%119) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc876)
        %690 = "ttnn.slice_static"(%689) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc877)
        %691 = "ttnn.slice_static"(%689) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc878)
        %692 = "ttnn.slice_static"(%689) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc879)
        "ttnn.deallocate"(%689) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc879)
        %693 = "ttnn.reshape"(%690) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc880)
        "ttnn.deallocate"(%690) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc880)
        %694 = "ttnn.reshape"(%691) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc881)
        "ttnn.deallocate"(%691) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc881)
        %695 = "ttnn.reshape"(%692) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc882)
        "ttnn.deallocate"(%692) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc882)
        %696 = "ttnn.permute"(%693) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc883)
        "ttnn.deallocate"(%693) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc883)
        %697 = "ttnn.permute"(%694) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc884)
        "ttnn.deallocate"(%694) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc884)
        %698 = "ttnn.permute"(%695) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc885)
        "ttnn.deallocate"(%695) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc885)
        %699 = "ttnn.pad"(%696) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc352)
        "ttnn.deallocate"(%696) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc352)
        %700 = "ttnn.pad"(%697) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc352)
        "ttnn.deallocate"(%697) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc352)
        %701 = "ttnn.pad"(%698) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc352)
        "ttnn.deallocate"(%698) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc352)
        %702 = "ttnn.scaled_dot_product_attention"(%699, %700, %701) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc352)
        "ttnn.deallocate"(%701) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc352)
        "ttnn.deallocate"(%700) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc352)
        "ttnn.deallocate"(%699) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc352)
        %703 = "ttnn.slice_static"(%702) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc352)
        "ttnn.deallocate"(%702) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc352)
        %704 = "ttnn.permute"(%703) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc886)
        "ttnn.deallocate"(%703) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc886)
        %705 = "ttnn.reshape"(%704) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc353)
        "ttnn.deallocate"(%704) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc353)
        %706 = "ttnn.matmul"(%705, %arg188) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc887)
        "ttnn.deallocate"(%705) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc887)
        "ttnn.deallocate"(%arg188) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc887)
        %707 = "ttnn.add"(%706, %64) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc888)
        "ttnn.deallocate"(%706) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc888)
        "ttnn.deallocate"(%64) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc888)
        %708 = "ttnn.add"(%685, %707) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc354)
        "ttnn.deallocate"(%707) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc354)
        "ttnn.deallocate"(%685) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc354)
        %709 = "ttnn.layer_norm"(%708, %arg186, %arg185) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc355)
        "ttnn.deallocate"(%arg186) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc355)
        "ttnn.deallocate"(%arg185) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc355)
        %710 = "ttnn.reshape"(%709) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc356)
        "ttnn.deallocate"(%709) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc356)
        %711 = "ttnn.matmul"(%710, %arg184) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc889)
        "ttnn.deallocate"(%710) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc889)
        "ttnn.deallocate"(%arg184) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc889)
        %712 = "ttnn.add"(%711, %131) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc890)
        "ttnn.deallocate"(%711) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc890)
        "ttnn.deallocate"(%131) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc890)
        %713 = "ttnn.gelu"(%712) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc891)
        "ttnn.deallocate"(%712) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc891)
        %714 = "ttnn.reshape"(%713) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc357)
        "ttnn.deallocate"(%713) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc357)
        %715 = "ttnn.matmul"(%714, %arg182) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc892)
        "ttnn.deallocate"(%714) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc892)
        "ttnn.deallocate"(%arg182) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc892)
        %716 = "ttnn.add"(%715, %105) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc893)
        "ttnn.deallocate"(%715) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc893)
        "ttnn.deallocate"(%105) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc893)
        %717 = "ttnn.add"(%708, %716) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc358)
        "ttnn.deallocate"(%716) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc358)
        "ttnn.deallocate"(%708) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc358)
        %718 = "ttnn.layer_norm"(%717, %arg180, %arg179) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc359)
        "ttnn.deallocate"(%arg180) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc359)
        "ttnn.deallocate"(%arg179) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc359)
        %719 = "ttnn.reshape"(%718) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc360)
        "ttnn.deallocate"(%718) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc360)
        %720 = "ttnn.matmul"(%719, %35) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc894)
        "ttnn.deallocate"(%719) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc894)
        "ttnn.deallocate"(%35) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc894)
        %721 = "ttnn.add"(%720, %18) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc895)
        "ttnn.deallocate"(%720) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc895)
        "ttnn.deallocate"(%18) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc895)
        %722 = "ttnn.slice_static"(%721) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc896)
        %723 = "ttnn.slice_static"(%721) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc897)
        %724 = "ttnn.slice_static"(%721) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc898)
        "ttnn.deallocate"(%721) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc898)
        %725 = "ttnn.reshape"(%722) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc899)
        "ttnn.deallocate"(%722) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc899)
        %726 = "ttnn.reshape"(%723) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc900)
        "ttnn.deallocate"(%723) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc900)
        %727 = "ttnn.reshape"(%724) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc901)
        "ttnn.deallocate"(%724) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc901)
        %728 = "ttnn.permute"(%725) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc902)
        "ttnn.deallocate"(%725) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc902)
        %729 = "ttnn.permute"(%726) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc903)
        "ttnn.deallocate"(%726) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc903)
        %730 = "ttnn.permute"(%727) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc904)
        "ttnn.deallocate"(%727) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc904)
        %731 = "ttnn.pad"(%728) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc361)
        "ttnn.deallocate"(%728) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc361)
        %732 = "ttnn.pad"(%729) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc361)
        "ttnn.deallocate"(%729) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc361)
        %733 = "ttnn.pad"(%730) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc361)
        "ttnn.deallocate"(%730) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc361)
        %734 = "ttnn.scaled_dot_product_attention"(%731, %732, %733) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc361)
        "ttnn.deallocate"(%733) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc361)
        "ttnn.deallocate"(%732) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc361)
        "ttnn.deallocate"(%731) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc361)
        %735 = "ttnn.slice_static"(%734) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc361)
        "ttnn.deallocate"(%734) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc361)
        %736 = "ttnn.permute"(%735) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc905)
        "ttnn.deallocate"(%735) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc905)
        %737 = "ttnn.reshape"(%736) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc362)
        "ttnn.deallocate"(%736) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc362)
        %738 = "ttnn.matmul"(%737, %arg176) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc906)
        "ttnn.deallocate"(%737) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc906)
        "ttnn.deallocate"(%arg176) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc906)
        %739 = "ttnn.add"(%738, %8) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc907)
        "ttnn.deallocate"(%738) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc907)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc907)
        %740 = "ttnn.add"(%717, %739) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc363)
        "ttnn.deallocate"(%739) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc363)
        "ttnn.deallocate"(%717) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc363)
        %741 = "ttnn.layer_norm"(%740, %arg174, %arg173) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc364)
        "ttnn.deallocate"(%arg174) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc364)
        "ttnn.deallocate"(%arg173) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc364)
        %742 = "ttnn.reshape"(%741) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc365)
        "ttnn.deallocate"(%741) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc365)
        %743 = "ttnn.matmul"(%742, %arg172) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc908)
        "ttnn.deallocate"(%742) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc908)
        "ttnn.deallocate"(%arg172) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc908)
        %744 = "ttnn.add"(%743, %109) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc909)
        "ttnn.deallocate"(%743) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc909)
        "ttnn.deallocate"(%109) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc909)
        %745 = "ttnn.gelu"(%744) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc910)
        "ttnn.deallocate"(%744) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc910)
        %746 = "ttnn.reshape"(%745) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc366)
        "ttnn.deallocate"(%745) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc366)
        %747 = "ttnn.matmul"(%746, %arg170) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc911)
        "ttnn.deallocate"(%746) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc911)
        "ttnn.deallocate"(%arg170) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc911)
        %748 = "ttnn.add"(%747, %20) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc912)
        "ttnn.deallocate"(%747) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc912)
        "ttnn.deallocate"(%20) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc912)
        %749 = "ttnn.add"(%740, %748) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc367)
        "ttnn.deallocate"(%748) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc367)
        "ttnn.deallocate"(%740) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc367)
        %750 = "ttnn.layer_norm"(%749, %arg168, %arg167) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc368)
        "ttnn.deallocate"(%arg168) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc368)
        "ttnn.deallocate"(%arg167) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc368)
        %751 = "ttnn.reshape"(%750) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc369)
        "ttnn.deallocate"(%750) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc369)
        %752 = "ttnn.matmul"(%751, %113) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc913)
        "ttnn.deallocate"(%751) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc913)
        "ttnn.deallocate"(%113) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc913)
        %753 = "ttnn.add"(%752, %135) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc914)
        "ttnn.deallocate"(%752) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc914)
        "ttnn.deallocate"(%135) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc914)
        %754 = "ttnn.slice_static"(%753) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc915)
        %755 = "ttnn.slice_static"(%753) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc916)
        %756 = "ttnn.slice_static"(%753) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc917)
        "ttnn.deallocate"(%753) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc917)
        %757 = "ttnn.reshape"(%754) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc918)
        "ttnn.deallocate"(%754) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc918)
        %758 = "ttnn.reshape"(%755) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc919)
        "ttnn.deallocate"(%755) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc919)
        %759 = "ttnn.reshape"(%756) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc920)
        "ttnn.deallocate"(%756) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc920)
        %760 = "ttnn.permute"(%757) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc921)
        "ttnn.deallocate"(%757) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc921)
        %761 = "ttnn.permute"(%758) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc922)
        "ttnn.deallocate"(%758) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc922)
        %762 = "ttnn.permute"(%759) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc923)
        "ttnn.deallocate"(%759) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc923)
        %763 = "ttnn.pad"(%760) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc370)
        "ttnn.deallocate"(%760) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc370)
        %764 = "ttnn.pad"(%761) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc370)
        "ttnn.deallocate"(%761) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc370)
        %765 = "ttnn.pad"(%762) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc370)
        "ttnn.deallocate"(%762) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc370)
        %766 = "ttnn.scaled_dot_product_attention"(%763, %764, %765) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc370)
        "ttnn.deallocate"(%765) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc370)
        "ttnn.deallocate"(%764) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc370)
        "ttnn.deallocate"(%763) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc370)
        %767 = "ttnn.slice_static"(%766) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc370)
        "ttnn.deallocate"(%766) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc370)
        %768 = "ttnn.permute"(%767) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc924)
        "ttnn.deallocate"(%767) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc924)
        %769 = "ttnn.reshape"(%768) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc371)
        "ttnn.deallocate"(%768) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc371)
        %770 = "ttnn.matmul"(%769, %arg164) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc925)
        "ttnn.deallocate"(%769) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc925)
        "ttnn.deallocate"(%arg164) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc925)
        %771 = "ttnn.add"(%770, %101) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc926)
        "ttnn.deallocate"(%770) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc926)
        "ttnn.deallocate"(%101) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc926)
        %772 = "ttnn.add"(%749, %771) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc372)
        "ttnn.deallocate"(%771) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc372)
        "ttnn.deallocate"(%749) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc372)
        %773 = "ttnn.layer_norm"(%772, %arg162, %arg161) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc373)
        "ttnn.deallocate"(%arg162) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc373)
        "ttnn.deallocate"(%arg161) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc373)
        %774 = "ttnn.reshape"(%773) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc374)
        "ttnn.deallocate"(%773) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc374)
        %775 = "ttnn.matmul"(%774, %arg160) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc927)
        "ttnn.deallocate"(%774) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc927)
        "ttnn.deallocate"(%arg160) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc927)
        %776 = "ttnn.add"(%775, %95) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc928)
        "ttnn.deallocate"(%775) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc928)
        "ttnn.deallocate"(%95) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc928)
        %777 = "ttnn.gelu"(%776) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc929)
        "ttnn.deallocate"(%776) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc929)
        %778 = "ttnn.reshape"(%777) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc375)
        "ttnn.deallocate"(%777) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc375)
        %779 = "ttnn.matmul"(%778, %arg158) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc930)
        "ttnn.deallocate"(%778) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc930)
        "ttnn.deallocate"(%arg158) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc930)
        %780 = "ttnn.add"(%779, %148) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc931)
        "ttnn.deallocate"(%779) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc931)
        "ttnn.deallocate"(%148) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc931)
        %781 = "ttnn.add"(%772, %780) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc376)
        "ttnn.deallocate"(%780) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc376)
        "ttnn.deallocate"(%772) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc376)
        %782 = "ttnn.layer_norm"(%781, %arg156, %arg155) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc377)
        "ttnn.deallocate"(%arg156) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc377)
        "ttnn.deallocate"(%arg155) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc377)
        %783 = "ttnn.reshape"(%782) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc378)
        "ttnn.deallocate"(%782) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc378)
        %784 = "ttnn.matmul"(%783, %13) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc932)
        "ttnn.deallocate"(%783) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc932)
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc932)
        %785 = "ttnn.add"(%784, %51) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc933)
        "ttnn.deallocate"(%784) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc933)
        "ttnn.deallocate"(%51) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc933)
        %786 = "ttnn.slice_static"(%785) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc934)
        %787 = "ttnn.slice_static"(%785) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc935)
        %788 = "ttnn.slice_static"(%785) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc936)
        "ttnn.deallocate"(%785) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc936)
        %789 = "ttnn.reshape"(%786) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc937)
        "ttnn.deallocate"(%786) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc937)
        %790 = "ttnn.reshape"(%787) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc938)
        "ttnn.deallocate"(%787) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc938)
        %791 = "ttnn.reshape"(%788) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc939)
        "ttnn.deallocate"(%788) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc939)
        %792 = "ttnn.permute"(%789) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc940)
        "ttnn.deallocate"(%789) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc940)
        %793 = "ttnn.permute"(%790) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc941)
        "ttnn.deallocate"(%790) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc941)
        %794 = "ttnn.permute"(%791) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc942)
        "ttnn.deallocate"(%791) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc942)
        %795 = "ttnn.pad"(%792) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc379)
        "ttnn.deallocate"(%792) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc379)
        %796 = "ttnn.pad"(%793) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc379)
        "ttnn.deallocate"(%793) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc379)
        %797 = "ttnn.pad"(%794) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc379)
        "ttnn.deallocate"(%794) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc379)
        %798 = "ttnn.scaled_dot_product_attention"(%795, %796, %797) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc379)
        "ttnn.deallocate"(%797) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc379)
        "ttnn.deallocate"(%796) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc379)
        "ttnn.deallocate"(%795) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc379)
        %799 = "ttnn.slice_static"(%798) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc379)
        "ttnn.deallocate"(%798) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc379)
        %800 = "ttnn.permute"(%799) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc943)
        "ttnn.deallocate"(%799) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc943)
        %801 = "ttnn.reshape"(%800) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc380)
        "ttnn.deallocate"(%800) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc380)
        %802 = "ttnn.matmul"(%801, %arg152) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc944)
        "ttnn.deallocate"(%801) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc944)
        "ttnn.deallocate"(%arg152) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc944)
        %803 = "ttnn.add"(%802, %53) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc945)
        "ttnn.deallocate"(%802) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc945)
        "ttnn.deallocate"(%53) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc945)
        %804 = "ttnn.add"(%781, %803) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc381)
        "ttnn.deallocate"(%803) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc381)
        "ttnn.deallocate"(%781) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc381)
        %805 = "ttnn.layer_norm"(%804, %arg150, %arg149) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc382)
        "ttnn.deallocate"(%arg150) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc382)
        "ttnn.deallocate"(%arg149) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc382)
        %806 = "ttnn.reshape"(%805) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc383)
        "ttnn.deallocate"(%805) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc383)
        %807 = "ttnn.matmul"(%806, %arg148) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc946)
        "ttnn.deallocate"(%806) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc946)
        "ttnn.deallocate"(%arg148) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc946)
        %808 = "ttnn.add"(%807, %45) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc947)
        "ttnn.deallocate"(%807) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc947)
        "ttnn.deallocate"(%45) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc947)
        %809 = "ttnn.gelu"(%808) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc948)
        "ttnn.deallocate"(%808) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc948)
        %810 = "ttnn.reshape"(%809) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc384)
        "ttnn.deallocate"(%809) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc384)
        %811 = "ttnn.matmul"(%810, %arg146) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc949)
        "ttnn.deallocate"(%810) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc949)
        "ttnn.deallocate"(%arg146) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc949)
        %812 = "ttnn.add"(%811, %29) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc950)
        "ttnn.deallocate"(%811) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc950)
        "ttnn.deallocate"(%29) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc950)
        %813 = "ttnn.add"(%804, %812) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc385)
        "ttnn.deallocate"(%812) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc385)
        "ttnn.deallocate"(%804) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc385)
        %814 = "ttnn.layer_norm"(%813, %arg144, %arg143) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc386)
        "ttnn.deallocate"(%arg144) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc386)
        "ttnn.deallocate"(%arg143) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc386)
        %815 = "ttnn.reshape"(%814) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc387)
        "ttnn.deallocate"(%814) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc387)
        %816 = "ttnn.matmul"(%815, %66) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc951)
        "ttnn.deallocate"(%815) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc951)
        "ttnn.deallocate"(%66) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc951)
        %817 = "ttnn.add"(%816, %61) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc952)
        "ttnn.deallocate"(%816) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc952)
        "ttnn.deallocate"(%61) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc952)
        %818 = "ttnn.slice_static"(%817) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc953)
        %819 = "ttnn.slice_static"(%817) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc954)
        %820 = "ttnn.slice_static"(%817) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc955)
        "ttnn.deallocate"(%817) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc955)
        %821 = "ttnn.reshape"(%818) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc956)
        "ttnn.deallocate"(%818) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc956)
        %822 = "ttnn.reshape"(%819) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc957)
        "ttnn.deallocate"(%819) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc957)
        %823 = "ttnn.reshape"(%820) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc958)
        "ttnn.deallocate"(%820) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc958)
        %824 = "ttnn.permute"(%821) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc959)
        "ttnn.deallocate"(%821) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc959)
        %825 = "ttnn.permute"(%822) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc960)
        "ttnn.deallocate"(%822) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc960)
        %826 = "ttnn.permute"(%823) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc961)
        "ttnn.deallocate"(%823) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc961)
        %827 = "ttnn.pad"(%824) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc388)
        "ttnn.deallocate"(%824) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc388)
        %828 = "ttnn.pad"(%825) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc388)
        "ttnn.deallocate"(%825) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc388)
        %829 = "ttnn.pad"(%826) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc388)
        "ttnn.deallocate"(%826) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc388)
        %830 = "ttnn.scaled_dot_product_attention"(%827, %828, %829) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc388)
        "ttnn.deallocate"(%829) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc388)
        "ttnn.deallocate"(%828) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc388)
        "ttnn.deallocate"(%827) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc388)
        %831 = "ttnn.slice_static"(%830) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc388)
        "ttnn.deallocate"(%830) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc388)
        %832 = "ttnn.permute"(%831) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc962)
        "ttnn.deallocate"(%831) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc962)
        %833 = "ttnn.reshape"(%832) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc389)
        "ttnn.deallocate"(%832) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc389)
        %834 = "ttnn.matmul"(%833, %arg140) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc963)
        "ttnn.deallocate"(%833) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc963)
        "ttnn.deallocate"(%arg140) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc963)
        %835 = "ttnn.add"(%834, %79) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc964)
        "ttnn.deallocate"(%834) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc964)
        "ttnn.deallocate"(%79) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc964)
        %836 = "ttnn.add"(%813, %835) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc390)
        "ttnn.deallocate"(%835) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc390)
        "ttnn.deallocate"(%813) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc390)
        %837 = "ttnn.layer_norm"(%836, %arg138, %arg137) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc391)
        "ttnn.deallocate"(%arg138) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc391)
        "ttnn.deallocate"(%arg137) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc391)
        %838 = "ttnn.reshape"(%837) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc392)
        "ttnn.deallocate"(%837) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc392)
        %839 = "ttnn.matmul"(%838, %arg136) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc965)
        "ttnn.deallocate"(%838) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc965)
        "ttnn.deallocate"(%arg136) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc965)
        %840 = "ttnn.add"(%839, %108) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc966)
        "ttnn.deallocate"(%839) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc966)
        "ttnn.deallocate"(%108) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc966)
        %841 = "ttnn.gelu"(%840) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc967)
        "ttnn.deallocate"(%840) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc967)
        %842 = "ttnn.reshape"(%841) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc393)
        "ttnn.deallocate"(%841) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc393)
        %843 = "ttnn.matmul"(%842, %arg134) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc968)
        "ttnn.deallocate"(%842) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc968)
        "ttnn.deallocate"(%arg134) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc968)
        %844 = "ttnn.add"(%843, %83) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc969)
        "ttnn.deallocate"(%843) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc969)
        "ttnn.deallocate"(%83) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc969)
        %845 = "ttnn.add"(%836, %844) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc394)
        "ttnn.deallocate"(%844) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc394)
        "ttnn.deallocate"(%836) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc394)
        %846 = "ttnn.layer_norm"(%845, %arg132, %arg131) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc395)
        "ttnn.deallocate"(%arg132) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc395)
        "ttnn.deallocate"(%arg131) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc395)
        %847 = "ttnn.reshape"(%846) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc396)
        "ttnn.deallocate"(%846) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc396)
        %848 = "ttnn.matmul"(%847, %38) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc970)
        "ttnn.deallocate"(%847) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc970)
        "ttnn.deallocate"(%38) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc970)
        %849 = "ttnn.add"(%848, %112) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc971)
        "ttnn.deallocate"(%848) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc971)
        "ttnn.deallocate"(%112) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc971)
        %850 = "ttnn.slice_static"(%849) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc972)
        %851 = "ttnn.slice_static"(%849) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc973)
        %852 = "ttnn.slice_static"(%849) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc974)
        "ttnn.deallocate"(%849) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc974)
        %853 = "ttnn.reshape"(%850) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc975)
        "ttnn.deallocate"(%850) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc975)
        %854 = "ttnn.reshape"(%851) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc976)
        "ttnn.deallocate"(%851) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc976)
        %855 = "ttnn.reshape"(%852) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc977)
        "ttnn.deallocate"(%852) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc977)
        %856 = "ttnn.permute"(%853) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc978)
        "ttnn.deallocate"(%853) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc978)
        %857 = "ttnn.permute"(%854) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc979)
        "ttnn.deallocate"(%854) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc979)
        %858 = "ttnn.permute"(%855) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc980)
        "ttnn.deallocate"(%855) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc980)
        %859 = "ttnn.pad"(%856) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc397)
        "ttnn.deallocate"(%856) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc397)
        %860 = "ttnn.pad"(%857) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc397)
        "ttnn.deallocate"(%857) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc397)
        %861 = "ttnn.pad"(%858) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc397)
        "ttnn.deallocate"(%858) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc397)
        %862 = "ttnn.scaled_dot_product_attention"(%859, %860, %861) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc397)
        "ttnn.deallocate"(%861) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc397)
        "ttnn.deallocate"(%860) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc397)
        "ttnn.deallocate"(%859) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc397)
        %863 = "ttnn.slice_static"(%862) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc397)
        "ttnn.deallocate"(%862) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc397)
        %864 = "ttnn.permute"(%863) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc981)
        "ttnn.deallocate"(%863) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc981)
        %865 = "ttnn.reshape"(%864) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc398)
        "ttnn.deallocate"(%864) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc398)
        %866 = "ttnn.matmul"(%865, %arg128) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc982)
        "ttnn.deallocate"(%865) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc982)
        "ttnn.deallocate"(%arg128) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc982)
        %867 = "ttnn.add"(%866, %21) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc983)
        "ttnn.deallocate"(%866) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc983)
        "ttnn.deallocate"(%21) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc983)
        %868 = "ttnn.add"(%845, %867) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc399)
        "ttnn.deallocate"(%867) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc399)
        "ttnn.deallocate"(%845) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc399)
        %869 = "ttnn.layer_norm"(%868, %arg126, %arg125) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc400)
        "ttnn.deallocate"(%arg126) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc400)
        "ttnn.deallocate"(%arg125) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc400)
        %870 = "ttnn.reshape"(%869) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc401)
        "ttnn.deallocate"(%869) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc401)
        %871 = "ttnn.matmul"(%870, %arg124) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc984)
        "ttnn.deallocate"(%870) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc984)
        "ttnn.deallocate"(%arg124) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc984)
        %872 = "ttnn.add"(%871, %111) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc985)
        "ttnn.deallocate"(%871) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc985)
        "ttnn.deallocate"(%111) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc985)
        %873 = "ttnn.gelu"(%872) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc986)
        "ttnn.deallocate"(%872) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc986)
        %874 = "ttnn.reshape"(%873) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc402)
        "ttnn.deallocate"(%873) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc402)
        %875 = "ttnn.matmul"(%874, %arg122) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc987)
        "ttnn.deallocate"(%874) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc987)
        "ttnn.deallocate"(%arg122) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc987)
        %876 = "ttnn.add"(%875, %161) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc988)
        "ttnn.deallocate"(%875) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc988)
        "ttnn.deallocate"(%161) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc988)
        %877 = "ttnn.add"(%868, %876) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc403)
        "ttnn.deallocate"(%876) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc403)
        "ttnn.deallocate"(%868) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc403)
        %878 = "ttnn.layer_norm"(%877, %arg120, %arg119) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc404)
        "ttnn.deallocate"(%arg120) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc404)
        "ttnn.deallocate"(%arg119) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc404)
        %879 = "ttnn.reshape"(%878) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc405)
        "ttnn.deallocate"(%878) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc405)
        %880 = "ttnn.matmul"(%879, %149) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc989)
        "ttnn.deallocate"(%879) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc989)
        "ttnn.deallocate"(%149) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc989)
        %881 = "ttnn.add"(%880, %58) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc990)
        "ttnn.deallocate"(%880) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc990)
        "ttnn.deallocate"(%58) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc990)
        %882 = "ttnn.slice_static"(%881) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc991)
        %883 = "ttnn.slice_static"(%881) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc992)
        %884 = "ttnn.slice_static"(%881) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc993)
        "ttnn.deallocate"(%881) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc993)
        %885 = "ttnn.reshape"(%882) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc994)
        "ttnn.deallocate"(%882) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc994)
        %886 = "ttnn.reshape"(%883) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc995)
        "ttnn.deallocate"(%883) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc995)
        %887 = "ttnn.reshape"(%884) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc996)
        "ttnn.deallocate"(%884) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc996)
        %888 = "ttnn.permute"(%885) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc997)
        "ttnn.deallocate"(%885) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc997)
        %889 = "ttnn.permute"(%886) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc998)
        "ttnn.deallocate"(%886) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc998)
        %890 = "ttnn.permute"(%887) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc999)
        "ttnn.deallocate"(%887) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc999)
        %891 = "ttnn.pad"(%888) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc406)
        "ttnn.deallocate"(%888) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc406)
        %892 = "ttnn.pad"(%889) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc406)
        "ttnn.deallocate"(%889) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc406)
        %893 = "ttnn.pad"(%890) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc406)
        "ttnn.deallocate"(%890) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc406)
        %894 = "ttnn.scaled_dot_product_attention"(%891, %892, %893) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc406)
        "ttnn.deallocate"(%893) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc406)
        "ttnn.deallocate"(%892) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc406)
        "ttnn.deallocate"(%891) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc406)
        %895 = "ttnn.slice_static"(%894) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc406)
        "ttnn.deallocate"(%894) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc406)
        %896 = "ttnn.permute"(%895) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1000)
        "ttnn.deallocate"(%895) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc1000)
        %897 = "ttnn.reshape"(%896) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc407)
        "ttnn.deallocate"(%896) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc407)
        %898 = "ttnn.matmul"(%897, %arg116) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc1001)
        "ttnn.deallocate"(%897) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1001)
        "ttnn.deallocate"(%arg116) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc1001)
        %899 = "ttnn.add"(%898, %34) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1002)
        "ttnn.deallocate"(%898) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1002)
        "ttnn.deallocate"(%34) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1002)
        %900 = "ttnn.add"(%877, %899) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc408)
        "ttnn.deallocate"(%899) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc408)
        "ttnn.deallocate"(%877) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc408)
        %901 = "ttnn.layer_norm"(%900, %arg114, %arg113) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc409)
        "ttnn.deallocate"(%arg114) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc409)
        "ttnn.deallocate"(%arg113) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc409)
        %902 = "ttnn.reshape"(%901) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc410)
        "ttnn.deallocate"(%901) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc410)
        %903 = "ttnn.matmul"(%902, %arg112) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc1003)
        "ttnn.deallocate"(%902) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1003)
        "ttnn.deallocate"(%arg112) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc1003)
        %904 = "ttnn.add"(%903, %5) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc1004)
        "ttnn.deallocate"(%903) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc1004)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc1004)
        %905 = "ttnn.gelu"(%904) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc1005)
        "ttnn.deallocate"(%904) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc1005)
        %906 = "ttnn.reshape"(%905) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc411)
        "ttnn.deallocate"(%905) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc411)
        %907 = "ttnn.matmul"(%906, %arg110) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc1006)
        "ttnn.deallocate"(%906) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc1006)
        "ttnn.deallocate"(%arg110) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc1006)
        %908 = "ttnn.add"(%907, %126) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1007)
        "ttnn.deallocate"(%907) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1007)
        "ttnn.deallocate"(%126) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1007)
        %909 = "ttnn.add"(%900, %908) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc412)
        "ttnn.deallocate"(%908) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc412)
        "ttnn.deallocate"(%900) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc412)
        %910 = "ttnn.layer_norm"(%909, %arg108, %arg107) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc413)
        "ttnn.deallocate"(%arg108) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc413)
        "ttnn.deallocate"(%arg107) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc413)
        %911 = "ttnn.reshape"(%910) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc414)
        "ttnn.deallocate"(%910) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc414)
        %912 = "ttnn.matmul"(%911, %37) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc1008)
        "ttnn.deallocate"(%911) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1008)
        "ttnn.deallocate"(%37) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc1008)
        %913 = "ttnn.add"(%912, %33) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc1009)
        "ttnn.deallocate"(%912) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc1009)
        "ttnn.deallocate"(%33) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc1009)
        %914 = "ttnn.slice_static"(%913) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1010)
        %915 = "ttnn.slice_static"(%913) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1011)
        %916 = "ttnn.slice_static"(%913) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1012)
        "ttnn.deallocate"(%913) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc1012)
        %917 = "ttnn.reshape"(%914) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1013)
        "ttnn.deallocate"(%914) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1013)
        %918 = "ttnn.reshape"(%915) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1014)
        "ttnn.deallocate"(%915) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1014)
        %919 = "ttnn.reshape"(%916) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1015)
        "ttnn.deallocate"(%916) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1015)
        %920 = "ttnn.permute"(%917) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1016)
        "ttnn.deallocate"(%917) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1016)
        %921 = "ttnn.permute"(%918) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1017)
        "ttnn.deallocate"(%918) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1017)
        %922 = "ttnn.permute"(%919) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1018)
        "ttnn.deallocate"(%919) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1018)
        %923 = "ttnn.pad"(%920) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc415)
        "ttnn.deallocate"(%920) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc415)
        %924 = "ttnn.pad"(%921) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc415)
        "ttnn.deallocate"(%921) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc415)
        %925 = "ttnn.pad"(%922) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc415)
        "ttnn.deallocate"(%922) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc415)
        %926 = "ttnn.scaled_dot_product_attention"(%923, %924, %925) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc415)
        "ttnn.deallocate"(%925) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc415)
        "ttnn.deallocate"(%924) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc415)
        "ttnn.deallocate"(%923) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc415)
        %927 = "ttnn.slice_static"(%926) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc415)
        "ttnn.deallocate"(%926) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc415)
        %928 = "ttnn.permute"(%927) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1019)
        "ttnn.deallocate"(%927) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc1019)
        %929 = "ttnn.reshape"(%928) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc416)
        "ttnn.deallocate"(%928) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc416)
        %930 = "ttnn.matmul"(%929, %arg104) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc1020)
        "ttnn.deallocate"(%929) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1020)
        "ttnn.deallocate"(%arg104) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc1020)
        %931 = "ttnn.add"(%930, %52) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1021)
        "ttnn.deallocate"(%930) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1021)
        "ttnn.deallocate"(%52) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1021)
        %932 = "ttnn.add"(%909, %931) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc417)
        "ttnn.deallocate"(%931) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc417)
        "ttnn.deallocate"(%909) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc417)
        %933 = "ttnn.layer_norm"(%932, %arg102, %arg101) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc418)
        "ttnn.deallocate"(%arg102) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc418)
        "ttnn.deallocate"(%arg101) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc418)
        %934 = "ttnn.reshape"(%933) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc419)
        "ttnn.deallocate"(%933) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc419)
        %935 = "ttnn.matmul"(%934, %arg100) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc1022)
        "ttnn.deallocate"(%934) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1022)
        "ttnn.deallocate"(%arg100) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc1022)
        %936 = "ttnn.add"(%935, %1) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc1023)
        "ttnn.deallocate"(%935) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc1023)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc1023)
        %937 = "ttnn.gelu"(%936) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc1024)
        "ttnn.deallocate"(%936) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc1024)
        %938 = "ttnn.reshape"(%937) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc420)
        "ttnn.deallocate"(%937) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc420)
        %939 = "ttnn.matmul"(%938, %arg98) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc1025)
        "ttnn.deallocate"(%938) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc1025)
        "ttnn.deallocate"(%arg98) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc1025)
        %940 = "ttnn.add"(%939, %23) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1026)
        "ttnn.deallocate"(%939) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1026)
        "ttnn.deallocate"(%23) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1026)
        %941 = "ttnn.add"(%932, %940) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc421)
        "ttnn.deallocate"(%940) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc421)
        "ttnn.deallocate"(%932) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc421)
        %942 = "ttnn.layer_norm"(%941, %arg96, %arg95) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc422)
        "ttnn.deallocate"(%arg96) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc422)
        "ttnn.deallocate"(%arg95) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc422)
        %943 = "ttnn.reshape"(%942) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc423)
        "ttnn.deallocate"(%942) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc423)
        %944 = "ttnn.matmul"(%943, %77) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc1027)
        "ttnn.deallocate"(%943) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1027)
        "ttnn.deallocate"(%77) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc1027)
        %945 = "ttnn.add"(%944, %60) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc1028)
        "ttnn.deallocate"(%944) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc1028)
        "ttnn.deallocate"(%60) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc1028)
        %946 = "ttnn.slice_static"(%945) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1029)
        %947 = "ttnn.slice_static"(%945) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1030)
        %948 = "ttnn.slice_static"(%945) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1031)
        "ttnn.deallocate"(%945) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc1031)
        %949 = "ttnn.reshape"(%946) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1032)
        "ttnn.deallocate"(%946) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1032)
        %950 = "ttnn.reshape"(%947) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1033)
        "ttnn.deallocate"(%947) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1033)
        %951 = "ttnn.reshape"(%948) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1034)
        "ttnn.deallocate"(%948) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1034)
        %952 = "ttnn.permute"(%949) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1035)
        "ttnn.deallocate"(%949) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1035)
        %953 = "ttnn.permute"(%950) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1036)
        "ttnn.deallocate"(%950) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1036)
        %954 = "ttnn.permute"(%951) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1037)
        "ttnn.deallocate"(%951) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1037)
        %955 = "ttnn.pad"(%952) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc424)
        "ttnn.deallocate"(%952) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc424)
        %956 = "ttnn.pad"(%953) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc424)
        "ttnn.deallocate"(%953) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc424)
        %957 = "ttnn.pad"(%954) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc424)
        "ttnn.deallocate"(%954) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc424)
        %958 = "ttnn.scaled_dot_product_attention"(%955, %956, %957) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc424)
        "ttnn.deallocate"(%957) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc424)
        "ttnn.deallocate"(%956) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc424)
        "ttnn.deallocate"(%955) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc424)
        %959 = "ttnn.slice_static"(%958) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc424)
        "ttnn.deallocate"(%958) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc424)
        %960 = "ttnn.permute"(%959) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1038)
        "ttnn.deallocate"(%959) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc1038)
        %961 = "ttnn.reshape"(%960) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc425)
        "ttnn.deallocate"(%960) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc425)
        %962 = "ttnn.matmul"(%961, %arg92) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc1039)
        "ttnn.deallocate"(%961) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1039)
        "ttnn.deallocate"(%arg92) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc1039)
        %963 = "ttnn.add"(%962, %144) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1040)
        "ttnn.deallocate"(%962) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1040)
        "ttnn.deallocate"(%144) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1040)
        %964 = "ttnn.add"(%941, %963) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc426)
        "ttnn.deallocate"(%963) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc426)
        "ttnn.deallocate"(%941) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc426)
        %965 = "ttnn.layer_norm"(%964, %arg90, %arg89) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc427)
        "ttnn.deallocate"(%arg90) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc427)
        "ttnn.deallocate"(%arg89) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc427)
        %966 = "ttnn.reshape"(%965) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc428)
        "ttnn.deallocate"(%965) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc428)
        %967 = "ttnn.matmul"(%966, %arg88) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc1041)
        "ttnn.deallocate"(%966) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1041)
        "ttnn.deallocate"(%arg88) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc1041)
        %968 = "ttnn.add"(%967, %140) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc1042)
        "ttnn.deallocate"(%967) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc1042)
        "ttnn.deallocate"(%140) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc1042)
        %969 = "ttnn.gelu"(%968) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc1043)
        "ttnn.deallocate"(%968) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc1043)
        %970 = "ttnn.reshape"(%969) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc429)
        "ttnn.deallocate"(%969) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc429)
        %971 = "ttnn.matmul"(%970, %arg86) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc1044)
        "ttnn.deallocate"(%970) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc1044)
        "ttnn.deallocate"(%arg86) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc1044)
        %972 = "ttnn.add"(%971, %145) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1045)
        "ttnn.deallocate"(%971) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1045)
        "ttnn.deallocate"(%145) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1045)
        %973 = "ttnn.add"(%964, %972) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc430)
        "ttnn.deallocate"(%972) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc430)
        "ttnn.deallocate"(%964) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc430)
        %974 = "ttnn.layer_norm"(%973, %arg84, %arg83) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc431)
        "ttnn.deallocate"(%arg84) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc431)
        "ttnn.deallocate"(%arg83) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc431)
        %975 = "ttnn.reshape"(%974) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc432)
        "ttnn.deallocate"(%974) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc432)
        %976 = "ttnn.matmul"(%975, %62) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc1046)
        "ttnn.deallocate"(%975) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1046)
        "ttnn.deallocate"(%62) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc1046)
        %977 = "ttnn.add"(%976, %59) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc1047)
        "ttnn.deallocate"(%976) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc1047)
        "ttnn.deallocate"(%59) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc1047)
        %978 = "ttnn.slice_static"(%977) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1048)
        %979 = "ttnn.slice_static"(%977) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1049)
        %980 = "ttnn.slice_static"(%977) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1050)
        "ttnn.deallocate"(%977) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc1050)
        %981 = "ttnn.reshape"(%978) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1051)
        "ttnn.deallocate"(%978) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1051)
        %982 = "ttnn.reshape"(%979) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1052)
        "ttnn.deallocate"(%979) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1052)
        %983 = "ttnn.reshape"(%980) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1053)
        "ttnn.deallocate"(%980) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1053)
        %984 = "ttnn.permute"(%981) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1054)
        "ttnn.deallocate"(%981) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1054)
        %985 = "ttnn.permute"(%982) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1055)
        "ttnn.deallocate"(%982) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1055)
        %986 = "ttnn.permute"(%983) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1056)
        "ttnn.deallocate"(%983) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1056)
        %987 = "ttnn.pad"(%984) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc433)
        "ttnn.deallocate"(%984) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc433)
        %988 = "ttnn.pad"(%985) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc433)
        "ttnn.deallocate"(%985) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc433)
        %989 = "ttnn.pad"(%986) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc433)
        "ttnn.deallocate"(%986) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc433)
        %990 = "ttnn.scaled_dot_product_attention"(%987, %988, %989) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc433)
        "ttnn.deallocate"(%989) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc433)
        "ttnn.deallocate"(%988) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc433)
        "ttnn.deallocate"(%987) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc433)
        %991 = "ttnn.slice_static"(%990) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc433)
        "ttnn.deallocate"(%990) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc433)
        %992 = "ttnn.permute"(%991) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1057)
        "ttnn.deallocate"(%991) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc1057)
        %993 = "ttnn.reshape"(%992) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc434)
        "ttnn.deallocate"(%992) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc434)
        %994 = "ttnn.matmul"(%993, %arg80) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc1058)
        "ttnn.deallocate"(%993) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1058)
        "ttnn.deallocate"(%arg80) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc1058)
        %995 = "ttnn.add"(%994, %32) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1059)
        "ttnn.deallocate"(%994) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1059)
        "ttnn.deallocate"(%32) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1059)
        %996 = "ttnn.add"(%973, %995) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc435)
        "ttnn.deallocate"(%995) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc435)
        "ttnn.deallocate"(%973) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc435)
        %997 = "ttnn.layer_norm"(%996, %arg78, %arg77) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc436)
        "ttnn.deallocate"(%arg78) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc436)
        "ttnn.deallocate"(%arg77) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc436)
        %998 = "ttnn.reshape"(%997) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc437)
        "ttnn.deallocate"(%997) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc437)
        %999 = "ttnn.matmul"(%998, %arg76) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc1060)
        "ttnn.deallocate"(%998) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1060)
        "ttnn.deallocate"(%arg76) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc1060)
        %1000 = "ttnn.add"(%999, %118) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc1061)
        "ttnn.deallocate"(%999) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc1061)
        "ttnn.deallocate"(%118) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc1061)
        %1001 = "ttnn.gelu"(%1000) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc1062)
        "ttnn.deallocate"(%1000) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc1062)
        %1002 = "ttnn.reshape"(%1001) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc438)
        "ttnn.deallocate"(%1001) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc438)
        %1003 = "ttnn.matmul"(%1002, %arg74) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc1063)
        "ttnn.deallocate"(%1002) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc1063)
        "ttnn.deallocate"(%arg74) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc1063)
        %1004 = "ttnn.add"(%1003, %40) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1064)
        "ttnn.deallocate"(%1003) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1064)
        "ttnn.deallocate"(%40) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1064)
        %1005 = "ttnn.add"(%996, %1004) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc439)
        "ttnn.deallocate"(%1004) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc439)
        "ttnn.deallocate"(%996) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc439)
        %1006 = "ttnn.layer_norm"(%1005, %arg72, %arg71) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc440)
        "ttnn.deallocate"(%arg72) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc440)
        "ttnn.deallocate"(%arg71) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc440)
        %1007 = "ttnn.reshape"(%1006) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc441)
        "ttnn.deallocate"(%1006) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc441)
        %1008 = "ttnn.matmul"(%1007, %10) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc1065)
        "ttnn.deallocate"(%1007) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1065)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc1065)
        %1009 = "ttnn.add"(%1008, %78) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc1066)
        "ttnn.deallocate"(%1008) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc1066)
        "ttnn.deallocate"(%78) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc1066)
        %1010 = "ttnn.slice_static"(%1009) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1067)
        %1011 = "ttnn.slice_static"(%1009) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1068)
        %1012 = "ttnn.slice_static"(%1009) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1069)
        "ttnn.deallocate"(%1009) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc1069)
        %1013 = "ttnn.reshape"(%1010) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1070)
        "ttnn.deallocate"(%1010) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1070)
        %1014 = "ttnn.reshape"(%1011) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1071)
        "ttnn.deallocate"(%1011) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1071)
        %1015 = "ttnn.reshape"(%1012) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1072)
        "ttnn.deallocate"(%1012) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1072)
        %1016 = "ttnn.permute"(%1013) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1073)
        "ttnn.deallocate"(%1013) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1073)
        %1017 = "ttnn.permute"(%1014) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1074)
        "ttnn.deallocate"(%1014) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1074)
        %1018 = "ttnn.permute"(%1015) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1075)
        "ttnn.deallocate"(%1015) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1075)
        %1019 = "ttnn.pad"(%1016) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc442)
        "ttnn.deallocate"(%1016) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc442)
        %1020 = "ttnn.pad"(%1017) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc442)
        "ttnn.deallocate"(%1017) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc442)
        %1021 = "ttnn.pad"(%1018) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc442)
        "ttnn.deallocate"(%1018) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc442)
        %1022 = "ttnn.scaled_dot_product_attention"(%1019, %1020, %1021) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc442)
        "ttnn.deallocate"(%1021) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc442)
        "ttnn.deallocate"(%1020) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc442)
        "ttnn.deallocate"(%1019) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc442)
        %1023 = "ttnn.slice_static"(%1022) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc442)
        "ttnn.deallocate"(%1022) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc442)
        %1024 = "ttnn.permute"(%1023) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1076)
        "ttnn.deallocate"(%1023) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc1076)
        %1025 = "ttnn.reshape"(%1024) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc443)
        "ttnn.deallocate"(%1024) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc443)
        %1026 = "ttnn.matmul"(%1025, %arg68) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc1077)
        "ttnn.deallocate"(%1025) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1077)
        "ttnn.deallocate"(%arg68) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc1077)
        %1027 = "ttnn.add"(%1026, %106) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1078)
        "ttnn.deallocate"(%1026) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1078)
        "ttnn.deallocate"(%106) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1078)
        %1028 = "ttnn.add"(%1005, %1027) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc444)
        "ttnn.deallocate"(%1027) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc444)
        "ttnn.deallocate"(%1005) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc444)
        %1029 = "ttnn.layer_norm"(%1028, %arg66, %arg65) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc445)
        "ttnn.deallocate"(%arg66) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc445)
        "ttnn.deallocate"(%arg65) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc445)
        %1030 = "ttnn.reshape"(%1029) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc446)
        "ttnn.deallocate"(%1029) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc446)
        %1031 = "ttnn.matmul"(%1030, %arg64) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc1079)
        "ttnn.deallocate"(%1030) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1079)
        "ttnn.deallocate"(%arg64) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc1079)
        %1032 = "ttnn.add"(%1031, %99) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc1080)
        "ttnn.deallocate"(%1031) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc1080)
        "ttnn.deallocate"(%99) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc1080)
        %1033 = "ttnn.gelu"(%1032) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc1081)
        "ttnn.deallocate"(%1032) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc1081)
        %1034 = "ttnn.reshape"(%1033) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc447)
        "ttnn.deallocate"(%1033) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc447)
        %1035 = "ttnn.matmul"(%1034, %arg62) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc1082)
        "ttnn.deallocate"(%1034) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc1082)
        "ttnn.deallocate"(%arg62) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc1082)
        %1036 = "ttnn.add"(%1035, %124) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1083)
        "ttnn.deallocate"(%1035) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1083)
        "ttnn.deallocate"(%124) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1083)
        %1037 = "ttnn.add"(%1028, %1036) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc448)
        "ttnn.deallocate"(%1036) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc448)
        "ttnn.deallocate"(%1028) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc448)
        %1038 = "ttnn.layer_norm"(%1037, %arg60, %arg59) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc449)
        "ttnn.deallocate"(%arg60) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc449)
        "ttnn.deallocate"(%arg59) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc449)
        %1039 = "ttnn.reshape"(%1038) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc450)
        "ttnn.deallocate"(%1038) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc450)
        %1040 = "ttnn.matmul"(%1039, %160) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc1084)
        "ttnn.deallocate"(%1039) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1084)
        "ttnn.deallocate"(%160) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc1084)
        %1041 = "ttnn.add"(%1040, %42) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc1085)
        "ttnn.deallocate"(%1040) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc1085)
        "ttnn.deallocate"(%42) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc1085)
        %1042 = "ttnn.slice_static"(%1041) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1086)
        %1043 = "ttnn.slice_static"(%1041) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1087)
        %1044 = "ttnn.slice_static"(%1041) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1088)
        "ttnn.deallocate"(%1041) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc1088)
        %1045 = "ttnn.reshape"(%1042) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1089)
        "ttnn.deallocate"(%1042) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1089)
        %1046 = "ttnn.reshape"(%1043) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1090)
        "ttnn.deallocate"(%1043) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1090)
        %1047 = "ttnn.reshape"(%1044) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1091)
        "ttnn.deallocate"(%1044) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1091)
        %1048 = "ttnn.permute"(%1045) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1092)
        "ttnn.deallocate"(%1045) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1092)
        %1049 = "ttnn.permute"(%1046) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1093)
        "ttnn.deallocate"(%1046) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1093)
        %1050 = "ttnn.permute"(%1047) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1094)
        "ttnn.deallocate"(%1047) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1094)
        %1051 = "ttnn.pad"(%1048) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc451)
        "ttnn.deallocate"(%1048) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc451)
        %1052 = "ttnn.pad"(%1049) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc451)
        "ttnn.deallocate"(%1049) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc451)
        %1053 = "ttnn.pad"(%1050) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc451)
        "ttnn.deallocate"(%1050) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc451)
        %1054 = "ttnn.scaled_dot_product_attention"(%1051, %1052, %1053) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc451)
        "ttnn.deallocate"(%1053) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc451)
        "ttnn.deallocate"(%1052) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc451)
        "ttnn.deallocate"(%1051) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc451)
        %1055 = "ttnn.slice_static"(%1054) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc451)
        "ttnn.deallocate"(%1054) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc451)
        %1056 = "ttnn.permute"(%1055) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1095)
        "ttnn.deallocate"(%1055) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc1095)
        %1057 = "ttnn.reshape"(%1056) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc452)
        "ttnn.deallocate"(%1056) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc452)
        %1058 = "ttnn.matmul"(%1057, %arg56) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc1096)
        "ttnn.deallocate"(%1057) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1096)
        "ttnn.deallocate"(%arg56) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc1096)
        %1059 = "ttnn.add"(%1058, %9) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1097)
        "ttnn.deallocate"(%1058) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1097)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1097)
        %1060 = "ttnn.add"(%1037, %1059) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc453)
        "ttnn.deallocate"(%1059) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc453)
        "ttnn.deallocate"(%1037) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc453)
        %1061 = "ttnn.layer_norm"(%1060, %arg54, %arg53) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc454)
        "ttnn.deallocate"(%arg54) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc454)
        "ttnn.deallocate"(%arg53) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc454)
        %1062 = "ttnn.reshape"(%1061) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc455)
        "ttnn.deallocate"(%1061) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc455)
        %1063 = "ttnn.matmul"(%1062, %arg52) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc1098)
        "ttnn.deallocate"(%1062) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1098)
        "ttnn.deallocate"(%arg52) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc1098)
        %1064 = "ttnn.add"(%1063, %116) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc1099)
        "ttnn.deallocate"(%1063) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc1099)
        "ttnn.deallocate"(%116) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc1099)
        %1065 = "ttnn.gelu"(%1064) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc1100)
        "ttnn.deallocate"(%1064) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc1100)
        %1066 = "ttnn.reshape"(%1065) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc456)
        "ttnn.deallocate"(%1065) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc456)
        %1067 = "ttnn.matmul"(%1066, %arg50) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc1101)
        "ttnn.deallocate"(%1066) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc1101)
        "ttnn.deallocate"(%arg50) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc1101)
        %1068 = "ttnn.add"(%1067, %130) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1102)
        "ttnn.deallocate"(%1067) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1102)
        "ttnn.deallocate"(%130) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1102)
        %1069 = "ttnn.add"(%1060, %1068) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc457)
        "ttnn.deallocate"(%1068) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc457)
        "ttnn.deallocate"(%1060) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc457)
        %1070 = "ttnn.layer_norm"(%1069, %arg48, %arg47) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc458)
        "ttnn.deallocate"(%arg48) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc458)
        "ttnn.deallocate"(%arg47) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc458)
        %1071 = "ttnn.reshape"(%1070) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc459)
        "ttnn.deallocate"(%1070) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc459)
        %1072 = "ttnn.matmul"(%1071, %4) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc1103)
        "ttnn.deallocate"(%1071) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1103)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc1103)
        %1073 = "ttnn.add"(%1072, %17) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc1104)
        "ttnn.deallocate"(%1072) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc1104)
        "ttnn.deallocate"(%17) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc1104)
        %1074 = "ttnn.slice_static"(%1073) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1105)
        %1075 = "ttnn.slice_static"(%1073) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1106)
        %1076 = "ttnn.slice_static"(%1073) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1107)
        "ttnn.deallocate"(%1073) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc1107)
        %1077 = "ttnn.reshape"(%1074) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1108)
        "ttnn.deallocate"(%1074) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1108)
        %1078 = "ttnn.reshape"(%1075) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1109)
        "ttnn.deallocate"(%1075) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1109)
        %1079 = "ttnn.reshape"(%1076) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1110)
        "ttnn.deallocate"(%1076) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1110)
        %1080 = "ttnn.permute"(%1077) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1111)
        "ttnn.deallocate"(%1077) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1111)
        %1081 = "ttnn.permute"(%1078) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1112)
        "ttnn.deallocate"(%1078) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1112)
        %1082 = "ttnn.permute"(%1079) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1113)
        "ttnn.deallocate"(%1079) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1113)
        %1083 = "ttnn.pad"(%1080) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc460)
        "ttnn.deallocate"(%1080) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc460)
        %1084 = "ttnn.pad"(%1081) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc460)
        "ttnn.deallocate"(%1081) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc460)
        %1085 = "ttnn.pad"(%1082) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc460)
        "ttnn.deallocate"(%1082) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc460)
        %1086 = "ttnn.scaled_dot_product_attention"(%1083, %1084, %1085) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc460)
        "ttnn.deallocate"(%1085) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc460)
        "ttnn.deallocate"(%1084) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc460)
        "ttnn.deallocate"(%1083) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc460)
        %1087 = "ttnn.slice_static"(%1086) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc460)
        "ttnn.deallocate"(%1086) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc460)
        %1088 = "ttnn.permute"(%1087) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1114)
        "ttnn.deallocate"(%1087) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc1114)
        %1089 = "ttnn.reshape"(%1088) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc461)
        "ttnn.deallocate"(%1088) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc461)
        %1090 = "ttnn.matmul"(%1089, %arg44) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc1115)
        "ttnn.deallocate"(%1089) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1115)
        "ttnn.deallocate"(%arg44) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc1115)
        %1091 = "ttnn.add"(%1090, %122) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1116)
        "ttnn.deallocate"(%1090) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1116)
        "ttnn.deallocate"(%122) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1116)
        %1092 = "ttnn.add"(%1069, %1091) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc462)
        "ttnn.deallocate"(%1091) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc462)
        "ttnn.deallocate"(%1069) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc462)
        %1093 = "ttnn.layer_norm"(%1092, %arg42, %arg41) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc463)
        "ttnn.deallocate"(%arg42) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc463)
        "ttnn.deallocate"(%arg41) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc463)
        %1094 = "ttnn.reshape"(%1093) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc464)
        "ttnn.deallocate"(%1093) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc464)
        %1095 = "ttnn.matmul"(%1094, %arg40) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc1117)
        "ttnn.deallocate"(%1094) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1117)
        "ttnn.deallocate"(%arg40) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc1117)
        %1096 = "ttnn.add"(%1095, %15) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc1118)
        "ttnn.deallocate"(%1095) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc1118)
        "ttnn.deallocate"(%15) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc1118)
        %1097 = "ttnn.gelu"(%1096) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc1119)
        "ttnn.deallocate"(%1096) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc1119)
        %1098 = "ttnn.reshape"(%1097) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc465)
        "ttnn.deallocate"(%1097) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc465)
        %1099 = "ttnn.matmul"(%1098, %arg38) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc1120)
        "ttnn.deallocate"(%1098) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc1120)
        "ttnn.deallocate"(%arg38) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc1120)
        %1100 = "ttnn.add"(%1099, %57) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1121)
        "ttnn.deallocate"(%1099) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1121)
        "ttnn.deallocate"(%57) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1121)
        %1101 = "ttnn.add"(%1092, %1100) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc466)
        "ttnn.deallocate"(%1100) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc466)
        "ttnn.deallocate"(%1092) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc466)
        %1102 = "ttnn.layer_norm"(%1101, %arg36, %arg35) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc467)
        "ttnn.deallocate"(%arg36) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc467)
        "ttnn.deallocate"(%arg35) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc467)
        %1103 = "ttnn.reshape"(%1102) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc468)
        "ttnn.deallocate"(%1102) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc468)
        %1104 = "ttnn.matmul"(%1103, %76) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc1122)
        "ttnn.deallocate"(%1103) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1122)
        "ttnn.deallocate"(%76) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc1122)
        %1105 = "ttnn.add"(%1104, %46) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc1123)
        "ttnn.deallocate"(%1104) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc1123)
        "ttnn.deallocate"(%46) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc1123)
        %1106 = "ttnn.slice_static"(%1105) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1124)
        %1107 = "ttnn.slice_static"(%1105) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1125)
        %1108 = "ttnn.slice_static"(%1105) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1126)
        "ttnn.deallocate"(%1105) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc1126)
        %1109 = "ttnn.reshape"(%1106) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1127)
        "ttnn.deallocate"(%1106) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1127)
        %1110 = "ttnn.reshape"(%1107) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1128)
        "ttnn.deallocate"(%1107) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1128)
        %1111 = "ttnn.reshape"(%1108) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1129)
        "ttnn.deallocate"(%1108) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1129)
        %1112 = "ttnn.permute"(%1109) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1130)
        "ttnn.deallocate"(%1109) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1130)
        %1113 = "ttnn.permute"(%1110) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1131)
        "ttnn.deallocate"(%1110) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1131)
        %1114 = "ttnn.permute"(%1111) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1132)
        "ttnn.deallocate"(%1111) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1132)
        %1115 = "ttnn.pad"(%1112) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc469)
        "ttnn.deallocate"(%1112) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc469)
        %1116 = "ttnn.pad"(%1113) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc469)
        "ttnn.deallocate"(%1113) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc469)
        %1117 = "ttnn.pad"(%1114) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc469)
        "ttnn.deallocate"(%1114) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc469)
        %1118 = "ttnn.scaled_dot_product_attention"(%1115, %1116, %1117) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc469)
        "ttnn.deallocate"(%1117) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc469)
        "ttnn.deallocate"(%1116) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc469)
        "ttnn.deallocate"(%1115) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc469)
        %1119 = "ttnn.slice_static"(%1118) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc469)
        "ttnn.deallocate"(%1118) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc469)
        %1120 = "ttnn.permute"(%1119) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1133)
        "ttnn.deallocate"(%1119) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc1133)
        %1121 = "ttnn.reshape"(%1120) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc470)
        "ttnn.deallocate"(%1120) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc470)
        %1122 = "ttnn.matmul"(%1121, %arg32) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc1134)
        "ttnn.deallocate"(%1121) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1134)
        "ttnn.deallocate"(%arg32) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc1134)
        %1123 = "ttnn.add"(%1122, %80) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1135)
        "ttnn.deallocate"(%1122) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1135)
        "ttnn.deallocate"(%80) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1135)
        %1124 = "ttnn.add"(%1101, %1123) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc471)
        "ttnn.deallocate"(%1123) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc471)
        "ttnn.deallocate"(%1101) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc471)
        %1125 = "ttnn.layer_norm"(%1124, %arg30, %arg29) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc472)
        "ttnn.deallocate"(%arg30) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc472)
        "ttnn.deallocate"(%arg29) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc472)
        %1126 = "ttnn.reshape"(%1125) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc473)
        "ttnn.deallocate"(%1125) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc473)
        %1127 = "ttnn.matmul"(%1126, %arg28) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc1136)
        "ttnn.deallocate"(%1126) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1136)
        "ttnn.deallocate"(%arg28) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc1136)
        %1128 = "ttnn.add"(%1127, %39) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc1137)
        "ttnn.deallocate"(%1127) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc1137)
        "ttnn.deallocate"(%39) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc1137)
        %1129 = "ttnn.gelu"(%1128) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc1138)
        "ttnn.deallocate"(%1128) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc1138)
        %1130 = "ttnn.reshape"(%1129) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc474)
        "ttnn.deallocate"(%1129) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc474)
        %1131 = "ttnn.matmul"(%1130, %arg26) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc1139)
        "ttnn.deallocate"(%1130) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc1139)
        "ttnn.deallocate"(%arg26) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc1139)
        %1132 = "ttnn.add"(%1131, %36) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1140)
        "ttnn.deallocate"(%1131) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1140)
        "ttnn.deallocate"(%36) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1140)
        %1133 = "ttnn.add"(%1124, %1132) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc475)
        "ttnn.deallocate"(%1132) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc475)
        "ttnn.deallocate"(%1124) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc475)
        %1134 = "ttnn.layer_norm"(%1133, %arg24, %arg23) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc476)
        "ttnn.deallocate"(%arg24) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc476)
        "ttnn.deallocate"(%arg23) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc476)
        %1135 = "ttnn.reshape"(%1134) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc477)
        "ttnn.deallocate"(%1134) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc477)
        %1136 = "ttnn.matmul"(%1135, %139) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<3840x1280xbf16, #ttnn_layout12>) -> tensor<257x3840xbf16, #ttnn_layout46> loc(#loc1141)
        "ttnn.deallocate"(%1135) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1141)
        "ttnn.deallocate"(%139) <{force = false}> : (tensor<3840x1280xbf16, #ttnn_layout12>) -> () loc(#loc1141)
        %1137 = "ttnn.add"(%1136, %132) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x3840xbf16, #ttnn_layout46>, tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x3840xbf16, #ttnn_layout7> loc(#loc1142)
        "ttnn.deallocate"(%1136) <{force = false}> : (tensor<257x3840xbf16, #ttnn_layout46>) -> () loc(#loc1142)
        "ttnn.deallocate"(%132) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc1142)
        %1138 = "ttnn.slice_static"(%1137) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 257 : i32, 1280 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1143)
        %1139 = "ttnn.slice_static"(%1137) <{begins = [0 : i32, 0 : i32, 1280 : i32], ends = [1 : i32, 257 : i32, 2560 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1144)
        %1140 = "ttnn.slice_static"(%1137) <{begins = [0 : i32, 0 : i32, 2560 : i32], ends = [1 : i32, 257 : i32, 3840 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1145)
        "ttnn.deallocate"(%1137) <{force = false}> : (tensor<1x257x3840xbf16, #ttnn_layout7>) -> () loc(#loc1145)
        %1141 = "ttnn.reshape"(%1138) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1146)
        "ttnn.deallocate"(%1138) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1146)
        %1142 = "ttnn.reshape"(%1139) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1147)
        "ttnn.deallocate"(%1139) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1147)
        %1143 = "ttnn.reshape"(%1140) <{shape = [1 : i32, 257 : i32, 16 : i32, 80 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1148)
        "ttnn.deallocate"(%1140) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1148)
        %1144 = "ttnn.permute"(%1141) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1149)
        "ttnn.deallocate"(%1141) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1149)
        %1145 = "ttnn.permute"(%1142) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1150)
        "ttnn.deallocate"(%1142) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1150)
        %1146 = "ttnn.permute"(%1143) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc1151)
        "ttnn.deallocate"(%1143) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc1151)
        %1147 = "ttnn.pad"(%1144) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc478)
        "ttnn.deallocate"(%1144) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc478)
        %1148 = "ttnn.pad"(%1145) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc478)
        "ttnn.deallocate"(%1145) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc478)
        %1149 = "ttnn.pad"(%1146) <{padding = array<i32: 0, 0, 0, 0, 0, 0, 0, 16>, use_multicore = true, value = 0.000000e+00 : f32}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc478)
        "ttnn.deallocate"(%1146) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc478)
        %1150 = "ttnn.scaled_dot_product_attention"(%1147, %1148, %1149) <{is_causal = false, scale = 0.111803405 : f32}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>, tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x96xbf16, #ttnn_layout48> loc(#loc478)
        "ttnn.deallocate"(%1149) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc478)
        "ttnn.deallocate"(%1148) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc478)
        "ttnn.deallocate"(%1147) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc478)
        %1151 = "ttnn.slice_static"(%1150) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 16 : i32, 257 : i32, 80 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> tensor<1x16x257x80xbf16, #ttnn_layout48> loc(#loc478)
        "ttnn.deallocate"(%1150) <{force = false}> : (tensor<1x16x257x96xbf16, #ttnn_layout48>) -> () loc(#loc478)
        %1152 = "ttnn.permute"(%1151) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> tensor<1x257x16x80xbf16, #ttnn_layout47> loc(#loc1152)
        "ttnn.deallocate"(%1151) <{force = false}> : (tensor<1x16x257x80xbf16, #ttnn_layout48>) -> () loc(#loc1152)
        %1153 = "ttnn.reshape"(%1152) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc479)
        "ttnn.deallocate"(%1152) <{force = false}> : (tensor<1x257x16x80xbf16, #ttnn_layout47>) -> () loc(#loc479)
        %1154 = "ttnn.matmul"(%1153, %arg20) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc1153)
        "ttnn.deallocate"(%1153) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1153)
        "ttnn.deallocate"(%arg20) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc1153)
        %1155 = "ttnn.add"(%1154, %49) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1154)
        "ttnn.deallocate"(%1154) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1154)
        "ttnn.deallocate"(%49) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1154)
        %1156 = "ttnn.add"(%1133, %1155) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc480)
        "ttnn.deallocate"(%1155) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc480)
        "ttnn.deallocate"(%1133) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc480)
        %1157 = "ttnn.layer_norm"(%1156, %arg18, %arg17) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc481)
        "ttnn.deallocate"(%arg18) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc481)
        "ttnn.deallocate"(%arg17) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc481)
        %1158 = "ttnn.reshape"(%1157) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc482)
        "ttnn.deallocate"(%1157) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc482)
        %1159 = "ttnn.matmul"(%1158, %arg16) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc1155)
        "ttnn.deallocate"(%1158) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1155)
        "ttnn.deallocate"(%arg16) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc1155)
        %1160 = "ttnn.add"(%1159, %136) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc1156)
        "ttnn.deallocate"(%1159) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc1156)
        "ttnn.deallocate"(%136) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc1156)
        %1161 = "ttnn.gelu"(%1160) : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<1x257x5120xbf16, #ttnn_layout2> loc(#loc1157)
        "ttnn.deallocate"(%1160) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc1157)
        %1162 = "ttnn.reshape"(%1161) <{shape = [257 : i32, 5120 : i32]}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> tensor<257x5120xbf16, #ttnn_layout49> loc(#loc483)
        "ttnn.deallocate"(%1161) <{force = false}> : (tensor<1x257x5120xbf16, #ttnn_layout2>) -> () loc(#loc483)
        %1163 = "ttnn.matmul"(%1162, %arg14) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x5120xbf16, #ttnn_layout49>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc1158)
        "ttnn.deallocate"(%1162) <{force = false}> : (tensor<257x5120xbf16, #ttnn_layout49>) -> () loc(#loc1158)
        "ttnn.deallocate"(%arg14) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc1158)
        %1164 = "ttnn.add"(%1163, %55) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1159)
        "ttnn.deallocate"(%1163) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1159)
        "ttnn.deallocate"(%55) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1159)
        %1165 = "ttnn.add"(%1156, %1164) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc484)
        "ttnn.deallocate"(%1164) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc484)
        "ttnn.deallocate"(%1156) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc484)
        %1166 = "ttnn.reshape"(%1165) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc484)
        "ttnn.deallocate"(%1165) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc484)
        %1167 = "ttnn.matmul"(%1166, %arg12) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc1160)
        "ttnn.deallocate"(%1166) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1160)
        "ttnn.deallocate"(%arg12) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc1160)
        %1168 = "ttnn.add"(%1167, %138) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc1161)
        "ttnn.deallocate"(%1167) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc1161)
        "ttnn.deallocate"(%138) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc1161)
        %1169 = "ttnn.layer_norm"(%1168, %arg10, %arg9) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc485)
        "ttnn.deallocate"(%arg10) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc485)
        "ttnn.deallocate"(%arg9) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc485)
        %1170 = "ttnn.reshape"(%1169) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc39)
        "ttnn.deallocate"(%1169) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc39)
        %1171 = "ttnn.concat"(%1170, %31#0) <{dim = 0 : si32}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<16x1280xbf16, #ttnn_layout19>) -> tensor<273x1280xbf16, #ttnn_layout45> loc(#loc39)
        "ttnn.deallocate"(%1170) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc39)
        "ttnn.deallocate"(%31#0) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc39)
        %1172 = "ttnn.matmul"(%1171, %arg516) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<273x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<273x1280xbf16, #ttnn_layout45> loc(#loc486)
        "ttnn.deallocate"(%arg516) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc486)
        %1173 = "ttnn.typecast"(%1172) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<273x1280xbf16, #ttnn_layout45>) -> tensor<273x1280xf32, #ttnn_layout50> loc(#loc487)
        "ttnn.deallocate"(%1172) <{force = false}> : (tensor<273x1280xbf16, #ttnn_layout45>) -> () loc(#loc487)
        %1174 = "ttnn.reshape"(%1173) <{shape = [1 : i32, 273 : i32, 20 : i32, 64 : i32]}> : (tensor<273x1280xf32, #ttnn_layout50>) -> tensor<1x273x20x64xf32, #ttnn_layout51> loc(#loc487)
        "ttnn.deallocate"(%1173) <{force = false}> : (tensor<273x1280xf32, #ttnn_layout50>) -> () loc(#loc487)
        %1175 = "ttnn.permute"(%1174) <{permutation = array<i64: 0, 2, 3, 1>}> : (tensor<1x273x20x64xf32, #ttnn_layout51>) -> tensor<1x20x64x273xf32, #ttnn_layout52> loc(#loc487)
        "ttnn.deallocate"(%1174) <{force = false}> : (tensor<1x273x20x64xf32, #ttnn_layout51>) -> () loc(#loc487)
        %1176 = "ttnn.matmul"(%1171, %arg6) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<273x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<273x1280xbf16, #ttnn_layout45> loc(#loc488)
        "ttnn.deallocate"(%1171) <{force = false}> : (tensor<273x1280xbf16, #ttnn_layout45>) -> () loc(#loc488)
        "ttnn.deallocate"(%arg6) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc488)
        %1177 = "ttnn.typecast"(%1176) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<273x1280xbf16, #ttnn_layout45>) -> tensor<273x1280xf32, #ttnn_layout50> loc(#loc489)
        "ttnn.deallocate"(%1176) <{force = false}> : (tensor<273x1280xbf16, #ttnn_layout45>) -> () loc(#loc489)
        %1178 = "ttnn.reshape"(%1177) <{shape = [1 : i32, 273 : i32, 20 : i32, 64 : i32]}> : (tensor<273x1280xf32, #ttnn_layout50>) -> tensor<1x273x20x64xf32, #ttnn_layout51> loc(#loc489)
        "ttnn.deallocate"(%1177) <{force = false}> : (tensor<273x1280xf32, #ttnn_layout50>) -> () loc(#loc489)
        %1179 = "ttnn.permute"(%1178) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x273x20x64xf32, #ttnn_layout51>) -> tensor<1x20x273x64xf32, #ttnn_layout53> loc(#loc489)
        "ttnn.deallocate"(%1178) <{force = false}> : (tensor<1x273x20x64xf32, #ttnn_layout51>) -> () loc(#loc489)
        %1180 = "ttnn.permute"(%1175) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x20x64x273xf32, #ttnn_layout52>) -> tensor<1x20x273x64xf32, #ttnn_layout53> loc(#loc490)
        "ttnn.deallocate"(%1175) <{force = false}> : (tensor<1x20x64x273xf32, #ttnn_layout52>) -> () loc(#loc490)
        %1181 = "ttnn.typecast"(%1180) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x20x273x64xf32, #ttnn_layout53>) -> tensor<1x20x273x64xbf16, #ttnn_layout54> loc(#loc490)
        "ttnn.deallocate"(%1180) <{force = false}> : (tensor<1x20x273x64xf32, #ttnn_layout53>) -> () loc(#loc490)
        %1182 = "ttnn.typecast"(%1179) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x20x273x64xf32, #ttnn_layout53>) -> tensor<1x20x273x64xbf16, #ttnn_layout54> loc(#loc489)
        "ttnn.deallocate"(%1179) <{force = false}> : (tensor<1x20x273x64xf32, #ttnn_layout53>) -> () loc(#loc489)
        %1183 = "ttnn.scaled_dot_product_attention"(%31#1, %1181, %1182) <{is_causal = false, scale = 0.353553385 : f32}> : (tensor<1x20x16x64xbf16, #ttnn_layout20>, tensor<1x20x273x64xbf16, #ttnn_layout54>, tensor<1x20x273x64xbf16, #ttnn_layout54>) -> tensor<1x20x16x64xbf16, #ttnn_layout20> loc(#loc490)
        "ttnn.deallocate"(%1182) <{force = false}> : (tensor<1x20x273x64xbf16, #ttnn_layout54>) -> () loc(#loc490)
        "ttnn.deallocate"(%1181) <{force = false}> : (tensor<1x20x273x64xbf16, #ttnn_layout54>) -> () loc(#loc490)
        "ttnn.deallocate"(%31#1) <{force = false}> : (tensor<1x20x16x64xbf16, #ttnn_layout20>) -> () loc(#loc490)
        %1184 = "ttnn.concatenate_heads"(%1183) : (tensor<1x20x16x64xbf16, #ttnn_layout20>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc491)
        "ttnn.deallocate"(%1183) <{force = false}> : (tensor<1x20x16x64xbf16, #ttnn_layout20>) -> () loc(#loc491)
        %1185 = "ttnn.reshape"(%1184) <{shape = [16 : i32, 1280 : i32]}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc491)
        "ttnn.deallocate"(%1184) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc491)
        %1186 = "ttnn.matmul"(%1185, %arg5) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<16x1280xbf16, #ttnn_layout19>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc492)
        "ttnn.deallocate"(%1185) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc492)
        "ttnn.deallocate"(%arg5) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc492)
        %1187 = "ttnn.reshape"(%1186) <{shape = [1 : i32, 16 : i32, 1280 : i32]}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc493)
        "ttnn.deallocate"(%1186) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc493)
        %1188 = "ttnn.divide"(%1187, %0) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x16x1280xbf16, #ttnn_layout>, tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc494)
        "ttnn.deallocate"(%1187) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc494)
        %1189 = "ttnn.add"(%1188, %arg4) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x16x1280xbf16, #ttnn_layout>, tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc495)
        "ttnn.deallocate"(%1188) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc495)
        "ttnn.deallocate"(%arg4) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc495)
        %1190 = "ttnn.layer_norm"(%1189, %arg521, %arg520) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x16x1280xbf16, #ttnn_layout>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc496)
        "ttnn.deallocate"(%arg521) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc496)
        "ttnn.deallocate"(%arg520) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc496)
        %1191 = "ttnn.reshape"(%1190) <{shape = [16 : i32, 1280 : i32]}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc497)
        "ttnn.deallocate"(%1190) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc497)
        %1192 = "ttnn.matmul"(%1191, %arg519) <{activation = "gelu", compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<16x1280xbf16, #ttnn_layout19>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<16x5120xbf16, #ttnn_layout55> loc(#loc498)
        "ttnn.deallocate"(%1191) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc498)
        "ttnn.deallocate"(%arg519) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc498)
        %1193 = "ttnn.matmul"(%1192, %arg518) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<16x5120xbf16, #ttnn_layout55>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc499)
        "ttnn.deallocate"(%1192) <{force = false}> : (tensor<16x5120xbf16, #ttnn_layout55>) -> () loc(#loc499)
        "ttnn.deallocate"(%arg518) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc499)
        %1194 = "ttnn.reshape"(%1193) <{shape = [1 : i32, 16 : i32, 1280 : i32]}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc500)
        "ttnn.deallocate"(%1193) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc500)
        %1195 = "ttnn.add"(%1194, %1189) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x16x1280xbf16, #ttnn_layout>, tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc501)
        "ttnn.deallocate"(%1194) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc501)
        "ttnn.deallocate"(%1189) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc501)
        %1196 = "ttnn.layer_norm"(%1195, %arg525, %arg524) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x16x1280xbf16, #ttnn_layout>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc502)
        "ttnn.deallocate"(%arg525) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc502)
        "ttnn.deallocate"(%arg524) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc502)
        %1197 = "ttnn.reshape"(%1196) <{shape = [16 : i32, 1280 : i32]}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc503)
        %1198 = "ttnn.matmul"(%1197, %arg529) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<16x1280xbf16, #ttnn_layout19>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc504)
        "ttnn.deallocate"(%1197) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc504)
        "ttnn.deallocate"(%arg529) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc504)
        %1199 = "ttnn.typecast"(%1198) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> tensor<16x1280xf32, #ttnn_layout56> loc(#loc505)
        "ttnn.deallocate"(%1198) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc505)
        %1200 = "ttnn.reshape"(%1199) <{shape = [1 : i32, 16 : i32, 20 : i32, 64 : i32]}> : (tensor<16x1280xf32, #ttnn_layout56>) -> tensor<1x16x20x64xf32, #ttnn_layout57> loc(#loc505)
        "ttnn.deallocate"(%1199) <{force = false}> : (tensor<16x1280xf32, #ttnn_layout56>) -> () loc(#loc505)
        %1201 = "ttnn.permute"(%1200) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x20x64xf32, #ttnn_layout57>) -> tensor<1x20x16x64xf32, #ttnn_layout21> loc(#loc505)
        "ttnn.deallocate"(%1200) <{force = false}> : (tensor<1x16x20x64xf32, #ttnn_layout57>) -> () loc(#loc505)
        %1202 = "ttnn.layer_norm"(%1168, %arg527, %arg526) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc506)
        "ttnn.deallocate"(%arg527) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc506)
        "ttnn.deallocate"(%arg526) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc506)
        %1203 = "ttnn.reshape"(%1202) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc507)
        "ttnn.deallocate"(%1202) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc507)
        %1204 = "ttnn.reshape"(%1196) <{shape = [16 : i32, 1280 : i32]}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc507)
        "ttnn.deallocate"(%1196) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc507)
        %1205 = "ttnn.concat"(%1203, %1204) <{dim = 0 : si32}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<16x1280xbf16, #ttnn_layout19>) -> tensor<273x1280xbf16, #ttnn_layout45> loc(#loc507)
        "ttnn.deallocate"(%1204) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc507)
        "ttnn.deallocate"(%1203) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc507)
        %1206 = "ttnn.matmul"(%1205, %arg528) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<273x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<273x1280xbf16, #ttnn_layout45> loc(#loc508)
        "ttnn.deallocate"(%arg528) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc508)
        %1207 = "ttnn.typecast"(%1206) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<273x1280xbf16, #ttnn_layout45>) -> tensor<273x1280xf32, #ttnn_layout50> loc(#loc509)
        "ttnn.deallocate"(%1206) <{force = false}> : (tensor<273x1280xbf16, #ttnn_layout45>) -> () loc(#loc509)
        %1208 = "ttnn.reshape"(%1207) <{shape = [1 : i32, 273 : i32, 20 : i32, 64 : i32]}> : (tensor<273x1280xf32, #ttnn_layout50>) -> tensor<1x273x20x64xf32, #ttnn_layout51> loc(#loc509)
        "ttnn.deallocate"(%1207) <{force = false}> : (tensor<273x1280xf32, #ttnn_layout50>) -> () loc(#loc509)
        %1209 = "ttnn.permute"(%1208) <{permutation = array<i64: 0, 2, 3, 1>}> : (tensor<1x273x20x64xf32, #ttnn_layout51>) -> tensor<1x20x64x273xf32, #ttnn_layout52> loc(#loc509)
        "ttnn.deallocate"(%1208) <{force = false}> : (tensor<1x273x20x64xf32, #ttnn_layout51>) -> () loc(#loc509)
        %1210 = "ttnn.matmul"(%1205, %arg523) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<273x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<273x1280xbf16, #ttnn_layout45> loc(#loc510)
        "ttnn.deallocate"(%1205) <{force = false}> : (tensor<273x1280xbf16, #ttnn_layout45>) -> () loc(#loc510)
        "ttnn.deallocate"(%arg523) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc510)
        %1211 = "ttnn.typecast"(%1210) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<273x1280xbf16, #ttnn_layout45>) -> tensor<273x1280xf32, #ttnn_layout50> loc(#loc511)
        "ttnn.deallocate"(%1210) <{force = false}> : (tensor<273x1280xbf16, #ttnn_layout45>) -> () loc(#loc511)
        %1212 = "ttnn.reshape"(%1211) <{shape = [1 : i32, 273 : i32, 20 : i32, 64 : i32]}> : (tensor<273x1280xf32, #ttnn_layout50>) -> tensor<1x273x20x64xf32, #ttnn_layout51> loc(#loc511)
        "ttnn.deallocate"(%1211) <{force = false}> : (tensor<273x1280xf32, #ttnn_layout50>) -> () loc(#loc511)
        %1213 = "ttnn.permute"(%1212) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x273x20x64xf32, #ttnn_layout51>) -> tensor<1x20x273x64xf32, #ttnn_layout53> loc(#loc511)
        "ttnn.deallocate"(%1212) <{force = false}> : (tensor<1x273x20x64xf32, #ttnn_layout51>) -> () loc(#loc511)
        %1214 = "ttnn.typecast"(%1201) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x20x16x64xf32, #ttnn_layout21>) -> tensor<1x20x16x64xbf16, #ttnn_layout20> loc(#loc505)
        "ttnn.deallocate"(%1201) <{force = false}> : (tensor<1x20x16x64xf32, #ttnn_layout21>) -> () loc(#loc505)
        %1215 = "ttnn.permute"(%1209) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x20x64x273xf32, #ttnn_layout52>) -> tensor<1x20x273x64xf32, #ttnn_layout53> loc(#loc512)
        "ttnn.deallocate"(%1209) <{force = false}> : (tensor<1x20x64x273xf32, #ttnn_layout52>) -> () loc(#loc512)
        %1216 = "ttnn.typecast"(%1215) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x20x273x64xf32, #ttnn_layout53>) -> tensor<1x20x273x64xbf16, #ttnn_layout54> loc(#loc512)
        "ttnn.deallocate"(%1215) <{force = false}> : (tensor<1x20x273x64xf32, #ttnn_layout53>) -> () loc(#loc512)
        %1217 = "ttnn.typecast"(%1213) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x20x273x64xf32, #ttnn_layout53>) -> tensor<1x20x273x64xbf16, #ttnn_layout54> loc(#loc511)
        "ttnn.deallocate"(%1213) <{force = false}> : (tensor<1x20x273x64xf32, #ttnn_layout53>) -> () loc(#loc511)
        %1218 = "ttnn.scaled_dot_product_attention"(%1214, %1216, %1217) <{is_causal = false, scale = 0.124999993 : f32}> : (tensor<1x20x16x64xbf16, #ttnn_layout20>, tensor<1x20x273x64xbf16, #ttnn_layout54>, tensor<1x20x273x64xbf16, #ttnn_layout54>) -> tensor<1x20x16x64xbf16, #ttnn_layout20> loc(#loc512)
        "ttnn.deallocate"(%1217) <{force = false}> : (tensor<1x20x273x64xbf16, #ttnn_layout54>) -> () loc(#loc512)
        "ttnn.deallocate"(%1216) <{force = false}> : (tensor<1x20x273x64xbf16, #ttnn_layout54>) -> () loc(#loc512)
        "ttnn.deallocate"(%1214) <{force = false}> : (tensor<1x20x16x64xbf16, #ttnn_layout20>) -> () loc(#loc512)
        %1219 = "ttnn.concatenate_heads"(%1218) : (tensor<1x20x16x64xbf16, #ttnn_layout20>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc513)
        "ttnn.deallocate"(%1218) <{force = false}> : (tensor<1x20x16x64xbf16, #ttnn_layout20>) -> () loc(#loc513)
        %1220 = "ttnn.reshape"(%1219) <{shape = [16 : i32, 1280 : i32]}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc513)
        "ttnn.deallocate"(%1219) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc513)
        %1221 = "ttnn.matmul"(%1220, %arg522) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<16x1280xbf16, #ttnn_layout19>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc514)
        "ttnn.deallocate"(%1220) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc514)
        "ttnn.deallocate"(%arg522) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc514)
        %1222 = "ttnn.reshape"(%1221) <{shape = [1 : i32, 16 : i32, 1280 : i32]}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc515)
        "ttnn.deallocate"(%1221) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc515)
        %1223 = "ttnn.divide"(%1222, %0) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x16x1280xbf16, #ttnn_layout>, tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc516)
        "ttnn.deallocate"(%1222) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc516)
        %1224 = "ttnn.add"(%1223, %1195) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x16x1280xbf16, #ttnn_layout>, tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc517)
        "ttnn.deallocate"(%1223) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc517)
        "ttnn.deallocate"(%1195) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc517)
        %1225 = "ttnn.layer_norm"(%1224, %arg533, %arg532) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x16x1280xbf16, #ttnn_layout>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc518)
        "ttnn.deallocate"(%arg533) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc518)
        "ttnn.deallocate"(%arg532) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc518)
        %1226 = "ttnn.reshape"(%1225) <{shape = [16 : i32, 1280 : i32]}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc519)
        "ttnn.deallocate"(%1225) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc519)
        %1227 = "ttnn.matmul"(%1226, %arg531) <{activation = "gelu", compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<16x1280xbf16, #ttnn_layout19>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<16x5120xbf16, #ttnn_layout55> loc(#loc520)
        "ttnn.deallocate"(%1226) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc520)
        "ttnn.deallocate"(%arg531) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc520)
        %1228 = "ttnn.matmul"(%1227, %arg530) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<16x5120xbf16, #ttnn_layout55>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc521)
        "ttnn.deallocate"(%1227) <{force = false}> : (tensor<16x5120xbf16, #ttnn_layout55>) -> () loc(#loc521)
        "ttnn.deallocate"(%arg530) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc521)
        %1229 = "ttnn.reshape"(%1228) <{shape = [1 : i32, 16 : i32, 1280 : i32]}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc522)
        "ttnn.deallocate"(%1228) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc522)
        %1230 = "ttnn.add"(%1229, %1224) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x16x1280xbf16, #ttnn_layout>, tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc523)
        "ttnn.deallocate"(%1229) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc523)
        "ttnn.deallocate"(%1224) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc523)
        %1231 = "ttnn.layer_norm"(%1230, %arg537, %arg536) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x16x1280xbf16, #ttnn_layout>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc524)
        "ttnn.deallocate"(%arg537) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc524)
        "ttnn.deallocate"(%arg536) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc524)
        %1232 = "ttnn.reshape"(%1231) <{shape = [16 : i32, 1280 : i32]}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc525)
        %1233 = "ttnn.matmul"(%1232, %arg541) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<16x1280xbf16, #ttnn_layout19>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc526)
        "ttnn.deallocate"(%1232) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc526)
        "ttnn.deallocate"(%arg541) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc526)
        %1234 = "ttnn.typecast"(%1233) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> tensor<16x1280xf32, #ttnn_layout56> loc(#loc527)
        "ttnn.deallocate"(%1233) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc527)
        %1235 = "ttnn.reshape"(%1234) <{shape = [1 : i32, 16 : i32, 20 : i32, 64 : i32]}> : (tensor<16x1280xf32, #ttnn_layout56>) -> tensor<1x16x20x64xf32, #ttnn_layout57> loc(#loc527)
        "ttnn.deallocate"(%1234) <{force = false}> : (tensor<16x1280xf32, #ttnn_layout56>) -> () loc(#loc527)
        %1236 = "ttnn.permute"(%1235) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x20x64xf32, #ttnn_layout57>) -> tensor<1x20x16x64xf32, #ttnn_layout21> loc(#loc527)
        "ttnn.deallocate"(%1235) <{force = false}> : (tensor<1x16x20x64xf32, #ttnn_layout57>) -> () loc(#loc527)
        %1237 = "ttnn.layer_norm"(%1168, %arg539, %arg538) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc528)
        "ttnn.deallocate"(%arg539) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc528)
        "ttnn.deallocate"(%arg538) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc528)
        %1238 = "ttnn.reshape"(%1237) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc529)
        "ttnn.deallocate"(%1237) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc529)
        %1239 = "ttnn.reshape"(%1231) <{shape = [16 : i32, 1280 : i32]}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc529)
        "ttnn.deallocate"(%1231) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc529)
        %1240 = "ttnn.concat"(%1238, %1239) <{dim = 0 : si32}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<16x1280xbf16, #ttnn_layout19>) -> tensor<273x1280xbf16, #ttnn_layout45> loc(#loc529)
        "ttnn.deallocate"(%1239) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc529)
        "ttnn.deallocate"(%1238) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc529)
        %1241 = "ttnn.matmul"(%1240, %arg540) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<273x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<273x1280xbf16, #ttnn_layout45> loc(#loc530)
        "ttnn.deallocate"(%arg540) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc530)
        %1242 = "ttnn.typecast"(%1241) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<273x1280xbf16, #ttnn_layout45>) -> tensor<273x1280xf32, #ttnn_layout50> loc(#loc531)
        "ttnn.deallocate"(%1241) <{force = false}> : (tensor<273x1280xbf16, #ttnn_layout45>) -> () loc(#loc531)
        %1243 = "ttnn.reshape"(%1242) <{shape = [1 : i32, 273 : i32, 20 : i32, 64 : i32]}> : (tensor<273x1280xf32, #ttnn_layout50>) -> tensor<1x273x20x64xf32, #ttnn_layout51> loc(#loc531)
        "ttnn.deallocate"(%1242) <{force = false}> : (tensor<273x1280xf32, #ttnn_layout50>) -> () loc(#loc531)
        %1244 = "ttnn.permute"(%1243) <{permutation = array<i64: 0, 2, 3, 1>}> : (tensor<1x273x20x64xf32, #ttnn_layout51>) -> tensor<1x20x64x273xf32, #ttnn_layout52> loc(#loc531)
        "ttnn.deallocate"(%1243) <{force = false}> : (tensor<1x273x20x64xf32, #ttnn_layout51>) -> () loc(#loc531)
        %1245 = "ttnn.matmul"(%1240, %arg535) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<273x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<273x1280xbf16, #ttnn_layout45> loc(#loc532)
        "ttnn.deallocate"(%1240) <{force = false}> : (tensor<273x1280xbf16, #ttnn_layout45>) -> () loc(#loc532)
        "ttnn.deallocate"(%arg535) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc532)
        %1246 = "ttnn.typecast"(%1245) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<273x1280xbf16, #ttnn_layout45>) -> tensor<273x1280xf32, #ttnn_layout50> loc(#loc533)
        "ttnn.deallocate"(%1245) <{force = false}> : (tensor<273x1280xbf16, #ttnn_layout45>) -> () loc(#loc533)
        %1247 = "ttnn.reshape"(%1246) <{shape = [1 : i32, 273 : i32, 20 : i32, 64 : i32]}> : (tensor<273x1280xf32, #ttnn_layout50>) -> tensor<1x273x20x64xf32, #ttnn_layout51> loc(#loc533)
        "ttnn.deallocate"(%1246) <{force = false}> : (tensor<273x1280xf32, #ttnn_layout50>) -> () loc(#loc533)
        %1248 = "ttnn.permute"(%1247) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x273x20x64xf32, #ttnn_layout51>) -> tensor<1x20x273x64xf32, #ttnn_layout53> loc(#loc533)
        "ttnn.deallocate"(%1247) <{force = false}> : (tensor<1x273x20x64xf32, #ttnn_layout51>) -> () loc(#loc533)
        %1249 = "ttnn.typecast"(%1236) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x20x16x64xf32, #ttnn_layout21>) -> tensor<1x20x16x64xbf16, #ttnn_layout20> loc(#loc527)
        "ttnn.deallocate"(%1236) <{force = false}> : (tensor<1x20x16x64xf32, #ttnn_layout21>) -> () loc(#loc527)
        %1250 = "ttnn.permute"(%1244) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x20x64x273xf32, #ttnn_layout52>) -> tensor<1x20x273x64xf32, #ttnn_layout53> loc(#loc534)
        "ttnn.deallocate"(%1244) <{force = false}> : (tensor<1x20x64x273xf32, #ttnn_layout52>) -> () loc(#loc534)
        %1251 = "ttnn.typecast"(%1250) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x20x273x64xf32, #ttnn_layout53>) -> tensor<1x20x273x64xbf16, #ttnn_layout54> loc(#loc534)
        "ttnn.deallocate"(%1250) <{force = false}> : (tensor<1x20x273x64xf32, #ttnn_layout53>) -> () loc(#loc534)
        %1252 = "ttnn.typecast"(%1248) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x20x273x64xf32, #ttnn_layout53>) -> tensor<1x20x273x64xbf16, #ttnn_layout54> loc(#loc533)
        "ttnn.deallocate"(%1248) <{force = false}> : (tensor<1x20x273x64xf32, #ttnn_layout53>) -> () loc(#loc533)
        %1253 = "ttnn.scaled_dot_product_attention"(%1249, %1251, %1252) <{is_causal = false, scale = 0.124999993 : f32}> : (tensor<1x20x16x64xbf16, #ttnn_layout20>, tensor<1x20x273x64xbf16, #ttnn_layout54>, tensor<1x20x273x64xbf16, #ttnn_layout54>) -> tensor<1x20x16x64xbf16, #ttnn_layout20> loc(#loc534)
        "ttnn.deallocate"(%1252) <{force = false}> : (tensor<1x20x273x64xbf16, #ttnn_layout54>) -> () loc(#loc534)
        "ttnn.deallocate"(%1251) <{force = false}> : (tensor<1x20x273x64xbf16, #ttnn_layout54>) -> () loc(#loc534)
        "ttnn.deallocate"(%1249) <{force = false}> : (tensor<1x20x16x64xbf16, #ttnn_layout20>) -> () loc(#loc534)
        %1254 = "ttnn.concatenate_heads"(%1253) : (tensor<1x20x16x64xbf16, #ttnn_layout20>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc535)
        "ttnn.deallocate"(%1253) <{force = false}> : (tensor<1x20x16x64xbf16, #ttnn_layout20>) -> () loc(#loc535)
        %1255 = "ttnn.reshape"(%1254) <{shape = [16 : i32, 1280 : i32]}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc535)
        "ttnn.deallocate"(%1254) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc535)
        %1256 = "ttnn.matmul"(%1255, %arg534) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<16x1280xbf16, #ttnn_layout19>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc536)
        "ttnn.deallocate"(%1255) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc536)
        "ttnn.deallocate"(%arg534) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc536)
        %1257 = "ttnn.reshape"(%1256) <{shape = [1 : i32, 16 : i32, 1280 : i32]}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc537)
        "ttnn.deallocate"(%1256) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc537)
        %1258 = "ttnn.divide"(%1257, %0) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x16x1280xbf16, #ttnn_layout>, tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc538)
        "ttnn.deallocate"(%1257) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc538)
        %1259 = "ttnn.add"(%1258, %1230) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x16x1280xbf16, #ttnn_layout>, tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc539)
        "ttnn.deallocate"(%1258) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc539)
        "ttnn.deallocate"(%1230) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc539)
        %1260 = "ttnn.layer_norm"(%1259, %arg545, %arg544) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x16x1280xbf16, #ttnn_layout>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc540)
        "ttnn.deallocate"(%arg545) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc540)
        "ttnn.deallocate"(%arg544) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc540)
        %1261 = "ttnn.reshape"(%1260) <{shape = [16 : i32, 1280 : i32]}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc541)
        "ttnn.deallocate"(%1260) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc541)
        %1262 = "ttnn.matmul"(%1261, %arg543) <{activation = "gelu", compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<16x1280xbf16, #ttnn_layout19>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<16x5120xbf16, #ttnn_layout55> loc(#loc542)
        "ttnn.deallocate"(%1261) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc542)
        "ttnn.deallocate"(%arg543) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc542)
        %1263 = "ttnn.matmul"(%1262, %arg542) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<16x5120xbf16, #ttnn_layout55>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc543)
        "ttnn.deallocate"(%1262) <{force = false}> : (tensor<16x5120xbf16, #ttnn_layout55>) -> () loc(#loc543)
        "ttnn.deallocate"(%arg542) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc543)
        %1264 = "ttnn.reshape"(%1263) <{shape = [1 : i32, 16 : i32, 1280 : i32]}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc544)
        "ttnn.deallocate"(%1263) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc544)
        %1265 = "ttnn.add"(%1264, %1259) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x16x1280xbf16, #ttnn_layout>, tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc545)
        "ttnn.deallocate"(%1264) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc545)
        "ttnn.deallocate"(%1259) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc545)
        %1266 = "ttnn.layer_norm"(%1265, %arg549, %arg548) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x16x1280xbf16, #ttnn_layout>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc546)
        "ttnn.deallocate"(%arg549) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc546)
        "ttnn.deallocate"(%arg548) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc546)
        %1267 = "ttnn.reshape"(%1266) <{shape = [16 : i32, 1280 : i32]}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc547)
        %1268 = "ttnn.matmul"(%1267, %arg553) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<16x1280xbf16, #ttnn_layout19>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc548)
        "ttnn.deallocate"(%1267) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc548)
        "ttnn.deallocate"(%arg553) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc548)
        %1269 = "ttnn.typecast"(%1268) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> tensor<16x1280xf32, #ttnn_layout56> loc(#loc549)
        "ttnn.deallocate"(%1268) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc549)
        %1270 = "ttnn.reshape"(%1269) <{shape = [1 : i32, 16 : i32, 20 : i32, 64 : i32]}> : (tensor<16x1280xf32, #ttnn_layout56>) -> tensor<1x16x20x64xf32, #ttnn_layout57> loc(#loc549)
        "ttnn.deallocate"(%1269) <{force = false}> : (tensor<16x1280xf32, #ttnn_layout56>) -> () loc(#loc549)
        %1271 = "ttnn.permute"(%1270) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x16x20x64xf32, #ttnn_layout57>) -> tensor<1x20x16x64xf32, #ttnn_layout21> loc(#loc549)
        "ttnn.deallocate"(%1270) <{force = false}> : (tensor<1x16x20x64xf32, #ttnn_layout57>) -> () loc(#loc549)
        %1272 = "ttnn.layer_norm"(%1168, %arg551, %arg550) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x257x1280xbf16, #ttnn_layout10>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x257x1280xbf16, #ttnn_layout10> loc(#loc550)
        "ttnn.deallocate"(%1168) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc550)
        "ttnn.deallocate"(%arg551) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc550)
        "ttnn.deallocate"(%arg550) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc550)
        %1273 = "ttnn.reshape"(%1272) <{shape = [257 : i32, 1280 : i32]}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> tensor<257x1280xbf16, #ttnn_layout45> loc(#loc551)
        "ttnn.deallocate"(%1272) <{force = false}> : (tensor<1x257x1280xbf16, #ttnn_layout10>) -> () loc(#loc551)
        %1274 = "ttnn.reshape"(%1266) <{shape = [16 : i32, 1280 : i32]}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc551)
        "ttnn.deallocate"(%1266) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc551)
        %1275 = "ttnn.concat"(%1273, %1274) <{dim = 0 : si32}> : (tensor<257x1280xbf16, #ttnn_layout45>, tensor<16x1280xbf16, #ttnn_layout19>) -> tensor<273x1280xbf16, #ttnn_layout45> loc(#loc551)
        "ttnn.deallocate"(%1274) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc551)
        "ttnn.deallocate"(%1273) <{force = false}> : (tensor<257x1280xbf16, #ttnn_layout45>) -> () loc(#loc551)
        %1276 = "ttnn.matmul"(%1275, %arg552) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<273x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<273x1280xbf16, #ttnn_layout45> loc(#loc552)
        "ttnn.deallocate"(%arg552) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc552)
        %1277 = "ttnn.typecast"(%1276) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<273x1280xbf16, #ttnn_layout45>) -> tensor<273x1280xf32, #ttnn_layout50> loc(#loc553)
        "ttnn.deallocate"(%1276) <{force = false}> : (tensor<273x1280xbf16, #ttnn_layout45>) -> () loc(#loc553)
        %1278 = "ttnn.reshape"(%1277) <{shape = [1 : i32, 273 : i32, 20 : i32, 64 : i32]}> : (tensor<273x1280xf32, #ttnn_layout50>) -> tensor<1x273x20x64xf32, #ttnn_layout51> loc(#loc553)
        "ttnn.deallocate"(%1277) <{force = false}> : (tensor<273x1280xf32, #ttnn_layout50>) -> () loc(#loc553)
        %1279 = "ttnn.permute"(%1278) <{permutation = array<i64: 0, 2, 3, 1>}> : (tensor<1x273x20x64xf32, #ttnn_layout51>) -> tensor<1x20x64x273xf32, #ttnn_layout52> loc(#loc553)
        "ttnn.deallocate"(%1278) <{force = false}> : (tensor<1x273x20x64xf32, #ttnn_layout51>) -> () loc(#loc553)
        %1280 = "ttnn.matmul"(%1275, %arg547) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<273x1280xbf16, #ttnn_layout45>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<273x1280xbf16, #ttnn_layout45> loc(#loc554)
        "ttnn.deallocate"(%1275) <{force = false}> : (tensor<273x1280xbf16, #ttnn_layout45>) -> () loc(#loc554)
        "ttnn.deallocate"(%arg547) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc554)
        %1281 = "ttnn.typecast"(%1280) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<273x1280xbf16, #ttnn_layout45>) -> tensor<273x1280xf32, #ttnn_layout50> loc(#loc555)
        "ttnn.deallocate"(%1280) <{force = false}> : (tensor<273x1280xbf16, #ttnn_layout45>) -> () loc(#loc555)
        %1282 = "ttnn.reshape"(%1281) <{shape = [1 : i32, 273 : i32, 20 : i32, 64 : i32]}> : (tensor<273x1280xf32, #ttnn_layout50>) -> tensor<1x273x20x64xf32, #ttnn_layout51> loc(#loc555)
        "ttnn.deallocate"(%1281) <{force = false}> : (tensor<273x1280xf32, #ttnn_layout50>) -> () loc(#loc555)
        %1283 = "ttnn.permute"(%1282) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x273x20x64xf32, #ttnn_layout51>) -> tensor<1x20x273x64xf32, #ttnn_layout53> loc(#loc555)
        "ttnn.deallocate"(%1282) <{force = false}> : (tensor<1x273x20x64xf32, #ttnn_layout51>) -> () loc(#loc555)
        %1284 = "ttnn.typecast"(%1271) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x20x16x64xf32, #ttnn_layout21>) -> tensor<1x20x16x64xbf16, #ttnn_layout20> loc(#loc549)
        "ttnn.deallocate"(%1271) <{force = false}> : (tensor<1x20x16x64xf32, #ttnn_layout21>) -> () loc(#loc549)
        %1285 = "ttnn.permute"(%1279) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x20x64x273xf32, #ttnn_layout52>) -> tensor<1x20x273x64xf32, #ttnn_layout53> loc(#loc556)
        "ttnn.deallocate"(%1279) <{force = false}> : (tensor<1x20x64x273xf32, #ttnn_layout52>) -> () loc(#loc556)
        %1286 = "ttnn.typecast"(%1285) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x20x273x64xf32, #ttnn_layout53>) -> tensor<1x20x273x64xbf16, #ttnn_layout54> loc(#loc556)
        "ttnn.deallocate"(%1285) <{force = false}> : (tensor<1x20x273x64xf32, #ttnn_layout53>) -> () loc(#loc556)
        %1287 = "ttnn.typecast"(%1283) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x20x273x64xf32, #ttnn_layout53>) -> tensor<1x20x273x64xbf16, #ttnn_layout54> loc(#loc555)
        "ttnn.deallocate"(%1283) <{force = false}> : (tensor<1x20x273x64xf32, #ttnn_layout53>) -> () loc(#loc555)
        %1288 = "ttnn.scaled_dot_product_attention"(%1284, %1286, %1287) <{is_causal = false, scale = 0.124999993 : f32}> : (tensor<1x20x16x64xbf16, #ttnn_layout20>, tensor<1x20x273x64xbf16, #ttnn_layout54>, tensor<1x20x273x64xbf16, #ttnn_layout54>) -> tensor<1x20x16x64xbf16, #ttnn_layout20> loc(#loc556)
        "ttnn.deallocate"(%1287) <{force = false}> : (tensor<1x20x273x64xbf16, #ttnn_layout54>) -> () loc(#loc556)
        "ttnn.deallocate"(%1286) <{force = false}> : (tensor<1x20x273x64xbf16, #ttnn_layout54>) -> () loc(#loc556)
        "ttnn.deallocate"(%1284) <{force = false}> : (tensor<1x20x16x64xbf16, #ttnn_layout20>) -> () loc(#loc556)
        %1289 = "ttnn.concatenate_heads"(%1288) : (tensor<1x20x16x64xbf16, #ttnn_layout20>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc557)
        "ttnn.deallocate"(%1288) <{force = false}> : (tensor<1x20x16x64xbf16, #ttnn_layout20>) -> () loc(#loc557)
        %1290 = "ttnn.reshape"(%1289) <{shape = [16 : i32, 1280 : i32]}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc557)
        "ttnn.deallocate"(%1289) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc557)
        %1291 = "ttnn.matmul"(%1290, %arg546) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<16x1280xbf16, #ttnn_layout19>, tensor<1280x1280xbf16, #ttnn_layout14>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc558)
        "ttnn.deallocate"(%1290) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc558)
        "ttnn.deallocate"(%arg546) <{force = false}> : (tensor<1280x1280xbf16, #ttnn_layout14>) -> () loc(#loc558)
        %1292 = "ttnn.reshape"(%1291) <{shape = [1 : i32, 16 : i32, 1280 : i32]}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc559)
        "ttnn.deallocate"(%1291) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc559)
        %1293 = "ttnn.divide"(%1292, %0) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x16x1280xbf16, #ttnn_layout>, tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc560)
        "ttnn.deallocate"(%1292) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc560)
        "ttnn.deallocate"(%0) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc560)
        %1294 = "ttnn.add"(%1293, %1265) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x16x1280xbf16, #ttnn_layout>, tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc561)
        "ttnn.deallocate"(%1293) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc561)
        "ttnn.deallocate"(%1265) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc561)
        %1295 = "ttnn.layer_norm"(%1294, %arg557, %arg556) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x16x1280xbf16, #ttnn_layout>, tensor<1280xbf16, #ttnn_layout9>, tensor<1280xbf16, #ttnn_layout9>) -> tensor<1x16x1280xbf16, #ttnn_layout> loc(#loc562)
        "ttnn.deallocate"(%arg557) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc562)
        "ttnn.deallocate"(%arg556) <{force = false}> : (tensor<1280xbf16, #ttnn_layout9>) -> () loc(#loc562)
        %1296 = "ttnn.reshape"(%1295) <{shape = [16 : i32, 1280 : i32]}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc563)
        "ttnn.deallocate"(%1295) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc563)
        %1297 = "ttnn.matmul"(%1296, %arg555) <{activation = "gelu", compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<16x1280xbf16, #ttnn_layout19>, tensor<5120x1280xbf16, #ttnn_layout36>) -> tensor<16x5120xbf16, #ttnn_layout55> loc(#loc564)
        "ttnn.deallocate"(%1296) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc564)
        "ttnn.deallocate"(%arg555) <{force = false}> : (tensor<5120x1280xbf16, #ttnn_layout36>) -> () loc(#loc564)
        %1298 = "ttnn.reshape"(%1294) <{shape = [16 : i32, 1280 : i32]}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc1162)
        "ttnn.deallocate"(%1294) <{force = false}> : (tensor<1x16x1280xbf16, #ttnn_layout>) -> () loc(#loc1162)
        %1299 = "ttnn.matmul"(%1297, %arg554) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<16x5120xbf16, #ttnn_layout55>, tensor<1280x5120xbf16, #ttnn_layout35>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc1163)
        "ttnn.deallocate"(%1297) <{force = false}> : (tensor<16x5120xbf16, #ttnn_layout55>) -> () loc(#loc1163)
        "ttnn.deallocate"(%arg554) <{force = false}> : (tensor<1280x5120xbf16, #ttnn_layout35>) -> () loc(#loc1163)
        %1300 = "ttnn.add"(%1299, %1298) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<16x1280xbf16, #ttnn_layout19>, tensor<16x1280xbf16, #ttnn_layout19>) -> tensor<16x1280xbf16, #ttnn_layout19> loc(#loc1164)
        "ttnn.deallocate"(%1299) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc1164)
        "ttnn.deallocate"(%1298) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc1164)
        %1301 = "ttnn.matmul"(%1300, %arg3) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<16x1280xbf16, #ttnn_layout19>, tensor<2048x1280xbf16, #ttnn_layout34>) -> tensor<16x2048xbf16, #ttnn_layout58> loc(#loc1165)
        "ttnn.deallocate"(%1300) <{force = false}> : (tensor<16x1280xbf16, #ttnn_layout19>) -> () loc(#loc1165)
        "ttnn.deallocate"(%arg3) <{force = false}> : (tensor<2048x1280xbf16, #ttnn_layout34>) -> () loc(#loc1165)
        %1302 = "ttnn.add"(%1301, %7) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<16x2048xbf16, #ttnn_layout58>, tensor<1x16x2048xbf16, #ttnn_layout16>) -> tensor<1x16x2048xbf16, #ttnn_layout16> loc(#loc1166)
        "ttnn.deallocate"(%1301) <{force = false}> : (tensor<16x2048xbf16, #ttnn_layout58>) -> () loc(#loc1166)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x16x2048xbf16, #ttnn_layout16>) -> () loc(#loc1166)
        %1303 = "ttnn.layer_norm"(%1302, %arg1, %arg0) <{epsilon = 9.99999974E-6 : f32, operandSegmentSizes = array<i32: 1, 1, 1>}> : (tensor<1x16x2048xbf16, #ttnn_layout16>, tensor<2048xbf16, #ttnn_layout18>, tensor<2048xbf16, #ttnn_layout18>) -> tensor<1x16x2048xbf16, #ttnn_layout16> loc(#loc567)
        "ttnn.deallocate"(%1302) <{force = false}> : (tensor<1x16x2048xbf16, #ttnn_layout16>) -> () loc(#loc567)
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<2048xbf16, #ttnn_layout18>) -> () loc(#loc567)
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<2048xbf16, #ttnn_layout18>) -> () loc(#loc567)
        return %1303 : tensor<1x16x2048xbf16, #ttnn_layout16> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc1 = loc("558|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPVisionEmbeddings[image_encoder.vision_model.embeddings]|Conv2d[image_encoder.vision_model.embeddings.patch_embedding]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:195|forward|202|convolutionaten__convolution_overrideable_in_0_layout")
#loc2 = loc("2346|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPMLP[image_encoder.vision_model.encoder.layers[23].mlp]|Linear[image_encoder.vision_model.encoder.layers[23].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_288aten__add")
#loc3 = loc("1555|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|Linear[image_encoder.vision_model.encoder.layers[13].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_161aten__add")
#loc4 = loc("1558|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|Linear[image_encoder.vision_model.encoder.layers[13].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_162aten__add")
#loc5 = loc("1561|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|Linear[image_encoder.vision_model.encoder.layers[13].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_163aten__add")
#loc6 = loc("1316|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPMLP[image_encoder.vision_model.encoder.layers[9].mlp]|Linear[image_encoder.vision_model.encoder.layers[9].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_121aten__add")
#loc8 = loc("2272|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPMLP[image_encoder.vision_model.encoder.layers[22].mlp]|Linear[image_encoder.vision_model.encoder.layers[22].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_276aten__add")
#loc9 = loc("1532|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPMLP[image_encoder.vision_model.encoder.layers[12].mlp]|Linear[image_encoder.vision_model.encoder.layers[12].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_156aten__add")
#loc10 = loc("3218|IPAdapterPlusImageProjection[resampler]|Linear[resampler.proj_out]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2293|forward|2309|add_422aten__add")
#loc11 = loc("1885|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|Linear[image_encoder.vision_model.encoder.layers[17].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_212aten__add")
#loc12 = loc("2625|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|Linear[image_encoder.vision_model.encoder.layers[27].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_332aten__add")
#loc13 = loc("872|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPMLP[image_encoder.vision_model.encoder.layers[3].mlp]|Linear[image_encoder.vision_model.encoder.layers[3].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_49aten__add")
#loc14 = loc("1663|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|Linear[image_encoder.vision_model.encoder.layers[14].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_176aten__add")
#loc15 = loc("718|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPMLP[image_encoder.vision_model.encoder.layers[1].mlp]|Linear[image_encoder.vision_model.encoder.layers[1].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_24aten__add")
#loc16 = loc("2716|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPMLP[image_encoder.vision_model.encoder.layers[28].mlp]|Linear[image_encoder.vision_model.encoder.layers[28].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_348aten__add")
#loc17 = loc("1538|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPMLP[image_encoder.vision_model.encoder.layers[12].mlp]|Linear[image_encoder.vision_model.encoder.layers[12].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_157aten__add")
#loc18 = loc("2665|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|Linear[image_encoder.vision_model.encoder.layers[28].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_341aten__add")
#loc19 = loc("2668|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|Linear[image_encoder.vision_model.encoder.layers[28].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_342aten__add")
#loc20 = loc("2671|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|Linear[image_encoder.vision_model.encoder.layers[28].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_343aten__add")
#loc21 = loc("1851|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|Linear[image_encoder.vision_model.encoder.layers[17].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_209aten__add")
#loc22 = loc("1854|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|Linear[image_encoder.vision_model.encoder.layers[17].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_210aten__add")
#loc23 = loc("1857|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|Linear[image_encoder.vision_model.encoder.layers[17].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_211aten__add")
#loc24 = loc("1686|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPMLP[image_encoder.vision_model.encoder.layers[14].mlp]|Linear[image_encoder.vision_model.encoder.layers[14].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_181aten__add")
#loc25 = loc("1908|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPMLP[image_encoder.vision_model.encoder.layers[17].mlp]|Linear[image_encoder.vision_model.encoder.layers[17].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_217aten__add")
#loc26 = loc("2181|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|Linear[image_encoder.vision_model.encoder.layers[21].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_260aten__add")
#loc27 = loc("724|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPMLP[image_encoder.vision_model.encoder.layers[1].mlp]|Linear[image_encoder.vision_model.encoder.layers[1].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_25aten__add")
#loc28 = loc("2352|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPMLP[image_encoder.vision_model.encoder.layers[23].mlp]|Linear[image_encoder.vision_model.encoder.layers[23].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_289aten__add")
#loc29 = loc("1236|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPMLP[image_encoder.vision_model.encoder.layers[8].mlp]|Linear[image_encoder.vision_model.encoder.layers[8].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_108aten__add")
#loc30 = loc("1162|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPMLP[image_encoder.vision_model.encoder.layers[7].mlp]|Linear[image_encoder.vision_model.encoder.layers[7].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_96aten__add")
#loc31 = loc("2056|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPMLP[image_encoder.vision_model.encoder.layers[19].mlp]|Linear[image_encoder.vision_model.encoder.layers[19].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_241aten__add")
#loc32 = loc("2901|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|LayerNorm[resampler.layers[0].ln1]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2247|mark_tensor_335xla__mark_tensor")
#loc33 = loc("2904|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|Attention[resampler.layers[0].attn]|Linear[resampler.layers[0].attn.to_q]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2740|matmul_194aten__view")
#loc34 = loc("2904|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|Attention[resampler.layers[0].attn]|Linear[resampler.layers[0].attn.to_q]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2740|matmul_194aten__mm")
#loc35 = loc("2909|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|Attention[resampler.layers[0].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2753|view_129aten__view")
#loc36 = loc("2910|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|Attention[resampler.layers[0].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2753|permute_358aten__permute")
#loc37 = loc("2915|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|Attention[resampler.layers[0].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2765|_to_copy_296xla__cast")
#loc38 = loc("2918|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|Attention[resampler.layers[0].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2765|mul_200aten__mul")
#loc39 = loc("2902|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2248|cat_1aten__cat")
#loc40 = loc("2477|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|Linear[image_encoder.vision_model.encoder.layers[25].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_308aten__add")
#loc41 = loc("2295|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|Linear[image_encoder.vision_model.encoder.layers[23].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_281aten__add")
#loc42 = loc("2298|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|Linear[image_encoder.vision_model.encoder.layers[23].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_282aten__add")
#loc43 = loc("2301|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|Linear[image_encoder.vision_model.encoder.layers[23].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_283aten__add")
#loc44 = loc("2255|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|Linear[image_encoder.vision_model.encoder.layers[22].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_272aten__add")
#loc45 = loc("2796|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPMLP[image_encoder.vision_model.encoder.layers[29].mlp]|Linear[image_encoder.vision_model.encoder.layers[29].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_361aten__add")
#loc46 = loc("2790|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPMLP[image_encoder.vision_model.encoder.layers[29].mlp]|Linear[image_encoder.vision_model.encoder.layers[29].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_360aten__add")
#loc47 = loc("2500|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPMLP[image_encoder.vision_model.encoder.layers[25].mlp]|Linear[image_encoder.vision_model.encoder.layers[25].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_313aten__add")
#loc48 = loc("1185|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|Linear[image_encoder.vision_model.encoder.layers[8].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_101aten__add")
#loc49 = loc("1188|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|Linear[image_encoder.vision_model.encoder.layers[8].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_102aten__add")
#loc50 = loc("1191|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|Linear[image_encoder.vision_model.encoder.layers[8].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_103aten__add")
#loc51 = loc("2591|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|Linear[image_encoder.vision_model.encoder.layers[27].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_329aten__add")
#loc52 = loc("2594|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|Linear[image_encoder.vision_model.encoder.layers[27].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_330aten__add")
#loc53 = loc("2597|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|Linear[image_encoder.vision_model.encoder.layers[27].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_331aten__add")
#loc54 = loc("644|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPMLP[image_encoder.vision_model.encoder.layers[0].mlp]|Linear[image_encoder.vision_model.encoder.layers[0].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_12aten__add")
#loc55 = loc("889|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|Linear[image_encoder.vision_model.encoder.layers[4].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_53aten__add")
#loc56 = loc("892|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|Linear[image_encoder.vision_model.encoder.layers[4].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_54aten__add")
#loc57 = loc("895|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|Linear[image_encoder.vision_model.encoder.layers[4].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_55aten__add")
#loc58 = loc("2050|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPMLP[image_encoder.vision_model.encoder.layers[19].mlp]|Linear[image_encoder.vision_model.encoder.layers[19].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_240aten__add")
#loc59 = loc("2739|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|Linear[image_encoder.vision_model.encoder.layers[29].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_353aten__add")
#loc60 = loc("2742|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|Linear[image_encoder.vision_model.encoder.layers[29].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_354aten__add")
#loc61 = loc("2745|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|Linear[image_encoder.vision_model.encoder.layers[29].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_355aten__add")
#loc62 = loc("1071|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|Linear[image_encoder.vision_model.encoder.layers[6].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_80aten__add")
#loc63 = loc("593|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|Linear[image_encoder.vision_model.encoder.layers[0].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_5aten__add")
#loc64 = loc("596|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|Linear[image_encoder.vision_model.encoder.layers[0].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_6aten__add")
#loc65 = loc("599|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|Linear[image_encoder.vision_model.encoder.layers[0].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_7aten__add")
#loc66 = loc("2847|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|Linear[image_encoder.vision_model.encoder.layers[30].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_368aten__add")
#loc67 = loc("1999|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|Linear[image_encoder.vision_model.encoder.layers[19].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_233aten__add")
#loc68 = loc("2002|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|Linear[image_encoder.vision_model.encoder.layers[19].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_234aten__add")
#loc69 = loc("2005|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|Linear[image_encoder.vision_model.encoder.layers[19].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_235aten__add")
#loc70 = loc("2329|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|Linear[image_encoder.vision_model.encoder.layers[23].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_284aten__add")
#loc71 = loc("2033|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|Linear[image_encoder.vision_model.encoder.layers[19].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_236aten__add")
#loc72 = loc("1088|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPMLP[image_encoder.vision_model.encoder.layers[6].mlp]|Linear[image_encoder.vision_model.encoder.layers[6].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_84aten__add")
#loc73 = loc("2870|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPMLP[image_encoder.vision_model.encoder.layers[30].mlp]|Linear[image_encoder.vision_model.encoder.layers[30].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_373aten__add")
#loc74 = loc("701|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|Linear[image_encoder.vision_model.encoder.layers[1].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_20aten__add")
#loc75 = loc("2722|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPMLP[image_encoder.vision_model.encoder.layers[28].mlp]|Linear[image_encoder.vision_model.encoder.layers[28].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_349aten__add")
#loc76 = loc("2221|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|Linear[image_encoder.vision_model.encoder.layers[22].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_269aten__add")
#loc77 = loc("2224|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|Linear[image_encoder.vision_model.encoder.layers[22].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_270aten__add")
#loc78 = loc("2227|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|Linear[image_encoder.vision_model.encoder.layers[22].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_271aten__add")
#loc79 = loc("2443|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|Linear[image_encoder.vision_model.encoder.layers[25].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_305aten__add")
#loc80 = loc("2446|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|Linear[image_encoder.vision_model.encoder.layers[25].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_306aten__add")
#loc81 = loc("2449|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|Linear[image_encoder.vision_model.encoder.layers[25].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_307aten__add")
#loc82 = loc("2369|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|Linear[image_encoder.vision_model.encoder.layers[24].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_293aten__add")
#loc83 = loc("2372|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|Linear[image_encoder.vision_model.encoder.layers[24].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_294aten__add")
#loc84 = loc("2375|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|Linear[image_encoder.vision_model.encoder.layers[24].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_295aten__add")
#loc85 = loc("2073|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|Linear[image_encoder.vision_model.encoder.layers[20].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_245aten__add")
#loc86 = loc("2076|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|Linear[image_encoder.vision_model.encoder.layers[20].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_246aten__add")
#loc87 = loc("2079|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|Linear[image_encoder.vision_model.encoder.layers[20].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_247aten__add")
#loc88 = loc("667|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|Linear[image_encoder.vision_model.encoder.layers[1].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_17aten__add")
#loc89 = loc("670|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|Linear[image_encoder.vision_model.encoder.layers[1].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_18aten__add")
#loc90 = loc("673|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|Linear[image_encoder.vision_model.encoder.layers[1].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_19aten__add")
#loc91 = loc("1811|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|Linear[image_encoder.vision_model.encoder.layers[16].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_200aten__add")
#loc92 = loc("1367|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|Linear[image_encoder.vision_model.encoder.layers[10].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_128aten__add")
#loc93 = loc("558|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPVisionEmbeddings[image_encoder.vision_model.embeddings]|Conv2d[image_encoder.vision_model.embeddings.patch_embedding]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:195|forward|202|convolutionaten__convolution_overrideable")
#loc94 = loc("1515|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|Linear[image_encoder.vision_model.encoder.layers[12].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_152aten__add")
#loc95 = loc("997|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|Linear[image_encoder.vision_model.encoder.layers[5].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_68aten__add")
#loc96 = loc("1333|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|Linear[image_encoder.vision_model.encoder.layers[10].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_125aten__add")
#loc97 = loc("1336|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|Linear[image_encoder.vision_model.encoder.layers[10].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_126aten__add")
#loc98 = loc("1339|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|Linear[image_encoder.vision_model.encoder.layers[10].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_127aten__add")
#loc99 = loc("1703|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|Linear[image_encoder.vision_model.encoder.layers[15].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_185aten__add")
#loc100 = loc("1706|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|Linear[image_encoder.vision_model.encoder.layers[15].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_186aten__add")
#loc101 = loc("1709|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|Linear[image_encoder.vision_model.encoder.layers[15].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_187aten__add")
#loc102 = loc("650|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPMLP[image_encoder.vision_model.encoder.layers[0].mlp]|Linear[image_encoder.vision_model.encoder.layers[0].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_13aten__add")
#loc103 = loc("1219|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|Linear[image_encoder.vision_model.encoder.layers[8].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_104aten__add")
#loc104 = loc("2517|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|Linear[image_encoder.vision_model.encoder.layers[26].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_317aten__add")
#loc105 = loc("2520|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|Linear[image_encoder.vision_model.encoder.layers[26].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_318aten__add")
#loc106 = loc("2523|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|Linear[image_encoder.vision_model.encoder.layers[26].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_319aten__add")
#loc107 = loc("2107|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|Linear[image_encoder.vision_model.encoder.layers[20].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_248aten__add")
#loc108 = loc("2773|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|Linear[image_encoder.vision_model.encoder.layers[29].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_356aten__add")
#loc109 = loc("741|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|Linear[image_encoder.vision_model.encoder.layers[2].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_29aten__add")
#loc110 = loc("744|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|Linear[image_encoder.vision_model.encoder.layers[2].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_30aten__add")
#loc111 = loc("747|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|Linear[image_encoder.vision_model.encoder.layers[2].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_31aten__add")
#loc112 = loc("792|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPMLP[image_encoder.vision_model.encoder.layers[2].mlp]|Linear[image_encoder.vision_model.encoder.layers[2].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_36aten__add")
#loc113 = loc("2130|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPMLP[image_encoder.vision_model.encoder.layers[20].mlp]|Linear[image_encoder.vision_model.encoder.layers[20].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_253aten__add")
#loc114 = loc("1760|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPMLP[image_encoder.vision_model.encoder.layers[15].mlp]|Linear[image_encoder.vision_model.encoder.layers[15].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_193aten__add")
#loc115 = loc("1111|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|Linear[image_encoder.vision_model.encoder.layers[7].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_89aten__add")
#loc116 = loc("1114|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|Linear[image_encoder.vision_model.encoder.layers[7].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_90aten__add")
#loc117 = loc("1117|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|Linear[image_encoder.vision_model.encoder.layers[7].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_91aten__add")
#loc118 = loc("1390|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPMLP[image_encoder.vision_model.encoder.layers[10].mlp]|Linear[image_encoder.vision_model.encoder.layers[10].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_133aten__add")
#loc119 = loc("563|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPVisionEmbeddings[image_encoder.vision_model.embeddings]|Embedding[image_encoder.vision_model.embeddings.position_embedding]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:195|forward|210|embeddingaten__index_select")
#loc120 = loc("562|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPVisionEmbeddings[image_encoder.vision_model.embeddings]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:195|forward|206|cataten__cat")
#loc121 = loc("815|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|Linear[image_encoder.vision_model.encoder.layers[3].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_41aten__add")
#loc122 = loc("818|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|Linear[image_encoder.vision_model.encoder.layers[3].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_42aten__add")
#loc123 = loc("821|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|Linear[image_encoder.vision_model.encoder.layers[3].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_43aten__add")
#loc124 = loc("1014|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPMLP[image_encoder.vision_model.encoder.layers[5].mlp]|Linear[image_encoder.vision_model.encoder.layers[5].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_72aten__add")
#loc125 = loc("1606|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPMLP[image_encoder.vision_model.encoder.layers[13].mlp]|Linear[image_encoder.vision_model.encoder.layers[13].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_168aten__add")
#loc126 = loc("1242|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPMLP[image_encoder.vision_model.encoder.layers[8].mlp]|Linear[image_encoder.vision_model.encoder.layers[8].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_109aten__add")
#loc127 = loc("1976|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPMLP[image_encoder.vision_model.encoder.layers[18].mlp]|Linear[image_encoder.vision_model.encoder.layers[18].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_228aten__add")
#loc128 = loc("1384|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPMLP[image_encoder.vision_model.encoder.layers[10].mlp]|Linear[image_encoder.vision_model.encoder.layers[10].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_132aten__add")
#loc129 = loc("923|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|Linear[image_encoder.vision_model.encoder.layers[4].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_56aten__add")
#loc130 = loc("2568|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPMLP[image_encoder.vision_model.encoder.layers[26].mlp]|Linear[image_encoder.vision_model.encoder.layers[26].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_324aten__add")
#loc131 = loc("1037|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|Linear[image_encoder.vision_model.encoder.layers[6].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_77aten__add")
#loc132 = loc("1040|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|Linear[image_encoder.vision_model.encoder.layers[6].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_78aten__add")
#loc133 = loc("1043|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|Linear[image_encoder.vision_model.encoder.layers[6].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_79aten__add")
#loc134 = loc("1959|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|Linear[image_encoder.vision_model.encoder.layers[18].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_224aten__add")
#loc135 = loc("1629|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|Linear[image_encoder.vision_model.encoder.layers[14].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_173aten__add")
#loc136 = loc("1632|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|Linear[image_encoder.vision_model.encoder.layers[14].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_174aten__add")
#loc137 = loc("1635|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|Linear[image_encoder.vision_model.encoder.layers[14].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_175aten__add")
#loc138 = loc("1094|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPMLP[image_encoder.vision_model.encoder.layers[6].mlp]|Linear[image_encoder.vision_model.encoder.layers[6].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_85aten__add")
#loc139 = loc("1834|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPMLP[image_encoder.vision_model.encoder.layers[16].mlp]|Linear[image_encoder.vision_model.encoder.layers[16].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_205aten__add")
#loc140 = loc("2551|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|Linear[image_encoder.vision_model.encoder.layers[26].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_320aten__add")
#loc141 = loc("1020|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPMLP[image_encoder.vision_model.encoder.layers[5].mlp]|Linear[image_encoder.vision_model.encoder.layers[5].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_73aten__add")
#loc142 = loc("2124|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPMLP[image_encoder.vision_model.encoder.layers[20].mlp]|Linear[image_encoder.vision_model.encoder.layers[20].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_252aten__add")
#loc143 = loc("1902|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPMLP[image_encoder.vision_model.encoder.layers[17].mlp]|Linear[image_encoder.vision_model.encoder.layers[17].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_216aten__add")
#loc144 = loc("1612|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPMLP[image_encoder.vision_model.encoder.layers[13].mlp]|Linear[image_encoder.vision_model.encoder.layers[13].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_169aten__add")
#loc145 = loc("2198|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPMLP[image_encoder.vision_model.encoder.layers[21].mlp]|Linear[image_encoder.vision_model.encoder.layers[21].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_264aten__add")
#loc146 = loc("2147|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|Linear[image_encoder.vision_model.encoder.layers[21].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_257aten__add")
#loc147 = loc("2150|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|Linear[image_encoder.vision_model.encoder.layers[21].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_258aten__add")
#loc148 = loc("2153|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|Linear[image_encoder.vision_model.encoder.layers[21].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_259aten__add")
#loc149 = loc("1293|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|Linear[image_encoder.vision_model.encoder.layers[9].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_116aten__add")
#loc150 = loc("1737|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|Linear[image_encoder.vision_model.encoder.layers[15].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_188aten__add")
#loc151 = loc("2642|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPMLP[image_encoder.vision_model.encoder.layers[27].mlp]|Linear[image_encoder.vision_model.encoder.layers[27].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_336aten__add")
#loc152 = loc("1407|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|Linear[image_encoder.vision_model.encoder.layers[11].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_137aten__add")
#loc153 = loc("1410|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|Linear[image_encoder.vision_model.encoder.layers[11].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_138aten__add")
#loc154 = loc("1413|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|Linear[image_encoder.vision_model.encoder.layers[11].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_139aten__add")
#loc155 = loc("2494|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPMLP[image_encoder.vision_model.encoder.layers[25].mlp]|Linear[image_encoder.vision_model.encoder.layers[25].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_312aten__add")
#loc156 = loc("1777|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|Linear[image_encoder.vision_model.encoder.layers[16].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_197aten__add")
#loc157 = loc("1780|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|Linear[image_encoder.vision_model.encoder.layers[16].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_198aten__add")
#loc158 = loc("1783|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|Linear[image_encoder.vision_model.encoder.layers[16].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_199aten__add")
#loc159 = loc("1145|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|Linear[image_encoder.vision_model.encoder.layers[7].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_92aten__add")
#loc160 = loc("2699|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|Linear[image_encoder.vision_model.encoder.layers[28].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_344aten__add")
#loc161 = loc("775|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|Linear[image_encoder.vision_model.encoder.layers[2].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_32aten__add")
#loc162 = loc("2574|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPMLP[image_encoder.vision_model.encoder.layers[26].mlp]|Linear[image_encoder.vision_model.encoder.layers[26].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_325aten__add")
#loc163 = loc("627|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|Linear[image_encoder.vision_model.encoder.layers[0].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_8aten__add")
#loc164 = loc("2278|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPMLP[image_encoder.vision_model.encoder.layers[22].mlp]|Linear[image_encoder.vision_model.encoder.layers[22].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_277aten__add")
#loc165 = loc("1589|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|Linear[image_encoder.vision_model.encoder.layers[13].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_164aten__add")
#loc166 = loc("2648|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPMLP[image_encoder.vision_model.encoder.layers[27].mlp]|Linear[image_encoder.vision_model.encoder.layers[27].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_337aten__add")
#loc167 = loc("1828|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPMLP[image_encoder.vision_model.encoder.layers[16].mlp]|Linear[image_encoder.vision_model.encoder.layers[16].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_204aten__add")
#loc168 = loc("2813|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|Linear[image_encoder.vision_model.encoder.layers[30].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_365aten__add")
#loc169 = loc("2816|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|Linear[image_encoder.vision_model.encoder.layers[30].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_366aten__add")
#loc170 = loc("2819|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|Linear[image_encoder.vision_model.encoder.layers[30].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_367aten__add")
#loc171 = loc("849|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|Linear[image_encoder.vision_model.encoder.layers[3].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_44aten__add")
#loc172 = loc("1259|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|Linear[image_encoder.vision_model.encoder.layers[9].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_113aten__add")
#loc173 = loc("1262|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|Linear[image_encoder.vision_model.encoder.layers[9].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_114aten__add")
#loc174 = loc("1265|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|Linear[image_encoder.vision_model.encoder.layers[9].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_115aten__add")
#loc175 = loc("1925|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|Linear[image_encoder.vision_model.encoder.layers[18].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_221aten__add")
#loc176 = loc("1928|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|Linear[image_encoder.vision_model.encoder.layers[18].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_222aten__add")
#loc177 = loc("1931|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|Linear[image_encoder.vision_model.encoder.layers[18].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_223aten__add")
#loc178 = loc("2864|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPMLP[image_encoder.vision_model.encoder.layers[30].mlp]|Linear[image_encoder.vision_model.encoder.layers[30].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_372aten__add")
#loc179 = loc("1481|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|Linear[image_encoder.vision_model.encoder.layers[12].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_149aten__add")
#loc180 = loc("1484|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|Linear[image_encoder.vision_model.encoder.layers[12].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_150aten__add")
#loc181 = loc("1487|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|Linear[image_encoder.vision_model.encoder.layers[12].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_151aten__add")
#loc182 = loc("2875|IPAdapterPlusImageProjection[resampler]|Linear[resampler.proj_in]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2293|forward|2303|add_389aten__add")
#loc183 = loc("2420|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPMLP[image_encoder.vision_model.encoder.layers[24].mlp]|Linear[image_encoder.vision_model.encoder.layers[24].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_300aten__add")
#loc184 = loc("1441|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|Linear[image_encoder.vision_model.encoder.layers[11].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_140aten__add")
#loc185 = loc("1680|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPMLP[image_encoder.vision_model.encoder.layers[14].mlp]|Linear[image_encoder.vision_model.encoder.layers[14].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_180aten__add")
#loc186 = loc("-1|unknown|unknown|-1|unknownaten__view")
#loc187 = loc("2403|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|Linear[image_encoder.vision_model.encoder.layers[24].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_296aten__add")
#loc188 = loc("2426|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPMLP[image_encoder.vision_model.encoder.layers[24].mlp]|Linear[image_encoder.vision_model.encoder.layers[24].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_301aten__add")
#loc189 = loc("866|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPMLP[image_encoder.vision_model.encoder.layers[3].mlp]|Linear[image_encoder.vision_model.encoder.layers[3].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_48aten__add")
#loc190 = loc("798|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPMLP[image_encoder.vision_model.encoder.layers[2].mlp]|Linear[image_encoder.vision_model.encoder.layers[2].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_37aten__add")
#loc191 = loc("1982|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPMLP[image_encoder.vision_model.encoder.layers[18].mlp]|Linear[image_encoder.vision_model.encoder.layers[18].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_229aten__add")
#loc192 = loc("946|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPMLP[image_encoder.vision_model.encoder.layers[4].mlp]|Linear[image_encoder.vision_model.encoder.layers[4].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_61aten__add")
#loc193 = loc("940|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPMLP[image_encoder.vision_model.encoder.layers[4].mlp]|Linear[image_encoder.vision_model.encoder.layers[4].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_60aten__add")
#loc194 = loc("1464|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPMLP[image_encoder.vision_model.encoder.layers[11].mlp]|Linear[image_encoder.vision_model.encoder.layers[11].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_145aten__add")
#loc195 = loc("1168|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPMLP[image_encoder.vision_model.encoder.layers[7].mlp]|Linear[image_encoder.vision_model.encoder.layers[7].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_97aten__add")
#loc196 = loc("1754|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPMLP[image_encoder.vision_model.encoder.layers[15].mlp]|Linear[image_encoder.vision_model.encoder.layers[15].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_192aten__add")
#loc197 = loc("1310|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPMLP[image_encoder.vision_model.encoder.layers[9].mlp]|Linear[image_encoder.vision_model.encoder.layers[9].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_120aten__add")
#loc198 = loc("1458|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPMLP[image_encoder.vision_model.encoder.layers[11].mlp]|Linear[image_encoder.vision_model.encoder.layers[11].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_144aten__add")
#loc199 = loc("963|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|Linear[image_encoder.vision_model.encoder.layers[5].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_65aten__add")
#loc200 = loc("966|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|Linear[image_encoder.vision_model.encoder.layers[5].self_attn.k_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|313|add_66aten__add")
#loc201 = loc("969|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|Linear[image_encoder.vision_model.encoder.layers[5].self_attn.v_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|314|add_67aten__add")
#loc202 = loc("2204|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPMLP[image_encoder.vision_model.encoder.layers[21].mlp]|Linear[image_encoder.vision_model.encoder.layers[21].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_265aten__add")
#loc203 = loc("559|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPVisionEmbeddings[image_encoder.vision_model.embeddings]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:195|forward|203|viewaten__view")
#loc204 = loc("564|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPVisionEmbeddings[image_encoder.vision_model.embeddings]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:195|forward|210|addaten__add")
#loc205 = loc("577|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|LayerNorm[image_encoder.vision_model.pre_layrnorm]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:727|forward|743|mark_tensor_3xla__mark_tensor")
#loc206 = loc("590|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|LayerNorm[image_encoder.vision_model.encoder.layers[0].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_7xla__mark_tensor")
#loc207 = loc("592|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|Linear[image_encoder.vision_model.encoder.layers[0].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmulaten__view")
#loc208 = loc("621|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_8aten__einsum")
#loc209 = loc("626|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|Linear[image_encoder.vision_model.encoder.layers[0].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_3aten__view")
#loc210 = loc("628|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_9aten__add")
#loc211 = loc("641|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|LayerNorm[image_encoder.vision_model.encoder.layers[0].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_11xla__mark_tensor")
#loc212 = loc("643|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPMLP[image_encoder.vision_model.encoder.layers[0].mlp]|Linear[image_encoder.vision_model.encoder.layers[0].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_4aten__view")
#loc213 = loc("647|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPMLP[image_encoder.vision_model.encoder.layers[0].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[0].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_13xla__mark_tensor")
#loc214 = loc("651|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_14aten__add")
#loc215 = loc("664|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|LayerNorm[image_encoder.vision_model.encoder.layers[1].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_17xla__mark_tensor")
#loc216 = loc("666|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|Linear[image_encoder.vision_model.encoder.layers[1].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_6aten__view")
#loc217 = loc("695|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_17aten__einsum")
#loc218 = loc("700|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|Linear[image_encoder.vision_model.encoder.layers[1].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_9aten__view")
#loc219 = loc("702|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_21aten__add")
#loc220 = loc("715|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|LayerNorm[image_encoder.vision_model.encoder.layers[1].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_21xla__mark_tensor")
#loc221 = loc("717|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPMLP[image_encoder.vision_model.encoder.layers[1].mlp]|Linear[image_encoder.vision_model.encoder.layers[1].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_10aten__view")
#loc222 = loc("721|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPMLP[image_encoder.vision_model.encoder.layers[1].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[1].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_23xla__mark_tensor")
#loc223 = loc("725|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_26aten__add")
#loc224 = loc("738|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|LayerNorm[image_encoder.vision_model.encoder.layers[2].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_27xla__mark_tensor")
#loc225 = loc("740|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|Linear[image_encoder.vision_model.encoder.layers[2].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_12aten__view")
#loc226 = loc("769|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_26aten__einsum")
#loc227 = loc("774|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|Linear[image_encoder.vision_model.encoder.layers[2].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_15aten__view")
#loc228 = loc("776|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_33aten__add")
#loc229 = loc("789|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|LayerNorm[image_encoder.vision_model.encoder.layers[2].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_31xla__mark_tensor")
#loc230 = loc("791|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPMLP[image_encoder.vision_model.encoder.layers[2].mlp]|Linear[image_encoder.vision_model.encoder.layers[2].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_16aten__view")
#loc231 = loc("795|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPMLP[image_encoder.vision_model.encoder.layers[2].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[2].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_33xla__mark_tensor")
#loc232 = loc("799|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_38aten__add")
#loc233 = loc("812|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|LayerNorm[image_encoder.vision_model.encoder.layers[3].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_37xla__mark_tensor")
#loc234 = loc("814|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|Linear[image_encoder.vision_model.encoder.layers[3].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_18aten__view")
#loc235 = loc("843|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_35aten__einsum")
#loc236 = loc("848|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|Linear[image_encoder.vision_model.encoder.layers[3].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_21aten__view")
#loc237 = loc("850|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_45aten__add")
#loc238 = loc("863|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|LayerNorm[image_encoder.vision_model.encoder.layers[3].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_41xla__mark_tensor")
#loc239 = loc("865|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPMLP[image_encoder.vision_model.encoder.layers[3].mlp]|Linear[image_encoder.vision_model.encoder.layers[3].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_22aten__view")
#loc240 = loc("869|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPMLP[image_encoder.vision_model.encoder.layers[3].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[3].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_43xla__mark_tensor")
#loc241 = loc("873|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_50aten__add")
#loc242 = loc("886|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|LayerNorm[image_encoder.vision_model.encoder.layers[4].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_47xla__mark_tensor")
#loc243 = loc("888|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|Linear[image_encoder.vision_model.encoder.layers[4].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_24aten__view")
#loc244 = loc("917|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_44aten__einsum")
#loc245 = loc("922|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|Linear[image_encoder.vision_model.encoder.layers[4].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_27aten__view")
#loc246 = loc("924|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_57aten__add")
#loc247 = loc("937|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|LayerNorm[image_encoder.vision_model.encoder.layers[4].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_51xla__mark_tensor")
#loc248 = loc("939|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPMLP[image_encoder.vision_model.encoder.layers[4].mlp]|Linear[image_encoder.vision_model.encoder.layers[4].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_28aten__view")
#loc249 = loc("943|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPMLP[image_encoder.vision_model.encoder.layers[4].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[4].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_53xla__mark_tensor")
#loc250 = loc("947|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_62aten__add")
#loc251 = loc("960|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|LayerNorm[image_encoder.vision_model.encoder.layers[5].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_57xla__mark_tensor")
#loc252 = loc("962|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|Linear[image_encoder.vision_model.encoder.layers[5].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_30aten__view")
#loc253 = loc("991|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_53aten__einsum")
#loc254 = loc("996|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|Linear[image_encoder.vision_model.encoder.layers[5].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_33aten__view")
#loc255 = loc("998|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_69aten__add")
#loc256 = loc("1011|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|LayerNorm[image_encoder.vision_model.encoder.layers[5].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_61xla__mark_tensor")
#loc257 = loc("1013|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPMLP[image_encoder.vision_model.encoder.layers[5].mlp]|Linear[image_encoder.vision_model.encoder.layers[5].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_34aten__view")
#loc258 = loc("1017|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPMLP[image_encoder.vision_model.encoder.layers[5].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[5].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_63xla__mark_tensor")
#loc259 = loc("1021|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_74aten__add")
#loc260 = loc("1034|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|LayerNorm[image_encoder.vision_model.encoder.layers[6].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_67xla__mark_tensor")
#loc261 = loc("1036|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|Linear[image_encoder.vision_model.encoder.layers[6].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_36aten__view")
#loc262 = loc("1065|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_62aten__einsum")
#loc263 = loc("1070|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|Linear[image_encoder.vision_model.encoder.layers[6].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_39aten__view")
#loc264 = loc("1072|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_81aten__add")
#loc265 = loc("1085|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|LayerNorm[image_encoder.vision_model.encoder.layers[6].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_71xla__mark_tensor")
#loc266 = loc("1087|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPMLP[image_encoder.vision_model.encoder.layers[6].mlp]|Linear[image_encoder.vision_model.encoder.layers[6].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_40aten__view")
#loc267 = loc("1091|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPMLP[image_encoder.vision_model.encoder.layers[6].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[6].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_73xla__mark_tensor")
#loc268 = loc("1095|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_86aten__add")
#loc269 = loc("1108|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|LayerNorm[image_encoder.vision_model.encoder.layers[7].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_77xla__mark_tensor")
#loc270 = loc("1110|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|Linear[image_encoder.vision_model.encoder.layers[7].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_42aten__view")
#loc271 = loc("1139|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_71aten__einsum")
#loc272 = loc("1144|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|Linear[image_encoder.vision_model.encoder.layers[7].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_45aten__view")
#loc273 = loc("1146|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_93aten__add")
#loc274 = loc("1159|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|LayerNorm[image_encoder.vision_model.encoder.layers[7].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_81xla__mark_tensor")
#loc275 = loc("1161|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPMLP[image_encoder.vision_model.encoder.layers[7].mlp]|Linear[image_encoder.vision_model.encoder.layers[7].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_46aten__view")
#loc276 = loc("1165|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPMLP[image_encoder.vision_model.encoder.layers[7].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[7].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_83xla__mark_tensor")
#loc277 = loc("1169|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_98aten__add")
#loc278 = loc("1182|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|LayerNorm[image_encoder.vision_model.encoder.layers[8].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_87xla__mark_tensor")
#loc279 = loc("1184|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|Linear[image_encoder.vision_model.encoder.layers[8].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_48aten__view")
#loc280 = loc("1213|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_80aten__einsum")
#loc281 = loc("1218|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|Linear[image_encoder.vision_model.encoder.layers[8].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_51aten__view")
#loc282 = loc("1220|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_105aten__add")
#loc283 = loc("1233|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|LayerNorm[image_encoder.vision_model.encoder.layers[8].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_91xla__mark_tensor")
#loc284 = loc("1235|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPMLP[image_encoder.vision_model.encoder.layers[8].mlp]|Linear[image_encoder.vision_model.encoder.layers[8].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_52aten__view")
#loc285 = loc("1239|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPMLP[image_encoder.vision_model.encoder.layers[8].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[8].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_93xla__mark_tensor")
#loc286 = loc("1243|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_110aten__add")
#loc287 = loc("1256|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|LayerNorm[image_encoder.vision_model.encoder.layers[9].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_97xla__mark_tensor")
#loc288 = loc("1258|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|Linear[image_encoder.vision_model.encoder.layers[9].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_54aten__view")
#loc289 = loc("1287|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_89aten__einsum")
#loc290 = loc("1292|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|Linear[image_encoder.vision_model.encoder.layers[9].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_57aten__view")
#loc291 = loc("1294|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_117aten__add")
#loc292 = loc("1307|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|LayerNorm[image_encoder.vision_model.encoder.layers[9].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_101xla__mark_tensor")
#loc293 = loc("1309|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPMLP[image_encoder.vision_model.encoder.layers[9].mlp]|Linear[image_encoder.vision_model.encoder.layers[9].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_58aten__view")
#loc294 = loc("1313|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPMLP[image_encoder.vision_model.encoder.layers[9].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[9].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_103xla__mark_tensor")
#loc295 = loc("1317|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_122aten__add")
#loc296 = loc("1330|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|LayerNorm[image_encoder.vision_model.encoder.layers[10].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_107xla__mark_tensor")
#loc297 = loc("1332|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|Linear[image_encoder.vision_model.encoder.layers[10].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_60aten__view")
#loc298 = loc("1361|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_98aten__einsum")
#loc299 = loc("1366|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|Linear[image_encoder.vision_model.encoder.layers[10].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_63aten__view")
#loc300 = loc("1368|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_129aten__add")
#loc301 = loc("1381|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|LayerNorm[image_encoder.vision_model.encoder.layers[10].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_111xla__mark_tensor")
#loc302 = loc("1383|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPMLP[image_encoder.vision_model.encoder.layers[10].mlp]|Linear[image_encoder.vision_model.encoder.layers[10].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_64aten__view")
#loc303 = loc("1387|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPMLP[image_encoder.vision_model.encoder.layers[10].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[10].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_113xla__mark_tensor")
#loc304 = loc("1391|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_134aten__add")
#loc305 = loc("1404|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|LayerNorm[image_encoder.vision_model.encoder.layers[11].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_117xla__mark_tensor")
#loc306 = loc("1406|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|Linear[image_encoder.vision_model.encoder.layers[11].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_66aten__view")
#loc307 = loc("1435|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_107aten__einsum")
#loc308 = loc("1440|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|Linear[image_encoder.vision_model.encoder.layers[11].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_69aten__view")
#loc309 = loc("1442|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_141aten__add")
#loc310 = loc("1455|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|LayerNorm[image_encoder.vision_model.encoder.layers[11].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_121xla__mark_tensor")
#loc311 = loc("1457|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPMLP[image_encoder.vision_model.encoder.layers[11].mlp]|Linear[image_encoder.vision_model.encoder.layers[11].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_70aten__view")
#loc312 = loc("1461|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPMLP[image_encoder.vision_model.encoder.layers[11].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[11].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_123xla__mark_tensor")
#loc313 = loc("1465|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_146aten__add")
#loc314 = loc("1478|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|LayerNorm[image_encoder.vision_model.encoder.layers[12].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_127xla__mark_tensor")
#loc315 = loc("1480|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|Linear[image_encoder.vision_model.encoder.layers[12].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_72aten__view")
#loc316 = loc("1509|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_116aten__einsum")
#loc317 = loc("1514|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|Linear[image_encoder.vision_model.encoder.layers[12].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_75aten__view")
#loc318 = loc("1516|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_153aten__add")
#loc319 = loc("1529|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|LayerNorm[image_encoder.vision_model.encoder.layers[12].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_131xla__mark_tensor")
#loc320 = loc("1531|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPMLP[image_encoder.vision_model.encoder.layers[12].mlp]|Linear[image_encoder.vision_model.encoder.layers[12].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_76aten__view")
#loc321 = loc("1535|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPMLP[image_encoder.vision_model.encoder.layers[12].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[12].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_133xla__mark_tensor")
#loc322 = loc("1539|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_158aten__add")
#loc323 = loc("1552|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|LayerNorm[image_encoder.vision_model.encoder.layers[13].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_137xla__mark_tensor")
#loc324 = loc("1554|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|Linear[image_encoder.vision_model.encoder.layers[13].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_78aten__view")
#loc325 = loc("1583|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_125aten__einsum")
#loc326 = loc("1588|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|Linear[image_encoder.vision_model.encoder.layers[13].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_81aten__view")
#loc327 = loc("1590|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_165aten__add")
#loc328 = loc("1603|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|LayerNorm[image_encoder.vision_model.encoder.layers[13].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_141xla__mark_tensor")
#loc329 = loc("1605|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPMLP[image_encoder.vision_model.encoder.layers[13].mlp]|Linear[image_encoder.vision_model.encoder.layers[13].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_82aten__view")
#loc330 = loc("1609|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPMLP[image_encoder.vision_model.encoder.layers[13].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[13].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_143xla__mark_tensor")
#loc331 = loc("1613|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_170aten__add")
#loc332 = loc("1626|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|LayerNorm[image_encoder.vision_model.encoder.layers[14].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_147xla__mark_tensor")
#loc333 = loc("1628|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|Linear[image_encoder.vision_model.encoder.layers[14].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_84aten__view")
#loc334 = loc("1657|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_134aten__einsum")
#loc335 = loc("1662|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|Linear[image_encoder.vision_model.encoder.layers[14].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_87aten__view")
#loc336 = loc("1664|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_177aten__add")
#loc337 = loc("1677|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|LayerNorm[image_encoder.vision_model.encoder.layers[14].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_151xla__mark_tensor")
#loc338 = loc("1679|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPMLP[image_encoder.vision_model.encoder.layers[14].mlp]|Linear[image_encoder.vision_model.encoder.layers[14].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_88aten__view")
#loc339 = loc("1683|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPMLP[image_encoder.vision_model.encoder.layers[14].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[14].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_153xla__mark_tensor")
#loc340 = loc("1687|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_182aten__add")
#loc341 = loc("1700|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|LayerNorm[image_encoder.vision_model.encoder.layers[15].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_157xla__mark_tensor")
#loc342 = loc("1702|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|Linear[image_encoder.vision_model.encoder.layers[15].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_90aten__view")
#loc343 = loc("1731|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_143aten__einsum")
#loc344 = loc("1736|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|Linear[image_encoder.vision_model.encoder.layers[15].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_93aten__view")
#loc345 = loc("1738|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_189aten__add")
#loc346 = loc("1751|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|LayerNorm[image_encoder.vision_model.encoder.layers[15].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_161xla__mark_tensor")
#loc347 = loc("1753|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPMLP[image_encoder.vision_model.encoder.layers[15].mlp]|Linear[image_encoder.vision_model.encoder.layers[15].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_94aten__view")
#loc348 = loc("1757|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPMLP[image_encoder.vision_model.encoder.layers[15].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[15].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_163xla__mark_tensor")
#loc349 = loc("1761|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_194aten__add")
#loc350 = loc("1774|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|LayerNorm[image_encoder.vision_model.encoder.layers[16].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_167xla__mark_tensor")
#loc351 = loc("1776|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|Linear[image_encoder.vision_model.encoder.layers[16].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_96aten__view")
#loc352 = loc("1805|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_152aten__einsum")
#loc353 = loc("1810|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|Linear[image_encoder.vision_model.encoder.layers[16].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_99aten__view")
#loc354 = loc("1812|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_201aten__add")
#loc355 = loc("1825|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|LayerNorm[image_encoder.vision_model.encoder.layers[16].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_171xla__mark_tensor")
#loc356 = loc("1827|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPMLP[image_encoder.vision_model.encoder.layers[16].mlp]|Linear[image_encoder.vision_model.encoder.layers[16].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_100aten__view")
#loc357 = loc("1831|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPMLP[image_encoder.vision_model.encoder.layers[16].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[16].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_173xla__mark_tensor")
#loc358 = loc("1835|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_206aten__add")
#loc359 = loc("1848|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|LayerNorm[image_encoder.vision_model.encoder.layers[17].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_177xla__mark_tensor")
#loc360 = loc("1850|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|Linear[image_encoder.vision_model.encoder.layers[17].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_102aten__view")
#loc361 = loc("1879|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_161aten__einsum")
#loc362 = loc("1884|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|Linear[image_encoder.vision_model.encoder.layers[17].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_105aten__view")
#loc363 = loc("1886|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_213aten__add")
#loc364 = loc("1899|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|LayerNorm[image_encoder.vision_model.encoder.layers[17].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_181xla__mark_tensor")
#loc365 = loc("1901|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPMLP[image_encoder.vision_model.encoder.layers[17].mlp]|Linear[image_encoder.vision_model.encoder.layers[17].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_106aten__view")
#loc366 = loc("1905|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPMLP[image_encoder.vision_model.encoder.layers[17].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[17].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_183xla__mark_tensor")
#loc367 = loc("1909|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_218aten__add")
#loc368 = loc("1922|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|LayerNorm[image_encoder.vision_model.encoder.layers[18].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_187xla__mark_tensor")
#loc369 = loc("1924|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|Linear[image_encoder.vision_model.encoder.layers[18].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_108aten__view")
#loc370 = loc("1953|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_170aten__einsum")
#loc371 = loc("1958|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|Linear[image_encoder.vision_model.encoder.layers[18].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_111aten__view")
#loc372 = loc("1960|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_225aten__add")
#loc373 = loc("1973|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|LayerNorm[image_encoder.vision_model.encoder.layers[18].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_191xla__mark_tensor")
#loc374 = loc("1975|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPMLP[image_encoder.vision_model.encoder.layers[18].mlp]|Linear[image_encoder.vision_model.encoder.layers[18].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_112aten__view")
#loc375 = loc("1979|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPMLP[image_encoder.vision_model.encoder.layers[18].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[18].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_193xla__mark_tensor")
#loc376 = loc("1983|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_230aten__add")
#loc377 = loc("1996|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|LayerNorm[image_encoder.vision_model.encoder.layers[19].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_197xla__mark_tensor")
#loc378 = loc("1998|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|Linear[image_encoder.vision_model.encoder.layers[19].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_114aten__view")
#loc379 = loc("2027|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_179aten__einsum")
#loc380 = loc("2032|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|Linear[image_encoder.vision_model.encoder.layers[19].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_117aten__view")
#loc381 = loc("2034|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_237aten__add")
#loc382 = loc("2047|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|LayerNorm[image_encoder.vision_model.encoder.layers[19].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_201xla__mark_tensor")
#loc383 = loc("2049|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPMLP[image_encoder.vision_model.encoder.layers[19].mlp]|Linear[image_encoder.vision_model.encoder.layers[19].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_118aten__view")
#loc384 = loc("2053|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPMLP[image_encoder.vision_model.encoder.layers[19].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[19].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_203xla__mark_tensor")
#loc385 = loc("2057|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_242aten__add")
#loc386 = loc("2070|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|LayerNorm[image_encoder.vision_model.encoder.layers[20].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_207xla__mark_tensor")
#loc387 = loc("2072|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|Linear[image_encoder.vision_model.encoder.layers[20].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_120aten__view")
#loc388 = loc("2101|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_188aten__einsum")
#loc389 = loc("2106|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|Linear[image_encoder.vision_model.encoder.layers[20].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_123aten__view")
#loc390 = loc("2108|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_249aten__add")
#loc391 = loc("2121|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|LayerNorm[image_encoder.vision_model.encoder.layers[20].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_211xla__mark_tensor")
#loc392 = loc("2123|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPMLP[image_encoder.vision_model.encoder.layers[20].mlp]|Linear[image_encoder.vision_model.encoder.layers[20].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_124aten__view")
#loc393 = loc("2127|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPMLP[image_encoder.vision_model.encoder.layers[20].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[20].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_213xla__mark_tensor")
#loc394 = loc("2131|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_254aten__add")
#loc395 = loc("2144|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|LayerNorm[image_encoder.vision_model.encoder.layers[21].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_217xla__mark_tensor")
#loc396 = loc("2146|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|Linear[image_encoder.vision_model.encoder.layers[21].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_126aten__view")
#loc397 = loc("2175|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_197aten__einsum")
#loc398 = loc("2180|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|Linear[image_encoder.vision_model.encoder.layers[21].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_129aten__view")
#loc399 = loc("2182|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_261aten__add")
#loc400 = loc("2195|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|LayerNorm[image_encoder.vision_model.encoder.layers[21].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_221xla__mark_tensor")
#loc401 = loc("2197|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPMLP[image_encoder.vision_model.encoder.layers[21].mlp]|Linear[image_encoder.vision_model.encoder.layers[21].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_130aten__view")
#loc402 = loc("2201|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPMLP[image_encoder.vision_model.encoder.layers[21].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[21].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_223xla__mark_tensor")
#loc403 = loc("2205|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_266aten__add")
#loc404 = loc("2218|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|LayerNorm[image_encoder.vision_model.encoder.layers[22].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_227xla__mark_tensor")
#loc405 = loc("2220|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|Linear[image_encoder.vision_model.encoder.layers[22].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_132aten__view")
#loc406 = loc("2249|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_206aten__einsum")
#loc407 = loc("2254|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|Linear[image_encoder.vision_model.encoder.layers[22].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_135aten__view")
#loc408 = loc("2256|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_273aten__add")
#loc409 = loc("2269|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|LayerNorm[image_encoder.vision_model.encoder.layers[22].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_231xla__mark_tensor")
#loc410 = loc("2271|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPMLP[image_encoder.vision_model.encoder.layers[22].mlp]|Linear[image_encoder.vision_model.encoder.layers[22].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_136aten__view")
#loc411 = loc("2275|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPMLP[image_encoder.vision_model.encoder.layers[22].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[22].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_233xla__mark_tensor")
#loc412 = loc("2279|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_278aten__add")
#loc413 = loc("2292|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|LayerNorm[image_encoder.vision_model.encoder.layers[23].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_237xla__mark_tensor")
#loc414 = loc("2294|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|Linear[image_encoder.vision_model.encoder.layers[23].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_138aten__view")
#loc415 = loc("2323|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_215aten__einsum")
#loc416 = loc("2328|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|Linear[image_encoder.vision_model.encoder.layers[23].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_141aten__view")
#loc417 = loc("2330|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_285aten__add")
#loc418 = loc("2343|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|LayerNorm[image_encoder.vision_model.encoder.layers[23].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_241xla__mark_tensor")
#loc419 = loc("2345|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPMLP[image_encoder.vision_model.encoder.layers[23].mlp]|Linear[image_encoder.vision_model.encoder.layers[23].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_142aten__view")
#loc420 = loc("2349|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPMLP[image_encoder.vision_model.encoder.layers[23].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[23].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_243xla__mark_tensor")
#loc421 = loc("2353|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_290aten__add")
#loc422 = loc("2366|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|LayerNorm[image_encoder.vision_model.encoder.layers[24].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_247xla__mark_tensor")
#loc423 = loc("2368|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|Linear[image_encoder.vision_model.encoder.layers[24].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_144aten__view")
#loc424 = loc("2397|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_224aten__einsum")
#loc425 = loc("2402|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|Linear[image_encoder.vision_model.encoder.layers[24].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_147aten__view")
#loc426 = loc("2404|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_297aten__add")
#loc427 = loc("2417|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|LayerNorm[image_encoder.vision_model.encoder.layers[24].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_251xla__mark_tensor")
#loc428 = loc("2419|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPMLP[image_encoder.vision_model.encoder.layers[24].mlp]|Linear[image_encoder.vision_model.encoder.layers[24].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_148aten__view")
#loc429 = loc("2423|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPMLP[image_encoder.vision_model.encoder.layers[24].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[24].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_253xla__mark_tensor")
#loc430 = loc("2427|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_302aten__add")
#loc431 = loc("2440|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|LayerNorm[image_encoder.vision_model.encoder.layers[25].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_257xla__mark_tensor")
#loc432 = loc("2442|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|Linear[image_encoder.vision_model.encoder.layers[25].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_150aten__view")
#loc433 = loc("2471|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_233aten__einsum")
#loc434 = loc("2476|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|Linear[image_encoder.vision_model.encoder.layers[25].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_153aten__view")
#loc435 = loc("2478|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_309aten__add")
#loc436 = loc("2491|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|LayerNorm[image_encoder.vision_model.encoder.layers[25].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_261xla__mark_tensor")
#loc437 = loc("2493|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPMLP[image_encoder.vision_model.encoder.layers[25].mlp]|Linear[image_encoder.vision_model.encoder.layers[25].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_154aten__view")
#loc438 = loc("2497|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPMLP[image_encoder.vision_model.encoder.layers[25].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[25].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_263xla__mark_tensor")
#loc439 = loc("2501|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_314aten__add")
#loc440 = loc("2514|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|LayerNorm[image_encoder.vision_model.encoder.layers[26].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_267xla__mark_tensor")
#loc441 = loc("2516|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|Linear[image_encoder.vision_model.encoder.layers[26].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_156aten__view")
#loc442 = loc("2545|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_242aten__einsum")
#loc443 = loc("2550|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|Linear[image_encoder.vision_model.encoder.layers[26].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_159aten__view")
#loc444 = loc("2552|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_321aten__add")
#loc445 = loc("2565|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|LayerNorm[image_encoder.vision_model.encoder.layers[26].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_271xla__mark_tensor")
#loc446 = loc("2567|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPMLP[image_encoder.vision_model.encoder.layers[26].mlp]|Linear[image_encoder.vision_model.encoder.layers[26].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_160aten__view")
#loc447 = loc("2571|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPMLP[image_encoder.vision_model.encoder.layers[26].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[26].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_273xla__mark_tensor")
#loc448 = loc("2575|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_326aten__add")
#loc449 = loc("2588|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|LayerNorm[image_encoder.vision_model.encoder.layers[27].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_277xla__mark_tensor")
#loc450 = loc("2590|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|Linear[image_encoder.vision_model.encoder.layers[27].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_162aten__view")
#loc451 = loc("2619|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_251aten__einsum")
#loc452 = loc("2624|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|Linear[image_encoder.vision_model.encoder.layers[27].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_165aten__view")
#loc453 = loc("2626|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_333aten__add")
#loc454 = loc("2639|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|LayerNorm[image_encoder.vision_model.encoder.layers[27].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_281xla__mark_tensor")
#loc455 = loc("2641|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPMLP[image_encoder.vision_model.encoder.layers[27].mlp]|Linear[image_encoder.vision_model.encoder.layers[27].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_166aten__view")
#loc456 = loc("2645|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPMLP[image_encoder.vision_model.encoder.layers[27].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[27].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_283xla__mark_tensor")
#loc457 = loc("2649|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_338aten__add")
#loc458 = loc("2662|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|LayerNorm[image_encoder.vision_model.encoder.layers[28].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_287xla__mark_tensor")
#loc459 = loc("2664|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|Linear[image_encoder.vision_model.encoder.layers[28].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_168aten__view")
#loc460 = loc("2693|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_260aten__einsum")
#loc461 = loc("2698|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|Linear[image_encoder.vision_model.encoder.layers[28].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_171aten__view")
#loc462 = loc("2700|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_345aten__add")
#loc463 = loc("2713|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|LayerNorm[image_encoder.vision_model.encoder.layers[28].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_291xla__mark_tensor")
#loc464 = loc("2715|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPMLP[image_encoder.vision_model.encoder.layers[28].mlp]|Linear[image_encoder.vision_model.encoder.layers[28].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_172aten__view")
#loc465 = loc("2719|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPMLP[image_encoder.vision_model.encoder.layers[28].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[28].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_293xla__mark_tensor")
#loc466 = loc("2723|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_350aten__add")
#loc467 = loc("2736|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|LayerNorm[image_encoder.vision_model.encoder.layers[29].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_297xla__mark_tensor")
#loc468 = loc("2738|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|Linear[image_encoder.vision_model.encoder.layers[29].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_174aten__view")
#loc469 = loc("2767|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_269aten__einsum")
#loc470 = loc("2772|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|Linear[image_encoder.vision_model.encoder.layers[29].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_177aten__view")
#loc471 = loc("2774|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_357aten__add")
#loc472 = loc("2787|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|LayerNorm[image_encoder.vision_model.encoder.layers[29].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_301xla__mark_tensor")
#loc473 = loc("2789|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPMLP[image_encoder.vision_model.encoder.layers[29].mlp]|Linear[image_encoder.vision_model.encoder.layers[29].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_178aten__view")
#loc474 = loc("2793|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPMLP[image_encoder.vision_model.encoder.layers[29].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[29].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_303xla__mark_tensor")
#loc475 = loc("2797|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_362aten__add")
#loc476 = loc("2810|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|LayerNorm[image_encoder.vision_model.encoder.layers[30].layer_norm1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|396|mark_tensor_307xla__mark_tensor")
#loc477 = loc("2812|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|Linear[image_encoder.vision_model.encoder.layers[30].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|matmul_180aten__view")
#loc478 = loc("2841|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|333|_to_copy_278aten__einsum")
#loc479 = loc("2846|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|Linear[image_encoder.vision_model.encoder.layers[30].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_183aten__view")
#loc480 = loc("2848|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|403|add_369aten__add")
#loc481 = loc("2861|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|LayerNorm[image_encoder.vision_model.encoder.layers[30].layer_norm2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|406|mark_tensor_311xla__mark_tensor")
#loc482 = loc("2863|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPMLP[image_encoder.vision_model.encoder.layers[30].mlp]|Linear[image_encoder.vision_model.encoder.layers[30].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|matmul_184aten__view")
#loc483 = loc("2867|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPMLP[image_encoder.vision_model.encoder.layers[30].mlp]|GELUActivation[image_encoder.vision_model.encoder.layers[30].mlp.activation_fn]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|363|mark_tensor_313xla__mark_tensor")
#loc484 = loc("2871|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:377|forward|408|add_374aten__add")
#loc485 = loc("2888|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|LayerNorm[resampler.layers[0].ln0]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2246|mark_tensor_331xla__mark_tensor")
#loc486 = loc("2906|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|Attention[resampler.layers[0].attn]|Linear[resampler.layers[0].attn.to_k]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2747|matmul_195aten__mm")
#loc487 = loc("2916|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|Attention[resampler.layers[0].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2765|_to_copy_297xla__cast")
#loc488 = loc("2908|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|Attention[resampler.layers[0].attn]|Linear[resampler.layers[0].attn.to_v]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2748|matmul_196aten__mm")
#loc489 = loc("2917|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|Attention[resampler.layers[0].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2765|_to_copy_298xla__cast")
#loc490 = loc("2930|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|Attention[resampler.layers[0].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2765|_to_copy_300aten__einsum")
#loc491 = loc("2935|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|Attention[resampler.layers[0].attn]|Linear[resampler.layers[0].attn.to_out[0]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2773|matmul_197aten__view")
#loc492 = loc("2935|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|Attention[resampler.layers[0].attn]|Linear[resampler.layers[0].attn.to_out[0]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2773|matmul_197aten__mm")
#loc493 = loc("2936|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|Attention[resampler.layers[0].attn]|Dropout[resampler.layers[0].attn.to_out[1]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2775|clone_33aten__view")
#loc494 = loc("2937|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|Attention[resampler.layers[0].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2783|divaten__div")
#loc495 = loc("2938|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2249|add_394aten__add")
#loc496 = loc("2951|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|Sequential[resampler.layers[0].ff]|LayerNorm[getattr(resampler.layers[0].ff, '0')]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2250|mark_tensor_339xla__mark_tensor")
#loc497 = loc("2953|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|Sequential[resampler.layers[0].ff]|FeedForward[getattr(resampler.layers[0].ff, '1')]|GELU[getattr(resampler.layers[0].ff, '1').net[0]]|Linear[getattr(resampler.layers[0].ff, '1').net[0].proj]|/usr/local/lib/python3.11/dist-packages/diffusers/models/activations.py:87|forward|88|matmul_198aten__view")
#loc498 = loc("2953|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|Sequential[resampler.layers[0].ff]|FeedForward[getattr(resampler.layers[0].ff, '1')]|GELU[getattr(resampler.layers[0].ff, '1').net[0]]|Linear[getattr(resampler.layers[0].ff, '1').net[0].proj]|/usr/local/lib/python3.11/dist-packages/diffusers/models/activations.py:87|forward|88|matmul_198aten__mm")
#loc499 = loc("2959|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|Sequential[resampler.layers[0].ff]|FeedForward[getattr(resampler.layers[0].ff, '1')]|Linear[getattr(resampler.layers[0].ff, '1').net[2]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention.py:1736|forward|1741|matmul_199aten__mm")
#loc500 = loc("2959|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|Sequential[resampler.layers[0].ff]|FeedForward[getattr(resampler.layers[0].ff, '1')]|Linear[getattr(resampler.layers[0].ff, '1').net[2]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention.py:1736|forward|1741|matmul_199aten__view")
#loc501 = loc("2960|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[0]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2250|add_397aten__add")
#loc502 = loc("2986|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|LayerNorm[resampler.layers[1].ln1]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2247|mark_tensor_349xla__mark_tensor")
#loc503 = loc("2989|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|Attention[resampler.layers[1].attn]|Linear[resampler.layers[1].attn.to_q]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2740|matmul_200aten__view")
#loc504 = loc("2989|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|Attention[resampler.layers[1].attn]|Linear[resampler.layers[1].attn.to_q]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2740|matmul_200aten__mm")
#loc505 = loc("3000|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|Attention[resampler.layers[1].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2765|_to_copy_307xla__cast")
#loc506 = loc("2973|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|LayerNorm[resampler.layers[1].ln0]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2246|mark_tensor_345xla__mark_tensor")
#loc507 = loc("2987|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2248|cat_2aten__cat")
#loc508 = loc("2991|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|Attention[resampler.layers[1].attn]|Linear[resampler.layers[1].attn.to_k]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2747|matmul_201aten__mm")
#loc509 = loc("3001|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|Attention[resampler.layers[1].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2765|_to_copy_308xla__cast")
#loc510 = loc("2993|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|Attention[resampler.layers[1].attn]|Linear[resampler.layers[1].attn.to_v]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2748|matmul_202aten__mm")
#loc511 = loc("3002|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|Attention[resampler.layers[1].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2765|_to_copy_309xla__cast")
#loc512 = loc("3015|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|Attention[resampler.layers[1].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2765|_to_copy_311aten__einsum")
#loc513 = loc("3020|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|Attention[resampler.layers[1].attn]|Linear[resampler.layers[1].attn.to_out[0]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2773|matmul_203aten__view")
#loc514 = loc("3020|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|Attention[resampler.layers[1].attn]|Linear[resampler.layers[1].attn.to_out[0]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2773|matmul_203aten__mm")
#loc515 = loc("3021|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|Attention[resampler.layers[1].attn]|Dropout[resampler.layers[1].attn.to_out[1]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2775|clone_36aten__view")
#loc516 = loc("3022|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|Attention[resampler.layers[1].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2783|div_1aten__div")
#loc517 = loc("3023|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2249|add_402aten__add")
#loc518 = loc("3036|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|Sequential[resampler.layers[1].ff]|LayerNorm[getattr(resampler.layers[1].ff, '0')]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2250|mark_tensor_353xla__mark_tensor")
#loc519 = loc("3038|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|Sequential[resampler.layers[1].ff]|FeedForward[getattr(resampler.layers[1].ff, '1')]|GELU[getattr(resampler.layers[1].ff, '1').net[0]]|Linear[getattr(resampler.layers[1].ff, '1').net[0].proj]|/usr/local/lib/python3.11/dist-packages/diffusers/models/activations.py:87|forward|88|matmul_204aten__view")
#loc520 = loc("3038|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|Sequential[resampler.layers[1].ff]|FeedForward[getattr(resampler.layers[1].ff, '1')]|GELU[getattr(resampler.layers[1].ff, '1').net[0]]|Linear[getattr(resampler.layers[1].ff, '1').net[0].proj]|/usr/local/lib/python3.11/dist-packages/diffusers/models/activations.py:87|forward|88|matmul_204aten__mm")
#loc521 = loc("3044|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|Sequential[resampler.layers[1].ff]|FeedForward[getattr(resampler.layers[1].ff, '1')]|Linear[getattr(resampler.layers[1].ff, '1').net[2]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention.py:1736|forward|1741|matmul_205aten__mm")
#loc522 = loc("3044|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|Sequential[resampler.layers[1].ff]|FeedForward[getattr(resampler.layers[1].ff, '1')]|Linear[getattr(resampler.layers[1].ff, '1').net[2]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention.py:1736|forward|1741|matmul_205aten__view")
#loc523 = loc("3045|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[1]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2250|add_405aten__add")
#loc524 = loc("3071|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|LayerNorm[resampler.layers[2].ln1]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2247|mark_tensor_363xla__mark_tensor")
#loc525 = loc("3074|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|Attention[resampler.layers[2].attn]|Linear[resampler.layers[2].attn.to_q]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2740|matmul_206aten__view")
#loc526 = loc("3074|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|Attention[resampler.layers[2].attn]|Linear[resampler.layers[2].attn.to_q]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2740|matmul_206aten__mm")
#loc527 = loc("3085|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|Attention[resampler.layers[2].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2765|_to_copy_318xla__cast")
#loc528 = loc("3058|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|LayerNorm[resampler.layers[2].ln0]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2246|mark_tensor_359xla__mark_tensor")
#loc529 = loc("3072|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2248|cat_3aten__cat")
#loc530 = loc("3076|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|Attention[resampler.layers[2].attn]|Linear[resampler.layers[2].attn.to_k]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2747|matmul_207aten__mm")
#loc531 = loc("3086|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|Attention[resampler.layers[2].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2765|_to_copy_319xla__cast")
#loc532 = loc("3078|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|Attention[resampler.layers[2].attn]|Linear[resampler.layers[2].attn.to_v]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2748|matmul_208aten__mm")
#loc533 = loc("3087|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|Attention[resampler.layers[2].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2765|_to_copy_320xla__cast")
#loc534 = loc("3100|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|Attention[resampler.layers[2].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2765|_to_copy_322aten__einsum")
#loc535 = loc("3105|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|Attention[resampler.layers[2].attn]|Linear[resampler.layers[2].attn.to_out[0]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2773|matmul_209aten__view")
#loc536 = loc("3105|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|Attention[resampler.layers[2].attn]|Linear[resampler.layers[2].attn.to_out[0]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2773|matmul_209aten__mm")
#loc537 = loc("3106|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|Attention[resampler.layers[2].attn]|Dropout[resampler.layers[2].attn.to_out[1]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2775|clone_39aten__view")
#loc538 = loc("3107|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|Attention[resampler.layers[2].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2783|div_2aten__div")
#loc539 = loc("3108|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2249|add_410aten__add")
#loc540 = loc("3121|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|Sequential[resampler.layers[2].ff]|LayerNorm[getattr(resampler.layers[2].ff, '0')]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2250|mark_tensor_367xla__mark_tensor")
#loc541 = loc("3123|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|Sequential[resampler.layers[2].ff]|FeedForward[getattr(resampler.layers[2].ff, '1')]|GELU[getattr(resampler.layers[2].ff, '1').net[0]]|Linear[getattr(resampler.layers[2].ff, '1').net[0].proj]|/usr/local/lib/python3.11/dist-packages/diffusers/models/activations.py:87|forward|88|matmul_210aten__view")
#loc542 = loc("3123|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|Sequential[resampler.layers[2].ff]|FeedForward[getattr(resampler.layers[2].ff, '1')]|GELU[getattr(resampler.layers[2].ff, '1').net[0]]|Linear[getattr(resampler.layers[2].ff, '1').net[0].proj]|/usr/local/lib/python3.11/dist-packages/diffusers/models/activations.py:87|forward|88|matmul_210aten__mm")
#loc543 = loc("3129|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|Sequential[resampler.layers[2].ff]|FeedForward[getattr(resampler.layers[2].ff, '1')]|Linear[getattr(resampler.layers[2].ff, '1').net[2]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention.py:1736|forward|1741|matmul_211aten__mm")
#loc544 = loc("3129|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|Sequential[resampler.layers[2].ff]|FeedForward[getattr(resampler.layers[2].ff, '1')]|Linear[getattr(resampler.layers[2].ff, '1').net[2]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention.py:1736|forward|1741|matmul_211aten__view")
#loc545 = loc("3130|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[2]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2250|add_413aten__add")
#loc546 = loc("3156|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|LayerNorm[resampler.layers[3].ln1]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2247|mark_tensor_377xla__mark_tensor")
#loc547 = loc("3159|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|Attention[resampler.layers[3].attn]|Linear[resampler.layers[3].attn.to_q]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2740|matmul_212aten__view")
#loc548 = loc("3159|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|Attention[resampler.layers[3].attn]|Linear[resampler.layers[3].attn.to_q]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2740|matmul_212aten__mm")
#loc549 = loc("3170|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|Attention[resampler.layers[3].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2765|_to_copy_329xla__cast")
#loc550 = loc("3143|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|LayerNorm[resampler.layers[3].ln0]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2246|mark_tensor_373xla__mark_tensor")
#loc551 = loc("3157|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2248|cat_4aten__cat")
#loc552 = loc("3161|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|Attention[resampler.layers[3].attn]|Linear[resampler.layers[3].attn.to_k]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2747|matmul_213aten__mm")
#loc553 = loc("3171|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|Attention[resampler.layers[3].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2765|_to_copy_330xla__cast")
#loc554 = loc("3163|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|Attention[resampler.layers[3].attn]|Linear[resampler.layers[3].attn.to_v]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2748|matmul_214aten__mm")
#loc555 = loc("3172|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|Attention[resampler.layers[3].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2765|_to_copy_331xla__cast")
#loc556 = loc("3185|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|Attention[resampler.layers[3].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2765|_to_copy_333aten__einsum")
#loc557 = loc("3190|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|Attention[resampler.layers[3].attn]|Linear[resampler.layers[3].attn.to_out[0]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2773|matmul_215aten__view")
#loc558 = loc("3190|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|Attention[resampler.layers[3].attn]|Linear[resampler.layers[3].attn.to_out[0]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2773|matmul_215aten__mm")
#loc559 = loc("3191|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|Attention[resampler.layers[3].attn]|Dropout[resampler.layers[3].attn.to_out[1]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2775|clone_42aten__view")
#loc560 = loc("3192|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|Attention[resampler.layers[3].attn]|/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py:2703|__call__|2783|div_3aten__div")
#loc561 = loc("3193|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2249|add_418aten__add")
#loc562 = loc("3206|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|Sequential[resampler.layers[3].ff]|LayerNorm[getattr(resampler.layers[3].ff, '0')]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2250|mark_tensor_381xla__mark_tensor")
#loc563 = loc("3208|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|Sequential[resampler.layers[3].ff]|FeedForward[getattr(resampler.layers[3].ff, '1')]|GELU[getattr(resampler.layers[3].ff, '1').net[0]]|Linear[getattr(resampler.layers[3].ff, '1').net[0].proj]|/usr/local/lib/python3.11/dist-packages/diffusers/models/activations.py:87|forward|88|matmul_216aten__view")
#loc564 = loc("3208|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|Sequential[resampler.layers[3].ff]|FeedForward[getattr(resampler.layers[3].ff, '1')]|GELU[getattr(resampler.layers[3].ff, '1').net[0]]|Linear[getattr(resampler.layers[3].ff, '1').net[0].proj]|/usr/local/lib/python3.11/dist-packages/diffusers/models/activations.py:87|forward|88|matmul_216aten__mm")
#loc565 = loc("3217|IPAdapterPlusImageProjection[resampler]|Linear[resampler.proj_out]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2293|forward|2309|matmul_218aten__view")
#loc566 = loc("3215|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2250|add_421aten__add")
#loc567 = loc("3231|IPAdapterPlusImageProjection[resampler]|LayerNorm[resampler.norm_out]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2293|forward|2310|mark_tensor_387xla__mark_tensor")
#loc568 = loc("558|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPVisionEmbeddings[image_encoder.vision_model.embeddings]|Conv2d[image_encoder.vision_model.embeddings.patch_embedding]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:195|forward|202|convolutionaten__convolution_overrideable_prepare_conv2d_weight"(#loc93))
#loc569 = loc("563|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPVisionEmbeddings[image_encoder.vision_model.embeddings]|Embedding[image_encoder.vision_model.embeddings.position_embedding]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:195|forward|210|embeddingaten__index_select_workaround"(#loc119))
#loc570 = loc("558|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPVisionEmbeddings[image_encoder.vision_model.embeddings]|Conv2d[image_encoder.vision_model.embeddings.patch_embedding]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:195|forward|202|convolutionaten__convolution_overrideable_reshape"(#loc93))
#loc571 = loc("593|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|Linear[image_encoder.vision_model.encoder.layers[0].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_5aten__add_decomp_matmul"(#loc63))
#loc572 = loc("593|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|Linear[image_encoder.vision_model.encoder.layers[0].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_5aten__add_decomp_add"(#loc63))
#loc573 = loc("593|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|Linear[image_encoder.vision_model.encoder.layers[0].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_5aten__add_split_q"(#loc63))
#loc574 = loc("593|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|Linear[image_encoder.vision_model.encoder.layers[0].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_5aten__add_split_k"(#loc63))
#loc575 = loc("593|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|Linear[image_encoder.vision_model.encoder.layers[0].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_5aten__add_split_v"(#loc63))
#loc576 = loc("593|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|Linear[image_encoder.vision_model.encoder.layers[0].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_5aten__add_reshape_q"(#loc63))
#loc577 = loc("593|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|Linear[image_encoder.vision_model.encoder.layers[0].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_5aten__add_reshape_k"(#loc63))
#loc578 = loc("593|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|Linear[image_encoder.vision_model.encoder.layers[0].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_5aten__add_reshape_v"(#loc63))
#loc579 = loc("593|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|Linear[image_encoder.vision_model.encoder.layers[0].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_5aten__add_permute_q"(#loc63))
#loc580 = loc("593|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|Linear[image_encoder.vision_model.encoder.layers[0].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_5aten__add_permute_k"(#loc63))
#loc581 = loc("593|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|Linear[image_encoder.vision_model.encoder.layers[0].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_5aten__add_permute_v"(#loc63))
#loc582 = loc("626|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|Linear[image_encoder.vision_model.encoder.layers[0].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_3aten__view_concat_heads"(#loc209))
#loc583 = loc("627|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|Linear[image_encoder.vision_model.encoder.layers[0].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_8aten__add_decomp_matmul"(#loc163))
#loc584 = loc("627|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPAttention[image_encoder.vision_model.encoder.layers[0].self_attn]|Linear[image_encoder.vision_model.encoder.layers[0].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_8aten__add_decomp_add"(#loc163))
#loc585 = loc("644|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPMLP[image_encoder.vision_model.encoder.layers[0].mlp]|Linear[image_encoder.vision_model.encoder.layers[0].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_12aten__add_decomp_matmul"(#loc54))
#loc586 = loc("644|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPMLP[image_encoder.vision_model.encoder.layers[0].mlp]|Linear[image_encoder.vision_model.encoder.layers[0].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_12aten__add_decomp_add"(#loc54))
#loc587 = loc("644|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPMLP[image_encoder.vision_model.encoder.layers[0].mlp]|Linear[image_encoder.vision_model.encoder.layers[0].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_12aten__add_decomp_gelu"(#loc54))
#loc588 = loc("650|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPMLP[image_encoder.vision_model.encoder.layers[0].mlp]|Linear[image_encoder.vision_model.encoder.layers[0].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_13aten__add_decomp_matmul"(#loc102))
#loc589 = loc("650|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[0]]|CLIPMLP[image_encoder.vision_model.encoder.layers[0].mlp]|Linear[image_encoder.vision_model.encoder.layers[0].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_13aten__add_decomp_add"(#loc102))
#loc590 = loc("667|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|Linear[image_encoder.vision_model.encoder.layers[1].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_17aten__add_decomp_matmul"(#loc88))
#loc591 = loc("667|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|Linear[image_encoder.vision_model.encoder.layers[1].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_17aten__add_decomp_add"(#loc88))
#loc592 = loc("667|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|Linear[image_encoder.vision_model.encoder.layers[1].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_17aten__add_split_q"(#loc88))
#loc593 = loc("667|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|Linear[image_encoder.vision_model.encoder.layers[1].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_17aten__add_split_k"(#loc88))
#loc594 = loc("667|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|Linear[image_encoder.vision_model.encoder.layers[1].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_17aten__add_split_v"(#loc88))
#loc595 = loc("667|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|Linear[image_encoder.vision_model.encoder.layers[1].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_17aten__add_reshape_q"(#loc88))
#loc596 = loc("667|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|Linear[image_encoder.vision_model.encoder.layers[1].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_17aten__add_reshape_k"(#loc88))
#loc597 = loc("667|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|Linear[image_encoder.vision_model.encoder.layers[1].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_17aten__add_reshape_v"(#loc88))
#loc598 = loc("667|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|Linear[image_encoder.vision_model.encoder.layers[1].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_17aten__add_permute_q"(#loc88))
#loc599 = loc("667|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|Linear[image_encoder.vision_model.encoder.layers[1].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_17aten__add_permute_k"(#loc88))
#loc600 = loc("667|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|Linear[image_encoder.vision_model.encoder.layers[1].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_17aten__add_permute_v"(#loc88))
#loc601 = loc("700|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|Linear[image_encoder.vision_model.encoder.layers[1].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_9aten__view_concat_heads"(#loc218))
#loc602 = loc("701|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|Linear[image_encoder.vision_model.encoder.layers[1].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_20aten__add_decomp_matmul"(#loc74))
#loc603 = loc("701|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPAttention[image_encoder.vision_model.encoder.layers[1].self_attn]|Linear[image_encoder.vision_model.encoder.layers[1].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_20aten__add_decomp_add"(#loc74))
#loc604 = loc("718|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPMLP[image_encoder.vision_model.encoder.layers[1].mlp]|Linear[image_encoder.vision_model.encoder.layers[1].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_24aten__add_decomp_matmul"(#loc15))
#loc605 = loc("718|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPMLP[image_encoder.vision_model.encoder.layers[1].mlp]|Linear[image_encoder.vision_model.encoder.layers[1].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_24aten__add_decomp_add"(#loc15))
#loc606 = loc("718|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPMLP[image_encoder.vision_model.encoder.layers[1].mlp]|Linear[image_encoder.vision_model.encoder.layers[1].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_24aten__add_decomp_gelu"(#loc15))
#loc607 = loc("724|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPMLP[image_encoder.vision_model.encoder.layers[1].mlp]|Linear[image_encoder.vision_model.encoder.layers[1].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_25aten__add_decomp_matmul"(#loc27))
#loc608 = loc("724|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[1]]|CLIPMLP[image_encoder.vision_model.encoder.layers[1].mlp]|Linear[image_encoder.vision_model.encoder.layers[1].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_25aten__add_decomp_add"(#loc27))
#loc609 = loc("741|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|Linear[image_encoder.vision_model.encoder.layers[2].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_29aten__add_decomp_matmul"(#loc109))
#loc610 = loc("741|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|Linear[image_encoder.vision_model.encoder.layers[2].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_29aten__add_decomp_add"(#loc109))
#loc611 = loc("741|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|Linear[image_encoder.vision_model.encoder.layers[2].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_29aten__add_split_q"(#loc109))
#loc612 = loc("741|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|Linear[image_encoder.vision_model.encoder.layers[2].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_29aten__add_split_k"(#loc109))
#loc613 = loc("741|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|Linear[image_encoder.vision_model.encoder.layers[2].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_29aten__add_split_v"(#loc109))
#loc614 = loc("741|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|Linear[image_encoder.vision_model.encoder.layers[2].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_29aten__add_reshape_q"(#loc109))
#loc615 = loc("741|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|Linear[image_encoder.vision_model.encoder.layers[2].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_29aten__add_reshape_k"(#loc109))
#loc616 = loc("741|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|Linear[image_encoder.vision_model.encoder.layers[2].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_29aten__add_reshape_v"(#loc109))
#loc617 = loc("741|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|Linear[image_encoder.vision_model.encoder.layers[2].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_29aten__add_permute_q"(#loc109))
#loc618 = loc("741|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|Linear[image_encoder.vision_model.encoder.layers[2].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_29aten__add_permute_k"(#loc109))
#loc619 = loc("741|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|Linear[image_encoder.vision_model.encoder.layers[2].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_29aten__add_permute_v"(#loc109))
#loc620 = loc("774|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|Linear[image_encoder.vision_model.encoder.layers[2].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_15aten__view_concat_heads"(#loc227))
#loc621 = loc("775|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|Linear[image_encoder.vision_model.encoder.layers[2].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_32aten__add_decomp_matmul"(#loc161))
#loc622 = loc("775|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPAttention[image_encoder.vision_model.encoder.layers[2].self_attn]|Linear[image_encoder.vision_model.encoder.layers[2].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_32aten__add_decomp_add"(#loc161))
#loc623 = loc("792|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPMLP[image_encoder.vision_model.encoder.layers[2].mlp]|Linear[image_encoder.vision_model.encoder.layers[2].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_36aten__add_decomp_matmul"(#loc112))
#loc624 = loc("792|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPMLP[image_encoder.vision_model.encoder.layers[2].mlp]|Linear[image_encoder.vision_model.encoder.layers[2].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_36aten__add_decomp_add"(#loc112))
#loc625 = loc("792|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPMLP[image_encoder.vision_model.encoder.layers[2].mlp]|Linear[image_encoder.vision_model.encoder.layers[2].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_36aten__add_decomp_gelu"(#loc112))
#loc626 = loc("798|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPMLP[image_encoder.vision_model.encoder.layers[2].mlp]|Linear[image_encoder.vision_model.encoder.layers[2].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_37aten__add_decomp_matmul"(#loc190))
#loc627 = loc("798|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[2]]|CLIPMLP[image_encoder.vision_model.encoder.layers[2].mlp]|Linear[image_encoder.vision_model.encoder.layers[2].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_37aten__add_decomp_add"(#loc190))
#loc628 = loc("815|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|Linear[image_encoder.vision_model.encoder.layers[3].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_41aten__add_decomp_matmul"(#loc121))
#loc629 = loc("815|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|Linear[image_encoder.vision_model.encoder.layers[3].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_41aten__add_decomp_add"(#loc121))
#loc630 = loc("815|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|Linear[image_encoder.vision_model.encoder.layers[3].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_41aten__add_split_q"(#loc121))
#loc631 = loc("815|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|Linear[image_encoder.vision_model.encoder.layers[3].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_41aten__add_split_k"(#loc121))
#loc632 = loc("815|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|Linear[image_encoder.vision_model.encoder.layers[3].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_41aten__add_split_v"(#loc121))
#loc633 = loc("815|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|Linear[image_encoder.vision_model.encoder.layers[3].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_41aten__add_reshape_q"(#loc121))
#loc634 = loc("815|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|Linear[image_encoder.vision_model.encoder.layers[3].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_41aten__add_reshape_k"(#loc121))
#loc635 = loc("815|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|Linear[image_encoder.vision_model.encoder.layers[3].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_41aten__add_reshape_v"(#loc121))
#loc636 = loc("815|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|Linear[image_encoder.vision_model.encoder.layers[3].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_41aten__add_permute_q"(#loc121))
#loc637 = loc("815|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|Linear[image_encoder.vision_model.encoder.layers[3].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_41aten__add_permute_k"(#loc121))
#loc638 = loc("815|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|Linear[image_encoder.vision_model.encoder.layers[3].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_41aten__add_permute_v"(#loc121))
#loc639 = loc("848|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|Linear[image_encoder.vision_model.encoder.layers[3].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_21aten__view_concat_heads"(#loc236))
#loc640 = loc("849|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|Linear[image_encoder.vision_model.encoder.layers[3].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_44aten__add_decomp_matmul"(#loc171))
#loc641 = loc("849|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPAttention[image_encoder.vision_model.encoder.layers[3].self_attn]|Linear[image_encoder.vision_model.encoder.layers[3].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_44aten__add_decomp_add"(#loc171))
#loc642 = loc("866|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPMLP[image_encoder.vision_model.encoder.layers[3].mlp]|Linear[image_encoder.vision_model.encoder.layers[3].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_48aten__add_decomp_matmul"(#loc189))
#loc643 = loc("866|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPMLP[image_encoder.vision_model.encoder.layers[3].mlp]|Linear[image_encoder.vision_model.encoder.layers[3].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_48aten__add_decomp_add"(#loc189))
#loc644 = loc("866|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPMLP[image_encoder.vision_model.encoder.layers[3].mlp]|Linear[image_encoder.vision_model.encoder.layers[3].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_48aten__add_decomp_gelu"(#loc189))
#loc645 = loc("872|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPMLP[image_encoder.vision_model.encoder.layers[3].mlp]|Linear[image_encoder.vision_model.encoder.layers[3].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_49aten__add_decomp_matmul"(#loc13))
#loc646 = loc("872|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[3]]|CLIPMLP[image_encoder.vision_model.encoder.layers[3].mlp]|Linear[image_encoder.vision_model.encoder.layers[3].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_49aten__add_decomp_add"(#loc13))
#loc647 = loc("889|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|Linear[image_encoder.vision_model.encoder.layers[4].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_53aten__add_decomp_matmul"(#loc55))
#loc648 = loc("889|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|Linear[image_encoder.vision_model.encoder.layers[4].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_53aten__add_decomp_add"(#loc55))
#loc649 = loc("889|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|Linear[image_encoder.vision_model.encoder.layers[4].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_53aten__add_split_q"(#loc55))
#loc650 = loc("889|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|Linear[image_encoder.vision_model.encoder.layers[4].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_53aten__add_split_k"(#loc55))
#loc651 = loc("889|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|Linear[image_encoder.vision_model.encoder.layers[4].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_53aten__add_split_v"(#loc55))
#loc652 = loc("889|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|Linear[image_encoder.vision_model.encoder.layers[4].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_53aten__add_reshape_q"(#loc55))
#loc653 = loc("889|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|Linear[image_encoder.vision_model.encoder.layers[4].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_53aten__add_reshape_k"(#loc55))
#loc654 = loc("889|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|Linear[image_encoder.vision_model.encoder.layers[4].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_53aten__add_reshape_v"(#loc55))
#loc655 = loc("889|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|Linear[image_encoder.vision_model.encoder.layers[4].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_53aten__add_permute_q"(#loc55))
#loc656 = loc("889|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|Linear[image_encoder.vision_model.encoder.layers[4].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_53aten__add_permute_k"(#loc55))
#loc657 = loc("889|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|Linear[image_encoder.vision_model.encoder.layers[4].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_53aten__add_permute_v"(#loc55))
#loc658 = loc("922|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|Linear[image_encoder.vision_model.encoder.layers[4].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_27aten__view_concat_heads"(#loc245))
#loc659 = loc("923|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|Linear[image_encoder.vision_model.encoder.layers[4].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_56aten__add_decomp_matmul"(#loc129))
#loc660 = loc("923|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPAttention[image_encoder.vision_model.encoder.layers[4].self_attn]|Linear[image_encoder.vision_model.encoder.layers[4].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_56aten__add_decomp_add"(#loc129))
#loc661 = loc("940|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPMLP[image_encoder.vision_model.encoder.layers[4].mlp]|Linear[image_encoder.vision_model.encoder.layers[4].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_60aten__add_decomp_matmul"(#loc193))
#loc662 = loc("940|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPMLP[image_encoder.vision_model.encoder.layers[4].mlp]|Linear[image_encoder.vision_model.encoder.layers[4].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_60aten__add_decomp_add"(#loc193))
#loc663 = loc("940|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPMLP[image_encoder.vision_model.encoder.layers[4].mlp]|Linear[image_encoder.vision_model.encoder.layers[4].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_60aten__add_decomp_gelu"(#loc193))
#loc664 = loc("946|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPMLP[image_encoder.vision_model.encoder.layers[4].mlp]|Linear[image_encoder.vision_model.encoder.layers[4].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_61aten__add_decomp_matmul"(#loc192))
#loc665 = loc("946|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[4]]|CLIPMLP[image_encoder.vision_model.encoder.layers[4].mlp]|Linear[image_encoder.vision_model.encoder.layers[4].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_61aten__add_decomp_add"(#loc192))
#loc666 = loc("963|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|Linear[image_encoder.vision_model.encoder.layers[5].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_65aten__add_decomp_matmul"(#loc199))
#loc667 = loc("963|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|Linear[image_encoder.vision_model.encoder.layers[5].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_65aten__add_decomp_add"(#loc199))
#loc668 = loc("963|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|Linear[image_encoder.vision_model.encoder.layers[5].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_65aten__add_split_q"(#loc199))
#loc669 = loc("963|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|Linear[image_encoder.vision_model.encoder.layers[5].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_65aten__add_split_k"(#loc199))
#loc670 = loc("963|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|Linear[image_encoder.vision_model.encoder.layers[5].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_65aten__add_split_v"(#loc199))
#loc671 = loc("963|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|Linear[image_encoder.vision_model.encoder.layers[5].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_65aten__add_reshape_q"(#loc199))
#loc672 = loc("963|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|Linear[image_encoder.vision_model.encoder.layers[5].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_65aten__add_reshape_k"(#loc199))
#loc673 = loc("963|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|Linear[image_encoder.vision_model.encoder.layers[5].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_65aten__add_reshape_v"(#loc199))
#loc674 = loc("963|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|Linear[image_encoder.vision_model.encoder.layers[5].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_65aten__add_permute_q"(#loc199))
#loc675 = loc("963|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|Linear[image_encoder.vision_model.encoder.layers[5].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_65aten__add_permute_k"(#loc199))
#loc676 = loc("963|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|Linear[image_encoder.vision_model.encoder.layers[5].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_65aten__add_permute_v"(#loc199))
#loc677 = loc("996|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|Linear[image_encoder.vision_model.encoder.layers[5].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_33aten__view_concat_heads"(#loc254))
#loc678 = loc("997|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|Linear[image_encoder.vision_model.encoder.layers[5].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_68aten__add_decomp_matmul"(#loc95))
#loc679 = loc("997|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPAttention[image_encoder.vision_model.encoder.layers[5].self_attn]|Linear[image_encoder.vision_model.encoder.layers[5].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_68aten__add_decomp_add"(#loc95))
#loc680 = loc("1014|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPMLP[image_encoder.vision_model.encoder.layers[5].mlp]|Linear[image_encoder.vision_model.encoder.layers[5].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_72aten__add_decomp_matmul"(#loc124))
#loc681 = loc("1014|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPMLP[image_encoder.vision_model.encoder.layers[5].mlp]|Linear[image_encoder.vision_model.encoder.layers[5].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_72aten__add_decomp_add"(#loc124))
#loc682 = loc("1014|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPMLP[image_encoder.vision_model.encoder.layers[5].mlp]|Linear[image_encoder.vision_model.encoder.layers[5].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_72aten__add_decomp_gelu"(#loc124))
#loc683 = loc("1020|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPMLP[image_encoder.vision_model.encoder.layers[5].mlp]|Linear[image_encoder.vision_model.encoder.layers[5].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_73aten__add_decomp_matmul"(#loc141))
#loc684 = loc("1020|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[5]]|CLIPMLP[image_encoder.vision_model.encoder.layers[5].mlp]|Linear[image_encoder.vision_model.encoder.layers[5].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_73aten__add_decomp_add"(#loc141))
#loc685 = loc("1037|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|Linear[image_encoder.vision_model.encoder.layers[6].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_77aten__add_decomp_matmul"(#loc131))
#loc686 = loc("1037|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|Linear[image_encoder.vision_model.encoder.layers[6].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_77aten__add_decomp_add"(#loc131))
#loc687 = loc("1037|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|Linear[image_encoder.vision_model.encoder.layers[6].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_77aten__add_split_q"(#loc131))
#loc688 = loc("1037|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|Linear[image_encoder.vision_model.encoder.layers[6].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_77aten__add_split_k"(#loc131))
#loc689 = loc("1037|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|Linear[image_encoder.vision_model.encoder.layers[6].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_77aten__add_split_v"(#loc131))
#loc690 = loc("1037|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|Linear[image_encoder.vision_model.encoder.layers[6].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_77aten__add_reshape_q"(#loc131))
#loc691 = loc("1037|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|Linear[image_encoder.vision_model.encoder.layers[6].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_77aten__add_reshape_k"(#loc131))
#loc692 = loc("1037|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|Linear[image_encoder.vision_model.encoder.layers[6].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_77aten__add_reshape_v"(#loc131))
#loc693 = loc("1037|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|Linear[image_encoder.vision_model.encoder.layers[6].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_77aten__add_permute_q"(#loc131))
#loc694 = loc("1037|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|Linear[image_encoder.vision_model.encoder.layers[6].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_77aten__add_permute_k"(#loc131))
#loc695 = loc("1037|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|Linear[image_encoder.vision_model.encoder.layers[6].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_77aten__add_permute_v"(#loc131))
#loc696 = loc("1070|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|Linear[image_encoder.vision_model.encoder.layers[6].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_39aten__view_concat_heads"(#loc263))
#loc697 = loc("1071|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|Linear[image_encoder.vision_model.encoder.layers[6].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_80aten__add_decomp_matmul"(#loc62))
#loc698 = loc("1071|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPAttention[image_encoder.vision_model.encoder.layers[6].self_attn]|Linear[image_encoder.vision_model.encoder.layers[6].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_80aten__add_decomp_add"(#loc62))
#loc699 = loc("1088|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPMLP[image_encoder.vision_model.encoder.layers[6].mlp]|Linear[image_encoder.vision_model.encoder.layers[6].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_84aten__add_decomp_matmul"(#loc72))
#loc700 = loc("1088|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPMLP[image_encoder.vision_model.encoder.layers[6].mlp]|Linear[image_encoder.vision_model.encoder.layers[6].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_84aten__add_decomp_add"(#loc72))
#loc701 = loc("1088|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPMLP[image_encoder.vision_model.encoder.layers[6].mlp]|Linear[image_encoder.vision_model.encoder.layers[6].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_84aten__add_decomp_gelu"(#loc72))
#loc702 = loc("1094|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPMLP[image_encoder.vision_model.encoder.layers[6].mlp]|Linear[image_encoder.vision_model.encoder.layers[6].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_85aten__add_decomp_matmul"(#loc138))
#loc703 = loc("1094|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[6]]|CLIPMLP[image_encoder.vision_model.encoder.layers[6].mlp]|Linear[image_encoder.vision_model.encoder.layers[6].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_85aten__add_decomp_add"(#loc138))
#loc704 = loc("1111|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|Linear[image_encoder.vision_model.encoder.layers[7].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_89aten__add_decomp_matmul"(#loc115))
#loc705 = loc("1111|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|Linear[image_encoder.vision_model.encoder.layers[7].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_89aten__add_decomp_add"(#loc115))
#loc706 = loc("1111|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|Linear[image_encoder.vision_model.encoder.layers[7].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_89aten__add_split_q"(#loc115))
#loc707 = loc("1111|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|Linear[image_encoder.vision_model.encoder.layers[7].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_89aten__add_split_k"(#loc115))
#loc708 = loc("1111|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|Linear[image_encoder.vision_model.encoder.layers[7].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_89aten__add_split_v"(#loc115))
#loc709 = loc("1111|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|Linear[image_encoder.vision_model.encoder.layers[7].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_89aten__add_reshape_q"(#loc115))
#loc710 = loc("1111|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|Linear[image_encoder.vision_model.encoder.layers[7].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_89aten__add_reshape_k"(#loc115))
#loc711 = loc("1111|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|Linear[image_encoder.vision_model.encoder.layers[7].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_89aten__add_reshape_v"(#loc115))
#loc712 = loc("1111|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|Linear[image_encoder.vision_model.encoder.layers[7].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_89aten__add_permute_q"(#loc115))
#loc713 = loc("1111|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|Linear[image_encoder.vision_model.encoder.layers[7].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_89aten__add_permute_k"(#loc115))
#loc714 = loc("1111|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|Linear[image_encoder.vision_model.encoder.layers[7].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_89aten__add_permute_v"(#loc115))
#loc715 = loc("1144|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|Linear[image_encoder.vision_model.encoder.layers[7].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_45aten__view_concat_heads"(#loc272))
#loc716 = loc("1145|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|Linear[image_encoder.vision_model.encoder.layers[7].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_92aten__add_decomp_matmul"(#loc159))
#loc717 = loc("1145|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPAttention[image_encoder.vision_model.encoder.layers[7].self_attn]|Linear[image_encoder.vision_model.encoder.layers[7].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_92aten__add_decomp_add"(#loc159))
#loc718 = loc("1162|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPMLP[image_encoder.vision_model.encoder.layers[7].mlp]|Linear[image_encoder.vision_model.encoder.layers[7].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_96aten__add_decomp_matmul"(#loc30))
#loc719 = loc("1162|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPMLP[image_encoder.vision_model.encoder.layers[7].mlp]|Linear[image_encoder.vision_model.encoder.layers[7].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_96aten__add_decomp_add"(#loc30))
#loc720 = loc("1162|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPMLP[image_encoder.vision_model.encoder.layers[7].mlp]|Linear[image_encoder.vision_model.encoder.layers[7].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_96aten__add_decomp_gelu"(#loc30))
#loc721 = loc("1168|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPMLP[image_encoder.vision_model.encoder.layers[7].mlp]|Linear[image_encoder.vision_model.encoder.layers[7].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_97aten__add_decomp_matmul"(#loc195))
#loc722 = loc("1168|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[7]]|CLIPMLP[image_encoder.vision_model.encoder.layers[7].mlp]|Linear[image_encoder.vision_model.encoder.layers[7].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_97aten__add_decomp_add"(#loc195))
#loc723 = loc("1185|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|Linear[image_encoder.vision_model.encoder.layers[8].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_101aten__add_decomp_matmul"(#loc48))
#loc724 = loc("1185|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|Linear[image_encoder.vision_model.encoder.layers[8].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_101aten__add_decomp_add"(#loc48))
#loc725 = loc("1185|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|Linear[image_encoder.vision_model.encoder.layers[8].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_101aten__add_split_q"(#loc48))
#loc726 = loc("1185|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|Linear[image_encoder.vision_model.encoder.layers[8].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_101aten__add_split_k"(#loc48))
#loc727 = loc("1185|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|Linear[image_encoder.vision_model.encoder.layers[8].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_101aten__add_split_v"(#loc48))
#loc728 = loc("1185|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|Linear[image_encoder.vision_model.encoder.layers[8].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_101aten__add_reshape_q"(#loc48))
#loc729 = loc("1185|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|Linear[image_encoder.vision_model.encoder.layers[8].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_101aten__add_reshape_k"(#loc48))
#loc730 = loc("1185|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|Linear[image_encoder.vision_model.encoder.layers[8].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_101aten__add_reshape_v"(#loc48))
#loc731 = loc("1185|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|Linear[image_encoder.vision_model.encoder.layers[8].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_101aten__add_permute_q"(#loc48))
#loc732 = loc("1185|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|Linear[image_encoder.vision_model.encoder.layers[8].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_101aten__add_permute_k"(#loc48))
#loc733 = loc("1185|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|Linear[image_encoder.vision_model.encoder.layers[8].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_101aten__add_permute_v"(#loc48))
#loc734 = loc("1218|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|Linear[image_encoder.vision_model.encoder.layers[8].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_51aten__view_concat_heads"(#loc281))
#loc735 = loc("1219|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|Linear[image_encoder.vision_model.encoder.layers[8].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_104aten__add_decomp_matmul"(#loc103))
#loc736 = loc("1219|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPAttention[image_encoder.vision_model.encoder.layers[8].self_attn]|Linear[image_encoder.vision_model.encoder.layers[8].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_104aten__add_decomp_add"(#loc103))
#loc737 = loc("1236|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPMLP[image_encoder.vision_model.encoder.layers[8].mlp]|Linear[image_encoder.vision_model.encoder.layers[8].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_108aten__add_decomp_matmul"(#loc29))
#loc738 = loc("1236|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPMLP[image_encoder.vision_model.encoder.layers[8].mlp]|Linear[image_encoder.vision_model.encoder.layers[8].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_108aten__add_decomp_add"(#loc29))
#loc739 = loc("1236|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPMLP[image_encoder.vision_model.encoder.layers[8].mlp]|Linear[image_encoder.vision_model.encoder.layers[8].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_108aten__add_decomp_gelu"(#loc29))
#loc740 = loc("1242|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPMLP[image_encoder.vision_model.encoder.layers[8].mlp]|Linear[image_encoder.vision_model.encoder.layers[8].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_109aten__add_decomp_matmul"(#loc126))
#loc741 = loc("1242|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[8]]|CLIPMLP[image_encoder.vision_model.encoder.layers[8].mlp]|Linear[image_encoder.vision_model.encoder.layers[8].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_109aten__add_decomp_add"(#loc126))
#loc742 = loc("1259|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|Linear[image_encoder.vision_model.encoder.layers[9].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_113aten__add_decomp_matmul"(#loc172))
#loc743 = loc("1259|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|Linear[image_encoder.vision_model.encoder.layers[9].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_113aten__add_decomp_add"(#loc172))
#loc744 = loc("1259|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|Linear[image_encoder.vision_model.encoder.layers[9].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_113aten__add_split_q"(#loc172))
#loc745 = loc("1259|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|Linear[image_encoder.vision_model.encoder.layers[9].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_113aten__add_split_k"(#loc172))
#loc746 = loc("1259|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|Linear[image_encoder.vision_model.encoder.layers[9].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_113aten__add_split_v"(#loc172))
#loc747 = loc("1259|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|Linear[image_encoder.vision_model.encoder.layers[9].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_113aten__add_reshape_q"(#loc172))
#loc748 = loc("1259|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|Linear[image_encoder.vision_model.encoder.layers[9].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_113aten__add_reshape_k"(#loc172))
#loc749 = loc("1259|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|Linear[image_encoder.vision_model.encoder.layers[9].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_113aten__add_reshape_v"(#loc172))
#loc750 = loc("1259|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|Linear[image_encoder.vision_model.encoder.layers[9].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_113aten__add_permute_q"(#loc172))
#loc751 = loc("1259|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|Linear[image_encoder.vision_model.encoder.layers[9].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_113aten__add_permute_k"(#loc172))
#loc752 = loc("1259|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|Linear[image_encoder.vision_model.encoder.layers[9].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_113aten__add_permute_v"(#loc172))
#loc753 = loc("1292|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|Linear[image_encoder.vision_model.encoder.layers[9].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_57aten__view_concat_heads"(#loc290))
#loc754 = loc("1293|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|Linear[image_encoder.vision_model.encoder.layers[9].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_116aten__add_decomp_matmul"(#loc149))
#loc755 = loc("1293|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPAttention[image_encoder.vision_model.encoder.layers[9].self_attn]|Linear[image_encoder.vision_model.encoder.layers[9].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_116aten__add_decomp_add"(#loc149))
#loc756 = loc("1310|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPMLP[image_encoder.vision_model.encoder.layers[9].mlp]|Linear[image_encoder.vision_model.encoder.layers[9].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_120aten__add_decomp_matmul"(#loc197))
#loc757 = loc("1310|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPMLP[image_encoder.vision_model.encoder.layers[9].mlp]|Linear[image_encoder.vision_model.encoder.layers[9].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_120aten__add_decomp_add"(#loc197))
#loc758 = loc("1310|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPMLP[image_encoder.vision_model.encoder.layers[9].mlp]|Linear[image_encoder.vision_model.encoder.layers[9].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_120aten__add_decomp_gelu"(#loc197))
#loc759 = loc("1316|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPMLP[image_encoder.vision_model.encoder.layers[9].mlp]|Linear[image_encoder.vision_model.encoder.layers[9].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_121aten__add_decomp_matmul"(#loc6))
#loc760 = loc("1316|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[9]]|CLIPMLP[image_encoder.vision_model.encoder.layers[9].mlp]|Linear[image_encoder.vision_model.encoder.layers[9].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_121aten__add_decomp_add"(#loc6))
#loc761 = loc("1333|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|Linear[image_encoder.vision_model.encoder.layers[10].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_125aten__add_decomp_matmul"(#loc96))
#loc762 = loc("1333|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|Linear[image_encoder.vision_model.encoder.layers[10].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_125aten__add_decomp_add"(#loc96))
#loc763 = loc("1333|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|Linear[image_encoder.vision_model.encoder.layers[10].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_125aten__add_split_q"(#loc96))
#loc764 = loc("1333|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|Linear[image_encoder.vision_model.encoder.layers[10].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_125aten__add_split_k"(#loc96))
#loc765 = loc("1333|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|Linear[image_encoder.vision_model.encoder.layers[10].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_125aten__add_split_v"(#loc96))
#loc766 = loc("1333|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|Linear[image_encoder.vision_model.encoder.layers[10].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_125aten__add_reshape_q"(#loc96))
#loc767 = loc("1333|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|Linear[image_encoder.vision_model.encoder.layers[10].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_125aten__add_reshape_k"(#loc96))
#loc768 = loc("1333|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|Linear[image_encoder.vision_model.encoder.layers[10].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_125aten__add_reshape_v"(#loc96))
#loc769 = loc("1333|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|Linear[image_encoder.vision_model.encoder.layers[10].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_125aten__add_permute_q"(#loc96))
#loc770 = loc("1333|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|Linear[image_encoder.vision_model.encoder.layers[10].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_125aten__add_permute_k"(#loc96))
#loc771 = loc("1333|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|Linear[image_encoder.vision_model.encoder.layers[10].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_125aten__add_permute_v"(#loc96))
#loc772 = loc("1366|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|Linear[image_encoder.vision_model.encoder.layers[10].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_63aten__view_concat_heads"(#loc299))
#loc773 = loc("1367|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|Linear[image_encoder.vision_model.encoder.layers[10].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_128aten__add_decomp_matmul"(#loc92))
#loc774 = loc("1367|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPAttention[image_encoder.vision_model.encoder.layers[10].self_attn]|Linear[image_encoder.vision_model.encoder.layers[10].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_128aten__add_decomp_add"(#loc92))
#loc775 = loc("1384|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPMLP[image_encoder.vision_model.encoder.layers[10].mlp]|Linear[image_encoder.vision_model.encoder.layers[10].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_132aten__add_decomp_matmul"(#loc128))
#loc776 = loc("1384|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPMLP[image_encoder.vision_model.encoder.layers[10].mlp]|Linear[image_encoder.vision_model.encoder.layers[10].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_132aten__add_decomp_add"(#loc128))
#loc777 = loc("1384|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPMLP[image_encoder.vision_model.encoder.layers[10].mlp]|Linear[image_encoder.vision_model.encoder.layers[10].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_132aten__add_decomp_gelu"(#loc128))
#loc778 = loc("1390|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPMLP[image_encoder.vision_model.encoder.layers[10].mlp]|Linear[image_encoder.vision_model.encoder.layers[10].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_133aten__add_decomp_matmul"(#loc118))
#loc779 = loc("1390|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[10]]|CLIPMLP[image_encoder.vision_model.encoder.layers[10].mlp]|Linear[image_encoder.vision_model.encoder.layers[10].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_133aten__add_decomp_add"(#loc118))
#loc780 = loc("1407|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|Linear[image_encoder.vision_model.encoder.layers[11].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_137aten__add_decomp_matmul"(#loc152))
#loc781 = loc("1407|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|Linear[image_encoder.vision_model.encoder.layers[11].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_137aten__add_decomp_add"(#loc152))
#loc782 = loc("1407|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|Linear[image_encoder.vision_model.encoder.layers[11].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_137aten__add_split_q"(#loc152))
#loc783 = loc("1407|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|Linear[image_encoder.vision_model.encoder.layers[11].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_137aten__add_split_k"(#loc152))
#loc784 = loc("1407|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|Linear[image_encoder.vision_model.encoder.layers[11].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_137aten__add_split_v"(#loc152))
#loc785 = loc("1407|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|Linear[image_encoder.vision_model.encoder.layers[11].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_137aten__add_reshape_q"(#loc152))
#loc786 = loc("1407|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|Linear[image_encoder.vision_model.encoder.layers[11].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_137aten__add_reshape_k"(#loc152))
#loc787 = loc("1407|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|Linear[image_encoder.vision_model.encoder.layers[11].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_137aten__add_reshape_v"(#loc152))
#loc788 = loc("1407|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|Linear[image_encoder.vision_model.encoder.layers[11].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_137aten__add_permute_q"(#loc152))
#loc789 = loc("1407|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|Linear[image_encoder.vision_model.encoder.layers[11].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_137aten__add_permute_k"(#loc152))
#loc790 = loc("1407|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|Linear[image_encoder.vision_model.encoder.layers[11].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_137aten__add_permute_v"(#loc152))
#loc791 = loc("1440|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|Linear[image_encoder.vision_model.encoder.layers[11].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_69aten__view_concat_heads"(#loc308))
#loc792 = loc("1441|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|Linear[image_encoder.vision_model.encoder.layers[11].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_140aten__add_decomp_matmul"(#loc184))
#loc793 = loc("1441|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPAttention[image_encoder.vision_model.encoder.layers[11].self_attn]|Linear[image_encoder.vision_model.encoder.layers[11].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_140aten__add_decomp_add"(#loc184))
#loc794 = loc("1458|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPMLP[image_encoder.vision_model.encoder.layers[11].mlp]|Linear[image_encoder.vision_model.encoder.layers[11].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_144aten__add_decomp_matmul"(#loc198))
#loc795 = loc("1458|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPMLP[image_encoder.vision_model.encoder.layers[11].mlp]|Linear[image_encoder.vision_model.encoder.layers[11].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_144aten__add_decomp_add"(#loc198))
#loc796 = loc("1458|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPMLP[image_encoder.vision_model.encoder.layers[11].mlp]|Linear[image_encoder.vision_model.encoder.layers[11].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_144aten__add_decomp_gelu"(#loc198))
#loc797 = loc("1464|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPMLP[image_encoder.vision_model.encoder.layers[11].mlp]|Linear[image_encoder.vision_model.encoder.layers[11].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_145aten__add_decomp_matmul"(#loc194))
#loc798 = loc("1464|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[11]]|CLIPMLP[image_encoder.vision_model.encoder.layers[11].mlp]|Linear[image_encoder.vision_model.encoder.layers[11].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_145aten__add_decomp_add"(#loc194))
#loc799 = loc("1481|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|Linear[image_encoder.vision_model.encoder.layers[12].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_149aten__add_decomp_matmul"(#loc179))
#loc800 = loc("1481|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|Linear[image_encoder.vision_model.encoder.layers[12].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_149aten__add_decomp_add"(#loc179))
#loc801 = loc("1481|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|Linear[image_encoder.vision_model.encoder.layers[12].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_149aten__add_split_q"(#loc179))
#loc802 = loc("1481|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|Linear[image_encoder.vision_model.encoder.layers[12].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_149aten__add_split_k"(#loc179))
#loc803 = loc("1481|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|Linear[image_encoder.vision_model.encoder.layers[12].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_149aten__add_split_v"(#loc179))
#loc804 = loc("1481|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|Linear[image_encoder.vision_model.encoder.layers[12].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_149aten__add_reshape_q"(#loc179))
#loc805 = loc("1481|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|Linear[image_encoder.vision_model.encoder.layers[12].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_149aten__add_reshape_k"(#loc179))
#loc806 = loc("1481|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|Linear[image_encoder.vision_model.encoder.layers[12].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_149aten__add_reshape_v"(#loc179))
#loc807 = loc("1481|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|Linear[image_encoder.vision_model.encoder.layers[12].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_149aten__add_permute_q"(#loc179))
#loc808 = loc("1481|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|Linear[image_encoder.vision_model.encoder.layers[12].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_149aten__add_permute_k"(#loc179))
#loc809 = loc("1481|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|Linear[image_encoder.vision_model.encoder.layers[12].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_149aten__add_permute_v"(#loc179))
#loc810 = loc("1514|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|Linear[image_encoder.vision_model.encoder.layers[12].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_75aten__view_concat_heads"(#loc317))
#loc811 = loc("1515|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|Linear[image_encoder.vision_model.encoder.layers[12].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_152aten__add_decomp_matmul"(#loc94))
#loc812 = loc("1515|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPAttention[image_encoder.vision_model.encoder.layers[12].self_attn]|Linear[image_encoder.vision_model.encoder.layers[12].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_152aten__add_decomp_add"(#loc94))
#loc813 = loc("1532|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPMLP[image_encoder.vision_model.encoder.layers[12].mlp]|Linear[image_encoder.vision_model.encoder.layers[12].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_156aten__add_decomp_matmul"(#loc9))
#loc814 = loc("1532|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPMLP[image_encoder.vision_model.encoder.layers[12].mlp]|Linear[image_encoder.vision_model.encoder.layers[12].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_156aten__add_decomp_add"(#loc9))
#loc815 = loc("1532|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPMLP[image_encoder.vision_model.encoder.layers[12].mlp]|Linear[image_encoder.vision_model.encoder.layers[12].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_156aten__add_decomp_gelu"(#loc9))
#loc816 = loc("1538|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPMLP[image_encoder.vision_model.encoder.layers[12].mlp]|Linear[image_encoder.vision_model.encoder.layers[12].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_157aten__add_decomp_matmul"(#loc17))
#loc817 = loc("1538|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[12]]|CLIPMLP[image_encoder.vision_model.encoder.layers[12].mlp]|Linear[image_encoder.vision_model.encoder.layers[12].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_157aten__add_decomp_add"(#loc17))
#loc818 = loc("1555|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|Linear[image_encoder.vision_model.encoder.layers[13].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_161aten__add_decomp_matmul"(#loc3))
#loc819 = loc("1555|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|Linear[image_encoder.vision_model.encoder.layers[13].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_161aten__add_decomp_add"(#loc3))
#loc820 = loc("1555|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|Linear[image_encoder.vision_model.encoder.layers[13].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_161aten__add_split_q"(#loc3))
#loc821 = loc("1555|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|Linear[image_encoder.vision_model.encoder.layers[13].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_161aten__add_split_k"(#loc3))
#loc822 = loc("1555|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|Linear[image_encoder.vision_model.encoder.layers[13].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_161aten__add_split_v"(#loc3))
#loc823 = loc("1555|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|Linear[image_encoder.vision_model.encoder.layers[13].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_161aten__add_reshape_q"(#loc3))
#loc824 = loc("1555|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|Linear[image_encoder.vision_model.encoder.layers[13].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_161aten__add_reshape_k"(#loc3))
#loc825 = loc("1555|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|Linear[image_encoder.vision_model.encoder.layers[13].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_161aten__add_reshape_v"(#loc3))
#loc826 = loc("1555|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|Linear[image_encoder.vision_model.encoder.layers[13].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_161aten__add_permute_q"(#loc3))
#loc827 = loc("1555|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|Linear[image_encoder.vision_model.encoder.layers[13].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_161aten__add_permute_k"(#loc3))
#loc828 = loc("1555|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|Linear[image_encoder.vision_model.encoder.layers[13].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_161aten__add_permute_v"(#loc3))
#loc829 = loc("1588|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|Linear[image_encoder.vision_model.encoder.layers[13].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_81aten__view_concat_heads"(#loc326))
#loc830 = loc("1589|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|Linear[image_encoder.vision_model.encoder.layers[13].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_164aten__add_decomp_matmul"(#loc165))
#loc831 = loc("1589|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPAttention[image_encoder.vision_model.encoder.layers[13].self_attn]|Linear[image_encoder.vision_model.encoder.layers[13].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_164aten__add_decomp_add"(#loc165))
#loc832 = loc("1606|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPMLP[image_encoder.vision_model.encoder.layers[13].mlp]|Linear[image_encoder.vision_model.encoder.layers[13].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_168aten__add_decomp_matmul"(#loc125))
#loc833 = loc("1606|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPMLP[image_encoder.vision_model.encoder.layers[13].mlp]|Linear[image_encoder.vision_model.encoder.layers[13].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_168aten__add_decomp_add"(#loc125))
#loc834 = loc("1606|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPMLP[image_encoder.vision_model.encoder.layers[13].mlp]|Linear[image_encoder.vision_model.encoder.layers[13].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_168aten__add_decomp_gelu"(#loc125))
#loc835 = loc("1612|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPMLP[image_encoder.vision_model.encoder.layers[13].mlp]|Linear[image_encoder.vision_model.encoder.layers[13].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_169aten__add_decomp_matmul"(#loc144))
#loc836 = loc("1612|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[13]]|CLIPMLP[image_encoder.vision_model.encoder.layers[13].mlp]|Linear[image_encoder.vision_model.encoder.layers[13].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_169aten__add_decomp_add"(#loc144))
#loc837 = loc("1629|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|Linear[image_encoder.vision_model.encoder.layers[14].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_173aten__add_decomp_matmul"(#loc135))
#loc838 = loc("1629|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|Linear[image_encoder.vision_model.encoder.layers[14].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_173aten__add_decomp_add"(#loc135))
#loc839 = loc("1629|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|Linear[image_encoder.vision_model.encoder.layers[14].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_173aten__add_split_q"(#loc135))
#loc840 = loc("1629|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|Linear[image_encoder.vision_model.encoder.layers[14].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_173aten__add_split_k"(#loc135))
#loc841 = loc("1629|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|Linear[image_encoder.vision_model.encoder.layers[14].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_173aten__add_split_v"(#loc135))
#loc842 = loc("1629|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|Linear[image_encoder.vision_model.encoder.layers[14].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_173aten__add_reshape_q"(#loc135))
#loc843 = loc("1629|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|Linear[image_encoder.vision_model.encoder.layers[14].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_173aten__add_reshape_k"(#loc135))
#loc844 = loc("1629|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|Linear[image_encoder.vision_model.encoder.layers[14].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_173aten__add_reshape_v"(#loc135))
#loc845 = loc("1629|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|Linear[image_encoder.vision_model.encoder.layers[14].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_173aten__add_permute_q"(#loc135))
#loc846 = loc("1629|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|Linear[image_encoder.vision_model.encoder.layers[14].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_173aten__add_permute_k"(#loc135))
#loc847 = loc("1629|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|Linear[image_encoder.vision_model.encoder.layers[14].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_173aten__add_permute_v"(#loc135))
#loc848 = loc("1662|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|Linear[image_encoder.vision_model.encoder.layers[14].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_87aten__view_concat_heads"(#loc335))
#loc849 = loc("1663|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|Linear[image_encoder.vision_model.encoder.layers[14].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_176aten__add_decomp_matmul"(#loc14))
#loc850 = loc("1663|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPAttention[image_encoder.vision_model.encoder.layers[14].self_attn]|Linear[image_encoder.vision_model.encoder.layers[14].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_176aten__add_decomp_add"(#loc14))
#loc851 = loc("1680|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPMLP[image_encoder.vision_model.encoder.layers[14].mlp]|Linear[image_encoder.vision_model.encoder.layers[14].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_180aten__add_decomp_matmul"(#loc185))
#loc852 = loc("1680|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPMLP[image_encoder.vision_model.encoder.layers[14].mlp]|Linear[image_encoder.vision_model.encoder.layers[14].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_180aten__add_decomp_add"(#loc185))
#loc853 = loc("1680|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPMLP[image_encoder.vision_model.encoder.layers[14].mlp]|Linear[image_encoder.vision_model.encoder.layers[14].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_180aten__add_decomp_gelu"(#loc185))
#loc854 = loc("1686|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPMLP[image_encoder.vision_model.encoder.layers[14].mlp]|Linear[image_encoder.vision_model.encoder.layers[14].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_181aten__add_decomp_matmul"(#loc24))
#loc855 = loc("1686|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[14]]|CLIPMLP[image_encoder.vision_model.encoder.layers[14].mlp]|Linear[image_encoder.vision_model.encoder.layers[14].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_181aten__add_decomp_add"(#loc24))
#loc856 = loc("1703|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|Linear[image_encoder.vision_model.encoder.layers[15].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_185aten__add_decomp_matmul"(#loc99))
#loc857 = loc("1703|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|Linear[image_encoder.vision_model.encoder.layers[15].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_185aten__add_decomp_add"(#loc99))
#loc858 = loc("1703|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|Linear[image_encoder.vision_model.encoder.layers[15].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_185aten__add_split_q"(#loc99))
#loc859 = loc("1703|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|Linear[image_encoder.vision_model.encoder.layers[15].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_185aten__add_split_k"(#loc99))
#loc860 = loc("1703|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|Linear[image_encoder.vision_model.encoder.layers[15].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_185aten__add_split_v"(#loc99))
#loc861 = loc("1703|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|Linear[image_encoder.vision_model.encoder.layers[15].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_185aten__add_reshape_q"(#loc99))
#loc862 = loc("1703|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|Linear[image_encoder.vision_model.encoder.layers[15].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_185aten__add_reshape_k"(#loc99))
#loc863 = loc("1703|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|Linear[image_encoder.vision_model.encoder.layers[15].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_185aten__add_reshape_v"(#loc99))
#loc864 = loc("1703|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|Linear[image_encoder.vision_model.encoder.layers[15].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_185aten__add_permute_q"(#loc99))
#loc865 = loc("1703|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|Linear[image_encoder.vision_model.encoder.layers[15].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_185aten__add_permute_k"(#loc99))
#loc866 = loc("1703|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|Linear[image_encoder.vision_model.encoder.layers[15].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_185aten__add_permute_v"(#loc99))
#loc867 = loc("1736|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|Linear[image_encoder.vision_model.encoder.layers[15].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_93aten__view_concat_heads"(#loc344))
#loc868 = loc("1737|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|Linear[image_encoder.vision_model.encoder.layers[15].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_188aten__add_decomp_matmul"(#loc150))
#loc869 = loc("1737|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPAttention[image_encoder.vision_model.encoder.layers[15].self_attn]|Linear[image_encoder.vision_model.encoder.layers[15].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_188aten__add_decomp_add"(#loc150))
#loc870 = loc("1754|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPMLP[image_encoder.vision_model.encoder.layers[15].mlp]|Linear[image_encoder.vision_model.encoder.layers[15].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_192aten__add_decomp_matmul"(#loc196))
#loc871 = loc("1754|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPMLP[image_encoder.vision_model.encoder.layers[15].mlp]|Linear[image_encoder.vision_model.encoder.layers[15].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_192aten__add_decomp_add"(#loc196))
#loc872 = loc("1754|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPMLP[image_encoder.vision_model.encoder.layers[15].mlp]|Linear[image_encoder.vision_model.encoder.layers[15].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_192aten__add_decomp_gelu"(#loc196))
#loc873 = loc("1760|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPMLP[image_encoder.vision_model.encoder.layers[15].mlp]|Linear[image_encoder.vision_model.encoder.layers[15].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_193aten__add_decomp_matmul"(#loc114))
#loc874 = loc("1760|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[15]]|CLIPMLP[image_encoder.vision_model.encoder.layers[15].mlp]|Linear[image_encoder.vision_model.encoder.layers[15].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_193aten__add_decomp_add"(#loc114))
#loc875 = loc("1777|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|Linear[image_encoder.vision_model.encoder.layers[16].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_197aten__add_decomp_matmul"(#loc156))
#loc876 = loc("1777|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|Linear[image_encoder.vision_model.encoder.layers[16].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_197aten__add_decomp_add"(#loc156))
#loc877 = loc("1777|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|Linear[image_encoder.vision_model.encoder.layers[16].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_197aten__add_split_q"(#loc156))
#loc878 = loc("1777|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|Linear[image_encoder.vision_model.encoder.layers[16].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_197aten__add_split_k"(#loc156))
#loc879 = loc("1777|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|Linear[image_encoder.vision_model.encoder.layers[16].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_197aten__add_split_v"(#loc156))
#loc880 = loc("1777|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|Linear[image_encoder.vision_model.encoder.layers[16].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_197aten__add_reshape_q"(#loc156))
#loc881 = loc("1777|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|Linear[image_encoder.vision_model.encoder.layers[16].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_197aten__add_reshape_k"(#loc156))
#loc882 = loc("1777|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|Linear[image_encoder.vision_model.encoder.layers[16].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_197aten__add_reshape_v"(#loc156))
#loc883 = loc("1777|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|Linear[image_encoder.vision_model.encoder.layers[16].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_197aten__add_permute_q"(#loc156))
#loc884 = loc("1777|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|Linear[image_encoder.vision_model.encoder.layers[16].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_197aten__add_permute_k"(#loc156))
#loc885 = loc("1777|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|Linear[image_encoder.vision_model.encoder.layers[16].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_197aten__add_permute_v"(#loc156))
#loc886 = loc("1810|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|Linear[image_encoder.vision_model.encoder.layers[16].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_99aten__view_concat_heads"(#loc353))
#loc887 = loc("1811|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|Linear[image_encoder.vision_model.encoder.layers[16].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_200aten__add_decomp_matmul"(#loc91))
#loc888 = loc("1811|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPAttention[image_encoder.vision_model.encoder.layers[16].self_attn]|Linear[image_encoder.vision_model.encoder.layers[16].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_200aten__add_decomp_add"(#loc91))
#loc889 = loc("1828|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPMLP[image_encoder.vision_model.encoder.layers[16].mlp]|Linear[image_encoder.vision_model.encoder.layers[16].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_204aten__add_decomp_matmul"(#loc167))
#loc890 = loc("1828|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPMLP[image_encoder.vision_model.encoder.layers[16].mlp]|Linear[image_encoder.vision_model.encoder.layers[16].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_204aten__add_decomp_add"(#loc167))
#loc891 = loc("1828|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPMLP[image_encoder.vision_model.encoder.layers[16].mlp]|Linear[image_encoder.vision_model.encoder.layers[16].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_204aten__add_decomp_gelu"(#loc167))
#loc892 = loc("1834|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPMLP[image_encoder.vision_model.encoder.layers[16].mlp]|Linear[image_encoder.vision_model.encoder.layers[16].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_205aten__add_decomp_matmul"(#loc139))
#loc893 = loc("1834|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[16]]|CLIPMLP[image_encoder.vision_model.encoder.layers[16].mlp]|Linear[image_encoder.vision_model.encoder.layers[16].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_205aten__add_decomp_add"(#loc139))
#loc894 = loc("1851|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|Linear[image_encoder.vision_model.encoder.layers[17].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_209aten__add_decomp_matmul"(#loc21))
#loc895 = loc("1851|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|Linear[image_encoder.vision_model.encoder.layers[17].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_209aten__add_decomp_add"(#loc21))
#loc896 = loc("1851|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|Linear[image_encoder.vision_model.encoder.layers[17].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_209aten__add_split_q"(#loc21))
#loc897 = loc("1851|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|Linear[image_encoder.vision_model.encoder.layers[17].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_209aten__add_split_k"(#loc21))
#loc898 = loc("1851|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|Linear[image_encoder.vision_model.encoder.layers[17].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_209aten__add_split_v"(#loc21))
#loc899 = loc("1851|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|Linear[image_encoder.vision_model.encoder.layers[17].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_209aten__add_reshape_q"(#loc21))
#loc900 = loc("1851|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|Linear[image_encoder.vision_model.encoder.layers[17].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_209aten__add_reshape_k"(#loc21))
#loc901 = loc("1851|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|Linear[image_encoder.vision_model.encoder.layers[17].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_209aten__add_reshape_v"(#loc21))
#loc902 = loc("1851|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|Linear[image_encoder.vision_model.encoder.layers[17].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_209aten__add_permute_q"(#loc21))
#loc903 = loc("1851|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|Linear[image_encoder.vision_model.encoder.layers[17].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_209aten__add_permute_k"(#loc21))
#loc904 = loc("1851|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|Linear[image_encoder.vision_model.encoder.layers[17].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_209aten__add_permute_v"(#loc21))
#loc905 = loc("1884|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|Linear[image_encoder.vision_model.encoder.layers[17].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_105aten__view_concat_heads"(#loc362))
#loc906 = loc("1885|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|Linear[image_encoder.vision_model.encoder.layers[17].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_212aten__add_decomp_matmul"(#loc11))
#loc907 = loc("1885|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPAttention[image_encoder.vision_model.encoder.layers[17].self_attn]|Linear[image_encoder.vision_model.encoder.layers[17].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_212aten__add_decomp_add"(#loc11))
#loc908 = loc("1902|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPMLP[image_encoder.vision_model.encoder.layers[17].mlp]|Linear[image_encoder.vision_model.encoder.layers[17].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_216aten__add_decomp_matmul"(#loc143))
#loc909 = loc("1902|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPMLP[image_encoder.vision_model.encoder.layers[17].mlp]|Linear[image_encoder.vision_model.encoder.layers[17].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_216aten__add_decomp_add"(#loc143))
#loc910 = loc("1902|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPMLP[image_encoder.vision_model.encoder.layers[17].mlp]|Linear[image_encoder.vision_model.encoder.layers[17].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_216aten__add_decomp_gelu"(#loc143))
#loc911 = loc("1908|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPMLP[image_encoder.vision_model.encoder.layers[17].mlp]|Linear[image_encoder.vision_model.encoder.layers[17].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_217aten__add_decomp_matmul"(#loc25))
#loc912 = loc("1908|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[17]]|CLIPMLP[image_encoder.vision_model.encoder.layers[17].mlp]|Linear[image_encoder.vision_model.encoder.layers[17].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_217aten__add_decomp_add"(#loc25))
#loc913 = loc("1925|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|Linear[image_encoder.vision_model.encoder.layers[18].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_221aten__add_decomp_matmul"(#loc175))
#loc914 = loc("1925|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|Linear[image_encoder.vision_model.encoder.layers[18].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_221aten__add_decomp_add"(#loc175))
#loc915 = loc("1925|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|Linear[image_encoder.vision_model.encoder.layers[18].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_221aten__add_split_q"(#loc175))
#loc916 = loc("1925|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|Linear[image_encoder.vision_model.encoder.layers[18].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_221aten__add_split_k"(#loc175))
#loc917 = loc("1925|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|Linear[image_encoder.vision_model.encoder.layers[18].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_221aten__add_split_v"(#loc175))
#loc918 = loc("1925|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|Linear[image_encoder.vision_model.encoder.layers[18].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_221aten__add_reshape_q"(#loc175))
#loc919 = loc("1925|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|Linear[image_encoder.vision_model.encoder.layers[18].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_221aten__add_reshape_k"(#loc175))
#loc920 = loc("1925|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|Linear[image_encoder.vision_model.encoder.layers[18].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_221aten__add_reshape_v"(#loc175))
#loc921 = loc("1925|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|Linear[image_encoder.vision_model.encoder.layers[18].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_221aten__add_permute_q"(#loc175))
#loc922 = loc("1925|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|Linear[image_encoder.vision_model.encoder.layers[18].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_221aten__add_permute_k"(#loc175))
#loc923 = loc("1925|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|Linear[image_encoder.vision_model.encoder.layers[18].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_221aten__add_permute_v"(#loc175))
#loc924 = loc("1958|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|Linear[image_encoder.vision_model.encoder.layers[18].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_111aten__view_concat_heads"(#loc371))
#loc925 = loc("1959|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|Linear[image_encoder.vision_model.encoder.layers[18].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_224aten__add_decomp_matmul"(#loc134))
#loc926 = loc("1959|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPAttention[image_encoder.vision_model.encoder.layers[18].self_attn]|Linear[image_encoder.vision_model.encoder.layers[18].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_224aten__add_decomp_add"(#loc134))
#loc927 = loc("1976|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPMLP[image_encoder.vision_model.encoder.layers[18].mlp]|Linear[image_encoder.vision_model.encoder.layers[18].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_228aten__add_decomp_matmul"(#loc127))
#loc928 = loc("1976|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPMLP[image_encoder.vision_model.encoder.layers[18].mlp]|Linear[image_encoder.vision_model.encoder.layers[18].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_228aten__add_decomp_add"(#loc127))
#loc929 = loc("1976|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPMLP[image_encoder.vision_model.encoder.layers[18].mlp]|Linear[image_encoder.vision_model.encoder.layers[18].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_228aten__add_decomp_gelu"(#loc127))
#loc930 = loc("1982|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPMLP[image_encoder.vision_model.encoder.layers[18].mlp]|Linear[image_encoder.vision_model.encoder.layers[18].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_229aten__add_decomp_matmul"(#loc191))
#loc931 = loc("1982|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[18]]|CLIPMLP[image_encoder.vision_model.encoder.layers[18].mlp]|Linear[image_encoder.vision_model.encoder.layers[18].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_229aten__add_decomp_add"(#loc191))
#loc932 = loc("1999|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|Linear[image_encoder.vision_model.encoder.layers[19].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_233aten__add_decomp_matmul"(#loc67))
#loc933 = loc("1999|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|Linear[image_encoder.vision_model.encoder.layers[19].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_233aten__add_decomp_add"(#loc67))
#loc934 = loc("1999|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|Linear[image_encoder.vision_model.encoder.layers[19].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_233aten__add_split_q"(#loc67))
#loc935 = loc("1999|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|Linear[image_encoder.vision_model.encoder.layers[19].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_233aten__add_split_k"(#loc67))
#loc936 = loc("1999|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|Linear[image_encoder.vision_model.encoder.layers[19].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_233aten__add_split_v"(#loc67))
#loc937 = loc("1999|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|Linear[image_encoder.vision_model.encoder.layers[19].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_233aten__add_reshape_q"(#loc67))
#loc938 = loc("1999|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|Linear[image_encoder.vision_model.encoder.layers[19].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_233aten__add_reshape_k"(#loc67))
#loc939 = loc("1999|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|Linear[image_encoder.vision_model.encoder.layers[19].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_233aten__add_reshape_v"(#loc67))
#loc940 = loc("1999|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|Linear[image_encoder.vision_model.encoder.layers[19].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_233aten__add_permute_q"(#loc67))
#loc941 = loc("1999|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|Linear[image_encoder.vision_model.encoder.layers[19].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_233aten__add_permute_k"(#loc67))
#loc942 = loc("1999|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|Linear[image_encoder.vision_model.encoder.layers[19].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_233aten__add_permute_v"(#loc67))
#loc943 = loc("2032|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|Linear[image_encoder.vision_model.encoder.layers[19].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_117aten__view_concat_heads"(#loc380))
#loc944 = loc("2033|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|Linear[image_encoder.vision_model.encoder.layers[19].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_236aten__add_decomp_matmul"(#loc71))
#loc945 = loc("2033|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPAttention[image_encoder.vision_model.encoder.layers[19].self_attn]|Linear[image_encoder.vision_model.encoder.layers[19].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_236aten__add_decomp_add"(#loc71))
#loc946 = loc("2050|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPMLP[image_encoder.vision_model.encoder.layers[19].mlp]|Linear[image_encoder.vision_model.encoder.layers[19].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_240aten__add_decomp_matmul"(#loc58))
#loc947 = loc("2050|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPMLP[image_encoder.vision_model.encoder.layers[19].mlp]|Linear[image_encoder.vision_model.encoder.layers[19].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_240aten__add_decomp_add"(#loc58))
#loc948 = loc("2050|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPMLP[image_encoder.vision_model.encoder.layers[19].mlp]|Linear[image_encoder.vision_model.encoder.layers[19].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_240aten__add_decomp_gelu"(#loc58))
#loc949 = loc("2056|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPMLP[image_encoder.vision_model.encoder.layers[19].mlp]|Linear[image_encoder.vision_model.encoder.layers[19].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_241aten__add_decomp_matmul"(#loc31))
#loc950 = loc("2056|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[19]]|CLIPMLP[image_encoder.vision_model.encoder.layers[19].mlp]|Linear[image_encoder.vision_model.encoder.layers[19].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_241aten__add_decomp_add"(#loc31))
#loc951 = loc("2073|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|Linear[image_encoder.vision_model.encoder.layers[20].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_245aten__add_decomp_matmul"(#loc85))
#loc952 = loc("2073|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|Linear[image_encoder.vision_model.encoder.layers[20].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_245aten__add_decomp_add"(#loc85))
#loc953 = loc("2073|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|Linear[image_encoder.vision_model.encoder.layers[20].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_245aten__add_split_q"(#loc85))
#loc954 = loc("2073|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|Linear[image_encoder.vision_model.encoder.layers[20].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_245aten__add_split_k"(#loc85))
#loc955 = loc("2073|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|Linear[image_encoder.vision_model.encoder.layers[20].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_245aten__add_split_v"(#loc85))
#loc956 = loc("2073|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|Linear[image_encoder.vision_model.encoder.layers[20].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_245aten__add_reshape_q"(#loc85))
#loc957 = loc("2073|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|Linear[image_encoder.vision_model.encoder.layers[20].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_245aten__add_reshape_k"(#loc85))
#loc958 = loc("2073|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|Linear[image_encoder.vision_model.encoder.layers[20].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_245aten__add_reshape_v"(#loc85))
#loc959 = loc("2073|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|Linear[image_encoder.vision_model.encoder.layers[20].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_245aten__add_permute_q"(#loc85))
#loc960 = loc("2073|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|Linear[image_encoder.vision_model.encoder.layers[20].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_245aten__add_permute_k"(#loc85))
#loc961 = loc("2073|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|Linear[image_encoder.vision_model.encoder.layers[20].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_245aten__add_permute_v"(#loc85))
#loc962 = loc("2106|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|Linear[image_encoder.vision_model.encoder.layers[20].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_123aten__view_concat_heads"(#loc389))
#loc963 = loc("2107|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|Linear[image_encoder.vision_model.encoder.layers[20].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_248aten__add_decomp_matmul"(#loc107))
#loc964 = loc("2107|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPAttention[image_encoder.vision_model.encoder.layers[20].self_attn]|Linear[image_encoder.vision_model.encoder.layers[20].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_248aten__add_decomp_add"(#loc107))
#loc965 = loc("2124|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPMLP[image_encoder.vision_model.encoder.layers[20].mlp]|Linear[image_encoder.vision_model.encoder.layers[20].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_252aten__add_decomp_matmul"(#loc142))
#loc966 = loc("2124|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPMLP[image_encoder.vision_model.encoder.layers[20].mlp]|Linear[image_encoder.vision_model.encoder.layers[20].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_252aten__add_decomp_add"(#loc142))
#loc967 = loc("2124|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPMLP[image_encoder.vision_model.encoder.layers[20].mlp]|Linear[image_encoder.vision_model.encoder.layers[20].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_252aten__add_decomp_gelu"(#loc142))
#loc968 = loc("2130|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPMLP[image_encoder.vision_model.encoder.layers[20].mlp]|Linear[image_encoder.vision_model.encoder.layers[20].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_253aten__add_decomp_matmul"(#loc113))
#loc969 = loc("2130|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[20]]|CLIPMLP[image_encoder.vision_model.encoder.layers[20].mlp]|Linear[image_encoder.vision_model.encoder.layers[20].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_253aten__add_decomp_add"(#loc113))
#loc970 = loc("2147|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|Linear[image_encoder.vision_model.encoder.layers[21].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_257aten__add_decomp_matmul"(#loc146))
#loc971 = loc("2147|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|Linear[image_encoder.vision_model.encoder.layers[21].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_257aten__add_decomp_add"(#loc146))
#loc972 = loc("2147|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|Linear[image_encoder.vision_model.encoder.layers[21].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_257aten__add_split_q"(#loc146))
#loc973 = loc("2147|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|Linear[image_encoder.vision_model.encoder.layers[21].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_257aten__add_split_k"(#loc146))
#loc974 = loc("2147|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|Linear[image_encoder.vision_model.encoder.layers[21].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_257aten__add_split_v"(#loc146))
#loc975 = loc("2147|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|Linear[image_encoder.vision_model.encoder.layers[21].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_257aten__add_reshape_q"(#loc146))
#loc976 = loc("2147|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|Linear[image_encoder.vision_model.encoder.layers[21].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_257aten__add_reshape_k"(#loc146))
#loc977 = loc("2147|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|Linear[image_encoder.vision_model.encoder.layers[21].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_257aten__add_reshape_v"(#loc146))
#loc978 = loc("2147|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|Linear[image_encoder.vision_model.encoder.layers[21].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_257aten__add_permute_q"(#loc146))
#loc979 = loc("2147|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|Linear[image_encoder.vision_model.encoder.layers[21].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_257aten__add_permute_k"(#loc146))
#loc980 = loc("2147|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|Linear[image_encoder.vision_model.encoder.layers[21].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_257aten__add_permute_v"(#loc146))
#loc981 = loc("2180|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|Linear[image_encoder.vision_model.encoder.layers[21].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_129aten__view_concat_heads"(#loc398))
#loc982 = loc("2181|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|Linear[image_encoder.vision_model.encoder.layers[21].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_260aten__add_decomp_matmul"(#loc26))
#loc983 = loc("2181|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPAttention[image_encoder.vision_model.encoder.layers[21].self_attn]|Linear[image_encoder.vision_model.encoder.layers[21].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_260aten__add_decomp_add"(#loc26))
#loc984 = loc("2198|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPMLP[image_encoder.vision_model.encoder.layers[21].mlp]|Linear[image_encoder.vision_model.encoder.layers[21].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_264aten__add_decomp_matmul"(#loc145))
#loc985 = loc("2198|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPMLP[image_encoder.vision_model.encoder.layers[21].mlp]|Linear[image_encoder.vision_model.encoder.layers[21].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_264aten__add_decomp_add"(#loc145))
#loc986 = loc("2198|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPMLP[image_encoder.vision_model.encoder.layers[21].mlp]|Linear[image_encoder.vision_model.encoder.layers[21].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_264aten__add_decomp_gelu"(#loc145))
#loc987 = loc("2204|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPMLP[image_encoder.vision_model.encoder.layers[21].mlp]|Linear[image_encoder.vision_model.encoder.layers[21].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_265aten__add_decomp_matmul"(#loc202))
#loc988 = loc("2204|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[21]]|CLIPMLP[image_encoder.vision_model.encoder.layers[21].mlp]|Linear[image_encoder.vision_model.encoder.layers[21].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_265aten__add_decomp_add"(#loc202))
#loc989 = loc("2221|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|Linear[image_encoder.vision_model.encoder.layers[22].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_269aten__add_decomp_matmul"(#loc76))
#loc990 = loc("2221|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|Linear[image_encoder.vision_model.encoder.layers[22].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_269aten__add_decomp_add"(#loc76))
#loc991 = loc("2221|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|Linear[image_encoder.vision_model.encoder.layers[22].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_269aten__add_split_q"(#loc76))
#loc992 = loc("2221|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|Linear[image_encoder.vision_model.encoder.layers[22].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_269aten__add_split_k"(#loc76))
#loc993 = loc("2221|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|Linear[image_encoder.vision_model.encoder.layers[22].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_269aten__add_split_v"(#loc76))
#loc994 = loc("2221|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|Linear[image_encoder.vision_model.encoder.layers[22].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_269aten__add_reshape_q"(#loc76))
#loc995 = loc("2221|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|Linear[image_encoder.vision_model.encoder.layers[22].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_269aten__add_reshape_k"(#loc76))
#loc996 = loc("2221|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|Linear[image_encoder.vision_model.encoder.layers[22].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_269aten__add_reshape_v"(#loc76))
#loc997 = loc("2221|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|Linear[image_encoder.vision_model.encoder.layers[22].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_269aten__add_permute_q"(#loc76))
#loc998 = loc("2221|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|Linear[image_encoder.vision_model.encoder.layers[22].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_269aten__add_permute_k"(#loc76))
#loc999 = loc("2221|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|Linear[image_encoder.vision_model.encoder.layers[22].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_269aten__add_permute_v"(#loc76))
#loc1000 = loc("2254|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|Linear[image_encoder.vision_model.encoder.layers[22].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_135aten__view_concat_heads"(#loc407))
#loc1001 = loc("2255|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|Linear[image_encoder.vision_model.encoder.layers[22].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_272aten__add_decomp_matmul"(#loc44))
#loc1002 = loc("2255|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPAttention[image_encoder.vision_model.encoder.layers[22].self_attn]|Linear[image_encoder.vision_model.encoder.layers[22].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_272aten__add_decomp_add"(#loc44))
#loc1003 = loc("2272|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPMLP[image_encoder.vision_model.encoder.layers[22].mlp]|Linear[image_encoder.vision_model.encoder.layers[22].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_276aten__add_decomp_matmul"(#loc8))
#loc1004 = loc("2272|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPMLP[image_encoder.vision_model.encoder.layers[22].mlp]|Linear[image_encoder.vision_model.encoder.layers[22].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_276aten__add_decomp_add"(#loc8))
#loc1005 = loc("2272|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPMLP[image_encoder.vision_model.encoder.layers[22].mlp]|Linear[image_encoder.vision_model.encoder.layers[22].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_276aten__add_decomp_gelu"(#loc8))
#loc1006 = loc("2278|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPMLP[image_encoder.vision_model.encoder.layers[22].mlp]|Linear[image_encoder.vision_model.encoder.layers[22].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_277aten__add_decomp_matmul"(#loc164))
#loc1007 = loc("2278|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[22]]|CLIPMLP[image_encoder.vision_model.encoder.layers[22].mlp]|Linear[image_encoder.vision_model.encoder.layers[22].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_277aten__add_decomp_add"(#loc164))
#loc1008 = loc("2295|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|Linear[image_encoder.vision_model.encoder.layers[23].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_281aten__add_decomp_matmul"(#loc41))
#loc1009 = loc("2295|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|Linear[image_encoder.vision_model.encoder.layers[23].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_281aten__add_decomp_add"(#loc41))
#loc1010 = loc("2295|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|Linear[image_encoder.vision_model.encoder.layers[23].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_281aten__add_split_q"(#loc41))
#loc1011 = loc("2295|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|Linear[image_encoder.vision_model.encoder.layers[23].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_281aten__add_split_k"(#loc41))
#loc1012 = loc("2295|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|Linear[image_encoder.vision_model.encoder.layers[23].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_281aten__add_split_v"(#loc41))
#loc1013 = loc("2295|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|Linear[image_encoder.vision_model.encoder.layers[23].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_281aten__add_reshape_q"(#loc41))
#loc1014 = loc("2295|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|Linear[image_encoder.vision_model.encoder.layers[23].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_281aten__add_reshape_k"(#loc41))
#loc1015 = loc("2295|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|Linear[image_encoder.vision_model.encoder.layers[23].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_281aten__add_reshape_v"(#loc41))
#loc1016 = loc("2295|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|Linear[image_encoder.vision_model.encoder.layers[23].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_281aten__add_permute_q"(#loc41))
#loc1017 = loc("2295|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|Linear[image_encoder.vision_model.encoder.layers[23].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_281aten__add_permute_k"(#loc41))
#loc1018 = loc("2295|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|Linear[image_encoder.vision_model.encoder.layers[23].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_281aten__add_permute_v"(#loc41))
#loc1019 = loc("2328|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|Linear[image_encoder.vision_model.encoder.layers[23].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_141aten__view_concat_heads"(#loc416))
#loc1020 = loc("2329|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|Linear[image_encoder.vision_model.encoder.layers[23].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_284aten__add_decomp_matmul"(#loc70))
#loc1021 = loc("2329|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPAttention[image_encoder.vision_model.encoder.layers[23].self_attn]|Linear[image_encoder.vision_model.encoder.layers[23].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_284aten__add_decomp_add"(#loc70))
#loc1022 = loc("2346|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPMLP[image_encoder.vision_model.encoder.layers[23].mlp]|Linear[image_encoder.vision_model.encoder.layers[23].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_288aten__add_decomp_matmul"(#loc2))
#loc1023 = loc("2346|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPMLP[image_encoder.vision_model.encoder.layers[23].mlp]|Linear[image_encoder.vision_model.encoder.layers[23].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_288aten__add_decomp_add"(#loc2))
#loc1024 = loc("2346|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPMLP[image_encoder.vision_model.encoder.layers[23].mlp]|Linear[image_encoder.vision_model.encoder.layers[23].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_288aten__add_decomp_gelu"(#loc2))
#loc1025 = loc("2352|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPMLP[image_encoder.vision_model.encoder.layers[23].mlp]|Linear[image_encoder.vision_model.encoder.layers[23].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_289aten__add_decomp_matmul"(#loc28))
#loc1026 = loc("2352|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[23]]|CLIPMLP[image_encoder.vision_model.encoder.layers[23].mlp]|Linear[image_encoder.vision_model.encoder.layers[23].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_289aten__add_decomp_add"(#loc28))
#loc1027 = loc("2369|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|Linear[image_encoder.vision_model.encoder.layers[24].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_293aten__add_decomp_matmul"(#loc82))
#loc1028 = loc("2369|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|Linear[image_encoder.vision_model.encoder.layers[24].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_293aten__add_decomp_add"(#loc82))
#loc1029 = loc("2369|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|Linear[image_encoder.vision_model.encoder.layers[24].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_293aten__add_split_q"(#loc82))
#loc1030 = loc("2369|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|Linear[image_encoder.vision_model.encoder.layers[24].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_293aten__add_split_k"(#loc82))
#loc1031 = loc("2369|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|Linear[image_encoder.vision_model.encoder.layers[24].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_293aten__add_split_v"(#loc82))
#loc1032 = loc("2369|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|Linear[image_encoder.vision_model.encoder.layers[24].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_293aten__add_reshape_q"(#loc82))
#loc1033 = loc("2369|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|Linear[image_encoder.vision_model.encoder.layers[24].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_293aten__add_reshape_k"(#loc82))
#loc1034 = loc("2369|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|Linear[image_encoder.vision_model.encoder.layers[24].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_293aten__add_reshape_v"(#loc82))
#loc1035 = loc("2369|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|Linear[image_encoder.vision_model.encoder.layers[24].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_293aten__add_permute_q"(#loc82))
#loc1036 = loc("2369|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|Linear[image_encoder.vision_model.encoder.layers[24].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_293aten__add_permute_k"(#loc82))
#loc1037 = loc("2369|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|Linear[image_encoder.vision_model.encoder.layers[24].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_293aten__add_permute_v"(#loc82))
#loc1038 = loc("2402|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|Linear[image_encoder.vision_model.encoder.layers[24].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_147aten__view_concat_heads"(#loc425))
#loc1039 = loc("2403|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|Linear[image_encoder.vision_model.encoder.layers[24].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_296aten__add_decomp_matmul"(#loc187))
#loc1040 = loc("2403|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPAttention[image_encoder.vision_model.encoder.layers[24].self_attn]|Linear[image_encoder.vision_model.encoder.layers[24].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_296aten__add_decomp_add"(#loc187))
#loc1041 = loc("2420|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPMLP[image_encoder.vision_model.encoder.layers[24].mlp]|Linear[image_encoder.vision_model.encoder.layers[24].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_300aten__add_decomp_matmul"(#loc183))
#loc1042 = loc("2420|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPMLP[image_encoder.vision_model.encoder.layers[24].mlp]|Linear[image_encoder.vision_model.encoder.layers[24].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_300aten__add_decomp_add"(#loc183))
#loc1043 = loc("2420|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPMLP[image_encoder.vision_model.encoder.layers[24].mlp]|Linear[image_encoder.vision_model.encoder.layers[24].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_300aten__add_decomp_gelu"(#loc183))
#loc1044 = loc("2426|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPMLP[image_encoder.vision_model.encoder.layers[24].mlp]|Linear[image_encoder.vision_model.encoder.layers[24].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_301aten__add_decomp_matmul"(#loc188))
#loc1045 = loc("2426|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[24]]|CLIPMLP[image_encoder.vision_model.encoder.layers[24].mlp]|Linear[image_encoder.vision_model.encoder.layers[24].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_301aten__add_decomp_add"(#loc188))
#loc1046 = loc("2443|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|Linear[image_encoder.vision_model.encoder.layers[25].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_305aten__add_decomp_matmul"(#loc79))
#loc1047 = loc("2443|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|Linear[image_encoder.vision_model.encoder.layers[25].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_305aten__add_decomp_add"(#loc79))
#loc1048 = loc("2443|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|Linear[image_encoder.vision_model.encoder.layers[25].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_305aten__add_split_q"(#loc79))
#loc1049 = loc("2443|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|Linear[image_encoder.vision_model.encoder.layers[25].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_305aten__add_split_k"(#loc79))
#loc1050 = loc("2443|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|Linear[image_encoder.vision_model.encoder.layers[25].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_305aten__add_split_v"(#loc79))
#loc1051 = loc("2443|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|Linear[image_encoder.vision_model.encoder.layers[25].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_305aten__add_reshape_q"(#loc79))
#loc1052 = loc("2443|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|Linear[image_encoder.vision_model.encoder.layers[25].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_305aten__add_reshape_k"(#loc79))
#loc1053 = loc("2443|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|Linear[image_encoder.vision_model.encoder.layers[25].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_305aten__add_reshape_v"(#loc79))
#loc1054 = loc("2443|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|Linear[image_encoder.vision_model.encoder.layers[25].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_305aten__add_permute_q"(#loc79))
#loc1055 = loc("2443|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|Linear[image_encoder.vision_model.encoder.layers[25].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_305aten__add_permute_k"(#loc79))
#loc1056 = loc("2443|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|Linear[image_encoder.vision_model.encoder.layers[25].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_305aten__add_permute_v"(#loc79))
#loc1057 = loc("2476|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|Linear[image_encoder.vision_model.encoder.layers[25].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_153aten__view_concat_heads"(#loc434))
#loc1058 = loc("2477|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|Linear[image_encoder.vision_model.encoder.layers[25].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_308aten__add_decomp_matmul"(#loc40))
#loc1059 = loc("2477|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPAttention[image_encoder.vision_model.encoder.layers[25].self_attn]|Linear[image_encoder.vision_model.encoder.layers[25].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_308aten__add_decomp_add"(#loc40))
#loc1060 = loc("2494|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPMLP[image_encoder.vision_model.encoder.layers[25].mlp]|Linear[image_encoder.vision_model.encoder.layers[25].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_312aten__add_decomp_matmul"(#loc155))
#loc1061 = loc("2494|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPMLP[image_encoder.vision_model.encoder.layers[25].mlp]|Linear[image_encoder.vision_model.encoder.layers[25].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_312aten__add_decomp_add"(#loc155))
#loc1062 = loc("2494|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPMLP[image_encoder.vision_model.encoder.layers[25].mlp]|Linear[image_encoder.vision_model.encoder.layers[25].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_312aten__add_decomp_gelu"(#loc155))
#loc1063 = loc("2500|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPMLP[image_encoder.vision_model.encoder.layers[25].mlp]|Linear[image_encoder.vision_model.encoder.layers[25].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_313aten__add_decomp_matmul"(#loc47))
#loc1064 = loc("2500|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[25]]|CLIPMLP[image_encoder.vision_model.encoder.layers[25].mlp]|Linear[image_encoder.vision_model.encoder.layers[25].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_313aten__add_decomp_add"(#loc47))
#loc1065 = loc("2517|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|Linear[image_encoder.vision_model.encoder.layers[26].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_317aten__add_decomp_matmul"(#loc104))
#loc1066 = loc("2517|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|Linear[image_encoder.vision_model.encoder.layers[26].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_317aten__add_decomp_add"(#loc104))
#loc1067 = loc("2517|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|Linear[image_encoder.vision_model.encoder.layers[26].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_317aten__add_split_q"(#loc104))
#loc1068 = loc("2517|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|Linear[image_encoder.vision_model.encoder.layers[26].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_317aten__add_split_k"(#loc104))
#loc1069 = loc("2517|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|Linear[image_encoder.vision_model.encoder.layers[26].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_317aten__add_split_v"(#loc104))
#loc1070 = loc("2517|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|Linear[image_encoder.vision_model.encoder.layers[26].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_317aten__add_reshape_q"(#loc104))
#loc1071 = loc("2517|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|Linear[image_encoder.vision_model.encoder.layers[26].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_317aten__add_reshape_k"(#loc104))
#loc1072 = loc("2517|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|Linear[image_encoder.vision_model.encoder.layers[26].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_317aten__add_reshape_v"(#loc104))
#loc1073 = loc("2517|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|Linear[image_encoder.vision_model.encoder.layers[26].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_317aten__add_permute_q"(#loc104))
#loc1074 = loc("2517|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|Linear[image_encoder.vision_model.encoder.layers[26].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_317aten__add_permute_k"(#loc104))
#loc1075 = loc("2517|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|Linear[image_encoder.vision_model.encoder.layers[26].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_317aten__add_permute_v"(#loc104))
#loc1076 = loc("2550|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|Linear[image_encoder.vision_model.encoder.layers[26].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_159aten__view_concat_heads"(#loc443))
#loc1077 = loc("2551|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|Linear[image_encoder.vision_model.encoder.layers[26].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_320aten__add_decomp_matmul"(#loc140))
#loc1078 = loc("2551|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPAttention[image_encoder.vision_model.encoder.layers[26].self_attn]|Linear[image_encoder.vision_model.encoder.layers[26].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_320aten__add_decomp_add"(#loc140))
#loc1079 = loc("2568|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPMLP[image_encoder.vision_model.encoder.layers[26].mlp]|Linear[image_encoder.vision_model.encoder.layers[26].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_324aten__add_decomp_matmul"(#loc130))
#loc1080 = loc("2568|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPMLP[image_encoder.vision_model.encoder.layers[26].mlp]|Linear[image_encoder.vision_model.encoder.layers[26].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_324aten__add_decomp_add"(#loc130))
#loc1081 = loc("2568|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPMLP[image_encoder.vision_model.encoder.layers[26].mlp]|Linear[image_encoder.vision_model.encoder.layers[26].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_324aten__add_decomp_gelu"(#loc130))
#loc1082 = loc("2574|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPMLP[image_encoder.vision_model.encoder.layers[26].mlp]|Linear[image_encoder.vision_model.encoder.layers[26].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_325aten__add_decomp_matmul"(#loc162))
#loc1083 = loc("2574|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[26]]|CLIPMLP[image_encoder.vision_model.encoder.layers[26].mlp]|Linear[image_encoder.vision_model.encoder.layers[26].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_325aten__add_decomp_add"(#loc162))
#loc1084 = loc("2591|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|Linear[image_encoder.vision_model.encoder.layers[27].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_329aten__add_decomp_matmul"(#loc51))
#loc1085 = loc("2591|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|Linear[image_encoder.vision_model.encoder.layers[27].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_329aten__add_decomp_add"(#loc51))
#loc1086 = loc("2591|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|Linear[image_encoder.vision_model.encoder.layers[27].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_329aten__add_split_q"(#loc51))
#loc1087 = loc("2591|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|Linear[image_encoder.vision_model.encoder.layers[27].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_329aten__add_split_k"(#loc51))
#loc1088 = loc("2591|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|Linear[image_encoder.vision_model.encoder.layers[27].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_329aten__add_split_v"(#loc51))
#loc1089 = loc("2591|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|Linear[image_encoder.vision_model.encoder.layers[27].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_329aten__add_reshape_q"(#loc51))
#loc1090 = loc("2591|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|Linear[image_encoder.vision_model.encoder.layers[27].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_329aten__add_reshape_k"(#loc51))
#loc1091 = loc("2591|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|Linear[image_encoder.vision_model.encoder.layers[27].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_329aten__add_reshape_v"(#loc51))
#loc1092 = loc("2591|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|Linear[image_encoder.vision_model.encoder.layers[27].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_329aten__add_permute_q"(#loc51))
#loc1093 = loc("2591|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|Linear[image_encoder.vision_model.encoder.layers[27].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_329aten__add_permute_k"(#loc51))
#loc1094 = loc("2591|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|Linear[image_encoder.vision_model.encoder.layers[27].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_329aten__add_permute_v"(#loc51))
#loc1095 = loc("2624|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|Linear[image_encoder.vision_model.encoder.layers[27].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_165aten__view_concat_heads"(#loc452))
#loc1096 = loc("2625|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|Linear[image_encoder.vision_model.encoder.layers[27].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_332aten__add_decomp_matmul"(#loc12))
#loc1097 = loc("2625|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPAttention[image_encoder.vision_model.encoder.layers[27].self_attn]|Linear[image_encoder.vision_model.encoder.layers[27].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_332aten__add_decomp_add"(#loc12))
#loc1098 = loc("2642|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPMLP[image_encoder.vision_model.encoder.layers[27].mlp]|Linear[image_encoder.vision_model.encoder.layers[27].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_336aten__add_decomp_matmul"(#loc151))
#loc1099 = loc("2642|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPMLP[image_encoder.vision_model.encoder.layers[27].mlp]|Linear[image_encoder.vision_model.encoder.layers[27].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_336aten__add_decomp_add"(#loc151))
#loc1100 = loc("2642|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPMLP[image_encoder.vision_model.encoder.layers[27].mlp]|Linear[image_encoder.vision_model.encoder.layers[27].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_336aten__add_decomp_gelu"(#loc151))
#loc1101 = loc("2648|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPMLP[image_encoder.vision_model.encoder.layers[27].mlp]|Linear[image_encoder.vision_model.encoder.layers[27].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_337aten__add_decomp_matmul"(#loc166))
#loc1102 = loc("2648|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[27]]|CLIPMLP[image_encoder.vision_model.encoder.layers[27].mlp]|Linear[image_encoder.vision_model.encoder.layers[27].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_337aten__add_decomp_add"(#loc166))
#loc1103 = loc("2665|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|Linear[image_encoder.vision_model.encoder.layers[28].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_341aten__add_decomp_matmul"(#loc18))
#loc1104 = loc("2665|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|Linear[image_encoder.vision_model.encoder.layers[28].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_341aten__add_decomp_add"(#loc18))
#loc1105 = loc("2665|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|Linear[image_encoder.vision_model.encoder.layers[28].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_341aten__add_split_q"(#loc18))
#loc1106 = loc("2665|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|Linear[image_encoder.vision_model.encoder.layers[28].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_341aten__add_split_k"(#loc18))
#loc1107 = loc("2665|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|Linear[image_encoder.vision_model.encoder.layers[28].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_341aten__add_split_v"(#loc18))
#loc1108 = loc("2665|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|Linear[image_encoder.vision_model.encoder.layers[28].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_341aten__add_reshape_q"(#loc18))
#loc1109 = loc("2665|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|Linear[image_encoder.vision_model.encoder.layers[28].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_341aten__add_reshape_k"(#loc18))
#loc1110 = loc("2665|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|Linear[image_encoder.vision_model.encoder.layers[28].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_341aten__add_reshape_v"(#loc18))
#loc1111 = loc("2665|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|Linear[image_encoder.vision_model.encoder.layers[28].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_341aten__add_permute_q"(#loc18))
#loc1112 = loc("2665|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|Linear[image_encoder.vision_model.encoder.layers[28].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_341aten__add_permute_k"(#loc18))
#loc1113 = loc("2665|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|Linear[image_encoder.vision_model.encoder.layers[28].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_341aten__add_permute_v"(#loc18))
#loc1114 = loc("2698|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|Linear[image_encoder.vision_model.encoder.layers[28].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_171aten__view_concat_heads"(#loc461))
#loc1115 = loc("2699|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|Linear[image_encoder.vision_model.encoder.layers[28].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_344aten__add_decomp_matmul"(#loc160))
#loc1116 = loc("2699|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPAttention[image_encoder.vision_model.encoder.layers[28].self_attn]|Linear[image_encoder.vision_model.encoder.layers[28].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_344aten__add_decomp_add"(#loc160))
#loc1117 = loc("2716|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPMLP[image_encoder.vision_model.encoder.layers[28].mlp]|Linear[image_encoder.vision_model.encoder.layers[28].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_348aten__add_decomp_matmul"(#loc16))
#loc1118 = loc("2716|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPMLP[image_encoder.vision_model.encoder.layers[28].mlp]|Linear[image_encoder.vision_model.encoder.layers[28].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_348aten__add_decomp_add"(#loc16))
#loc1119 = loc("2716|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPMLP[image_encoder.vision_model.encoder.layers[28].mlp]|Linear[image_encoder.vision_model.encoder.layers[28].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_348aten__add_decomp_gelu"(#loc16))
#loc1120 = loc("2722|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPMLP[image_encoder.vision_model.encoder.layers[28].mlp]|Linear[image_encoder.vision_model.encoder.layers[28].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_349aten__add_decomp_matmul"(#loc75))
#loc1121 = loc("2722|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[28]]|CLIPMLP[image_encoder.vision_model.encoder.layers[28].mlp]|Linear[image_encoder.vision_model.encoder.layers[28].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_349aten__add_decomp_add"(#loc75))
#loc1122 = loc("2739|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|Linear[image_encoder.vision_model.encoder.layers[29].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_353aten__add_decomp_matmul"(#loc59))
#loc1123 = loc("2739|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|Linear[image_encoder.vision_model.encoder.layers[29].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_353aten__add_decomp_add"(#loc59))
#loc1124 = loc("2739|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|Linear[image_encoder.vision_model.encoder.layers[29].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_353aten__add_split_q"(#loc59))
#loc1125 = loc("2739|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|Linear[image_encoder.vision_model.encoder.layers[29].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_353aten__add_split_k"(#loc59))
#loc1126 = loc("2739|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|Linear[image_encoder.vision_model.encoder.layers[29].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_353aten__add_split_v"(#loc59))
#loc1127 = loc("2739|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|Linear[image_encoder.vision_model.encoder.layers[29].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_353aten__add_reshape_q"(#loc59))
#loc1128 = loc("2739|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|Linear[image_encoder.vision_model.encoder.layers[29].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_353aten__add_reshape_k"(#loc59))
#loc1129 = loc("2739|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|Linear[image_encoder.vision_model.encoder.layers[29].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_353aten__add_reshape_v"(#loc59))
#loc1130 = loc("2739|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|Linear[image_encoder.vision_model.encoder.layers[29].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_353aten__add_permute_q"(#loc59))
#loc1131 = loc("2739|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|Linear[image_encoder.vision_model.encoder.layers[29].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_353aten__add_permute_k"(#loc59))
#loc1132 = loc("2739|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|Linear[image_encoder.vision_model.encoder.layers[29].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_353aten__add_permute_v"(#loc59))
#loc1133 = loc("2772|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|Linear[image_encoder.vision_model.encoder.layers[29].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_177aten__view_concat_heads"(#loc470))
#loc1134 = loc("2773|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|Linear[image_encoder.vision_model.encoder.layers[29].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_356aten__add_decomp_matmul"(#loc108))
#loc1135 = loc("2773|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPAttention[image_encoder.vision_model.encoder.layers[29].self_attn]|Linear[image_encoder.vision_model.encoder.layers[29].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_356aten__add_decomp_add"(#loc108))
#loc1136 = loc("2790|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPMLP[image_encoder.vision_model.encoder.layers[29].mlp]|Linear[image_encoder.vision_model.encoder.layers[29].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_360aten__add_decomp_matmul"(#loc46))
#loc1137 = loc("2790|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPMLP[image_encoder.vision_model.encoder.layers[29].mlp]|Linear[image_encoder.vision_model.encoder.layers[29].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_360aten__add_decomp_add"(#loc46))
#loc1138 = loc("2790|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPMLP[image_encoder.vision_model.encoder.layers[29].mlp]|Linear[image_encoder.vision_model.encoder.layers[29].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_360aten__add_decomp_gelu"(#loc46))
#loc1139 = loc("2796|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPMLP[image_encoder.vision_model.encoder.layers[29].mlp]|Linear[image_encoder.vision_model.encoder.layers[29].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_361aten__add_decomp_matmul"(#loc45))
#loc1140 = loc("2796|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[29]]|CLIPMLP[image_encoder.vision_model.encoder.layers[29].mlp]|Linear[image_encoder.vision_model.encoder.layers[29].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_361aten__add_decomp_add"(#loc45))
#loc1141 = loc("2813|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|Linear[image_encoder.vision_model.encoder.layers[30].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_365aten__add_decomp_matmul"(#loc168))
#loc1142 = loc("2813|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|Linear[image_encoder.vision_model.encoder.layers[30].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_365aten__add_decomp_add"(#loc168))
#loc1143 = loc("2813|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|Linear[image_encoder.vision_model.encoder.layers[30].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_365aten__add_split_q"(#loc168))
#loc1144 = loc("2813|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|Linear[image_encoder.vision_model.encoder.layers[30].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_365aten__add_split_k"(#loc168))
#loc1145 = loc("2813|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|Linear[image_encoder.vision_model.encoder.layers[30].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_365aten__add_split_v"(#loc168))
#loc1146 = loc("2813|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|Linear[image_encoder.vision_model.encoder.layers[30].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_365aten__add_reshape_q"(#loc168))
#loc1147 = loc("2813|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|Linear[image_encoder.vision_model.encoder.layers[30].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_365aten__add_reshape_k"(#loc168))
#loc1148 = loc("2813|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|Linear[image_encoder.vision_model.encoder.layers[30].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_365aten__add_reshape_v"(#loc168))
#loc1149 = loc("2813|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|Linear[image_encoder.vision_model.encoder.layers[30].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_365aten__add_permute_q"(#loc168))
#loc1150 = loc("2813|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|Linear[image_encoder.vision_model.encoder.layers[30].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_365aten__add_permute_k"(#loc168))
#loc1151 = loc("2813|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|Linear[image_encoder.vision_model.encoder.layers[30].self_attn.q_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|312|add_365aten__add_permute_v"(#loc168))
#loc1152 = loc("2846|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|Linear[image_encoder.vision_model.encoder.layers[30].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|matmul_183aten__view_concat_heads"(#loc479))
#loc1153 = loc("2847|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|Linear[image_encoder.vision_model.encoder.layers[30].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_368aten__add_decomp_matmul"(#loc66))
#loc1154 = loc("2847|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPAttention[image_encoder.vision_model.encoder.layers[30].self_attn]|Linear[image_encoder.vision_model.encoder.layers[30].self_attn.out_proj]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:301|forward|346|add_368aten__add_decomp_add"(#loc66))
#loc1155 = loc("2864|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPMLP[image_encoder.vision_model.encoder.layers[30].mlp]|Linear[image_encoder.vision_model.encoder.layers[30].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_372aten__add_decomp_matmul"(#loc178))
#loc1156 = loc("2864|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPMLP[image_encoder.vision_model.encoder.layers[30].mlp]|Linear[image_encoder.vision_model.encoder.layers[30].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_372aten__add_decomp_add"(#loc178))
#loc1157 = loc("2864|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPMLP[image_encoder.vision_model.encoder.layers[30].mlp]|Linear[image_encoder.vision_model.encoder.layers[30].mlp.fc1]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|362|add_372aten__add_decomp_gelu"(#loc178))
#loc1158 = loc("2870|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPMLP[image_encoder.vision_model.encoder.layers[30].mlp]|Linear[image_encoder.vision_model.encoder.layers[30].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_373aten__add_decomp_matmul"(#loc73))
#loc1159 = loc("2870|CLIPVisionModelWithProjection[image_encoder]|CLIPVisionTransformer[image_encoder.vision_model]|CLIPEncoder[image_encoder.vision_model.encoder]|CLIPEncoderLayer[image_encoder.vision_model.encoder.layers[30]]|CLIPMLP[image_encoder.vision_model.encoder.layers[30].mlp]|Linear[image_encoder.vision_model.encoder.layers[30].mlp.fc2]|/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py:361|forward|364|add_373aten__add_decomp_add"(#loc73))
#loc1160 = loc("2875|IPAdapterPlusImageProjection[resampler]|Linear[resampler.proj_in]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2293|forward|2303|add_389aten__add_decomp_matmul"(#loc182))
#loc1161 = loc("2875|IPAdapterPlusImageProjection[resampler]|Linear[resampler.proj_in]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2293|forward|2303|add_389aten__add_decomp_add"(#loc182))
#loc1162 = loc("3217|IPAdapterPlusImageProjection[resampler]|Linear[resampler.proj_out]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2293|forward|2309|matmul_218aten__view_tm1"(#loc565))
#loc1163 = loc("3215|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2250|add_421aten__add_decomp_matmul"(#loc566))
#loc1164 = loc("3215|IPAdapterPlusImageProjection[resampler]|IPAdapterPlusImageProjectionBlock[resampler.layers[3]]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2245|forward|2250|add_421aten__add_decomp_add"(#loc566))
#loc1165 = loc("3218|IPAdapterPlusImageProjection[resampler]|Linear[resampler.proj_out]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2293|forward|2309|add_422aten__add_decomp_matmul"(#loc10))
#loc1166 = loc("3218|IPAdapterPlusImageProjection[resampler]|Linear[resampler.proj_out]|/usr/local/lib/python3.11/dist-packages/diffusers/models/embeddings.py:2293|forward|2309|add_422aten__add_decomp_add"(#loc10))
